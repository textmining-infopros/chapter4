DESIDOC Journal of Library & Information Technology, Vol. 31, No. 6, November 2011, pp. 469-479
© 2011, DESIDOC

Evaluation of Usage of University Websites in Bangladesh
Anwarul Islam* and Keita Tsuji**
*Dept of Information Science & Library Management, University of Dhaka, Bangladesh-1000
**Graduate School of Library, Information and Media Studies, University of Tsukuba, Ibaraki-ken 305-8550, Japan

ABSTRACT
The study evaluates some selected university websites in Bangladesh from the usability perspectives.
Two online automated tools, namely, html toolbox and web page analyser were used along with a questionnaire
directed towards users of these websites. Tools were used to measure the websites’ internal attributes which
can not be perceived by the users such as html code errors, download time, and size of the html pages. The
questionnaire was developed and designed based on the 23 usability criteria divided into five categories. Each
category deals with one usability aspect. The study showed that users are not satisfied by overall usability
level of these websites and few of them are satisfied with the available features. However, there are some
weaknesses in some aspects of the design, interface, and performances. Websites’ internal features are
identified and suggestions are provided in the study to enhance the usability of these websites.
Keywords: Usability, web page analysis, website, internet, university websites

1. INTRODUCTION
The first electronic web service of the last century
have spread across the globe in various shapes and
changing the faces of many organisations. The new erevolution is not only reducing the global divide but also
transforming societies into knowledge-based society all
over the world1. Shortly after the commercialisation of the
internet, the multimedia component of the internet (web)
experienced the phenomenal growth. As a part of this
growth, businesses and individuals raced to place web
pages and content on the web2. Recently, a proliferation of
electronic websites with a tremendous amount of
information either with high quality, or with low quality, as
well as sites that are outright misleading are seen3, 4. The
explosion of the web has determined the need of
measurement criteria to evaluate the aspects related to
the quality in use, such as usability and accessibility of a
web application. The objective is to make the website
useful, profitable, user linkable, and accessible5.
Awareness of quality issues has recently affected every
industrial sector6. A university with a website that is
difficult to use and interact can make the university
position lower. Therefore, it is important for any
organisation to have the ability to make an assessment of
the quality of their e-services to improve their offerings
over time and benchmark against competitors and the
best practices in any industry7. The web is playing a
dynamic role in diverse application domains such as
Received on 31 March 2011; Revised on 17 May 2011

business, education, industry, and entertainment. The
present study focuses on usability of some academic
university websites in Bangladesh. Recently, more
universities in Bangladesh are creating their own web
pages to create awareness and promoting university
services to the user community. As a result, there are
increasing concerns about the ways in which websites
are developed and the quality delivered.

2. USABILITY OF WEBSITES: BANGLADESH
PERSPECTIVES
Developing a website should be passed through
several design guidelines to ensure that the website can
achieve the purposes and goals intended to be
accomplished. Additionally, an organisation’s website is a
gateway to its information, products, and services. As
such, it should ideally be a reflection of the needs of the
clients it serves. Unfortunately, website design is often
driven by technology, organisational structure, or
business objectives, rather than by users needs.
However, in recent years, website owners and developers
have gradually begun to acknowledge and address the
issue of usability.8
Based on the International Standards Organisation
(ISO) definition of usability, Powell9 defines website
usability as “the extent to which a site can be used by a
specified group of users to achieve specified goals with
469

effectiveness, efficiency, and satisfaction in a specified
context of use”. Note that this definition applies equally
well to webpage usability. It also implies that usability is
user- and task-dependent, as well as being related to how
well the user is able to accomplish what they set out to
do, how efficiently the user can do this, and how satisfied
the user is during and after the process.
Powell9 also recounts Nielsen’s10 usability guidelines
for determining the usability of a website:
Learnability—How easy it is to learn to use?
Rememberability—How easy it is to remember how to
use?
Efficiency of use—How much work does user require to
do?
Reliability in use—Does it work correctly and help user
perform tasks correctly?
User satisfaction—Is the user generally satisfied as a
result of using the site?
Likewise, McLaughin & Skinner11 break usability down
into six related but distinct components:
Checkability: The system has or allows checks that
ensure the correct information is going in and out of it.
Confidence: Users have confidence both in their
capability to use the system and in the system itself.
Control: Users have control over the operation of the
system, particularly of the information fed into and out of
the system.
Ease of use: The system is easy to use.
Speed: The system can be used quickly.
Understanding: The system and its outputs are
understandable.
Several evaluation methods have been proposed to
assess the usability of websites to suggest
enhancements in the design of websites. Some methods
are opinion of experts, while others are directed towards
users. Such evaluation methods include questionnaires
for extracting, recording, and collecting information to
measure the user satisfaction with website usability12, 13.
The usability of any website can be evaluated and
determined using usability evaluation methods and
techniques. Generally, any website should meet the
needs of its various stakeholders.14 Educational website
users are mainly concerned with the following two major
questions:
(a) Can the desired information be found easily in
website?

The university websites in Bangladesh aim at
providing up-to-date information and services to students,
instructors, academic administrators, and other users in
efficient ways. There are at present 88 public, private, and
international universities in Bangladesh. Most of them
have their own websites and 12 universities (8 private and
4 public) do not have any website15. Generally, usability
studies of websites and particularly in academic websites
are almost nonexistent. According to the Ranking Web of
World Universities16, Bangladesh University of Engineering
and Technology (BUET) was the 26th position in top 100
South Asian universities and is the best among all public
and private universities in Bangladesh.
However, global ranks of some universities in
Bangladesh are Rajshahi University (71st); American
International University, Bangladesh (83rd); East-West
University (88th); Daffodil International University (92nd);
Independent University, Bangladesh (98th); and North
South University, Bangladesh (99th) in top 100 South
Asian Universities. The research reported in this paper is
intended to point out the strength and weakness of the
usability aspects in the design of these academic
websites, including interface, performance and
effectiveness, content and organisation, and the
educational purposes.The results are supposed to draw
the attention of webmasters to overcome the limitations of
these websites and improve their efficiency. This is the
first time an effort has been made to usability analysis of
some university websites in Bangladesh. This study may
trigger more such research on this subject in Bangladesh
and beyond.

3. LITERATURE REVIEW
There are many articles that discuss the effectiveness
of websites from a usability standpoint. Many of these
studies result from a need to evaluate a webpage based
on information architecture rather than design attributes.
Most studies involve the direct observation of students’
performing a set of tasks and recording their ease or
difficulty in doing so. The majority of studies agree that
they are frustrated by confusing library terminology and
an overwhelming amount of information. The present
study focuses both the user’s point of view and used
automated tools to test usability of some academic
websites in Bangladesh. However, as the use of the web
has continued to grow, businesses have discovered that
simply having a web presence no longer guarantees that
an organisation’s site will attract visitors.2 As the
dependency on web services increases, the need to
assess characteristics with website quality and success
increases. Websites characteristics are important; they
have been a constant concern of research in different
domains and they were widely studied in the e-commerce
literature.17

(b) Can the information be found in timely manner?
470

DESIDOC J. Lib. Inf. Technol., 2011, 31(6)

Evaluations of the usability of websites have been
conducted over the years and for many domains. For
example, Akoglu18 developed a special tool for assessing
the usability of architectural department website in the
University of Istanbul. The tool consisted of two parts:
First part can be accessed by users where they visit and
answer the questions about the website, and the second
part was constructed for the use of administrator where
he/she can manage the content of the usability
evaluation. The evaluation was based on two
environments: Traditional laboratory environment and
internet environment. Battleson19, et al. focused that
usability testing is an invaluable tool for evaluating the
effectiveness and ease of use of academic library
websites. This article reviewed the major usability
principles and explores the application of formal usability
testing to an existing site at the University at Buffalo
libraries. Nielsen20 expressed that usability engineering is
the most comprehensive and practical discussion of
usability engineering and testing, covering the usability
engineering life cycle from product conceptualisation to
design and evaluation.
Kirakowski21, et al. and Kirakowski22 evaluated the
user satisfaction with usability of five websites based on a
questionnaire method. The authors developed a new
questionnaire (named WAMMI) for the evaluation. The
questionnaire showed that the evaluation of user
satisfaction contributes to the successful development of
websites. Harms & Schweibenz23 used a combination of
two methods of usability engineering for the web, namely,
the heuristics method and the laboratory-test method with
actual users involved in evaluating the usability of the
Saarland Museum’s website. The authors claim that this
combination of methods provides good results, but it is
costly in terms of time and resources. The results
obtained from the evaluation led to the redesign of the
Saarland Museum’s website. With regard to academic
websites, the research conducted by a group from the
University of Maryland performed a usability evaluation for
the master of information management (MIM) (part of the
College of Information Studies at the University of
Maryland, College Park) programme website to know
whether their website meets the needs of its users. The
methods focused on conducting user testing tasks and
performed heuristics evaluation for these tasks. A set of
recommendations were provided to guide future redesign
of the website24.
A similar case study was conducted by the Website
Usability Testing Center at Wisconsin-Stout University to
evaluate the usability of their University’s website. The
researchers used qualitative testing criteria such as
navigation times through subject evaluations to assess
the usability of the site. The study showed that the
website suffers from several problems including website
specific jargon, unorganised link patterns, confusing
search engines, and poorly emphasised information.
DESIDOC J. Lib. Inf. Technol., 2011, 31(6)

Based on the results of the evaluation the authors
proposed a number of recommendations in order to
improve and unify the university website25.
The research by Chiew & Salim26 focused on
developing a web-based tool (called WEBUSE) which
consists of 24-questions for evaluating the usability of
websites. The report generated by the tool indicates how
good is the website with respect to usability. The
researchers claim that WEBUSE is suitable for the
evaluation of all types of websites and for any domain. The
tool can assist webmasters to improve their websites
based on the response provided by the visitors of the
intended websites.
Corry27 , et al. conducted a usability evaluation of an
existing Midwestern University Website. An analysis was
conducted to restructure the information contained in the
current Website; a prototype was developed and tested
against the existing site. Usability was based on the
ability of subjects (such as students, parents, and
faculty) to quickly and accurately locates answers to a
set of questions. While the study worked well, the metrics
used to measure usability were limited to task completion
time and the number of user errors.
Educational websites were also studied from many
different perspectives. Zhang & Dran28 developed a
theoretical framework for evaluating website quality from a
user satisfaction perspective. Others concentrated on
some specific features of websites. For example,
Lautenbach29, et al. developed a framework to measure
usability of websites, while Yoo & Jin30 investigated and
evaluated the design of university websites. Other
researchers, while assessing the university websites took
in consideration other features.
Pinto31, et al. conducted a study on information
provided by Spanish university websites on their
assessment and quality processes. They analyse and
evaluate the information provided by Spanish public
universities on the web about their assessment and
quality processes with the aim of detecting aspects for
improvement and identifying best practices in universities
that could act as a benchmark for the rest of the sector.
The strengths and weaknesses of institutional websites
were analysed at both individual level and as a whole; the
possible relation between website quality and the
characteristics of the universities was also examined.

4. RESEARCH OBJECTIVES
The specific objectives of the study were to:
•
•

identify criteria for the evaluation of academic
websites,
investigate usability of some academic websites in
Bangladesh with the identified criteria for the
verification of validity, reliability, and usefulness, and
471

•

find out the weakness of the university websites and
give suggestions for improving the usability.

5. METHODOLOGY
In this study, two evaluation methods were used:
Questionnaire and automated tools. Secondary sources
of information were gathered through a comprehensive
review of the relevant literature available on the internet.
5.1 Questionnaire-based Evaluation Method
In order to select the appropriate website evaluation
usability criteria for the questionnaire-based evaluation
method, the usability aspects in terms of user
satisfaction, readability, navigation, and other aspects
related to the websites of universities in Bangladesh were
identified and analysed. The questionnaire was divided
into two sections. The first section addressed the
characteristics of participants, including: university name,
internet and computer usage, age of participant, and the
access frequency of participant university website. The
second section included thirty questions that were used
to evaluate the usability of some academic websites in
Bangladesh. The questions were classified into five
categories (Appendix 1):

depend on how the website has been designed and
developed36.
Table 1. List of selected university websites in Bangladesh
S. No.

Name of university

1.

Bangladesh University of Engineering & Technology

2.

Dhaka University

3.

Rajshahi University

4.

Shahjalal University of Science & Technology

5.

Bangabandhu Sheikh Mujib Medical University

6.

Bangladesh Agricultural University

7.

University of Chittagong

8.

Dhaka University of Engineering and Technology

9.

Khulna University of Engineering and Technology

10.

National University

11.

ASA University

12.

Bangladesh University of Business and Technology

13.

BRAC University

14.

Daffodil International University

15.

East West University

16.

North South University

17.
18.

Stamford University, Bangladesh
United International University

19.

Independent University, Bangladesh

20.

University of Liberal Arts, Bangladesh

(1) Content, organisation, and readability (Feature 1)
(2) Navigation and links (Feature 2)

Table 2. Usability evaluation features
S. No.

Usability features

(3) User interface design (Feature 3)

1.

Display space

(4) Performance and effectiveness (Feature 4)

2.

Scroll left and right

(5) Educational information (Feature 5)
Table 1 gives a list of selected universities whose
websites are evaluated. After an extensive study22, 27, 32-35 of
related resources 23 websites usability evaluation criteria
were identified as shown in Table 2.
5.2 Online Automated Tools
In another part of the evaluation, two automated
evaluation tools were used to assess website usability,
namely HTML Toolbox and Webpage Analyser. Since
Websites are dynamic in nature, each item noted on the
matrix was analysed within a day or so. Changes and new
pages that appeared after the date of analysis were not
included in the study. The first part of evaluation
methodology was intended to focus on how to evaluate
usability of the academic websites of the universities in
Bangladesh from the user’s perspective. However,
usability evaluation methods that are conducted by
human intervention (users and experts) can assess only
the external attributes of the website (such as readability
of the contents of the website) rather than its internal
attributes (such as textual duplicates of links embedded
in images). External attributes depend on the website and
its usage, while the internal attributes of the website only
472

3.

Accessibility

4.

Distracting or irritating elements

5.

Orphan page

6.

Placement and content of site map

7.

Information search

8.

Link colours

9.

Up-to-date information

10.

Download time

11.

Back button

12.

Open new browser windows

13.

Respond according to users’ expectations

14.

Web advertising

15.

Follow real world conventions

16.

Hyperlink description

17.

Consistent design

18.

Use of colour

19.

Organisation of information

20.

Navigational aids

21.

Registration information

22.

Faculties information

23.

Instructors information

These internal attributes of the website can be
assessed and evaluated using automated tools. In this
part of the evaluation, two automated online tools were
DESIDOC J. Lib. Inf. Technol., 2011, 31(6)

used: Web Page Analyser37 and HTML Toolbox38. The
internal attributes that were measured include: Total
number of HTML files on the page; total number of objects
on the pages; total number of images; total size of
images; browser’s compatibility; and total number of
broken and bad links

Statistical Package for Social Sciences (SPSS)
software was used to compile and analyse the surveyed
data. In general the users of these universities have
access to the internet through central library, computer
centre, and departments. Hence, they were asked to
indicate the location from which they prefer to access the
internet. Majority of the students (75 %) had internet
access at the central library and other responded (25 %)
refers to at home, cyber cafes, and others. Ages of most
participants ranged between 18 and 25 years. All the
respondents were graduate and from different disciplines.
As of gender, 73 per cent of the respondents were males
and 27 per cent were females.

5.2.1 Web Page Analyser
Web Page Analyser is a free web-based tool provided
by Website Optimisation. It can calculate page size (html
page size, total image size, and total image number),
composition, and download time for website. In this study,
the following attributes were measured using this tool:
•
•
•
•
•

Total number of html files
Total html page size
Total size of images
Total number of images
Total number of cascading style sheet (CSS) files

•

Total size of CSS files

Table 3 presents a summary of the results obtained
from the questionnaire-based evaluation method. It
reveals that the summary of the strongly dissatisfied,
dissatisfied, fair, agree and strongly agree features of the
websites by the users. Table 3 shows the five usability
features which are mainly related to the external
attributes of the academic web sites. Each of the features
focus different attributes of the website including
academic information, content, services, effectiveness
and decoration. The usability feature Educational
information (Feature 5) exhibits the highest evaluation
value as (40.9 %) students are strongly agree with the
features which is followed by User interface design (18.4
%) (Feature 3), Navigation and links (16.9 %) (Feature 2),
Content, organisation and readability (11.3 %) (Feature 1)
and the lowest one is Performance and effectiveness
(9.0 %) (Feature 4). According to the 5-item scale the
overall usability value for the websites is about 40.2 per
cent which are strongly dissatisfied and 19.3 per cent are
strongly agree with the features. In comparison, about
17.7 per cent of the respondents were not satisfied, 41.1
per cent judged these websites as being fair and 20.1 per
cent are agreed with respect to usability. The overall gap
sizes are high indicating that the website’s features are
not close to meeting users desired quality in all areas.

5.2.2 HTML Toolbox
HTML Toolbox is available from NetMechanic Inc. It
identifies site problems and automatically repairs HTML
code for the websites. This tool can assist in the
evaluation process by measuring and identifying some of
the internal attributes of a website. The internal attributes
that were measured using this tool include: download
time; HTML check and repair; and browsers compatibility.

6. RESULTS AND DISCUSSIONS
6.1 Results of Questionnaire-based Website
Evaluation
For this survey, in early December 2010, some of the
graduate students of selected universities were contacted
randomly through e-mail and given an explanation of the
study. Twenty university websites were selected for this
purpose. To maximise the response rate, students were
briefed that their responses would be completely
anonymous and the data would only be used for the
purposes of this study. A total of 200 users representing
20 different universities have participated in the e-mailbased questionnaire evaluation method and response rate
was 75 per cent (150).

6.2 HTML Tool Box
In this part of the evaluation, two automated evaluation
tools were used to assess website usability. The results
obtained from HTML Toolbox are presented in Table 4 and
those of Web Page Analyser are given in Table 5.

Table 3. Evaluation of websites by users
Features
Strongly

dissatisfied

Usability scale rate (%)
Dissatisfied
Fair

Agree

Strongly agree

Content, organisation, and readability

45.0

16.7

6.1

20.9

11.3

Navigation and links

33.3

22.2

8.3

19.2

16.9

User interface design

29.0

13.1

8.1

32.4

18.4

Performance and effectiveness

36.8

20.9

12.9

17.5

9.0

Educational information

56.9

15.9

5.7

10.2

40.9

Total feature

40.2

17.7

41.1

20.1

19.3

DESIDOC J. Lib. Inf. Technol., 2011, 31(6)

473

Table 4. Results obtained from HTML toolbox
S. No.

University

website

Elements to be measured
Load time (28 Kbps)(s)

HTML check errors

1.*

www.buet.ac.bd

65.57

20

8

2.

www.univdhaka.edu

71.64

28

20

3.

www.ru.ac.bd

12.70

7

14

4.

www.sust.edu

4.78

3

8

5.

www.bsmmu.org

734.01

26

12

6.

www.bau.edu.bd

680. 50

18

25

7.

www.cu.ac.bd

343.98

17

29

8.

www.duet.ac.bd

78.77

25

32

9.

www.kuet.ac.bd

298.79

9

8

10.

www.nu.edu.bd

29.60

16

10

11.

www.asaub.edu.bd

36.49

11

10

12.

www.bubt.edu.bd

50.56

9

13

13.

www.bracuniversity.net

28.51

34

5

14.

www.daffodilvarsity.edu.bd

26.36

25

31

15.

www.ewubd.edu

1.02

0

0

16.

www.northsouth.edu

163.63

55

21

17.

www.stamforduniversity.edu.bd

58.63

16

16

18.

www.uiubd.com

67.22

2

16

19.

www.iub.edu.bd

61.19

5

11

20.

www.ulab.edu.bd

15.29

17

24

Average

107.43

16.3

15.65

Browser

compatibility

problems

Source: www.netmechanic.com (Browsed and calculated on 5 March 2011)
Table 5. Results obtained from Webpage Analyser
S. No.

University website

Elements to be measured
THF

THS
(K)

TIS
(K)

TNI

TCS

TCSSS
(K)
20

1.*

www.buet.ac.bd

1

50

100

26

2

2.

www.univdhaka.edu

1

22.88

227

32

1

2

3.

www.ru.ac.bd

1

42

168.64

64

9

25.04

4.

www.sust.edu

1

13.28

112

16

1

8

5.

www.bsmmu.org

28.41

2535

11

2

12.76

6.

www.bau.edu.bd

1

22.12

2334

52

3

28.13

7.

www.cu.ac.bd

1

23.59

1182.53

11

1

0

8.

www.duet.ac.bd

1

16.50

253

20

2

7.48

9.

www.kuet.ac.bd

1

42

50

15

6

0

10.

www.nu.edu.bd

1

25.48

80

14

0

0

11.

www.asaub.edu.bd

1

17.76

223

15

2

11.75

12.

www.bubt.edu.bd

1

19.90

238

21

2

5.85

13.

www.bracuniversity.net

1

25

64

47

2

3.90

14.

www.daffodilvarsity.edu.bd

1

89.32

326

59

4

7.08

15.

www.ewubd.edu

1

105 Bytes

0

0

0

0

16.

www.northsouth.edu

1

110

126

21

2

8

17.

www.stamforduniversity.edu.bd

1

32.89

129

65

6

109

18.

www.uiubd.com

1

95.93

64.87

35

3

68.37

19.

www.iub.edu.bd

1

127

636.76

131

14

63.68

20.

www.ulab.edu.bd

1

154

64

3

1

1

Average

1

53.15

445.69

32.9

3.15

19

Source: www.websiteoptimisation.com (Browsed and calculated on 12 March 2011) (All the result shows in bytes and converted in KB)
Note: THF: Total # of HTML file, THS: Total HTML page size (KB), TIS: Total size of images (KB), TNI: Total # of images, TCSS: Total # of CSS
files, TCSSS: Total size of CSSS files (KB)
474

DESIDOC J. Lib. Inf. Technol., 2011, 31(6)

Table 4 shows that the average download time for all
websites is 107.43 second, and the average html check
errors are 16.3, and the average browsers compatibility
problems are 15.65. Each of the three evaluation
measures is described as:

6.3.2 Average Size of HTML Page

6.2.1 Load Time

6.3.3 Average Size of Images

Page load time depends on several factors such as:
the size of the HTML file and any frames it references, the
number and size of the images, the use of HEIGHT and
WIDTH attributes with image and table tags, the number
of servers that must be contacted to download files and
images, and the speed of the user’s modem. For the
websites covered in this study, the average download time
was approximately 107.43 s which exceeds 15 s, the
recommended acceptable level. Very few of the
universities have standard loading time, namely, Shahjalal
University of Science & Technology (SUST), East West
University (EWU), and University of Liberal Arts,
Bangladesh (ULAB). Others universities might be
attributed the large number and size of images some of
these websites contain.
6.2.2 HTML Check Errors
These errors are places where the web page does not
follow the rules for proper HTML coding. These problems
may cause the page to display incorrectly under different
browsers. As Table 4 indicates, there were 16.3 html code
errors in the websites covered in this study. Some of
these problems represent places where HTML tags or
attributes are used that does not follow the latest HTML
standard and may not be supported by all browsers.

The average web page size is 53.15 KB (54425.6
bytes) which will load in 23.93 seconds on a 56 Kbps
modem as show in Table 4.

The average image size is 445.69 K (456386.56
bytes) which is over the acceptable threshold, which is
100K. The tool issued a warning for such a value.
6.3.4 Average Number of Images
The average number of images is 32.9 which is not
reasonable. Hence, the tool issued a warning for such a
value.
6.3.5 Average Number of CSS Files
The average number of external CSS files is 3.15.
Because external CSS files must be in the HEAD of an
HTML document; these must load first before any body
content displays. Although they are cached, CSS files
slow down the initial display of the web page. The tool
indicated that such a value is appropriate.
6.3.6 Average Size of CSS Files
The average size of external CSS files is 19 K (19456
bytes) which is less than the threshold value (i.e., 4080
bytes). This will fit into three higher-speed TCP-IP
packets. The tool indicated that such a value is
appropriate.

7. FINDINGS AND RECOMMENDATIONS
6.2.3 Browsers Compatibility Problems
The measure, as assessed by the tool, shows how
well the web page is displayed by different browsers. As
Table 4 shows, 15.65 compatibility problems were found
in the studied websites. This number represents
problems which affect the website visitors.

In this study, two evaluation approaches were used:
questionnaire method and online automated tools. The
results obtained from both approaches showed that the
usability of the university websites in Bangladesh are not
satisfied or students do not agree with the features. Study
findings and recommendations are:

6.3 WebPage Analyser of University Websites

•

In automated tool box, this study counted that the
average download time was approximately 107.43 s
which exceeds the standard levels. In order to improve
this, it needs to reduce the number of servers
connected to the sites and reduce some of the
images that occupy large places.

•

Errors are places where page does not follow the
rules for proper HTML coding. These problems may
cause page to display incorrectly under different
browsers. There were 16.3 html code errors in the
websites covered in this study and it needs to use
good coding practices. Compatibility problems are
places where it uses an HTML tag or attribute that is
not part of the HTML 4.0 standard and may not be

WebPage Analyser is used to examine the internal
attributes of the websites including HTML page sizes,
total number of images, total number of HTML files and
other relevant items of websites. Table 5 summarises the
result obtained from the WebPage Analyser.
6.3.1 Average Number of HTML Files
The average number of HTML files for 20 web pages
(including the main HTML file) is 1 which most browsers
can multithread. Minimising HTTP requests is a key for
website optimisation. The tool used indicated that such a
value is appropriate.
DESIDOC J. Lib. Inf. Technol., 2011, 31(6)

475

supported by all browsers. The best way to view web
site in various browsers is to download and install
each one. However, not all may be compatible with
operating system. Some of the tools, namely,
Browser
Shots,
CrossBrowserTesting.Com,
BrowserCamp and Adobe Browser Lab allow to view
site in different web browsers, just as they would
actually appear.

•

The number of HTML files is appropriate for these
websites and the total size of this HTML file is
54425.6 bytes, which is more than 50 K and not
appropriate. Reducing photos, mp3, video, and web
pages may make the size of HTML standard.

•

As the size of images of these websites is not
acceptable consider different graphic formats to
achieve smaller file sizes (from JPEG to PNG for
example). Finally, substitute CSS techniques for
graphics techniques to create coloured borders,
backgrounds, and spacing.

•

•

•

•

476

The average number of images on these pages is 32.9
and there is a need to reduce this to a more
reasonable number. Recommend combining,
replacing, and optimising graphics. Replace graphic
rollover menus with CSS rollover menus to speed
display and minimise HTTP requests. Consider using
CSS sprites to help consolidate decorative images.
Finally, consider optimising parallel downloads by
using different hostnames to reduce object overhead.
The average number of external CSS files on this
page is 3.15 and is appropriate. Because external
CSS files must be in the HEAD of HTML document,
they must load first before any BODY content
displays. The average size of external CSS files is
19456 bytes, which is above 8 K and less than 20 K.
For external files, ideally keep them less than 1160
bytes to fit within one higher-speed TCP-IP packet (or
an approximate multiple thereof). Consider optimising
CSS and eliminating features to reduce this to a more
reasonable size.
The study covered various aspects of usability, some
of which have been meeting the user expectations. It
has been pointed out that some features of evaluation
have satisfied the users but most of the users
(40.19 %) are strongly dissatisfied with the features of
these websites. This finding suggests that website
authority needs to focus on these categories for better
usability of these websites by the users.
Result of the content, organisation, and readability;
navigation and links; user interface design;
performance and effectiveness, and educational
information categories are not satisfactory at the
user’s point of view of these university websites. The
questionnaire-based evaluation findings reveals that

these websites should be designed based on more
content; incorporate more educational information;
and priority should given for designing user friendly
websites.

8. CONCLUSIONS
The present study showed in general that usability
features of the university websites in Bangladesh do not
have good features. At user end, it failed to meet the user
demands and expectations. At the same time web-based
diagnosis tools reveal that internal qualities of these
websites are not ideal. University websites contain
educational features which aim to provide the information
and services to its stakeholders in different ways. To
achieve these purposes, universities websites design
should go through several design guidelines to ensure
that users are more satisfied with the services provided by
these websites.
By evaluating the usability aspects of these websites
we can improve the usability of these websites.
Universities webmaster should pay more attention to the
universities web design and content to make them more
attractive to the user community. This study has been
exploratory and there is a scope for future usability
research in this area.
It would be useful to carry out a more comprehensive
study covering more institutions and more diagnosis tools
to measure the usability of the university websites in
Bangladesh. The present study findings open the door to
further studies of this area in future.

ACKNOWLEDGEMENTS
Authors would like to express their gratitude to all the
students of the selected universities who participated in
different sessions. We would also like to thank the
professionals and some faculty members of Information
Science and Library Management, University of Dhaka,
for their assistance and guidance with this paper.

REFERENCES
1.

Hasan, L. & Abuelrub, E. Assessing the quality of
web sites. Appl. Comp. Inform., 2011, 9, 11–29.

2.

Shacklett, M. Gauging web site performance. Credit
Union Maga., 2001, 67(6), 60-62.

3.

Fogg, B.J.; Marshall, J.; Laraki, O.; Osipovich, A.;
Varma, C.; Fang, N.; Paul, J.; Rangnekar, A.; Shon,
J.; Swani, P. & Treinen, M. What makes web sites
credible? A report on a large quantitative study. Comp.
Human Interaction, 2001, 3(1), 61–68.

4.

Heimlich, J. Evaluating the content of web sites.
Environmental Education and Training Partnership
DESIDOC J. Lib. Inf. Technol., 2011, 31(6)

Resource Library, Ohio State University Extension,
USA, 1999.

20. Nielsen, J. Usability engineering. Academic Press,
Boston, 1993.

5.

Signore, O. A comprehensive model for web sites
quality. In Proceedings of the 7th IEEE International
Symposium on Web Site Evolution (WSE’05), 2005.

6.

Mich, L.; Franch, M. & Gaio, L. Evaluating and
designing web site quality, feature article. IEEE
Multimedia, IEEE Computer Society, USA, 2003.

21. Kirakowski, J.; Claridge, N & Whitehand, R. Human
centered measures of success in web site design. In
Proceedings of 4th Conference on Human Factors and
the Web, USA, 1998.

7.

8.

9.

Barnes, S. & Vidgen, R. An integrative approach to
the assessment of e-commerce quality. J. Electr.
Commerce Res., 2002, 3(3), 114-27.
Pierce, K.R. Usability review of the Harvard Edu Web
Site.
University
of
Texas,
2005
http://
works.bepress.com/kenneth_pierce/4 (accessed on
9 March 2011)
Powell, T. A web design: The complete reference.
Osborne/McGraw-Hill, Berkeley, CA, 2000.

10. Nielsen, J. Designing web usability: The practice of
simplicity. New Riders Publishing, Indianapolis, IN,
2000.
11. McLaughin, J. & Skinner, D. Developing usability and
utility: A comparative study of the user of new IT.
Technol. Anal. & Strat. Manag., 2000, 12(3), 413-23.
12. Lewis J.R IBM computer usability satisfaction
questionnaires: Psychometric evaluation and
instructions for use. Inter. J. Human-Comp.
Interaction, 1995, 7(1), 57-78
13. Perlman, G. Web-based UI questionnaire tool. Online
Computer Library Center, Ohio, USA, 1998.
14. Thompson, T.; Hourclé, J. & Ma, L. Website usability
evaluation. University of Maryland, USA, 2005
15. University Grants Commission (UGC) list of universities
in Bangladesh. 2011, http://www.ugc.gov.bd/ (accessed
on 10 March 2011).
16. Ranking web of world universities, rank data: Top
South Asia 2011, http://www.webometrics.info/
top100_continent.asp?cont=S_Asia (accessed on 27
February 2011)
17. Hasan, L.; Abuelrub, E. Criteria for evaluating quality
of websites. In Proceedings of the 6th IBMA
International Conference on Managing Information in
Digital Economy, Germany, 2006.
18. Akoglu, C. Usability evaluation: A method for a
specific field. Department of Communication Design,
Yildiz Technical University, Istanbul, Turkey, 2002.
19. Battleson, B.; Booth, A. & Weintrop, J. Usability
testing of an academic library web site: A case study.
J. Acad. Librarianship, 2001, 27(3), 188-98.
DESIDOC J. Lib. Inf. Technol., 2011, 31(6)

22. Kirakowski, J. Questionnaire in usability engineering:
A list of frequently asked questions. Ed. 3. Human
Factors Research Group, Ireland, 2000.
23. Harms, I. & Schweibenz, W. Evaluating the usability
of a museum website. University of Saarland,
Saarbrücken, Germany, 2001.
24. Nielsen, J. How to conduct a heuristic evaluation,
2001, www.usit.com/papers/heuristic/ (accessed on 5
March 2011).
25. Smith, M.; Rougier, B.; Hamman, D.; McKenzi, J.;
Johnston, B. & Maylath, B. Website usability
evaluation of uwstout.edu. Website Usability Testing
Center, The University of Wisconsin, Stouta, 2001.
26. Chiew, K.T. & Salim, S.S. WEBUSE: Website
usability evaluation tools. Malaysian J. Comp. Sci.,
2003, 16(1), 47-57.
27. Corry, D.; Frick, W. & Hansen, L. User centered
design and usability testing of a web site: An
illustrative case study. Edu. Technol. Res. Dev., 1997,
45(4), 65-76.
28. Zhang, P. & Dran, G. Expectations and ranking of
website quality features: Results of two studies on
user perceptions. In Proceedings of the 34th Hawaii
International Conference on System Sciences, 2001.
29. Lautenbach, M.A.E.; Schegget, I.S.; Schoute, A.M.
& Witteman, C.L.M. Evaluating the usability of web
pages: A case study, 2006. http://www.phil.uu.nl/
preprints/ckipreprints/PREPRINTS/preprint011.pdf.
30. Yoo, S. & Jin, J. Evaluation of the home page of the
top 100 university web sites. Academy Info. Manage.
Sci., 2004, 8(2), 57–69.
31. Pinto, M.; Guerero, D. & Fernández-ramos, A.
Information provided by Spanish university websites
on their assessment and quality processes.
Scientometrics, 2009, 8(1), 265-89.
32. Paterno, F. & Leporini, B. Testing the effects of web
usability criteria for vision impaired users. ISTI-C.N.R,
Italy, 2004.
33. Granic, A.; Glavinic, V. & Stankov, S. Usability
evaluation methodology for web-based educational
systems. Electrical Engineering and Computing,
Zagreb, Croatia, 2004.
477

34. Sinha, R.; Hearst, M. & Ivory, M. Content or graphics?
An empirical analysis of criteria for award-wining
websites. University of California, Berkley, 2001.
35. Marsico, M. & Levialdi, S. Evaluating web sites:
Exploiting user’s expectations. University of Rome,
Italy, 2003.
36. Brajnik, G. Automatic web usability evaluation: What
needs to be done? In Proceedings of 6th Conference
on Human Factors and the Web, Austin TX, 2000.
37. Website Optimisation Inc. Web Page Analyser, 2007,
www.websiteoptimisation.com/services/analyse
(accessed on 10 March 2011)
38. NetMechanic Inc. HTML Toolbox, 2007. http://
myhosting.com/NetMechanic/htmltoolbox.aspx
(accessed on 10 March 2011).

478

About the Authors
Md Anwarul Islam obtained his BA (Hons), MA and
MPhil in Information Science & Library Management from
the University of Dhaka, Bangladesh. He had worked as a
project member of Community Information Center (CIC)
and is presently working as Lecturer and Student Adviser
(Information Science & Library Management), University
of Dhaka. His areas of interest are webometrics, usability
study, information literacy, e-learning in LIS education,
developing knowledge, and skills of digital librarianship.
Dr Keita Tsuji obtained his PhD from University of Tokyo
in 2003 and is presently working as Associate Professor
in University of Tsukuba, Japan. His areas of interest
include knowledge of web, method for library education,
and knowledge collection and management.

DESIDOC J. Lib. Inf. Technol., 2011, 31(6)

Appendix 1
Questionnaire on Usability Evaluation of the University Websites in Bangladesh
Usability features

Corresponding statement

SD

Questions for
evaluating content,
organisation and
readability
(Feature 1)

a. This website contains most of my important topics and are up-to-date
b. I can easily find what I want at this website
c. The content of this website is well organised
d. Easy to read website content
e. Language is comfortable and familiar
f. Need not scroll left and right at this website.

Questions for
evaluating navigation
and links
(Feature 2)

a. I can easily know where I am at this website
b. This website provides useful cues and links
c. It is easy to move around at this website by using the links or back button of the browser
d. website links are well maintained and updated
e. The website does not open too many new browser windows when I am moving around
f. Placement of links or menu is standard throughout the website and I can recognise them

Questions for
evaluating user
interface design
(Feature 3)

a. This website’s interface design is attractive
b. I am comfortable with the colours of website
c. This website contains no feature that irritates me such as blinking text and looping animations
d. This website has a consistent feel and look
e. It does not contain too many advertisements
f. The design of the website makes sense and it is easy to learn how to use it

Questions for
evaluating
performance and
effectiveness
(Feature 4)

a. Need not wait too long to download a file
b. I can easily distinguish between visited and not visited links
c. I can access this website most of the time
d. Website responds to my actions as expected
e. It is efficient to use this website
f. This website always provides clear and usefulmessages when I do not know how to proceed

Questions for
evaluating education
purpose
(Feature5)

a. I can easily access the registration page and I can easily register for semester
b. When I need to register, the website providesinformation about what the courses are
offered and who is teaching the courses
c. This website is regularly updated in terms ofpersonnel and course
information in order to keep their information up-to-date
d. I can easily contact with my instructors because it gives information
about instructors’ office location and hours, and e-mail addresses
e. This website suffers from problems during registration process for students
f. I know who I can contact for more informationabout anything in this website

D

F

A

SA

SD-strongly dissatisfied; D- Disagree; F-Fair; A-Agree; SA- Strongly agree

DESIDOC J. Lib. Inf. Technol., 2011, 31(6)

479

