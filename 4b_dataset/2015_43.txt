A METHODOLOGY FOR SELECTING THE PREFERRED SYSTEM OF
SYSTEMS (SOS) DURING SOS MISSION
PLANNING AND ACQUISITION

Approved by:

_________________________________
Dr. Jerrell T. Stracener
_________________________________
Dr. Mathew Durchholz
_________________________________
Dr. Micheal Hahsler
_________________________________
Dr. Eli Olinick
_________________________________
Dr. Stephen A. Szygenda

A METHODOLOGY FOR SELECTING THE PREFERRED SYSTEM OF
SYSTEMS (SOS) DURING SOS MISSION
PLANNING AND ACQUISITION

A Dissertation Presented to the Graduate Faculty of
the Bobby B. Lyle School of Engineering
of
Southern Methodist University
in
Partial Fulfillment of the Requirements
for the Degree of
Doctor of Philosophy
with a
Major in Systems Engineering
By
Behrokh Mokhtarpour
(B.S.I.E., Mazandaran University of Science and Technology, 2004)
(M.S.I.E., K.N. Toosi University, 2008)
August 4, 2015

ProQuest Number: 3719653

All rights reserved
INFORMATION TO ALL USERS
The quality of this reproduction is dependent upon the quality of the copy submitted.
In the unlikely event that the author did not send a complete manuscript
and there are missing pages, these will be noted. Also, if material had to be removed,
a note will indicate the deletion.

ProQuest 3719653
Published by ProQuest LLC (2015). Copyright of the Dissertation is held by the Author.
All rights reserved.
This work is protected against unauthorized copying under Title 17, United States Code
Microform Edition © ProQuest LLC.
ProQuest LLC.
789 East Eisenhower Parkway
P.O. Box 1346
Ann Arbor, MI 48106 - 1346

Copyright 2015
Behrokh Mokhtarpour
All Rights Reserved

iii

Mokhtarpour, Behrokh

B.S.I.E., Mazandaran University, 2004
M.S.I.E., K.N Toosi University, 2008

A Methodology for Selecting The Preferred System of
Systems (SoS) During SoS Mission
Planning and Acquisition
Advisor: Dr. Jerrell T. Stracener
Doctor of Philosophy conferred August 4, 2015
Dissertation completed April 27, 2015

System of systems (SoS) has been receiving increased attention recently. SoS raise
unique development challenges, one of which is the process and methods for selecting the
“right mix” of systems for an SoS to meet operational capability and program
requirements. This dissertation presents a general methodology for generating feasible
SoS solutions and selecting the preferred one for a specific mission. An example of an
SoS mission is a response to a natural crisis or space missions, which involves multiple
systems to accomplish an assigned mission goal.
The methodology presented provides a basis for decision making during planning and
acquisition of a new capability through an SoS approach using existing systems and
enables comparison of candidate SoS solutions based on factors relating to: time to
achieve initial operating capability (IOC), mission effectiveness, capability sustainability
and affordability.
This methodology provides a more holistic approach over current methods for
selecting the preferred SoS solution. The value of this methodology is in the up front
iv

planning for a new capability and SoS acquisition before the actual system selection
starts. A systems engineering-based approach is employed for the development of the
methodology.

v

TABLE OF CONTENTS
Chapter 1: Introduction........................................................................................................ 1
1.1. SoS Definitions and Types ....................................................................................... 1
2.5. SoS Applications ...................................................................................................... 4
1.2. The Need for Developing SoS-Related Methods and Techniques ........................... 6
1.3. Dissertation Objective ............................................................................................ 10
1.4. Summary of Dissertation Contributions ................................................................. 11
1.5. Dissertation Organization ....................................................................................... 13
Chapter 2: Systems engineering process in methodology development ........................... 14
2.1. Sources of Complexity in System-of-Systems Development ................................ 14
2.2. Application of Systems Engineering ...................................................................... 16
2.3. Methodology Development Process ....................................................................... 20
2.4. Summary................................................................................................................. 22
Chapter 3: Methodology Concept Development and requirements definition .................. 23
3.1. Current State of Research on Methods for Selection of SoS Systems ................... 23
3.2. Statement of Need and Response to Need .............................................................. 24
3.3. Methodology Requirements Development for Selecting the Preferred SoS .......... 26
3.4. Summary................................................................................................................. 31
Chapter 4: Methodology Framework Overview................................................................ 33
4.1. Selection of Decision Attributes ............................................................................. 33
4.2. Methodology Key Ground Rules, Assumptions and Considerations .................... 35
4.3. Overview of Methodology Framework .................................................................. 36
4.4. Summary................................................................................................................. 47
Chapter 5: Estimation of decision attributes ..................................................................... 49
5.1. SoS Life Cycle ........................................................................................................ 50
5.2. SoS Time to Initial Operating Capability (IOC) .................................................... 52
5.2.1. SoS Time to Initial Operating Capability (IOC) Definition ............................ 52
5.2.2. SoS Time to Initial Operating Capability (IOC) Estimation ........................... 52
5.3. SoS Capability Cost ................................................................................................ 53
5.3.1 SoS Capability Cost Definition ........................................................................ 53
5.3.2. SoS Capability Cost Estimation Approach...................................................... 54
5.3.3. SoS Capability Cost Elements and Structure .................................................. 55
5.3.4. Evaluation of Current Cost Estimation Methods............................................. 61
5.3.5. SoS Capability Cost Estimation and Documentation ...................................... 62
5.4. SoS Mission Reliability .......................................................................................... 65
5.4.1. SoS Mission Reliability Definition ................................................................. 65
5.4.2. SoS Mission Reliability Estimation................................................................. 65
5.5. SoS Basic Reliability .............................................................................................. 66
5.5.1. SoS Basic Reliability Definition ..................................................................... 66
5.5.2. SoS Basic Reliability Estimation..................................................................... 66
5.6. SoS Priority ............................................................................................................ 68
5.6.1. SoS Priority Definition ................................................................................. 68
vi

5.6.2. SoS Priority Level Index Estimation ............................................................... 70
5.7. Summary................................................................................................................. 74
Chapter 6: System of systems mission reliability modeling and analysis ......................... 76
6.1. SoS Mission Environment ...................................................................................... 79
6.2. Review of Approaches to Phased-Mission Reliability Modeling and Analysis
Techniques (Single and multi-system missions) ........................................................... 80
6.3. A General Process for SoS Mission Reliability Analysis and Modeling ............... 87
6.4. SoS Mission Reliability Modeling and Analysis.................................................... 89
6.4.1. SoS Mission Description ................................................................................. 91
6.4.2. Mission Reliability Analysis of SoS Constituent Systems .............................. 93
6.4.3. SoS Mission Reliability Model By Mission phase .......................................... 98
6.4.4. Estimation of Lower Bound Mission Reliability for SoS Missions .............. 104
6.5. SoS Mission Reliability Modeling and Analysis of a Phased-Mission SoS with
Data Sharing Capability .............................................................................................. 109
6.5.1. Data-Sharing Capability in System-of-Systems ............................................ 110
6.5.2. Mission Reliability Model for Data Generation and Sharing Function ........ 111
6.5.3 Lower Bound Mission Reliability for a Phased-Mission SoS with Data Sharing
Capability ................................................................................................................ 115
6.6. Summary............................................................................................................... 116
Chapter 7: Selecting the preferred sos Solution .............................................................. 117
7.1. The Three-Phase Approach for Selecting the Preferred SoS Solution ................. 122
Inputs to the Three-Phase Approach ....................................................................... 124
Phase 1: Data Visualization and Analysis ............................................................... 125
Phase 2: Solution Space Simplification ................................................................... 132
Phase 3: Ranking SoS Solutions.............................................................................. 148
7.2. Summary............................................................................................................... 155
Chapter 8: Numerical Experiments ................................................................................. 157
8.1. Hypothetical Example of a Search and Rescue Operation (SAR)........................ 157
8.2. Estimation of Decision Attributes for SAR Mission ............................................ 162
8.3. Simulation of SAR Solution Space ...................................................................... 165
8.4. SAR Solution Space - Results of Data Visualization and Analysis ..................... 173
8.5. SAR Solution Space – Simplifying the Solution Space ....................................... 181
8.5.1 SAR SoS Mission Solution Space Simplification using DEA ....................... 182
8.5.2. SAR SoS Mission Solution Space Simplification using Data Clustering ..... 184
8.6. Selecting the Preferred SAR SoS ......................................................................... 190
8.7. Summary............................................................................................................... 194
Chapter 9: Methodology verification and validation....................................................... 196
9.1. Verification of SoS system selection methodology.............................................. 197
9.2. Validation of the Developed Methodology .......................................................... 205
9.3. Summary............................................................................................................... 207
Chapter 10: Summary, conclusions and future work ...................................................... 209
10.1. Summary of contributions .................................................................................. 209
10.2. Future Research .................................................................................................. 211
References ....................................................................................................................... 214
vii

LIST OF FIGURES

Figure 1: Types of SoS and Dissertation Focus .................................................................. 4	  
Figure 2: Healthcare As an SoS........................................................................................... 5	  
Figure 3: Roadmap for System of Systems Engineering..................................................... 7	  
Figure 4: SoS Development Complexity and Its Relation to Time to IOC ......................... 9	  
Figure 5: SoS Development Complexity and Its Relation to Acquisition Cost ................ 10	  
Figure 6: Waterfall Model(T. F. Bersson, T. Mazzuchi and S. Sarkani) .......................... 18	  
Figure 7: Spiral Model (Boehm 1986) .............................................................................. 19	  
Figure 8: The Systems Engineering Vee Model ............................................................... 20	  
Figure 9: Methodology Development Process for Selecting the Preferred SoS ............... 20	  
Figure 10: Dissertation Product Concept .......................................................................... 26	  
Figure 11: Methodology Requirements Development Process ......................................... 27	  
Figure 12: Factors Impacting Selecting the Preferred SoS ............................................... 34	  
Figure 13: Overview of Methodology for Selecting the Preferred SoS ............................ 37	  
Figure 14: SoS Mission Description Process .................................................................... 39	  
Figure 15: Process for Identifying Candidate Systems ..................................................... 40	  
Figure 16: Systems Screening Process for Identifying Feasible Candidates .................... 41	  
Figure 17: Mapping Feasible Systems to Mission Essential Functions of Each Phase..... 42	  
Figure 18: Screening Process for Determining Feasible SoS Solutions............................ 44	  
Figure 19: Process for Choosing an Approach for Selecting the Preferred SoS ............... 45	  
Figure 20: Defense Systems Lifecycle .............................................................................. 50	  
Figure 21: SoS Life Cycle ................................................................................................. 50	  
Figure 22: SoS Capability Development Phase as a Part of SoS Life Cycle .................... 52	  
Figure 23: Capability Time to Initial Operating Capability vs. SoS Life Cycle ............... 53	  
Figure 24: SoS Capability Cost Estimation Approach ...................................................... 55	  
Figure 25: SoS Capability Cost Elements ......................................................................... 56	  
Figure 26: Non-recurring and Recurring Cost of SoS Capability ..................................... 60	  
Figure 27: Mission and Basic Reliability Configuration for a Notional SoS with Four
Systems ...................................................................................................................... 67	  
Figure 28: Mission and Basic Reliability Configuration for the Notional SoS - Adding
Two Systems ............................................................................................................. 68	  
Figure 29: The Role of Priority in Trading Cost and SoS Capability ............................... 70	  
Figure 30: Estimation of PLI for the Notional Search and Rescue SoS ............................ 74	  
Figure 31: An Aircraft as a Single Phased-Mission System ............................................. 79	  
Figure 32: Existing Mission Reliability Modeling and Analysis Techniques ................... 82	  
Figure 33: A General Process for SoS Mission Reliability Modeling and Analysis......... 88	  
Figure 34: SoS Mission Reliability Estimation Process .................................................... 89	  
Figure 35: Mission Profile for a General SoS ................................................................... 92	  
Figure 36: Mission Profile for Constituent Systems - Possible Scenarios ........................ 94	  
Figure 37: SoS Mission Profile ......................................................................................... 95	  
Figure 38: Reliability Configuration of Subsystems for System j During Different Phases
of SoS Mission .......................................................................................................... 96	  
viii

Figure 39: SoS Phase-RBD: Series Configuration ............................................................ 99	  
Figure 40: SoS Phase-RBD: Parallel Configuration ....................................................... 100	  
Figure 41: SoS Phase-RBD: Standby Configuration....................................................... 102	  
Figure 42: SoS Mission RBD .......................................................................................... 105	  
Figure 43: SoS Mission Reliability at Time t .................................................................. 105	  
Figure 44: SoS Mission Reliability for the Entire Mission ............................................. 106	  
Figure 45: Hypothetical SoS - Example (1) .................................................................... 107	  
Figure 46: Hypothetical SoS - Example (2) .................................................................... 108	  
Figure 47: Improving SoS Mission Reliability via Adding Redundancy........................ 109	  
Figure 48: SoS Mission Profile with Data Sharing Capability........................................ 111	  
Figure 49: Data Link (DL) Structure for a Single System .............................................. 112	  
Figure 50: SoS Mission Reliability Estimation Prcoess: Considering Data Sharing
Capability ................................................................................................................ 115	  
Figure 51: Traditional Approach for SoS System Selection ........................................... 120	  
Figure 52: Proposed SoS Selection Approach................................................................. 121	  
Figure 53: A Framework for Selecting the Preferred SoS Solution ................................ 124	  
Figure 54: Phase 1- Data Visualization Process .............................................................. 126	  
Figure 55: (a) Scatter plot matrix, (b) trellis plot, (c) parallel coordinates plot, (d) icon
plot ........................................................................................................................... 127	  
Figure 56: Phase 2 - Simplifying the Solution Space ...................................................... 134	  
Figure 57: Phase 2 - Simplifying the Solution Space using Clustering Analysis ........... 137	  
Figure 58: Phase 2 - Simplifying the Solution Space using DEA ................................... 142	  
Figure 59: CRS and VRS Frontiers ................................................................................. 144	  
Figure 60: Multiplier Form and Envelopment Form of Input-Oriented VRS Model...... 146	  
Figure 61: Phase 3 - Selecting the Preferred SoS Solution ............................................. 151	  
Figure 62: Six Types of Preference Functions ................................................................ 153	  
Figure 63: Summary of the Three-Phase Approach for Selecting the Preferred SoS
Solution.................................................................................................................... 156	  
Figure 64: SoS Mission Representation for an SAR Mission ......................................... 158	  
Figure 65: SoS Mission Profile for an SAR Mission ...................................................... 158	  
Figure 66: RBD for the SAR Mission Example .............................................................. 163	  
Figure 67: Impact of Data Sharing on SoS Mission Reliability ..................................... 165	  
Figure 68: Beta Distribution with Parameters A=5 and B=2 .......................................... 166	  
Figure 69: Histograms of Simulated Data for Each Decision Attribute .......................... 171	  
Figure 70: Simulated Dependent Values of Mission Reliability and Basic Reliability .. 171	  
Figure 71: Simulated Dependent Values of Basic Reliability and Capability Cost ........ 172	  
Figure 72: Simulated Dependent Values of Capability Cost and Priority....................... 172	  
Figure 73: 3D Plot of Simulated Data ............................................................................. 173	  
Figure 74: 3D Plot of Simulated Data on the New Subspace.......................................... 177	  
Figure 75: The 2D View of the Simulated Data on Principal Component 1 and 2 ......... 179	  
Figure 76: The 2D View of the Simulated Data on Principal Component 2 and 3 ......... 180	  
Figure 77: The 2D View of the Simulated Data on Principal Component 1 and 3 ......... 181	  
Figure 78: The 3D view of the DEA results ................................................................... 183	  
Figure 79: A 3D view of the Normalized SoS solution space ......................................... 184	  
Figure 80: Silhouette Index for Various Number of Clusters ......................................... 186	  
ix

Figure 81: Clustered SAR SoS Solutions using K-means Algorithm ............................. 187	  
Figure 82: Box Plot per Decision Attributes ................................................................... 189	  
Figure 83:Methodology Development Process ............................................................... 197	  
Figure 84: Verification Method Selection Process .......................................................... 199	  

x

LIST OF TABLES

Table 1: List of Symbols for Capability Cost Estimation ................................................. 64	  
Table 2: Pre-defined Set of Values for System i Criticality and Capability Evaluation ... 72	  
Table 3: Mission Description for an SoS Mission with k Phases...................................... 92	  
Table 7: Principal Components and Variances computed for each Decision Attribute for
the Simulated Solution Space .................................................................................. 174	  
Table 8: Computed Latent Values for Each PC .............................................................. 175	  
Table 9: Percentage of the Total Variances Explained by Each Principal Component .. 176	  
Table 10: Results of DEA on Simulated Solution Space ................................................ 183	  
Table 12:The Calculated Total Sum of Distances for Various Replicates and Iterations
................................................................................................................................. 186	  
Table 14: DEA Results – Simplified Solution Space ...................................................... 190	  
Table 15: The set of Preferred SoS solutions considering mission reliability and time to
IOC .......................................................................................................................... 191	  
Table 16:Inputs of PROMETHEE II ............................................................................... 192	  
Table 17:The Result of PROMETHEE II – Complete Ranking ..................................... 193	  
Table 18:The Result of PROMETHEE II – Complete Ranking ..................................... 194	  
Table 19:Testing the CMEF Reliability Model Using a Simple Case ............................ 203	  
Table 20:Estimated Probability of Success for CMEF Function for the Notional SoS .. 204	  
Table 21:Model Verification Methods ........................................................................... 206	  

xi

ACKNOWLEDGEMENTS

First of all, I would like to thank my PhD advisor, Dr. Jerrell T. Stracener, for his great
support, supervision and encouragement throughout this journey. I would like to express
my special gratitude to my doctoral committee members for reviewing this work and
providing valuable comments. I am also thankful to Mrs. Daphne Biddle, Lockheed
Martin, for reviewing parts of this dissertation and for her advice and assistance.

Furthermore, I wish to thank my parents and my brothers, Behrang and Babak, for always
believing in me. Without their love and encouragement, I would have never been brave
enough to start this journey.

In particular, I would like to thank my wonderful partner, Dr. Farzan Farbiz, for his
endless love and unconditional support.

xii

CHAPTER 1
INTRODUCTION

An increasing need to provide new capabilities in response to continuously changing
environments, quickly and affordably, has given attention to the acquisition of system of
systems (SoS). The SoS approach enables adapting to continuously varying mission
requirements by integrating legacy and new systems over time. The system of systems
(SoS) concept is not new. This concept was initially introduced in the aerospace and
defense areas [1]. Nowadays, it has become the preferred approach for many applications
as users are more focused on developing broader and more flexible capabilities rather
than a single system that meets specific mission requirements.
1.1. SoS Definitions and Types
The term “System of Systems” has been in use for many years without an agreed
upon definition. In general, a system of systems (SoS) is defined as a combination of
stand-alone systems that collaborate to achieve the SoS mission goal [2]. These standalone systems were designed for various purposes but then they have been brought
together to provide a new required capability [3]. Madni [3] pictures an SoS as a system
that is designed to accommodate varying missions, some of which may have not been
defined yet. Some components of these systems might not have been developed yet and
those systems that have been formed from existing components for an specific mission
can be re-configured to be used in other missions.
1

Systems of systems are known for some combination of the following properties:
complex, large, networked, unbounded, geographically distributed, having complex
interfaces, adaptive, dynamic, evolving, without global visibility, interdependent,
distributive controlled, emergent, and nonhierarchical [4]. An SoS might not have all of
the abovementioned characteristics but it is called an SoS if it has a majority of these
characteristics. Boardman and Sauser summarized more than 40 different definitions and
extracted five major properties of an SoS as: autonomy, belonging, connectivity,
diversity, and emergence [5],[6].
Maier defines SoS based on the following five characteristics of its constituent
systems: operational and managerial independence, geographic distribution, emergent
behavior and evolutionary development [7]. Each of these characteristics are defined
below:
− Operational independence: constituent systems of SoSs are capable of operation in
isolation. According to A. Sage [8], if an SoS is dissassembled into its constituent
systems, these systems are able to perform operations independent from other parts
of the SoS. However, parts of a single complex system are not capable of operation
in isolation, which means that elements of a system are functionally related in a
hierarchical order.
− Managerial Independence: constituent systems of an SoS are acquired seperately
and managed independently.
− Geographic distribution: SoSs are different from systems in that unlike systems,
they are not usually viewable as entities even though their constituent systems are
2

viewable.

This is the result of constituent systems being geographically

distributed. However, the constituent systems should be capable of exchanging
information.
− Emergent behavior: An SoS may achieve capabilities that are far greater than the
sum of its constituent systems capabilities that could not be achived by single
operation of constituent systems.
− Evolutionary development: SoS development is evolutionary as its structure,
objectives and functiality may constantly change. Since constituent systems of an
SoS are independently managed, they are capable of independent evolution [4].
Therefore, SoS evolution is adaptive over time as its constituent systems evolve
over time.
In this dissertation, Maier’s definition of SoS is used. Here, an SoS is a system
whose elements are operationally and managerially independent of each other. An SoS
does not exist without these two properties, no matter how complex the elements of a
system are. Based on this definition, an aircraft is an example of a single complex system
while an airport is an SoS [9]. These characteristics provide more flexibility for the user
of SoS through adding and removing systems during operation over time. However, due
to these properties, SoSs may be highly complex and exhibit dynamic and emergent
behavior.
There are four types of system of systems: virtual, collaborative, acknowledged and
directed [10]. In a virtual SoS, there is no agreed-upon purpose for the SoS and there is
also a lack of central management. In a collaborative SoS, constituent systems cooperate
3

voluntarily to accomplish a common objective an example of which is the Internet. An
acknowledged SoS has a stated purpose and objective, and also a designated management
exists for this type of SoS, while the constituent systems maintain their own objectives,
independent ownership, funding, and development and sustainment approaches. A
directed SoS is developed and managed to accomplish specific goals under the control of
a central management. Even though the constituent systems operate independently, their
operational mode is under the control of the central management [10]. In this dissertation,
the focus is on the acknowledged SoS (Figure 1).

Types of SoS

Focus&of&this&
Dissertation&

Figure 1: Types of SoS and Dissertation Focus [10]

2.5. SoS Applications
Some applications of systems of systems are response to a natural crisis, space
missions, healthcare systems and search-and-rescue operations. In all these applications,
a group of systems is required to collaborate and accomplish the mission.
An example of SoSs formed in response to a natural crisis is the response to the
San Diego fire [11] and Japan’s earthquake in March 2011. Space missions are conducted
4

by clusters of satellites and spacecrafts to accomplish commercial, civil and military
missions. The SoS approach in conducting such missions enables responsive operations,
improves survivability and leverages technological advances [12]. A healthcare system
can also be viewed as an SoS as shown in Figure 2. The healthcare SoS involves many
systems and several stakeholders such as patients, physicians, nurses, hospitals,
healthcare organizations, pharmacies, and government regulatory, or funding agencies
[13].

Figure 2: Healthcare As an SoSFigure 2. Healthcare as an SoS –
(Adopted from [13])

Search and Rescue (SAR) is one of the U.S. Coast Guard's primary (high visibility
– high priority) missions which involves SoSs. This SAR application is further discussed
in this section to better explain what SoS means in this work. This application will be
used as an example in this dissertation for developing the methodology for selecting the
preferred SoS. In SAR missions, various categories of resources, e.g., aeronautical,
maritime etc, collaborate to conduct the mission. The SAR mission includes conducting
the search after reaching the scene quickly, rescuing survivors, delivering them to a place
of safety and finally returning to their bases. SAR missions involve airplanes, helicopters,
5

ships/cutters and boats linked by communications networks. Approaching SAR missions
from an SoS point of view can support decision-makers in mission planning and selecting
the right combination of Coast Guard resources for different (inland, maritime) mission
scenarios.
SAR can be considered as an SoS as its constituent systems have the major five
characteristics of SoS according to Maier’s definition [7]. All of SAR systems (resources)
e.g., aircraft and cutters, are operationally and managerially independent. The SAR SoS
also exhibits evolutionary development in the sense that at any given time, there can be
different numbers and combinations of systems involved in the mission. The SAR
mission exhibits geographic distribution in that its constituent systems cover different
search areas. According to [14], in missions similar to SAR, emergent behavior can be
achieved through the presence of redundancy. For example, if at any point in time
multiple aircraft collect search data from an specific area, the redundant data may provide
more important (or conflicting) information to decision-makers. Stakeholders in an SAR
mission include the SoS management team, systems owners, systems operators and
others.
1.2. The Need for Developing SoS-Related Methods and Techniques
Systems of systems have been gaining increased attention during the last decade
due to their increased applications in different areas such as aerospace and defense,
electronic systems, transportation systems and healthcare systems. This has led to
numerous research activities in developing SoS-related methods and techniques in
academic institutions including Purdue University, Massachusetts Institute of Technology
6

(MIT), University of Southern California and University of Texas at San Antonio. Also
in Europe, the project of Road2SoS started in 2011 by European Community to develop
research and engineering roadmaps to identify the most promising research areas in the
field of system of systems engineering in four key domain of power generation and smart
grids, integrated multi-site industrial production, emergency and crisis management and
multi-modal traffic control. As stated in [15], “The inherent complexity and dynamic of
an SoS raise many questions which nowadays are subject of important research efforts”.
This roadmap is shown in Figure 3.

Figure 3: Roadmap for System of Systems Engineering - Adopted from [15]

At the University of Southern California, a center of systems and software
engineering (CSSE) has been established to understand and evolve methods, processes
and tools to enhance system of systems engineering. The USC CSSE and SERC (Systems
Engineering Research Center) identified their research focus to better manage and evolve
system of systems [16]. Dr. DeLaurentis has been leading an on-going research in the
7

System-of-Systems Laboratory at Purdue University in which, he states, “With multiple,
evolving, heterogeneous, distributed systems involved and embedded in networks at
multiple levels, a guiding methodological framework is needed to enable adequate
decision-support.’ According to William Crossely at Purdue University [1], there is an
essential need for formalized methodologies and models that can be used repeatedly to
generate SoS solutions. The methodologies and models for optimized utilization of
existing resources that can adapt to evolving systems and mission dynamics are lacking
in many areas.
Providing a new required capability through an SoS approach raises unique
development challenges, one of which is the process and methods for selecting the “right
mix” of systems for an SoS to meet operational capability and program requirements.
There exist three distinct cases for providing a new required capability through an SoS
approach. One case is the need for a quick response SoS solution to meet capability
requirements within a short time. Examples are search and rescue operations and
response to a crisis such as a major earthquake. Another case is the need to respond to
changes in the business environment. Examples are for an airline to respond to the
competition’s lower cost structure by selecting a new aircraft to replace a less efficient
model or for a healthcare system to add a new service. The third case is the need for a
new capability that will require mostly new development. An example is a planned space
probe by NASA. In all cases, success of SoS development and effectiveness of the
resulting SoS is highly dependent on selection of systems from candidates. The shorter
the time at which a capability is needed derives the feasible solution to be an SoS
8

comprised of existing systems. An SoS solution of mixing existing systems is the
preferred approach in many cases for several reasons: First, the capability acquisition cost
could be less than the new development as we are getting extra benefit from systems that
have already been developed and paid for [17] and secondly, the initial SoS capability is
adaptable to changing operational needs by changes in SoS configuration and/or system
upgrades. Thus, the SoS solution of integrating existing systems enables flexible
adaptation to unexpected and uncertain situations [4]. Moreover, there may not be
sufficient time to develop new systems to form an SoS. For example, in the case of
missing Malaysian Airlines Flight MH370 in March 2014, an SoS capability was
required to begin a search mission within a short time frame.

Figure 4: SoS Development Complexity and Its Relation to Time to IOC

9

Figure 5: SoS Development Complexity and Its Relation to Acquisition Cost

1.3. Dissertation Objective
This dissertation presents a general methodology for selecting the preferred SoS
solution, which consists of existing systems, for a pre-defined SoS mission when a new
capability need is acknowledged. The preferred solution is the most acceptable solution
to the stakeholders. The methodology is designed to assist users and decision-makers in
generating SoS solutions and selecting the preferred SoS for an specific mission in an
organized and structured way. The application of this methodology is during SoS mission
planning, acquisition planning, and SoS development. The result of my literature search
reveals no methodology for systematic selection of the preferred SoS with the objective
of providing a new capability subject to specified requirements.
In a systems engineering approach as defined in [18], the process starts from
identification of the need for a new capability, which is complex in most cases. In
identifying the need and transforming the need into systems requirements, system’s
10

operational environment is defined and used in the form of operational scenarios.
However, the objective of defining the system’s context of use is to better understand the
new system itself rather than its operational environment and context of use. As stated by
Dahmann [19], “Context is important to the DoD requirements process. It is core to
conducting capability-based assessments and setting user capability needs. Capability
based assessments examine operational capability needs in a mission or operational
context environment. For acquisition, context plays a role in the front end of the process
and at key points in the acquisition lifecycle”. Considering the SoS context early during
planning and acquisition was one of the main objectives of this research to ensure
consideration of all possible SoS solutions and performance attributes which according to
[19] prevents unplanned cost and schedule growth.
1.4. Summary of Dissertation Contributions
This work will provide a significant contribution to the systems engineering and
SoS development body of knowledge by presenting a framework to support the selection
of the preferred SoS while considering some major factors and stakeholders’ preferences.
This methodology can be applied to current and future SoS mission planning and
acquisition needs. In particular, the methodology presented in this research provides a
more holistic approach over current methods for selecting the preferred SoS. The value of
the presented methodology is in the up front planning of SoS mission and acquisition
before the actual system selection starts. This methodology is unique as it:
− Provides a SE-based framework for repeatedly generating SoS solutions and
selecting the preferred SoS in a systematic and structured way that:
11

o Initiates from the SoS context of use and SoS mission and capability
requirements.
o Enables decision-makers to address various aspects of SoS
capability

(e.g.,

mission

effectiveness,

sustainability

and

affordability) in selecting the preferred SoS solution by taking into
account multiple decision attributes that have not been considered in
previous work.
o Presents a new measure of priority to evaluate candidate systems
and compare SoS solutions from the stakeholders’ point of view.
o Models SoS affordability in the form of SoS capability cost to
enable comparison of SoS solutions.
− Presents a methodology for SoS mission reliability modeling and analysis.
This methodology estimates a lower-bound mission reliability for an SoS
operating phased-missions. As an integral part of this methodology, SoS
interoperability was mathematically modelled in the form of data sharing
among constituent systems, which dramatically increases the probability of
mission success for SoS missions.
− Presents a hybrid approach that combines data analysis and multi-criteria
decision analysis for selecting the preferred SoS that (1) assists stakeholders
in better understanding the available options and identification of trade-offs
as the SoS solution space is often complex, (2) emphasizes increased
participation of stakeholders throughout the decision-making process,
12

which results in stakeholders’ improved level of acceptance of the final
selected SoS.
1.5. Dissertation Organization
This dissertation is organized to walk the reader through the need and development
of a methodology for selecting the preferred SoS solution to accomplish a specific SoS
mission. In chapter 2, the methodology development process using systems engineering
approach is discussed. Chapter 3 contains methodology concepts and requirements
definition. In chapter 4, the methodology framework overview is presented in several
steps. Modeling and estimation of decision attributes are explained in chapter 5. Chapter
6 presents the approach for estimating the lower bound mission reliability for an SoS
solution. In chapter 7, a three-phase approach is presented for selecting the preferred SoS
solution based on stakeholders’ preferences. In chapter 8, a hypothetical case of a search
and rescue is simulated for various scenarios and used to numerically illustrate the
performance of the methodology. Chapter 9 includes the methodology verification and
validation. Finally, the conclusions of this research, the contributions made and the future
directions are discussed in chapter 10.

13

CHAPTER 2
SYSTEMS ENGINEERING PROCESS IN METHODOLOGY DEVELOPMENT

In order to successfully develop a methodology for generating SoS solutions that is
adaptive and considers a large and diverse user community, a systematic approach is
required. To deal with the complexity of such a problem, an approach is required to
ensure that the developed methodology considers all aspect of such complex problem and
is flexible enough to be repeatedly used for generating SoS solution generation mission
planning. This chapter describes the application of systems engineering processes in
developing a methodology for SoS system selection methodology.
2.1. Sources of Complexity in System-of-Systems Development
Understanding complex aspects of SoS is necessary for developing a
methodology that could assist users and decision-makers in generating SoS solutions and
selecting the preferred option (candidate). According to Dahmann [20], there are four
sources of complexity in SoS: systems, users/stakeholders, development and operations.
In many cases, when a new capability need is acknowledged, a group of existing systems
are pulled together on a short notice to collaboratively accomplish a set of objectives.
Therefore, there is usually not enough time for new development. For instance, in a
search and rescue operation such as the search mission for the missing Malaysian flight
MH370, more than 100 systems got involved within days to conduct the search. In such
cases, systems that are assigned to the SoS mission have usually not been developed for
14

the purpose of SoS or meeting the mission objectives. The selected systems are often
independently developed, and consequently they are diverse in many ways such as
design, control structure, communication capabilities, life cycle maturity, etc [20]. Also,
systems of such an SoS are usually owned by different organization. These systems
participate in the SoS mission while continuing on their organizations’ missions.
Therefore, they may either be involved in concurrent missions or may not be available for
participation in the SoS mission. Another source of complexity is the number of
stakeholders involved in providing a capability solution through an SoS. Disparate
system owners and large number of stakeholders with their conflicting needs, objectives
and priorities and often their lack of motivations to participate in the SoS mission
complicates the problem of selecting the preferred SoS [21]. For example, in the case of
flight MH370, more than 25 countries were involved to conduct the search mission.
Moreover, SoS usually accomplishes its mission in an operationally dynamic
environment with changing requirements. Independent systems of the SoS perform their
own missions while contributing to the SoS mission goals. To perform SoS mission
essential functions, systems of an SoS interact and as a result of their interactions, a
complex behavior emerges [21]. Due to the changing requirements in SoS missions,
systems may be added or removed during operation or their configuration (e.g.,
operational status, series vs redundant) may change to adapt to the changing situations. In
other words, the configuration of systems in an SoS as well as the personnel and
stakeholders is temporary. Due to all of these reasons, developing a systematic
methodology for generating SoS solutions and selecting the preferred option is
15

challenging and requires an organized approach to deal with the complexity of this
problem.
2.2. Application of Systems Engineering
As stated before, selecting the preferred SoS solution for a specific SoS mission is
affected by many factors, various stakeholders and changing operational environments.
An approach to develop a methodology for selecting the preferred SoS must take all of
these factors into account. Integrating various systems that are operationally and
managerially independent; usually at different stages of their life cycles and owned by
different organizations imposes complexities that can be dealt with by a systematic
approach. Systems Engineering provides a systematic process for delivery of quality
solutions that satisfies user needs (INCOSE, 2010). Systems engineering is focused on
solving the problem in its entirety by taking a systems approach (INCOSE, 2010).
According to International Council of Systems Engineering (INCOSE):
“SE is a discipline that ensures that the user and stakeholders needs are satisfied in
a high quality, trustworthy, cost efficient and schedule compliant manner throughout a
system's entire life cycle. It is responsible for creating outputs such as (Stakeholders
requirements specification, listing of deliverables, trade study analysis, etc) and also a
process for producing these outputs in concrete context.”
SE has been developed around industries such as aerospace/defense and has largely
been used in DoD/NASA missions. The value that systems engineering brings into the
development of complex systems can be shown through its ability in reducing risk, cost,
schedule and improving the ability to deliver required technical performance [23]. An
16

empirical study by W. Forrest Frantz shows that systems engineering can increase a
system’s quality and simultaneously reduce its schedule (1995). Also, according to
Blanchard and Fabrycky (1998, p. 42-43), experienced engineers recognize that systems
engineering reduces the cost of system design and development.
An SE approach is suitable in developing this methodology due to the complex
nature of SoS selection. This approach is multidisciplinary, integrated and life cycle
oriented and has been applied to a variety of development projects [24]. To address how a
systems engineering approach could be used to develop this methodology, a
comprehensive survey has been conducted on systems engineering processes and models.
The result of this survey as discussed below was used to select a suitable SE process for
developing this methodology.
Applicable SE Process Models:
One can find systems engineering process definitions, guides, and handbooks
from the National Aeronautics and Space Administration, International Council on
Systems Engineering (INCOSE), Electronics Industrial Association (EIA), Institute of
Electrical and Electronics Engineers (IEEE), International Standards Organization (ISO),
and various Department of Defense (DoD) agencies and organizations [25]. Systems
engineering process models have proven effective in taking an integrated and
comprehensive view of a system while allowing for clear stakeholder engagement,
requirements definition, life cycle cost analysis, technology insertion, validation and
verification [26].

17

Some of the most commonly used SE models are the Waterfall, Incremental,
Spiral and Engineering “Vee” models. Each of these models are discussed here.
Waterfall: It is a sequential development method in which the project is divided
into phases and by completion of each phase, the project proceeds to the next phase in a
systematic manner. Figure 6 shows the Waterfall Model with feedback loops.

Figure 6: Waterfall Model(T. F. Bersson, T. Mazzuchi and S. Sarkani)

Incremental: In this model, requirements are defined before proceeding to
development of individual increments of the system. A series of mini-Waterfalls are
performed. In other words, all phases of the Waterfall development model are completed
for a small part of the system, before proceeding to the next increment.
Spiral: It is a cyclical approach that has built in risk management (see Figure 7). It
was developed by Barry Boehm and presented in his 1986 article. In this model, each
cycle begins with design requirements and ends with the user. Each cycle has the
following actions: identify design and development objectives, evaluate alternatives,
develop strategies to mitigate or eliminate risk for the next cycle. Each cycle results in a
deliverable [26].

18

Figure 7: Spiral Model (Boehm 1986)

The waterfall model does not apply for development of this methodology, as it is
not flexible enough to accommodate change and its stages cannot be completed in
parallel. The spiral and incremental do not seem suitable for developing this
methodology, as the requirements must be well known up front which is not the case in
developing this methodology.
The Engineering “Vee” model, which is used for developing this methodology
was developed by Forsberg and Mooz, and has been used in many acquisition efforts
[27]. This model has been modified over the years where the left and the right legs have
been added. As illustrated in Figure 8, this model breaks the system down to pieces (from
concept of operation to requirements definition), and then proceeds to the system design
stage and then detailed design. The right side of the Vee model includes integrating
different pieces into a complete system and verification and validation of different
components and the entire system.

19

Figure 8: The Systems Engineering Vee Model (Adopted from Overview of Systems Engineering
Processes)

2.3. Methodology Development Process
After conducting a comprehensive literature search in the area of system of systems
and identifying and documenting the need, the general “Vee” model has been tailored and
used for developing the methodology and models for selecting the preferred SoS for an
specific mission as shown in Figure 9.
Conduct SoS Literature
Review
Identify the
Gap

Define Methodology
Requirements

Verify and Validate the
Methodology and Model

Methodology Preliminary
Design
Develop Methodology
Framework

Document the Need for a
Methodology to Select
Develop a
the Preferred SoS
Response to the
Need

Methodology Integration
Develop an Approach for
Selecting the Preferred SoS

Methodology Detailed Design
Model the Decision attributes
Model Mission Reliability
Model Basic Reliability
Model Capability Cost
Model Priority Level Index
Estimate Time to IOC

Draft Summary
and Conclusion

List Future Work

Figure 9: Methodology Development Process for Selecting the Preferred SoS

20

The tailored “Vee” model illustrates the steps that were taken to systematically
develop this methodology as a system. As shown in Figure 9, the product (i.e.
methodology) development process started with identifying the methodology
requirements based on the user’s needs. A comprehensive literature survey was
performed to evaluate current state of the SoS system selection methodologies and
documenting a need for a more holistic methodology (which is discussed in the following
chapter). Once the user’s needs were identified, a response to the need was formulated
that included the methodology concept, inputs and outputs. Using this information,
methodology requirements were developed.
Once the requirements were defined and the methodology concept was established,
the overall framework of the methodology (preliminary design) was developed based on
the requirements, which was followed by methodology development (detailed design).
The methodology detailed design involved various blocks that were represented in
mathematical forms and models for each decision attribute that was considered in this
dissertation (implementation). These models were then integrated for evaluating,
comparing and selecting the preferred SoS using a hybrid method that was developed for
the purpose of this dissertation.
Various parts of the methodology and models were verified through demonstration,
inspection and testing to ensure that they were correct and accurate. Validation of the
methodology was partially accomplished using face validation and peer review. Full
validation will become available as users provide feedback on the methodology when

21

applied to providing a wide range of new capabilities and across a large range of SoS
missions.
2.4. Summary
There are different sources of complexity in developing system of systems
solutions, which calls for systematic processes to deal with the complex nature of
developing a methodology for selecting the preferred SoS solution.
Systems engineering process models that ensure successful development of
products were discussed in this chapter and the most suitable process, SE “Vee” model,
was selected and tailored for developing a methodology for selecting the preferred SoS
solution. The methodology development process used for this work starts from existing
research review and continues with documenting the need and defining the methodology
requirements. These three steps will be covered in the following chapter.

22

CHAPTER 3
METHODOLOGY CONCEPT DEVELOPMENT AND REQUIREMENTS
DEFINITION

A review of existing research and related work is provided in this chapter. The
result of the literature search was used to identify and document the need and to
formulate a response to the need, which is discussed in this chapter.
3.1. Current State of Research on Methods for Selection of SoS Systems
(Literature Review)
Based on the result of the extensive literature search, most of the existing methods
that can support selection of SoS systems focus on solving two kinds of problems: (1)
selecting the best SoS solution in order to maximize SoS performance subject to cost
constraints using optimization techniques, or (2) selecting the best solution while
balancing a set of performance measures through quantitative comparison of alternatives.
Some selected related work are listed and discussed in more detail in this section.
Skinner developed a methodology for selecting subsystems for integration into
complex systems [28]. Factors considered for sub-systems selection in this work were
cost, schedule, technical performance and risk factors. He modeled the problem as a
graph-theoretic multi-objective model and represented it as a network flow problem.
23

Astaphnko in [29] developed a genetic algorithm-based optimization approach to
construct an optimal design case for a phased mission system. The model was intended to
minimize the overall mission failure probability subject to cost constraints.
Chattopadhyay at MIT developed System of Systems Tradespace Exploration
Method (SoSTEM) to generate SoS-level performance attributes that are compared on the
performance and cost basis. In this method, systems forming each SoS, their method of
interaction and interfaces and an estimate of participation risk of each system within the
SoS was used for comparison as well as cost [30]. Richards introduced Multi-Attribute
Tradespace Exploration (MATE) for survivability to evaluate a large set of design
alternatives during conceptual design. He used survivability tradespace to select the best
design that balances cost, utility and survivability [31]. Azam solved the problem of
optimal systems selection using methods such as ordinal optimization; SNR-based
approach and non-parametric statistical testing. His approach was aimed to select the
subset of available systems to maximize mission reliability using Monte-Carlo simulation
[32]. Also, Warshawsky and Mavri used aggregation-function-based models for
calculating the overall performance of a SoS and exploring SoS alternative space [33].
3.2. Statement of Need and Response to Need
While these methods all show potential in assisting with SoS system selection and
some of them have considered a variety of factors, they still leave the decision maker
without the consideration of factors related to time to achieve the Initial Operating
Capability (IOC), systems and mission priorities and sustainability. They also do not

24

appear to help the decision makers with identifying and selecting candidate systems at the
early steps of SoS development.
Furthermore, depending on the situation and stakeholders’ preferences, SoS
development objectives may change over time. For example in some cases, forming an
SoS with maximum mission reliability may be the stakeholders’ objective while this
objective may change to minimum SoS capability cost in other missions.

Current

methods do not offer enough flexibility for the users in terms of changing objectives.
Therefore, there is a need for an SoS selection methodology that is flexible, considers
factors critical to meet SoS life cycle requirements and assists with identifying and
selecting candidate systems at the early stages of development to generate SoS solutions.
Methodology developed as a result of this work provides a more holistic approach
over current methods for selecting the preferred SoS and its prime value is in the up front
planning of SoS development before the actual system selection process starts. This
methodology is based on factors relating to time to IOC, mission effectiveness,
sustainability and affordability that will be introduced and explained in detail in chapter
4. The dissertation product concept as shown in Figure 10 illustrates the inputs, outputs
mechanisms and control of the final product.

25

• Existing Methods
• Technical literature
• Standards and Guides
Methodology Inputs

• List of available systems
• Project Requirements
(Mission Reliability,
Capability Cost, Time,
Mission Priorities)

• SoS Mission Objective
and Description

Methodology Output

Methodology for
Selecting the
Preferred SoS
Solution
to Provide a Required
Capability

Preferred SoS

• PhD SE Requirements
• Time Requirement

Figure 10: Dissertation Product Concept

3.3. Methodology Requirements Development for Selecting the Preferred SoS
Having the scope of the project, i.e. methodology, defined and users needs
identified, the first step was to create a list of requirements for the product. Development
of a clear statement of requirements is the key to a successful product development [34].
Requirements describe the key functions of the product that is to be developed. In
systems engineering, users needs are identified, analyzed and transformed into verifiable
requirements. These requirements define what the product, in this case the methodology,
is supposed to do when developed. This section deals with the development and
definition of requirements that the methodology for selecting the preferred SoS must
address. We first reviewed the standards that exist for requirements definition and
development to create a list of verifiable requirements for this methodology.
Requirements development process has been discussed in NASA Systems Engineering
Handbook, Systems Engineering Handbook (INCOSE), and ISO/IEC 15288.

26

The process for methodology requirements development is shown in Figure 11.
This process started with defining methodology high-level requirements based on the
user’s needs. High-level requirements are often described as customer requirements,
system requirements, operational requirements, concept of operations, mission statement,
stakeholder needs, stakeholder expectations, constraints, etc [35].
The high-level requirements were then validated to justify the need for each
requirement. The high level requirements were decomposed into verifiable lower-level
requirements in the next step. The low-level requirements are often described as derived
requirements, design requirements, technical requirements, product requirements,
allocated requirements, etc [35]. The defined requirements were finally validated to
ensure that the stated requirements would provide a valid outcome based on users needs.
Methodology V&V

Users Needs

Methodology*
High*Level*
Requirements*

Applicable V&V Techniques:
• Simple checks
– Traceability, well-written requirements
• Reviews and inspections
– Walkthroughs
– Formal inspections
– Checklists

Methodology*
Veriﬁable*
Low6Level*
Requirements*

Methodology*
High6Level*
Requirements*
Valida9on**

Completed*
Requirements*
V&V*

Figure 11: Methodology Requirements Development Process
Source for above V&V Techniques: Methodology verification and validation, Based on Powerpoint slides
by Gregor v. Bochmann, Gunter Mussbacher with material from: G. Kotonya and I. Sommerville, M. Jackson, P.
Heymans, S. Somé 2008, and D. Amyot 2008

27

Methodology high-level requirements:
The developed methodology must meet the following high-level requirements,
which were defined based on the users need.
R1. The methodology shall support decision-making in selecting the preferred SoS
capability solution during mission planning.
R2. The methodology inputs shall be obtainable.
R3. The methodology shall enable estimation of SoS decision attributes.
R4. The methodology shall be applicable to all well-defined SoS missions with
fixed phase durations.
R5. The methodology shall be flexible enough to respond to changing mission
requirements and priorities.

High-level requirements verification:
The defined high-level requirements were stated based on the need associated with
each requirement as discussed below:
R1. As noted in SE Guide for SoS, “In an SoS environment there may be a variety
of approaches to addressing objectives”. As stated by Crossly [1], “there is an essential
need for formalized methodologies and models that can be used repeatedly to generate
SoS solutions, the methodologies and models for optimized utilization of existing
resources that can adapt to evolving systems and mission dynamics”. Therefore, there is
a need for a systematic process to generate and compare SoS solutions to select the
preferred option.
28

R2. In order to generate capability solutions through an SoS approach, a complete
description of SoS mission is required. Also, having access to data associated with
candidate systems is also necessary to evaluate and compare available systems, identify
candidate systems and form SoS solutions.
R3. In order to select the preferred SoS solution, all options must be evaluated and
compared against requirements and each other. To enable this, generated solutions must
be assessed based on their performance in meeting program and mission objectives.
R4. As documented in the statement of the need, methodologies that can be
repeatedly used are lacking in many SoS areas. This requirement was stated to ensure that
the developed methodology could be easily modified for use in various missions and
needed capabilities.
R5. As mentioned in previous chapters, systems of systems usually operate in
dynamic environment. Systems join and leave the SoS as well as their stakeholders. The
key challenge for providing a capability solution through SoS is to be able to respond
quickly to changing mission requirements and environmental conditions in a structured
manner. Also mission and stakeholders priorities continuously change, for example,
sometimes affordability is the driving factor in selecting the preferred SoS and sometimes
performance is the critical driver. This methodology must be flexible in selecting the
preferred SoS depending on the situation.
Methodology low-level requirements:
When the methodology high-level requirements were validated and the need for
each requirement was justified, the low-level requirements were developed for each high29

level requirement. The developed low-level requirements support the objective of this
methodology, which is achieving the desired outcome (the preferred SoS) based on the
methodology inputs as defined in section 3.2. These requirements are traceable to the
operational, users and stakeholders’ needs and listed below:
i.

The methodology shall translate the mission description into SoS needed
capability objectives.

ii.

The methodology shall determine SoS requirements/technical objectives using the
SoS needed capability objectives.

iii.

The methodology shall determine systems that are key to SoS objectives based on
systems operational capabilities and mission key functions.

iv.

The methodology shall determine the relationships of essential systems.

v.

The methodology shall identify SoS candidate solutions to address SoS needed
capability objectives.

vi.

The methodology shall represent SoS candidate solutions in terms of constituent
systems and their configuration.

vii.

The methodology shall evaluate the operational capabilities of SoS candidate
solutions with respect to the needed SoS capabilities.

viii.

The methodology shall enable evaluation of options in terms of decision
attributes.

ix.

The methodology shall enable comparison of options vs. mission requirements.

x.

The methodology shall identify and involve stakeholders in decision-making.

30

xi.

The methodology shall enable comparison of the SoS candidate solutions in terms
of decision attributes.

xii.

The methodology shall enable the selection of preferred option, which best
matches the situation and meets stakeholders expectations.
Methodology requirements validation:
The objective of this dissertation was to develop a methodology to assist users in

systematically selecting the preferred SoS solution for an specific mission. The low-level
methodology requirements were validated via inspection to ensure that the developed
methodology would provide the outcome expected by users. The requirements developed
for this methodology support the documented need in this dissertation and guarantees
achieving the methodology outcome. Therefore, it can be concluded that the developed
requirements were valid. These requirements were used throughout this research in
developing a methodology for selecting the preferred SoS.
3.4. Summary
The results of literature search on existing related work in the area of system of
systems were discussed in this chapter. The result of the literature search identified a gap
and the need for a methodology that assists users in systematically selecting an SoS
candidate solution that meets program requirements and stakeholders expectations. The
identified need was documented and the dissertation product concept was developed.
Then methodology requirements were defined in two steps: high-level and low-level
requirements. The results of the methodology requirements development phase were
31

used as an input in generating a conceptual solution for this methodology. The
methodology preliminary design, methodology framework overview, is developed and
presented in the next chapter.

32

CHAPTER 4
METHODOLOGY FRAMEWORK OVERVIEW
As shown in the methodology development process, illustrated in Figure 9, the
methodology requirements defined in chapter 3 were used for developing a preliminary
design of the methodology. The ultimate goal of the developed methodology is to provide
a systematic process for generating SoS solutions for a specific mission and evaluating
these solutions to select the preferred SoS candidate. A methodology framework is
developed to achieve this goal, which is discussed in this chapter. This methodology
assists users in decision making during SoS mission planning, acquisition and
development that starts from mission requirements in an organized way. In order to select
the preferred SoS solution, SoS candidates are evaluated based on five selected decision
attributes. The selected attributes that have been utilized for decision-making in this
methodology are introduced in this chapter.
4.1. Selection of Decision Attributes
Developing a new SoS capability is said to be successful if the preferred solution
meets stakeholders’ expectations and is mission-effective. Figure 12 shows important
attributes that could be considered in the decision-making process during selecting the
preferred SoS solution. While all of these attributes are important and some of them
depend on each other to some extent, considering all of them was out of the scope of this
33

research and I only focused on five attributes based on their criticality in meeting SoS life
cycle requirements. These attributes are mission reliability, basic reliability, capability
cost, time to IOC and priority.
Ensure Meeting
Stakeholders
Expectations

The
preferred
SoS Solution

Ensure Stakeholders
Involvement

Ensures SoS Mission
Effectiveness

Ensure
Meeting SoS
Mission
Schedule

Ensure
SoS
Mission
Security

Ensure
SoS
Mission
Safety

Ensure SoS
Sustainability

Ensure
Meeting
Technical
Performance
Objectives

Reliability
Ensure SoS
Availability

Ensure
Mission
Affordability

Maintainability
Supportability

Ensure SoS
Sustainability

Ensure Achieving SoS
Mission Essential
Functions
Ensure Achieving
Capability Objectives
Ensure Meeting SoS
Priorities

Figure	  12:	  Factors	  Impacting	  Selecting	  the	  Preferred	  SoS

Specifically these factors were selected as they impact provision of the timely,
effective, sustainable and affordable capability through an SoS. There is usually limited
time available when a new capability need is acknowledged. Thus, selection of systems
for an SoS and creating an SoS solution must be completed within a short time frame to
ensure mission success. Therefore, time to initial operating capability was selected as a
decision attribute. Another attribute that drives mission success is the effectiveness of the
SoS solution. Mission reliability, as a measure of mission effectiveness, is particularly
important in missions whose failures may have severe consequences, such as in a searchand-rescue operation. Also, cost is a major factor in any acquisition programs. As
mentioned in [36] “Aerospace and defense systems today have to satisfy affordability,
34

adaptability, security, reliability, and resilience requirements”. Basic reliability as a
measure of capability sustainability, and SoS capability cost, as a measure of
affordability, have also been selected to address these two aspects of SoS capability.
Existing systems for an SoS are usually possessed by different organizations and
therefore are assigned to perform their organizations’ missions at the time. When a new
capability is needed, many systems may be considered to participate in providing the SoS
capability objectives. An approach to distinguish these systems from the management
point of view was through defining a new measure of priority. Systems that are
considered for the SoS mission might already be involved in their organizations’ priority
missions. Some may be idle at the time but they may need to be available for more
sensitive missions. Stakeholders’ consideration of the priority systems and missions with
respect to the SoS mission priority affects the selection of candidate systems and the
preferred SoS. The importance of the decision attributes changes depending on the
mission type as this methodology is applicable to both single missions and recurring
missions. Each of these decision attributes and their point estimations are discussed in
chapter five.
4.2. Methodology Key Ground Rules, Assumptions and Considerations
An SoS solution to provide a new required capability can range from a candidate
within which all constituent systems being selected from existing systems to a candidate
with all of its constituent systems being new developments.
The constituent systems of an SoS solution should be capable of interacting with
each other with no compatibility issues. Having some systems without the capability of
35

communicating and interacting with other parts of the SoS may prevent other systems
from being fully functional. This ability of an SoS is referred to as interoperability and is
the key enabler for SoS. Due to the interoperability of systems, emergent phenomena
occur and a SoS achieves capabilities that are greater than the sum of its constituent
systems [37]. The focus of this methodology is to generate SoS solutions from existing
systems and select the preferred candidate for an specific mission with pre-defined
mission description and requirements. This prevents the SoS emergent behavior to be
revealed in this application. However, emergent behaviors of an SoS can take the form of
quality attributes such as reliability, performance, safety, or capabilities/services that are
only achievable when they involve a significant number of systems [4]. Even though
modeling the emergent behavior of an SoS capability solution was not the focus of this
methodology, this behavior can be seen through data sharing considered among
constituent systems of SoS.
4.3. Overview of Methodology Framework
The objective of this dissertation was to produce a methodology for generating and
selecting the preferred SoS in an structured and organized way when a new capability
need is acknowledged. Having the methodology requirements defined, a methodology
framework was developed to achieve this objective. The methodology framework for
selecting the preferred SoS is illustrated in Figure 13. This methodology consists of two
fundamental phases:
Phase 1: Generating SoS solutions
Phase 2: Selecting the preferred SoS solution
36

Generate SoS
Solutions

Candidate Systems

SoS Mission
De#ine&SoS&
Mission&

De#ine&SoS&
Mission&
Objectives&

&

De#ine&Mission&
Success&Criteria&
by&Phase&

Develop&SoS&
Mission&Pro#ile&

Determine&
Mission&
Essential&
Function&by&
Phase&

Determine&
Duration&of&each&
Phase&

Identify)SoS)
Needed)
Capabilities)

De:ine))High)Level)
Capability)
Requirements)

Establish)
Capability)
Objectives))

Identify)Alternatives)
to)Perform)Essential)
Functions)
Candidate)Systems)

De:ine))Essential)
Functions)Required)to)
Provide)the)Capability))

Determine&
Mission&
Essential&
Systems&by&
Phase&

SoS Solutions

Library of Feasible Systems

Library of Systems
Select as a Feasible System
S1

S4

S2

S5

S3

S6

Sn-2

…"

Do Loop for all Identified
Systems, Si ,i = 1,2,…,n

Sn-1
Sn

Library of SoS Alternatives
S1
S1
S1
S1

S6

S2

S3

S5

SoS2

S2

S3

S5

SoS3

S4

S3

S5

SoSk

CAC<
CR?

No

Determine SoS
and System
Mission Priorities

SoS1

S5

…"

Yes
No

Not Feasible System

Identified
Systems

Estimate
Acquisition
Cost

System Mission Priority
<
SoS Mission Priority
?
No

Yes
Determine
Acquisition
Time

Systems of systems with the same set of systems but different configurations are
considered different. (see SoS2 and SoS3)

tAC<tR
?

Yes

!

!
!
Select the Preferred
SoS
Estimation of Decision
Attributes for Each SoS
Solution
Time to SoS IOC

SoS Decision
Attributes

Library of Feasible SoS Solutions
List%of%Possible%SoS%
Solu.ons%

No

?%

Do#Loop#for#All#
Alternatives#

Meet%%CCi%
requiremen?%

Feasible%SoS%
Solu.ons%

Select%the%system%with%
lowest%mission%
reliability%and%add%
redundancy%with%the%
same%type%of%system%%

ReDEs.mate%decision%
aFributes%

Yes

Meet%%BR%
requirement?%

Priority Level
Index
Mission Reliability

Alterna.ve%
meets%the%
MR%
requirements

Meet%Timei%%
requirements
?%

No

No

Not%a%
Feasible%
SoS%
Solu.on%

No

Basic Reliability
Capability Cost

Feasible SoS
Solution Space
The
Preferred
SoS
Solution

Stakeholders Involvement in Defining the preferred
Rank Selected
SoS Solutions

Simplified
Version of the
Solution Space

Solution Space
Visualization and
Analysis

!
Figure 13: Overview of Methodology for Selecting the Preferred SoS

37

Phase 1: Generating SoS solutions: This phase deals with generating all possible
SoS solutions from existing and available systems to provide a new capability for a
specific mission. This phase consists of the following four steps:
1.1. Describing the SoS Mission
1.2. Identifying Candidate Systems
1.3. Selecting Feasible Systems from Candidates
1.4. Determining SoS Solutions
Each step is discussed below.
1.1. Describing the SoS mission includes defining the intended mission and its
objectives. Mission objectives qualitatively define what the SoS mission should
accomplish to be successful. Top-level mission requirements and constraints will be
developed from the objectives to ensure that mission objectives will successfully be
achieved.
For the SoS mission, the SoS mission profile must be developed in terms of the
duration of the mission, mission phases and duration of each phase. Success criteria of
each phase will also be determined to assist in defining mission essential functions.
Mission essential systems and equipment of each phase as well as operating conditions
and environments are then determined (Figure 14).

38

De#ine&SoS&
Mission&

De#ine&SoS&
Mission&
Objectives&

&

Develop&SoS&
Mission&Pro#ile&

De#ine&SoS&Mission&
Success&Criteria&by&
Phase&

Determine&
Duration&of&each&
Phase&

Determine&SoS&
Mission&Essential&
Functions&by&
Phase&

Determine&SoS&
Mission&Essential&
Systems&by&Phase&

Figure 14: SoS Mission Description Process

1.2. Identifying Candidate Systems: As noted in [38], “The selection of the
constituent systems plays a crucial role in defining the quality of the SoS and its capacity
to deliver value and respond to uncertainty”. In this step, SoS needed capabilities are
identified and utilized for identifying capable candidate systems as shown in Figure 15.
An SoS performs a combination of mission essential functions in order to accomplish its
capability objectives within each mission phase. Systems functionality may change from
phase to phase as well as their criticality. SoS mission success results if all mission
essential functions for each mission phase is accomplished. Therefore, a Mission
Essential Function List (MEFL) will be developed that includes mission essential
functions of each phase. Mission essential functions are also used in defining high-level
capability requirements and identifying systems that are capable of performing essential
functions of the SoS mission.

39

Identify)SoS)
Needed)
Capabilities)

De:ine))High)Level)
Capability)
Requirements)

Establish)SoS)
Capability)
Objectives))

Identify)Alternatives)
to)Perform)Essential)
Functions)

De:ine))Essential)
Functions)Required)to)
Provide)the)SoS)
Capability))

Identi:ied)Systems)
System'1!
System'2!
System'3!
….!
System'n!

Figure 15: Process for Identifying Candidate Systems

1.3. Selecting Feasible Systems from Candidates: This step includes a screening
process to select feasible candidates from identified candidate systems. For each
identified candidate, three attributes of acquisition time, mission priority and acquisition
cost are evaluated and compared vs the requirements through a screening process. These
candidate systems are usually involved in concurrent missions, both by the organizations
that they are owned by and the SoS mission. Some may be idle at the time but they may
need to be available for higher priority missions. Mission priority is a new measure that is
introduced in this work to compare candidate systems missions to the SoS mission. This
attribute is explained in detail in chapter 5 – (Definition and Estimation of Decision
Attributes).
40

Requirements such as systems acquisition time, capability cost and mission priority
requirements are inputs of the methodology. Each candidate system that meets the
established requirements is selected as a feasible candidate system as shown in Figure 16.
In this Figure, tAC is the system i time to IOC, tR is the required time to acquire the
system, CAC is the system i acquisition cost, and CR is the cost requirement, which is the
maximum cost to acquire the system
Feasible System
Do Loop for all Identified
Systems, Si ,i = 1,2,…,n
Identifiy
Systems

Determine SoS
and System
Mission Priorities

Yes
Not Feasible System

No

CAC<
CR?

No
Estimate
Acquisition
Cost

System Mission Priority
<
SoS Mission Priority
?
Yes
Determine
Acquisition
Time

No

tAC<tR
?

Yes

Figure 16: Systems Screening Process for Identifying Feasible Candidates

1.4. Determining SoS Solutions: This step starts with combining various sets of
feasible candidate systems and generating all possible SoS solutions. It is very important
to recognize the feasible candidate systems, their capabilities and the role they can play in
providing the required capability and in the SoS mission. In this step, feasible systems are
41

mapped to mission essential functions of each phase based on their operational
capabilities. Mission essential functions may be performed by individual systems, by
subsets of systems or by the entire SoS [39]. Then, for each phase of the mission, all
possible combinations of systems that are collaboratively capable of performing SoS
mission essential functions of that phase are determined. SoSs with the same set of
systems but different configurations, e.g., series vs redundant, are considered to be
different SoSs.
SoS#Mission#Pro*ile#

Phase#

1#

2#

3#

4#

Duration#

t1#

t2#

t3#

t4#

F11#
F12#
…#
F1k#

F21#
F22#
…#
F2k#

F31#
F32#
…#
F3k#

F41#
F42#
…#
F4k#

"#

"#

Mission#Essential#Functions#

#

Feasible#Candidate#Systems#

"
#

i

i

i

i

S1#

!#

!#

S2#

!#

!#

"#

"#

S3#

!#

"#

!#

!#

…#

…#

…#

…#

…#

Si #

"#

!#

"#

"#

….#

…#

…#

…#

…#

Sn#

"#

"#

!#

!#

System#is#capable#of#performing#mission#essential#functions#of#the#corresponding#phase.#
#
#
System#is#not#capable#of#performing#mission#essential#functions#of#the#corresponding#phase.#

Figure 17: Mapping Feasible Systems to Mission Essential Functions of Each Phase

Phase 2: Selecting the preferred SoS solution: this phase is concerned with
evaluating SoS solutions in terms of the selected decision attributes and selecting the
preferred solution. There are three basic steps in phase 2:
2.1. Evaluating SoS solutions in terms of five decision attributes
2.2. Determining feasible SoS solutions
42

2.3. Selecting the preferred SoS solution
Each step is described below:
2.1. Evaluating SoS solutions in terms of five decision attributes: Each SoS solution that
has been determined in phase 1.4. is evaluated in terms of five decision attributes,
namely, mission reliability, basic reliability, time to IOC, capability cost and priority.
Estimation of each of the five decision attributes for each SoS solution is explained in
detain in chapter 5.
2.2. Determining feasible SoS solutions: In this step, a second round of screening is
conducted to determine a library of feasible SoS solutions as shown in Figure 18. The
calculated values of decision attributes for each SoS solution are compared to the
requirements to determine the feasibility of each SoS solution. Requirements including
SoS time, capability cost and basic reliability requirements are the inputs to the
methodology. The SoS mission reliability is limited by the reliability of the most critical
system of SoS or the weakest system in terms of reliability. If an SoS solution does not
meet the mission reliability requirement, redundancy can be added to the most critical or
the weakest system of this SoS to improve mission reliability of this solution.

43

List%of%Possible%SoS%
Solu.ons,%SoSi%

Solu.on%
meets%the%
MR%
requirements

No

?%

Do#Loop#for#All#
Possible#SoS#
Solutions#

No

Yes

Meet%%CCi%
requiremen?%

No

Yes

Yes

ReEEs.mate%decision%
aGributes%

Yes

Meet%%BR%
requirement?%

Feasible%SoS%
Solu.on%

Select%the%system%with%
lowest%mission%
reliability%and%add%
redundancy%with%the%
same%type%of%system%%

Meet%Time%to%
IOCi%%
requirements
?%

Not%a%
Feasible%
SoS%
Solu.on%

No

Figure 18: Screening Process for Determining Feasible SoS Solutions
CC: Capability Cost, BR: Basic Reliability, Time: Time to IOC, MR: Mission Reliability

2.3. Selecting the preferred SoS solution:
The feasible SoS solutions from the previous step and their estimated decision
attributes are used in this step to select the preferred SoS. The preferred solution may or
may not be the optimum solution in the solution space. This step can be formulated in
different ways, depending on the followings: (1) the number of objectives in selecting the
preferred SoS (single-objective or multi-objective), (2) Stakeholders knowledge about the
problem and their preferences (weights, utility, goals, etc) and finally (3) the adopted
approach (see Figure 19). The objectives are a function of one or a combination of
decision attributes.

44

Number'of'objec,ves'
in'selec,ng'the'best'
Alterna,ve'

More'than'
one'
objec,ve?'

Yes'

No'
Aggregate'
objec,ves''
Yes'
No'

Rank?order'op,ons'
based'on'one'
aDribute'

Stakeholders’'
preferences'
known?'

Yes'

Solve'a'Single?objec,ve'
Op,miza,on'Problem'
with'some'constraints'

Stakeholders’'
preferences'
known?'
No'
Solve'a'Mul,?
objec,ve'
Op,miza,on'Problem''

Select'The'Preferred'SoS'

Figure 19: Process for Choosing an Approach for Selecting the Preferred SoS

If only one decision factor (e.g. Cost) is important to stakeholders with no
preferences, the feasible solutions can be rank-ordered based on the selected decision
factor and the solution with the highest rank represents the preferred solution. The
problem of selecting the preferred SoS can be modeled as a single-objective optimization
model where stakeholders’ preferences are known and modeled as constraints. For
example, this problem can be formulated as minimizing cost subject to some constraints.
However, in many cases, a variety of objectives should be considered which turns the
problem into a multi-objective problem. A multi-objective optimization problem can be
solved by either combining all objective functions into a single-objective function or
acquiring a set of Pareto-optimal set [40]. Aggregating objective functions and solving a
multi-objective optimization problem can be accomplished by using techniques such as
weighted sum, goal programming and utility theory. This approach is more suitable when
45

stakeholders have enough information about their own priorities and understating of
possible solutions and available trade-offs to help decision-makers/analysts with
transforming their preferences and priorities into an appropriate set of weights for
objectives, reasonable goals or utilities.
A combination of these techniques such as Multi-attribute Tradespace Exploration
(MATE) can also be used. MATE is a quantitative method that provides a visual tool to
study the trades available between the solution spaces and attributes. Some advantages of
this method are its ability in determining solutions that result in little added value, but
much added cost and showing regions of the tradespace that provide value to multiple
stakeholders [41].
The other approach is obtaining a set of Pareto-optimal set through multi-objective
optimization techniques such as evolutionary algorithms (EA). The most commonly
developed EAs are MOGA (multi-objective genetic algorithm), NPGA (niched-Pareto
genetic algorithm), NSGA (non-dominated sorting genetic algorithm), SPEA (strength
Pareto evolutionary algorithm), PAES (Pareto-Archived Evolutionary Strategy) and
NSGA-II, These techniques are suitable for cases in which objective functions are
complex and representing a mathematical formulation of objective functions is not
possible [29].
For the purpose of this methodology, a hybrid approach is presented in chapter 7
that adopts data analysis methods and multi-criteria decision analysis to select the
preferred SoS solution. This approach ensures increased participation of SoS stakeholders
throughout the decision making process which will result in their higher acceptance of
46

the selected solution. This method, which is discussed in detail in chapter 7, involves
three phases of the SoS solution space (1) visualization, (2) simplification and (3)
ranking. Since the number of selected decision attributes were more than three, principal
component analysis (PCA) was used to project the five dimensional solution space into a
3D space. The 3D observation of the solution space without much loss of information
highlights existing patterns and trends. It also demonstrates if any further actions
(separate evaluation of outliers) need to be taken before the solution space simplification
step.
In order to enable communication among stakeholders, the SoS solution space,
which is often difficult to understand, will then be simplified using statistical data
clustering techniques, data envelopment analysis or a combination of both techniques.
Simplifying the solution space provides a smaller palette of the solution space for SoS
stakeholders to understand and discuss priorities. The third step of this method utilizes
stakeholders’ preferences to rank SoS solutions using a selected multi-criteria decision
method, namely PROMETHEE II.
4.4. Summary
In this chapter, preliminary design of the methodology for selecting the preferred
SoS was introduced in two steps: generating SoS solutions and selecting the preferred
SoS. Each step was also discussed in detail. Based on the methodology development
process, the next step was the methodology detailed design, which includes developing a
mathematical representation of different blocks for the methodology framework. These

47

blocks that include estimation of decision attributes for each SoS solution are discussed
in the next chapter.

48

CHAPTER 5
ESTIMATION OF DECISION ATTRIBUTES

Successful accomplishment of the mission requirements through an SoS solution
depends on a variety of technical and non-technical factors. Considering all relevant
factors as discussed in previous chapter was impractical due to the time limitation and
scope of this dissertation. Therefore, five decision attributes were selected in this work
based on their criticality in meeting SoS life cycle requirements.
The selected decision attributes are:
1. SoS mission reliability
2. SoS basic reliability
3. SoS capability cost
4. Time to SoS Initial Operating Capability (IOC)
5. Priority (SoS mission and systems)
This chapter provides a brief definition, background and also an approach for
estimating each of the selected attributes. In order to define and estimate each attribute, a
general SoS life cycle had to be defined. This chapter starts from defining the SoS lifecycle and then presents each decision attribute’s definition and estimation methods.

49

5.1. SoS Life Cycle
According to DoD 5000.2 [42] a defense system life cycle consists of the following
phases:

material

solution

analysis,

technology

development,

engineering

and

manufacturing development, production and deployment, operation and support.

Figure 20: Defense Systems Lifecycle [42]

For some SoSs, it may not be possible to define a life cycle due to the SoS
changing objectives, structures and resulting evolution. In this dissertation, the SoS life
cycle for an acknowledged SoS with purpose and central management is defined as four
cycles of Planning, Acquisition, Deployment and Dispersal (for either a single SoS
mission or a recurring SoS mission). The life cycle for SoS could span a short time, i.e.,
several days or a long period of time, years.
Planning

Acquisition

Deployment

Dispersal

Time

Figure 21: SoS Life Cycle

50

The Planning Phase includes interaction with SoS stakeholders, defining SoS
objectives and requirements, developing SoS concepts, modeling, trade studies, and
preparing the project’s detailed plans and schedule.
The Acquisition Phase consists of all the activities related to acquiring the required
(selected) systems to form the SoS. These systems could be existing systems or new
developments. In this dissertation, an established ground rule is that constituent systems
of the SoS are borrowed for an specific period of time to participate in the SoS mission
and they must be returned during the last phase of SoS life cycle which is called
Dispersal. Therefore, acquisition could be defined as the selection and taking possession
of existing systems to achieve SoS initial operating capability. The Acquisition phase
include planning and managing the activities required for the procurement of selected
systems and their support systems to provide the needed capability.
The Deployment phase is the phase in which acquired systems are prepared for
operation and deployed to accomplish the SoS mission (recurring and/or non-recurring).
SoS preparation involves SoS integration and development of interfaces as well as
maintenance and support. Operations, support and maintenance of the SoS take place
during this phase.
The Dispersal phase is the last phase in the SoS life cycle and consists of returning
constituent systems of SoS to their owners as most systems of an SoS are owned by other
organizations.

51

5.2. SoS Time to Initial Operating Capability (IOC)
5.2.1. SoS Time to Initial Operating Capability (IOC) Definition
Part of the decision-making in selecting systems for an SoS includes determining
those combinations of systems that can be ready for operation within the required time.
This factor plays an important role in mission and program success as prolonged SoS
initiation time impacts provision of required capability through SoS not being ready when
it’s needed [43]. Therefore, estimation of SoS required time to initial operating capability
is necessary for the methodology for selecting systems for an SoS.
As mentioned in previous chapters, the SoS life cycle starts with planning and then
acquisition, deployment and dispersal. The SoS time to IOC is defined as the time
required for achieving the needed SoS capability, which starts with the initiation of SoS
planning and ends with the SoS being ready for operation. Therefore, only the first two
phases of the SoS life cycle (planning and acquisition) impact its time to IOC.

SoS Planning SoS Acquisition

SoS Deployment

SoS Dispersal

SoS Initiation Phase
SoS Life Cycle
Figure 22: SoS Capability Development Phase as a Part of SoS Life Cycle

5.2.2. SoS Time to Initial Operating Capability (IOC) Estimation
SoS time to IOC can be broken down into two categories: planning and acquisition
times. Planning and acquisition activities determine the total amount of time required to
52

provide initial SoS capability in which planning includes defining capability objectives,
developing SoS and its constituent systems requirements, and identifying and evaluating
alternatives. Acquisition activities include systems acquisition and integration.
Developing a mathematical formula to calculate SoS time to IOC is challenging as
some of the tasks/activities may overlap each other as shown in Figure 23. The amount of
time required to carry out these activities can be estimated by consulting with experts
who have experience with similar development projects.
SoS Capability Development Time to Initial Operating Capability

Define
Capability
Objectives

Develop SoS
Requirements

Identify and
Evaluate
Alternatives

Acquire
Systems

Planning Time

Integrate,
Command
and Control

Acquisition Time

SoS Capability Need
Identified

Start Acquisition
Process

IOC

Figure 23: Capability Time to Initial Operating Capability vs. SoS Life Cycle

5.3. SoS Capability Cost
5.3.1 SoS Capability Cost Definition
SoS Capability Cost is a measure of affordability and it is defined as the total cost to
the customer for acquiring and owning the SoS over its lifecycle, from planning to
dispersal, that may span from months to years, in order to provide the required capability.
There are many cost challenges associated with planning and executing a system of
53

systems (SOS) mission. Cost Estimation of an SoS involves increased complexity due to
the number of individual/independent systems involved in the SoS missions, their
readiness (systems maturity level), various acquisition approaches, number of operational
scenarios, inconsistent interfaces and cost (asset) sharing [44],[45].
5.3.2. SoS Capability Cost Estimation Approach
There is a general process for project cost estimation in the literature [48],[49]. In
particular, the U.S. DoD has a long standing system acquisition and Life Cycle Cost
policy, guidance and methodology [50],[51]. The existing processes were modified for
SoS capability cost estimation in this dissertation. As shown in Figure 24., this process
starts from establishing ground rules and assumptions, defining SoS capability cost over
SoS life cycle, defining SoS capability cost elements and structure, evaluating and
selecting a suitable cost estimation method and finally estimating and documenting the
SoS capability cost over its life cycle.
Various cost estimating methods (expert judgment, analogy, parametric, engineering
and extrapolation of the actual cost) are evaluated and the one that best fits this
methodology is selected. A cost estimate for each cost element is obtained and prepared
for SoS capability cost estimation. The documented capability cost assists decision
makers in the selection of the preferred SoS by providing data for trade studies of level of
performance and affordability of candidate SoSs.

54

Establish Ground
Rules and
Assumption

Define SoS
Capability Cost
over its Life Cycle

Define SoS Cost
Elements and
Structure

Evaluate and
Select Cost
Estimation
Methods

Estimate and
Document SoS
Capability Cost

Obtain Cost Data

Figure 24: SoS Capability Cost Estimation Approach

5.3.3. SoS Capability Cost Elements and Structure
For the purpose of this methodology, the SoS capability cost structure was
developed to provide a cost estimate for each of the generated SoS solutions. The SoS
capability cost elements and structure are defined and explained in this section based on
the SoS life cycle. Since the SoS consists of existing systems, the required cost data
usually exists for each constituent system of a candidate SoS but will usually require
modification due to a different application.
The SoS capability cost is broken down into lower-level cost elements to form a cost
structure. The SoS capability cost structure captures all the costs associated with
providing the SoS capability at both SoS and system-level throughout the SoS life cycle.
SoS capability cost is the summation of the cost of SoS capability at both SoS and system
level from planning to dispersal. Figure 25 shows capability cost elements for calculating
the cost and performing trade studies in this methodology to select the perferred SoS.

55

SoS Capability
Cost

Cost of SoS
Acquisition

Cost of SoS
Planning

Cost of SoS
Engineering
Efforts

Cost of SoS
Integration

Cost of Manpower
for Each SoS
System

Cost of Operating
Resources for Each
SoS System

Cost of SoS
Deployment

Cost of SoS
Operations and
Support (O&S)

Cost of
Maintenance for
Each SoS System

Cost of SoS
Dispersal

Cost of SoS
Command and
Control

Cost of Support for
Each SoS System

Figure 25: SoS Capability Cost Elements

The cost elements shown in the SoS capability cost structure are identified as major
cost drivers in providing a new SoS capability over its life cycle. As shown in Figure 25,
at the SoS level, there are four categories of cost as:
1. Cost of SoS Planning
•

Cost of SoS Engineering Efforts

2. Cost of SoS Acquistion
•

Cost of SoS Integration

3. Cost of SoS Deployment
•

Cost of SoS Operations and Support

•

Cost of SoS Command and Control

4. Cost of SoS Dispersal

56

Each cost element is defined in detail in this section:
Cost of SoS planning: It is the cost of coordinating the SoS project including defining
objectives, developing SoS concepts, preparing detailed plans and schedule, acquisition
tasks and managing the SoS project. This cost also includes the cost of engineering
efforts which reflects the total cost of SoS engineering activities performed for providng
SoS capability including systems engineering efforts, e.g. requirements identification and
analysis tasks at both SoS and system level, capability risk analysis and mangement,
specialty engineering activities (e.g., security, safety, reliability and software engineering
activities) and managing and executing test plans. A cost model was developed by
Valerdi (COSYSMO) to estimate the Systems Engineering effort for large-scale systems
[52].
Cost of SoS Acquisition: Constituent systems of an SoS are often owned by different
organizations and they are usually called on to participate in the SoS mission for a period
of time. Cost of SoS acquisition is the cost of acquiring each constituent system of an
SoS which reflects the cost of leasing, borrowing or owning the system for a specific
period of time (e.g. hours, days, months or years). Cost of SoS acquisition also includes
the Cost of SoS integration. This cost element is particularly considered in the SoS
capability cost estimation because interoperability is the key enabler of a successful SoS
and to achieve interoperability, some form of integration is required. According to
Jamshidi [53], SoS Integration implies that each constituenet system of an SoS can
communicate, interact and take commands from other parts of the SoS with no
compatibility issues. Accordin to Madni [3], “SoS Integration (SoSI) involves interfacing
57

and enabling the interactions of component systems to create the needed SoS capability
to accomplish mission or business goals”. Constituent systems of an SoS are usually
designed for different purposes and they are at different stages of their life cycles. This
means that they may not have the ability to communicate and cooperate with each other
especially when there are legacy systems involved in an SoS mission. Thus, all
constituent systems need a common language to communicate. The cost of SoS
integration includes the cost of building interfaces to enable systems cooperation. This
can be made possible by modifying constituent systems (especially legacy systems) and
providing them with required interfaces to enable direct communication among systems.
This cost includes the cost of integration personnel, cost of integration equipmnet, and
cost of testing the developed interface.
Cost of SoS Deployment: This cost includes two categories of cost as:
•

Cost of SoS Command and Control: The U.S. DoD defines Command and
Control (C2) as: "The exercise of authority and direction by a properly
designated commander over assigned and attached forces in the
accomplishment of the mission [54]”. In order to accomplish an SoS mission,
SoS authorities must be able to lead and manage activities and SoS resources
to achieve the capability objectives. The cost of SoS Command and Control
(based on the definition of the world wide military command and control at
[55]) is the cost of arranging the SoS personnel, equipment, communications,
facilities, and procedures employed by SoS authorities in planning, directing,
coordinating, and controlling the SoS operational activities.
58

•

Cost of Operations and Support: O&S cost is the total cost of operating,
maintaining and supporting the SoS throughout its lifecycle. This cost is a
critical element as it tends to comprise a large portion of the total SoS life
cycle cost. Here, the 2014 Operating and Support Cost Estimating Guide
(O&S Guidebook) [50] is used to define this element in detail. The O&S cost
includes the costs of personnel, equipment supplies, software, and services
associated with operating, maintaining, supplying training and supporting the
SoS. The SoS O&S cost elements are:
o Cost of manpower includes the cost of skilled personnel to operate,
support and maintain each constituent system of SoS over its life cycle
o Cost of operating resources includes the cost of operating material
(e.g., fuel) and transportation.
o Cost of maintenance includes all maintenance (unscheduled and
scheduled) needed to keep the constituent systems of the SoS in an
operational state including manpower and consumable material for
repair.
o Cost of support for each constituent systems of SoS includes the cost
of support services including training, support equipment, test
equipment and spares. Here, the acquisition cost of support systems is
not considered. For each constituent systems of SoS, the required
support systems can be acquired from the system owner during SoS
deployment, as needed.
59

Cost of SoS Dispersal: is the cost of returning each constituent system to their owners
at the end of the SoS life cycle. This cost include the cost of personnel managing the
activity of returning or retiring the systems. Besides the cost of managing the SoS
dispersal, there is a cost at the system-level for dispersal of each constiuent systems. This
cost includes the required activities for preparing and returning each constituent system
which may be different from one system to another.
SoS capability cost can also be grouped into two categories: Non-recurring costs and
recurring costs. Non-recurring costs are one-time costs, while recurring costs occur on a
continuing basis over the SoS life cycle. SoS capability cost includes the non-recurring
costs of planning, acquisition and integration and dispersal to the recurring on-going cost
of SoS deployment including the on-going cost of command and control, the on-going
cost SoS operation and support, the on-going cost of SoS maintenance, and the on-going
cost of SoS manpower.
Cost of SoS Planning - Engineering Efforts
Non –
Recurring Cost

Cost of Systems Acquisitions - Integration
Cost of Systems Dispersal

SoS
Capability
Cost
Recurring
Cost

Cost of SoS
Deployment

Cost of SoS Command
and Control
Cost of Manpower
[Operation, Maintenance & Support]

Cost of Operation
& Support
(O&S)

Cost of Operation Resources
(e.g. Fuel)
Cost of Maintenance
Cost of Support

Figure 26: Non-recurring and Recurring Cost of SoS Capability

60

5.3.4. Evaluation of Current Cost Estimation Methods
Estimation of SoS life cycle capability cost can be made by using one of the
following four cost estimating methods: a) Expert Judgement; b) Analogy; c) Statistical
(Parametric); d) Engineering (Bottoms Up); and E) Extrapolation of Actual Costs [56].
The application of these methods in different projects depends on when the estimate is
needed and also the type of data available. Each of these cost estimating methods is
briefly explained in this section:
Expert judgement: This method captures the knowledge of a group of experts who
have had experience with similar projects by using questionaires and interviews [57]. It
can be used at different stages of an acquisition project and it is more appropriate when
data does not exist.
Analogy: This method uses similar systems or projects for comparative analysis [58].
Analogy which is more appropriate for a sanity check of already developed estimates
requires acurate data and detailed cost of the analogous systems. It is mostly used when
the system is not yet well defined and similar projects or systems exist. The advantage of
this method over other existing methods is its fast and inexpensive implementation.
However, there is risk related to the cost estimated by this method as it requires
subjective experts in identifying similar projects.
Statistical: As a system begins to become more mature, more robust methods can be
used such as a Statistical (Parametric) method. Parametric methods are based on cost
estimating relationships (CERs) algorithms which are mathematical relationships
between independent and dependant variables. This method can be used for identifying
61

the impact of different performance parameters on cost during early phases of a program.
The advantage of this method is that it is fast, easy to use, acurate and does not require a
lot of information [51], [52].
Engineering (Bottoms-Up): This method starts from lowest level of an SoS such as
its systems or subsystems and builds a cost estimate from the lowest level to the top.
Compiling the cost estimates from the bottom to the top level provides a system-level
cost estimate. In other words, it provides cost estimates for different systems, intefaces,
and management, one at a time, then sums all the piece from the lowest level to the top to
provide a single high level SoS cost estimate. This method can be used when more
detailed costs are available and it is mostly used when the SoS operation is well defined.
Although expensive and labor intensive, thie method provides more detail and visibility
into the cost drivers.
Extrapolation of the actual cost: This method estimates the future cost using the
actual current or past cost data [51]. It requires detailed and accurate data and as a result
it is more suitable at low rate initial production (LRIP) or full rate production (FRP)
phases of an acquisition process when actual data exist [57]
5.3.5. SoS Capability Cost Estimation and Documentation
For the methodology presented in this work, a cost model is developed for estimating
the capability cost of SoS solutions over the life cycle. The notations used in the SoS
capability cost model are presented in Table 1 and a cost model taking into consideration
the basic costs of SoS throughout its life cycle is given by:

62

c
p
A
Dep.
Dis.
CSoS
= CSoS
+ CSoS
+ CSoS + CSoS

where

(5-1)

c
p
CSoS
is the SoS capability cost, CSoS is the non-recurring cost of SoS
A

Dep.
Dis.
planning, , CSoS is the cost of SoS acquisition and CSoS , CSoS are, respectively, the

recurring cost of SoS deployment and non-recurring cost of dispersal. In equation (5-1):
P
Cd
EA
CSoS
= CSoS
+ CSoS

(5-2)
k
A
SoS

C

I
= ∑ cSiA + CSoS
i=1

Dep.
O&S
C3
CSoS
= CSoS
+ CSoS

(5-3)
(5-4)

k
Dis.
SoS

C

= ∑ cSidis.

(5-5)

i=1

The SoS cost of operation and support is the sum of the cost of O&S for all the
systems of SoS for the duration of their own missions. Systems O&S cost and the cost of
SoS C3 (command, control and communication) are functions of operating time of the
constituent systems and the SoS and the operating time between missions if the SoS life
cycle consist of recurring missions.
k
O&S
SoS

C

= ∑ ciO&S (ti )
i=1

(5-6)

63

ciO&S (ti ) = CiS (T ) + cimp (T ) + cir (ti ) + CiM (T )
(5-7)
pi

T
* CFij
j=1 MTBFij

C =∑
M
i

(5-8)

In equation (5-8), MTBF includes all failures that require maintenance actions, not
only the failures that lead to mission abort.
Table 1: List of Symbols for Capability Cost Estimation
Name

Description

Name

Description

SoS

System of systems SoS
={S1,S2,…,SK}

C3
CSoS

Cost of SoS communication, command
and control

k

Number of systems in an SoS

Si

System i

pi

Number of subsystems on system i

ti

Mission duration of Si

MTBFij

MTBF subsystem j on system i

T

SoS deployment time

CFij

Cost of failure for subsystem j on system i

c
CSoS

SoS capability cost over its
life cycle

ciI

Cost of integration for Si

p
CSoS

Cost of SoS planning

ciO&S

Total cost of operation and support for Si

EA
CSoS

Cost of engineering activities

cd
CSoS

Cost of coordinating SoS acquisition

cir

Cost of operating resources
for system i (i.e. fuel)

cSiA

Cost of acquisition for Si

cimp

Cost of manpower for Si (for
operation, support and
maintenance)
Cost of maintenance for Si

CiS

Cost of support for Si

cidis.

Cost of dispersal for Si

CiM

64

Since candidate SoS solutions consist of existing systems, detailed data (i.e. cost of
operation and support data) should be available for existing systems from their previous
mission operations. Even though the existing data may not be the same as what’s needed
for SoS mission, it can still be modified for different use in the the SoS capability cost
estimation. For similar systems and projects, Analogy and Expert judgment can be used
for a sanity check of the estimated SoS capability cost.
5.4. SoS Mission Reliability
5.4.1. SoS Mission Reliability Definition
SoS mission reliability is a primary measure of mission effectiveness and is defined
as the conditional probability of a SoS performing its mission essential functions given
that all the mission essential systems (MES) and equipment (MEE) are up at the mission
start. It is based on failures that lead to mission loss/abort and can also be stated as the
probability that an SoS can complete its required operational mission without an
operational mission failure (OMF). An OMF is a failure that keeps an SoS from
performing one or more mission essential functions [46]. SoS mission reliability may be
improved in two ways: (1) by redundancy, since having multiple components in parallel
configuration reduces the risk of mission failure, and (2) by selecting systems with higher
mission reliabilities.
5.4.2. SoS Mission Reliability Estimation
When selecting systems for an SoS, engineers and decision makers are interested in
identifying those systems that when connected to the network of the SoS meet the
65

probability of SoS mission success requirements. A methodology and mathematical
framework for modeling and analysis of SoS lower bound mission reliability is presented
in chapter 6 that is used in our methodology.

5.5. SoS Basic Reliability
5.5.1. SoS Basic Reliability Definition
SoS basic reliability is a measure of sustainability and O&S cost. According to
MIL-STD-785B, Mean-Time-Between-Failures (MTBF) as a measure of basic reliability
includes “all item life units (not just mission time) and all failures within the item (not
just mission-critical failures of the item itself)” where time (T) indicates the total
operating time and failure (F) is any event that requires maintenance. Basic reliability
requirements apply to all elements of an SoS (MIL-STD-785B).

5.5.2. SoS Basic Reliability Estimation
The objective of our methodology is to find the best SoS solution while balancing
all decision attributes including both basic and mission reliability. MTBF of an SoS
candidate (SoSi) as a metric of its basic reliability can be calculated as follows if the time
to failure of each element has the exponential distribution:

MTBFSoSi =

1

λSoSi

where
66

(5-9)

k

n

λSoSi = ∑∑ λij

(5-10)

i=1 j=1

where λij is the “failure” of subsystem j (for j=1,2,…,n) on system i (for i=1,2,…,k)
where k is the total number of systems constituting SoSi solution and n is the total
number of subsystems on a single constituent system. If there exist N SoS solutions, the
MTBF is calculated for all N SoS alternatives to be used in comparison of alternatives
and selecting the preferred one.
Basic reliability decreases with redundancy as it moves in the opposite directions
with the number of systems in SoS. For example, in the following hypothetical SoS
configuration that involves four systems (A, B, C and D), the reliability block diagram
for both mission and basic reliability is the same.

Reliability)Block)Diagrams)
(Mission)Reliability))
A"

B"

C"

Reliability)Block)Diagrams)
(Basic)Reliability))
A"

D"

B"

C"

D"

Figure 27: Mission and Basic Reliability Configuration for a Notional SoS with Four Systems

By creating redundancy for mission critical systems A and C as shown in Figure
28, SoS mission will be more reliable. However, the basic reliability of the mission in this
case will be lower than a non-redundant configuration. This is due to the fact that basic
reliability considers all failures, including those that might not result in SoS mission
failure, but do result in maintenance actions.

67

Reliability)Block)Diagrams)
(Mission)Reliability))

A"
A"

B"

C"
C"

Reliability)Block)Diagrams)
(Basic)Reliability))

A"

A"

B"

C"

D"

C"

D"

Figure 28: Mission and Basic Reliability Configuration for the Notional SoS - Adding Two Systems

5.6. SoS Priority
Systems of systems are often generated through partial participation from
independent, existing systems with their own assigned missions. These systems are
usually owned by different organizations and their contribution to an SoS may be
dependent on changing priorities and conditions [47]. Therefore, while selecting systems
for an SoS, priorities should be considered due to the lack of availability of
identified/capable systems (or willingness of their owners) for participating in the SoS
mission. The objective of this methodology is to systemativcally select an SoS solution
with the highest priority level while considering all the other decision attributes.
5.6.1. SoS Priority Definition
SoS Priority is introduced and considered as a decision attribute in this work to
compare various systems and SoS solutions in light of conflicting priorities of different
organizations. In order to evaluate and compare systems in terms of their availability and
capability level for an SoS mission, a priority measure was used. Two types of priorities
are needed: mission priority and systems priority.
Mission priority indicates the importance of the SoS mission and systems missions
68

based on consequences of SoS mission loss. As stated before, systems that are considered
for the SoS mission may already be assigned to other missions. In this case, systems’
missions will be compared to the SoS mission to decide on the availability of systems for
participating in the SoS mission. A priority value is assigned to the SoS mission and each
candidate system’s mission from a predefined set of values to compare the importance of
their missions. If the SoS mission receives a higher priority value than the candidate
system’s mission, then the candidate system is a feasible system for participation in the
SoS mission. This type of priority is used in developing a library of feasible systems for
use in generating SoS solutions.
System priority is a measure of the criticality of each system of an SoS in providing
the required capability. This priority type is used in calculating the SoS Priority Level
Index (PLI) and utilized in the second step of the methodology for comparing SoS
solutions and selecting the preferred candidate. SoS PLI is a function of the capability
and criticality level of each system of an SoS in providing the required SoS capability.
Even thought it is always desirable to have more capable systems involved in the
mission, putting an affordable and highly capable set of systems together to form an SoS
is challenging in most cases (see Figure 29). Therefore, SoS priority was used in trading
capability and cost while selecting the most ideal SoS candidate.

69

Capability

SoS Priority

Reduced
capability
Minimum required
capability to meet
operational need

Program cost
requirement

SoS Cost
Reduced Cost

Figure 29: The Role of Priority in Trading Cost and SoS Capability

5.6.2. SoS Priority Level Index Estimation
SoS PLI is a function of criticality and capability of SoS constituent systems. For
SoS solution j (SoSj), two values of capability (Ci) and criticality (Wi) from a set of predefined values are assigned to each system of the SoSj. The capability value represents
the capability level of a system and the criticality value represents the importance of a
system in providing that SoS capability.
In order to calculate a PLI value for each SoS solution, a priority value from a set
of pre-defined values is assigned to each constituent system of SoS solution.

The

assigned values to each system are then combined to a single priority value that is called
the Priority Level Index (PLI) and represents the priority of each SoS solution. If an SoS
solution is comprised of k systems (j=1,2,…,k in which k is a variable and changes from
one SoS solution to another), a Normalized Weighted Average function is used to
70

integrate systems’ capability and criticality values to calculate a single PLI for the SoS
solution as follows:
kj

PLI SoS j = ∑ (
i=1

Wi
). Ci
WT

(5-11)

where WT is the total weight of SoSj and calculated using equation (5-12):
kj

WT = ∑Wi
i=1

(5-12)

where Wi represents criticality of system i, kj is the total number of constituent
systems of SoSj and The PLI SoSi represents the priority of SoSj for j=1,2,…N.
The set of values W1, W2,…, Wkj can be defined as a result of negotiation among
stakeholders and analysts. Here, we used a 4-level scale in which Wi is considered to be
1000 for essential systems, 100 for desirable, 10 for optional and 1 for systems with
minimal role in providing SoS capability and Ci is assigned from 1 to 4 with 4 being the
most capable and 1 being the least capable system. For example, if the system is essential
for providing SoS capability, a value (W) of 1000 could be assigned to that system,
however, if the system is planned to be used as a redundant or stand-by system, a lower
importance value (i.e. 100) is assigned to that system.

71

Table 2: Pre-defined Set of Values for System i Criticality and Capability Evaluation
Predefined Set of Values for Criticality
Evaluation

Predefined Set of Values for Capability
Evaluation

System’s Criticality

System’s Capability

Wi

Ci

Essential

1000

High

4

Desirable

100

Desirable

3

Optional

10

Moderate

2

Minimal Role

1

Low

1

These values are assigned to each system of SoSj for j=1,2,…,N. The pre-defined
set of values are the inputs to the methodology, which will then be combined to a single
value called PLI using equation (5-11).
Example: In order to illustrate the estimation of PLI, a notional SoS solution is used
for accomplishing a search and rescue mission. The SoS considered includes five
constituent systems, three different types of airplanes (A1, A2, and A3), a helicopter and a
ship to conduct the mission. The three airplanes are required to search three different sub
search areas and the helicopter conducts the rescue while the ship is present in the area
(as standby) to get involved in the rescue if necessary. The objective is to estimate the
PLI for the defined SoS solution using the approach presented in this section.
First, Table 2 should be filled out for all five constituent systems of the SoS to
estimate the PLI. Since all three airplanes are required to search three sub areas, they are
all essential (critical) to complete a successful mission. Let A1 be the most capable
airplane in terms of speed, range, communication and navigation while A2 and A3 are
respectively less capable in terms of those capabilities. The helicopter, which is required
for rescuing survivors, is also essential while the ship, which starts in standby mode, may
72

not be as critical, therefore, we assigned the helicopter, the highest criticality and the
ship, the desired criticality (100). Lets assume that the helicopter is lacking an auxiliary
fuel tank (which is not required but it’s desirable) while satisfying all the other capability
requirements. In this case, the capability value that could be assigned to the helicopter is
3. Also for a similar reason, a capability level of 3 is assigned to the ship (see Figure 30)
For the SoS defined in this example, the PLI calculated using equation (5-11)
equals 3. Using equation (5-11), the maximum PLI (where all systems involved are
highly essential and highly capable) for an SoS with five constituent systems is 4 and the
minimum PLI for this case is 1.

73

Figure 30: Estimation of PLI for the Notional Search and Rescue SoS

5.7. Summary
This chapter provided the definition and estimation for four selected attributes of SoS
time to IOC, capability cost, basic reliability and priority. Chapter 6 covers the
methodology and model for estimating a lower bound mission reliability for SoS
solutions. The approach presented for estimating each decision attribute consitutes
74

different blocks of the methodology which will then be integrated for selecting the
preferred SoS.

75

CHAPTER 6
SYSTEM OF SYSTEMS MISSION RELIABILITY MODELING AND ANALYSIS

The challenge in collaboration of operationally independent systems (SoS) is in
achieving interoperability among systems and evaluating the key performance metric for
SoS mission effectiveness, namely mission reliability. The DoD’s acquisition policies
mandate that reliability be a Key Performance Parameter (KPP) for all systems and
System of Systems (SoS) [59]. When selecting systems for an SoS, engineers and
decision makers are interested in identifying those systems that when connected to the
network of the SoS that increase the SoS probability of mission success requirement.
Therefore, reliability modeling and analysis of the SoS mission is an integral element in
selecting the preferred SoS. In this chapter of the developed methodology, different SoS
solutions are evaluated in terms of their estimated mission reliability.
Reliability is formally defined as “the ability of a system to meet a given set of
requirements for a given period of time in a given set of conditions”. The reliability of an
SoS is described by “its ability to deliver a certain level of one or more functional
capabilities over a mission’s duration” [60]. SoS mission reliability, as a measure of SoS
mission effectiveness, is defined as the probability of successfully performing the SoS
mission essential functions for a specified mission given that all the systems, subsystems
and equipment are up at the mission start. Mission reliability as a metric that quantifies
76

the probability of SoS mission success is a critical factor in choosing systems for an SoS.
Evaluating SoS mission reliability is challenging due to the SoS dynamic operational
environment, which will be discussed in section 6.1.
Further complicating the reliability modeling and analysis of SoS missions is the
degree of interoperability of the constituent systems. Interoperability refers to the ability
of systems to work with each other with no compatibility issues and is the key enabler for
systems of systems. It provides SoS capabilities that are greater than the sum of its
constituent systems capabilities [37]. Multiple definitions have been introduced for
interoperability but these definitions keep changing, as new and more capable systems
are developed and more interactions between systems becomes possible in today’s
environment. U.S. Department of Defense (DoD) has multiple definitions for
interoperability, one of which is “The ability of systems, units, or forces to provide
services to and accept services from other systems, units, or forces, and to use the
services so exchanged to enable them to operate effectively together [DoD 01a] [61].
Interoperability of SoS can be very challenging as systems of an SoS are usually designed
for different purposes and may be at different stages of their life cycles. For example, in
an SoS, comprised of existing systems, some systems may not be capable of interacting
with other systems of the SoS, which may prevent systems from being fully functional. In
this dissertation, interoperability refers to the ability of constituent systems to work with
each other through exchanging information directly and satisfactorily [62]. Exchange of
information or data sharing capability refers to transferring data generated by one system
to the other systems involved in the SoS mission. This capability may greatly improve the
77

probability of SoS mission success. Data sharing may also avoid unnecessary cost of
providing all systems with high capability and expensive sensors. Having data sharing as
a redundant capability, as considered in this work, ensures that systems can be provided
with the required data even if they are not capable of generating data through their own
capabilities (e.g. sensor failure). The benefit of data sharing reaches its maximum if all
the systems of SoS participate in data sharing, however, this adds a new degree of
complexity to the SoS operation and its mission reliability analysis.
In this chapter, a methodology and mathematical framework for reliability
modeling and analysis of SoS missions is presented. This method estimates lower bound
mission reliability for an SoS operating a phased mission. It is based on defining and
describing the mission of SoS in terms of phases, i.e. durations, mission essential
functions and success criteria. This method estimates the lower bound of mission
reliability for two cases in which SoS constituent systems:
(1) are not capable of sharing data.
(2) are capable of sharing data.
Since data sharing among the systems is the key enabler of effective SoS operation,
the function of data generation and sharing function is modeled as a redundant common
SoS mission essential function. The methodology and framework developed for
estimating SoS mission reliability is an integral part of the methodology for selecting the
preferred set, number and configuration of systems for an SoS capability during SoS
acquisition and mission planning.

78

6.1. SoS Mission Environment
A SoS mission consists of multiple, consecutive, non-overlapping phases in which
each phase has different functional requirements and therefore different failure criteria
from other phases. Systems that are assigned to an SoS mission will each perform their
own phased missions within which certain functions will contribute to the overall SoS
mission. An example of a single system performing its own phased mission is an aircraft
that includes phases such as taxi, take off, climb, cruise, descent, land and taxi as shown

Descent&

in Figure 31 [63].

Phases&

Figure 31: An Aircraft as a Single Phased-Mission System

An SoS is often comprised of multiple complex systems of which some or all may be
identical. Different SoS mission essential functions may be carried out concurrently by
different systems. This differentiates an SoS mission from a single phased-mission
system.
The optimization of each system of an SoS does not guarantee the optimization of the
overall SoS [64] and also the loss of any part of the system may or may not degrade the
79

performance or capabilities of the SoS. The impact of systems performance degradation
on the SoS performance depends on whether their assigned task is a SoS mission
essential function or not.
During the execution of mission phases, the SoS can be dynamic such that the
systems and subsystems involved, their failure characteristics, or the reliability
configuration (series/parallel) at both SoS and system level may change from one phase
to another to accomplish different capability objectives. Also, systems may start their
own phased mission before the SoS mission starts, they may join or leave the SoS, their
status may change from active to standby or they may no longer be required during the
mission.
Many of SoSs operate in hostile, harsh or remote environments where mission failure
may cause severe consequences. Most systems are non-repairable during the SoS
mission, e.g. space systems. Hence, systems are considered to be non-repairable during
their missions in the methodology presented here.
6.2. Review of Approaches to Phased-Mission Reliability Modeling and
Analysis Techniques (Single and multi-system missions)
There exists a significant body of work in the area of mission reliability modeling
and analysis of a single complex system having a phased mission using techniques such
Bayesian Networks, Markov models, Binary Decision Diagrams (BDDs), Simulation and
Hybrid methods [65],[67].
Mission reliability modeling and analysis of an SoS is different from a single
complex system in that systems of an SoS (unlike equipment of a single complex system)
80

are operationally independent and not hierarchically structured. In the area of cooperating
systems or multi-system missions, techniques such as BDD [68], simulation [69] and
Colored petri-Nets [70] have been used in the literature. Each approach that has been
used in previous work has its own advantages and disadvantages. Even though shared
communication was considered in some previous work related to cooperating platforms
[68], data sharing has not been considered and modeled as a redundant function to
provide systems with the required data when their own data generating capabilities are
not available.
In this section, existing techniques and their advantages and disadvantages are
reviewed and evaluated to select a method that best fits the SoS system selection
methodology. In general, there are two classes of approaches to phased-missions
reliability analysis, analytical modeling and simulation. Analytical methods, as shown in
Figure 32, can incorporate a desirable combination of flexibility in representation, as well
as ease of solution. The analytical methods can be further categorized into three types,
namely: 1) combinatorial methods; 2) state-space-based methods, in particular, Markovbased methods (homogeneous, and non-homogeneous), and Petri nets; and 3) phase
modular methods that combine the former two methods.

81

Mission&Reliability&
Modeling&and&Analysis&
Techniques&

Figure 32: Existing Mission Reliability Modeling and Analysis Techniques

The Combinatorial approach is the simplest one. This approach is applicable for
phased mission systems that exhibit no dynamic behavior, transient errors or imperfect
fault recovery. This method involves connecting the reliability block diagrams/FTs/BDDs
of each phase in series and then solving for the reliability of the system [71]. The most
widely used combinatorial models are FT (Fault Tree) and Reliability RBD (Block
Diagram) [69].
The Fault Tree is a method for representing faults of a system in a logical manner
by identifying undesired states and conditions that lead to undesired states of that system.
A limitation of fault trees is their binary structure, which means that system phase
operations can only be modeled as fully operational or completely failed [65]. Also, Fault
Tree models cannot handle dynamic system behavior, such as repairable modules. This
limitation has been overcome in the past by converting the Fault Tree model to a Markov
chain and then adjusting the Markov chain to account for the dynamic behavior in the
system. This technique is cumbersome and not very intuitive [71]. Also, calculation of
82

minimal cut sets can be a time consuming task, even for moderate sized problems (FTs)
[72].
A reliability block diagram (RBD) is a diagrammatic method for showing how
component reliability contributes to the success or failure of a complex system. RBD is
also known as a dependence diagram (DD). A RBD or DD is drawn as a series of blocks
connected in different configurations, e.g., series, parallel or general configuration. Each
block represents a component of the system with its associated failure rate. [73]
Although the RBD and FT methods are commonly used, they are limited in their
modeling capacity of systems that have no sequential relationships among their
component failures. They do not provide any capabilities to model reliability interactions
among components or subsystems, or to represent system reliability configuration
changing (dynamics), such as: load-sharing, interferences, dependencies, common cause
failures, and so on. To overcome this deficiency, Dugan et al. developed the dynamic FT
(DFT). DFT extend static FT to enable modeling of time dependent failures by
introducing new dynamic gates and elements. DFT adds a temporal notion, by which the
system failures can depend on the order of component failures. It can model dynamic
replacement of failed components from pools of spares (CSP, WSP and HSP gates);
failures that occur only if others occur in certain orders (PAND gates); dependencies that
propagate the failure of one component to others (FDEP gates); and specification of
constraints on failure orders that simplify analysis computations (SEQ gates). Dynamic
fault trees use Markov models as analytical representations [74].

83

Dynamic RBD has also been developed to formalize the concepts of state, event
and dependence, providing a logic infrastructure to define several dynamic reliability
behaviors. In a DRBD model, the condition of each component is characterized by a
variable state identifying the operational condition of the component at a given time. The
evolution of a component’s state (component’s dynamic) is characterized by the events
occurring to it. The states a generic DRBD component can assume are: active if the
component works without any problem, failed if component is not operational, and
standby if it is reliable but not available [75].
Even though DFT and DRBD allow dynamic modelling of system behaviour, they
are complex and less readable, therefore, not easy to work with [76].
Binary Decision Diagram (BDD) is a method based on FT that reduces the
computation complexity. If the system is non-repairable and only one mission cycle is
considered, the binary decision diagram (BDD) method can be applied [Ref. RM
Techniques]. However, the BDD method is limited by the problem size. When the system
reliability configuration is complicated and the number of components is large, especially
when the system reliability of multiple mission cycles needs to be evaluated, using a
BDD will not be easy and straightforward [77].
Bayesian Network (BN) offers more than FTAs when it comes to modeling power.
However, the main barrier of traditional BN is that it can only deal with discrete

variables, i.e., it can not handle hybrid models with general static and time-dependent
failure distributions, where both continuous and discrete variables are considered
[78],[79].
84

FTA model can be transformed into equivalent discrete BN using quite
straightforward techniques (Bobbio et al., 2001) [80].
State Space based methods: For reliability evaluation of dynamic systems with
dependencies among components and/or variable structures, it is not possible to use
combinatorial models. Techniques such as state space methods (Markov models, Petri
nets

(PN),

Boolean

logic

driven

Markov

process

(BDMP),

etc),

hybrid

(combinatorial/state space) techniques, or simulation (Monte Carlo) are needed [81].
The State Space oriented approaches, which are based on Markov chains, are
flexible and powerful in modeling complex dependencies among system components.
However, they suffer from state explosion when modeling large-scale systems. The basic
idea to use Markov chain in calculating reliability of a system with a phased mission is to
construct a single Markov chain to represent the failure behavior of the entire mission or
several Markov chains, each representing the failure behavior in each phase. These
Markov models at once account for dependence among components within a phase as
well as dependence across phases for a given component. Solving Markov chain models
yields the probability of the system being in each state [65]. The main problem with
current Markov modeling techniques is the state explosion problem and handling of nonexponential distributions [71]. If the system is repairable and the life and repair time
distributions of components are exponential, the continuous time Markov chain methods
are well developed [77]. The major limitation with Markov methods is that if the failure
criterion in only one phase is dynamic, then a Markov approach must be used for every

85

phase. Due to the well-known state explosion problem of Markov approaches, it is often
computationally intensive and even infeasible to solve the model [65].
Phase Modular Method: Ou and Dugan [65] proposed a modular solution, which
divides a phased mission into its static and dynamic modules. Static modules are solved
using a combination of BDD solution techniques, while dynamic modules are solved
using Markov chain solution techniques. Then combines the results for the solution of the
entire system using the module joint probability method. The phase-modular approach
provides exact reliability measures for missions with dynamic phases in an efficient
manner [65].
Besides analytical methods, there has been extensive research on simulation-based
phased mission reliability evaluation. Monte Carlo simulation allows modeling of any
reliability distribution without particular restrictions when the distribution is specified
[69]. Simulation methods typically offer great generality in system representation but are
often expensive in computational requirements [82]. Therefore, they may not be the best
option due to the time taken to perform a sufficient number of simulations to obtain
convergent results.
Due to all the limitations that have been listed in this section, combinatorial
methods appear to offer greatest opportunity for performing the real-time analysis of SoS
mission reliability that is required in this methodology. This method exploits Boolean
algebra and RBD/DD to achieve low computational complexity. The analysis may give
us an approximation for the SoS mission reliability instead of an accurate value but it is
fast and does not require extensive computational resources.
86

6.3. A General Process for SoS Mission Reliability Analysis and Modeling
There is a well-established methodology for mission reliability modeling and
analysis of a single system. I have modified this methodology for use in the analysis of
system-of-systems mission reliability. Mission reliability analysis of an SoS starts at the
SoS level from defining SoS mission objectives and developing SoS mission profile. An
SoS mission profile includes length of the mission, mission phases and duration of each
phase. The phases of the SoS mission are represented by phase number, phase duration
and systems involved in the mission and their configuration. SoS mission essential
functions of each phase are determined along with the systems required to accomplish
those functions. Success criteria of each phase must also be developed.
The analysis then continues to the system level where constituent systems of the
SoS are treated as independent phased-mission systems. As mentioned before, systems
that are assigned to an SoS, perform their own phased-mission while completing their
assigned SoS mission essential functions. Therefore, mission profile for each constituent
system of an SoS is defined with respect to the SoS mission profile by number of phases
and duration of each phase. Mission essential functions of each system by phase and its
mission essential subsystems and equipment are identified at this level to be used in
system and SoS mission reliability modeling. The equipment failure rates can be
predicted using the failure histories of equipment for all the systems involved in the SoS
mission. Equipment failure rates can often be provided by the owners of the SoS
constituent systems.

87

For each system of SoS (Si , i=1,2,…,k)

Define SoS
Mission
including
objectives

Develop SoS
Mission
Profile

Establish SoS
Success
Criteria by
Phase

Develop SoS
Mission
Essential
Functions by
Phase
Identify
Mission
Essential
Systems by
Phase

Define Si
Mission Profile
(Based on its
assigned SoS
MEF)

Develop Si
Mission Essential
Functions by Phase
for its own Mission

Identify Mission
Essential
Equipment by
Phase

Identify Mission
Essential
Subsystems by
Phase

Predict
Equipment
Critical Failure
Rates

SoS Level

System Level

Figure 33: A General Process for SoS Mission Reliability Modeling and Analysis

SoS mission reliability modeling is conducted in the reverse order. It starts at the
subsystem and system level and is completed at the SoS level. At the system level, a
diagrammatic method is utilized (i.e., Reliability Block Diagram/Decision Diagram) for
each phase of the system mission profile to show how different subsystems and
equipment contribute to the success of a system. At the SoS level, an RBD is developed
for each phase of the SoS mission based on mission essential systems of each phase that
reflects systems’ functional dependencies. Using the mission profile and the
diagrammatic method (RBD) at both system-level and SoS-level, SoS reliability can be
mathematically modeled and computed for each phase and at different points of time
during the SoS mission.

88

For'each'phase'of'system’s'
mission:'

N1'

Develop'RBD'for'subDsystem'1'

For'each'phase'of'system’s'
mission'

Develop'RBD'for'subDsystem'2'

Develop'RBD'for'system'1'

…'

…'
…'
…'
…'
…'

Develop'RBD'for'subDsystem'm1'

Develop'RBD'for'subDsystem'1'

Nk'

Develop'RBD'for'subDsystem'2'

Develop'RBD'
for'SoS''
(by'SoS'mission'
Phase)'

Develop'RBD'for'system'k'

…'
Develop'RBD'for'subDsystem'mk'

Model'and'
Es6mate'Reliability'
for'subDsystem'f'
k

Nj

∑∑ m

i, j

Model'and'Es6mate'
Reliability'for'system'
j'
j=1,2,…,k'

Model'and'
Es6mate'SoS'
PhaseDReliabili6es'

j=1 i=1

Model'and'Es6mate'SoS'
Mission'Reliability'

Figure 34: SoS Mission Reliability Estimation Process

6.4. SoS Mission Reliability Modeling and Analysis
The accurate calculation of the SoS mission reliability requires the knowledge of
how and when each system enters and exits during phases [68]. A closed-formed
equation may not be obtained to represent the exact mission reliability as a function of
time for a dynamic complex SoS [83]. However, a mathematical formula can be obtained
for an SoS with pre-defined mission phases and fixed SoS mission essential functions.
This is the case in this methodology since the objective is to select a set of systems from
existing candidate systems for an specific mission with pre-defined mission description
and requirements.

89

Techniques such as Monte Carlo simulation, BDD or state-based models exist for
accurate evaluation of SoS mission reliability. However, for large scale phased mission
SoSs, they quickly become complex and require extensive computational resources
which may make it unlikely to deliver the results required in the time available in this
application. Here, I use an approximation that provides a lower bound for the SoS
mission. The method presented in this work is simple and practical and does not require
extensive computational resources. This method is based on subsystems and systems
functional dependencies by using SoS mission RBD. This approach provides a lower
bound for the SoS mission reliability by considering successful operation of systems
during all previous phases in calculating the reliability of each phase. This yields an
estimate for the SoS mission reliability that is equal or smaller than the actual reliability.
Even though this approach may not give the exact reliability value for all SoS
configurations, it provides decision makers with a quick and simple estimation of the
lower bound mission reliability that is not labor-intensive and can be used during SoS
acquisition and mission planning.

Ground Rules and Assumptions:
− SoS mission success requires that all SoS phases to be successfully
completed, i.e., the SoS mission essential functions of each phase must be
accomplished.
− If any one of the required systems fails in a phase, the SoS is considered to
have failed in that phase, unless there are redundant systems.
90

− The length of each phase is pre-determined.
− Binary states are considered for constituents systems (up or down) and
systems state may only change once during a mission.
− Failures are not repaired during the SoS mission.
− All systems and their equipment are up (in working state) at the beginning
of their own phased mission (not necessarily at the start of the SoS
mission).
− The systems and their subsystems have phase-dependent failure rates
depending on their operational state.
− The time to failure of all mission essential systems and their mission
essential subsystems follow the exponential distribution.
− Load sharing is not considered for redundant systems.
− Constituent systems of SoS are operationally independent.
− Dependent failures are not considered.
6.4.1. SoS Mission Description
Reliability modeling and analysis of an SoS mission requires a clearly defined SoS
mission description including number and duration of phases, mission critical systems,
success criteria by phase and mission critical failures rates. Table 3 illustrates a general
SoS mission with k phases. Let n be the number of systems involved in the SoS mission.
This table shows how these n systems contribute to different phases of the SoS mission to

91

successfully accomplish SoS mission essential functions by phase. For example, system 1
is required (R) during phase one but it is not required (NR) in phase 2.
Table 3: Mission Description for an SoS Mission with k Phases
(R: required, NR: Not-required)

Phase&No.&

1&

2&

3&

…&

k&

Phase&Length&

T1&

T2&

T3&

…&

Tk&

MEF&

…&

…&

…&

…&

…&

R&

NR&

R&

…&

NR&

S2&
Mission&&
Cri4cal&
Systems& …&

NR&

R&

R&

…&

NR&

…&

…&

…&

…&

…&

S n&

R&

R&

NR&

…&

NR&

S1&

Based on this information, a mission profile can be developed for the SoS mission
as shown in Figure 35. The mission profile represents SoS mission by phase in terms of
the missions of its constituent.
SoS#Mission#Phases#
System"1,"S1","Mission"Phase"
System"2,"S2","Mission"Phase"

I"
I"

1"

2"

…"

k"

1"

2"

…"

k"

1"

…"

…"

…"

I"

…"

…"

…"

System"n,"Sn","Mission"Phase"

2"

…"

k"

Figure 35: Mission Profile for a General SoS

92

…"

6.4.2. Mission Reliability Analysis of SoS Constituent Systems
The first step in estimating SoS mission reliability is to calculate the mission
reliabilities of SoS constituent systems. Evaluating systems reliabilities at any point of
time during the SoS mission that is required for SoS mission reliability estimation is
discussed in this section.
As explained in section 6.1., each constituent system of an SoS performs its own
phased mission while contributing to the SoS mission objectives. Occasionally, SoS
constituent systems may have to start their own phased mission before the SoS mission
starts. In this case, the first phase of system’s phased mission is called “Initiation (I)”
phase in this dissertation. Constituent systems of SoS may also continue their phased
missions after the SoS mission ends. For example, in the search and rescue example
(SAR SoS), the objective is to conduct a search, rescue survivors and return them to a
place of safety. If the helicopter is assigned to deliver survivor to a safe place, it should
also return to its base after the delivery. Since this phase of the helicopter mission, which
is return to the base, is not defined as an SoS mission objective and in the SAR SoS
mission essential functions, it will not be considered in mission reliability analysis of the
helicopter. Figure 36. illustrates missions for constituent systems of an SoS (Si) with
respect to the SoS mission, when the SoS mission consists of k phases. There are four
possible cases: A constituent system may
1) start its phased mission at the SoS mission starting point and end at SoS
mission ending point (S1).

93

2) start its phased mission before the SoS mission starts and end its phased
mission after the SoS mission ends (S2).
3) start its phased mission before the SoS mission starts and end its phased
mission before the SoS mission ends (S3). In other words, the system leaves
the SoS in this case.
4) start its phased mission after the SoS mission starts and end its phased
mission after the SoS mission ends (S4). Here, the system (S4) joins the SoS
after the SoS mission starts.

SoS"Mission"Phases""

1"

2"

…"

k"

S1"Mission"Phases"

1"

2"

…"

k"
k"

…"

K+i"

k"

…"

K+i"

S2"Mission"Phases"

I"

…"

1"

2"

…"

S3"Mission"Phases"

I"

…"

1"

…"

K4i"

S4"Mission"Phases"

I"

2"

…"

Figure 36: Mission Profile for Constituent Systems - Possible Scenarios

Here, a mathematical formula for reliability estimation of an SoS constituent
system, Sj, is shown for a general case. This evaluation starts from Sj mission description
in terms of number of phases and duration of each phase, with respect to the SoS mission
as shown in Figure 37.
A system of an SoS may complete a number of phases of its mission before the SoS
mission starts. Here, for simplification, all the phases that a system (e.g., Sj) performs
94

before the SoS mission starting point is combined into one phase and called the Initiation
phase. Initiation phase that is represented by I, highlighted in red in Figure 37. Also
mission phases after the SoS mission ending point is represented by dashed arrow and are
not considered in the system reliability analysis. This is due to the fact that the system
reliability during these phases does not affect the SoS mission success. For each phase of
the Sj’s mission, mission essential functions (MEF) and mission essential subsystems
(MESS) are defined. For example, in an aircraft, the propulsion system is an essential
subsystem to achieve aircraft’s mission objectives.
T1"

T2"

…"

Tm #

…

Tk"

1"

2"

…"

m"

…"

k"

SoS"Mission"Phases""

TI"

Sj"Mission"Phases""

I"

1"

2"

…"
…"

m"

…"

k"

Func."1"
Func."2"
"
…"
…"
"

Func."1"
Func."2"
"
…"
…"
"

…"
…"
"…"
"…"

…"
…"
"…"
"…"

…"
…"
"…"
"…"

…"
…"
"…"
"…"

…"
…"
"
…"
…"
"

Subsystem"1"
"
Subsystem"2"
"…"
…"

"
Subsystem"1"
Subsystem"2"
"
…"
…"

"…"
"…"

"…"
"…"

Sj"Mission"Essen5al"
Func5ons""
Sj"Mission"Essen5al"
Subsystems""

…"
…"

…"
…"

"…"
"…"
…"
…"

…""
…""
…"
…"

…"

K+i"

"…"
"…"
…"
…"

Figure 37: SoS Mission Profile

Mission reliability of a constituent system depends on the failure rate of its mission
essential subsystems and the manner in which essential subsystems are arranged within
each phase. Reliability configuration of subsystems for a constituent system can be series,
parallel or general (see Figure 38). In this dissertation, it is assumed that all the mission
essential subsystems for a single phase of the system’s mission are required during that
phase. This means that the subsystems that are essential for phase i are all required for
95

successful operation of the system and SoS during phase i. Using this information,
mission reliability of the system can be mathematically modeled and estimated for any
point of time during the mission and for the entire mission.

1"

2"

…"

m"

…"

k"

I"

1"

2"

…"
…"

m"

…"

k"

"
" …
"
"

"
"
…"
"
"

"
"
"
"

"
"
"
"

"
"
…
"
"

"
"
"
"

"
…"
" …
…"
"

SoS"Mission"Phases""
Sj"Mission"Phases""

Sj"RBD"by"Phase"

"

Yellow"boxes"represent"mission"essen?al"subsystems"of"Sj"by"phase"

Figure 38: Reliability Configuration of Subsystems for System j During Different Phases of SoS Mission

In order to calculate the mission reliability of system j , Sj, that contributes to the
SoS mission while completing its own phased mission, the approach presented by
Somani and Triverd in [84] is adopted. Phase-dependent failure rates are considered for
each subsystem of Sj. The mission reliability calculation for Sj during phase m accounts
for the system global mission time, which starts at the beginning of the initiation phase (I)
of system j.
For Sj to be successful during phase m, it should successfully complete all the
previous phases (I,1,2,…m-1). Let RS j , pm (t) be the reliability of system j during phase m
at time t, where tm-1 < t < tm, where tm-1 and tm are the end points of phase m-1 and m
respectively. Since the time to failure distributions of constituent systems of an SoS and

96

their subsystems follow exponential distribution, system reliability for a single system of
SoS can be calculated using the following equation:
m−1

RS j , pm (t) = e

− λ j,I .TI , j

−

.e

∑ λ j,i .Ti, j
i=1

.e

− λ j,m .t

(6-1)

where I is the initiation phase, λj,i is the failure rate of system j during phase i and
Ti,j is the duration of phase i for system j. In this equation,

e

− λ j,I .TI , j

denotes mission

m−1

−

reliability of Sj during its initiation phase,

during phase 1 through phase m-1, and

e

e

∑ λ j,i .Ti, j
i=1

represents reliability of Sj

− λ j,m .t

is its reliability for t amount of time

within phase m.
As mentioned before, mission reliability of Sj during each phase depends on the
arrangement of its mission critical subsystems and their failure rates. For example, if the
essential subsystems are in series reliability configuration during phase m, λj,i which is
the failure rate of system j during phase i can be calculated using equation (6-2).
d

λ j,i = ∑ λ lj,i

(6-2)

l=1

where

λ lj,i is the failure rate of subsystem l that is required on system j so that

system j can perform its assigned essential functions during phase i and d is the total
number of subsystems required for system j to perform its assigned essential functions
97

during phase i. If the reliability configuration of mission essential subsystems is general,
λj,i must be derived for Si. Reliability of Sj for its entire mission can be calculated for t=tk.
6.4.3. SoS Mission Reliability Model By Mission phase
In order to calculate mission reliability, SoS mission success or failure criteria by
phase must be determined. Mission success criteria reflect functions that are essential for
successful completion of the SoS mission. Here, reliability block diagrams are used to
represent the reliability arrangements of constituent systems within each phase of the SoS
mission.
Mission reliability of different phases of an SoS mission (SoS phase-reliability)
depends on the manner in which constituent systems are arranged within each phase of
the SoS mission (phase-configuration or phase-RBD). The SoS mission reliability of each
phase is calculated by the development of a mathematical model that is based on phaseconfiguration and reliabilities of constituent systems during each phase. As discussed in
the previous section, systems’ mission reliabilities that are used in calculating phasereliabilities and for the entire mission (section 6.4.2.) consider systems global mission
time and accounts for their successful operation during all of their previous phases.
In phase-RBDs, different blocks, which represent constituent systems of each
phase, can be connected in different ways. The most popular way of connecting various
blocks are series, parallel, r-out-n, standby and general reliability configurations [85].
Here, calculating SoS phase-reliabilities are discussed for each of these configurations.

98

SoS Phase-Reliability Model – Series Configuration
In a series configuration, constituent systems involved in phase m of the SoS
mission, are all required for successful operation of SoS during phase m. This
configuration is shown in Figure 39.
SoS"Mission"
Phases"

1"

…"

…"

i"
S1"

S2"

…"

K"

Sn"i"

Figure 39: SoS Phase-RBD: Series Configuration

Let

RSoS,Pm (t) be the reliability of SoS at any point of time (t) during phase m

and ni be the number of systems involved in the SoS mission during phase m. Reliability
of this configuration can be calculated as follows:
i
RSoS,Pm (t) = ∏ nj=1
RS j,Pm (t)
m−1

ni
j=1

=∏ [e
where

− λ j,I .TI , j

−

.e

∑ λ j,i .Ti, j
i=1

.e

− λ j,m .t

]

(6-3)

RS j,Pm (t) is the reliability of the jth system at time t and is replaced with

the formula explained in section 6.4.2. In order for system j to contribute to the SoS
mission during phase m, it should successfully complete all previous phases of its own
mission. Here, the time that each system has been involved in the mission is also
considered in calculating SoS phase-reliabilities.

99

SoS Phase-Reliability Model – Redundancy
An specific phase of an SoS mission may require two or more systems to perform
mission essential functions of that phase. This is called redundancy and its phase-RBD is
illustrated in Figure 40. shows two or more systems in parallel. There are different types
of redundancy such as active parallel, r-out-n, standby and general.
SoS"Mission"
Phases"

1"

…"

…"

i"

K"

S2"
S1"
…"

Sn"i"

Figure 40: SoS Phase-RBD: Parallel Configuration

In active parallel, systems are operational and in use, even though only one item is
required for the function [86]. Reliability of an SoS mission-phase with active parallel
configuration is:
n

i
RSoS,Pm (t) = 1− ∏ j=1
[1− RS j ,Pm (t)]
m−1

ni
j=1

=1− ∏ [1− e

− λ j,I .TI , j

−

.e

∑ λ j,i .Ti, j
i=1

.e

− λ j,m .t

]

(6-4)

In a phase with r-out-n reliability configuration, there are ni redundant systems and
r out of ni systems must function properly at a time for the mission to be successful. The
reliability block diagram for this configuration looks like a phase RBD with parallel
configuration; however, its reliability depends on the number of failed and operating
100

systems [87]. The phase reliability for this configuration can be mathematically modeled
using a binomial distribution for identical systems. For non-identical systems, all possible
operational combinations should be considered to calculate SoS phase reliability (even
space method).
SoS Phase-Reliability Model – Standby Configuration
Standby reliability configuration is considered as a type of redundancy as the
standby system is activated upon the failure of primary system. In this configuration, only
one item is operating at a time to accomplish the mission essential function. In some
special types of standby configurations, one item’s failure rate affects the failure
characteristics of others, as they are now more susceptible to failure because they are now
under increased load [86].
In general, there are three types of standby configurations, cold, hot and warm. In
the cold standby configuration, standby systems and components have zero failure rates
while failure rate of systems in hot standby is the same as their failure rates when they are
in active mode. Systems in a warm standby configuration have a failure rate between cold
and hot standby [88].
Figure 41 illustrates an SoS mission-phase with warm standby reliability
configuration that includes two systems, one primary active system (S1) and one standby
system (S2).

101

SoS"Mission"
Phases"

1"

…"

i"

…"

K"

S1"

S2"

Figure 41: SoS Phase-RBD: Standby Configuration

If this is the configuration during phase m, the reliability of SoS mission at any
point of time (t) during this phase can be calculated as:

RSoS,Pm (t) = RS1,A, pm (t) +
t

∫

fS1 (x). RS2 , SB, pm (x − tm−1 ). RS2 ,A, pm (t − x)dx

tm−1

(6-5)

where:

RS1,A, pm is the reliability of active system in active mode,
fS1 is the pdf of active system (S1)
RS2 , SB, pm is the reliability of standby system in standby mode
RS2 ,A, pm the reliability of standby system in active mode
Equation (6-5) can be used for reliability modeling of a mission phase with one
active system and one system in warm standby configuration. For cold standby
configuration or for cases in which several active or standby systems are involved during
a phase, phase-reliability should be modeled for that particular situation.

102

SoS Phase-Reliability Model – General Configurations
The reliability configuration of SoSs during different phases may not be purely
series or parallel. In this case, the SoS reliability configuration can be decomposed into
some combination of series/parallel configurations or if an SoS solution involves a small
number of systems, the combinatorial reliability expression can be easily written by
inspection. For cases in which, the reliability structure is more complex, general
approaches can be used for estimating the SoS mission reliabilities for each phase such as
Inspection, Event-Space, Path Tracing and Cut-Set and Tie-Set Methods [89].
In general, there are three methods that can be used for estimation of phasedmission reliabilities for complex configurations: complete enumeration methods,
conditional probability methods and concept of coherent structures [85].
Complete enumeration method: In this method, a list of all possible logical
occurrences in the mission can be created which includes all favorable and unfavorable
events. The sum of probabilities of all favorable events, which represents SoS mission
success, will yield the probability of SoS mission success.
Conditional probability method: This method is based on the law of total
probability. Based on this method, the SoS phase-mission reliability can be decomposed
by an specific system at time t. For example, phase-reliability is equal to the reliability of
the SoS given that system A is in operating state times the reliability of system A, plus
the SoS reliability given that system A is in a failed state times the unreliability of System
A:
𝑅!"!,!" = 𝑅!"!,!" 𝐴! . 𝑅! + 𝑅!"!,!" 𝐴! . 𝑄!
103

(6-6)

If the system A is either operating or failed, the reliability configuration can be
reduced and the SoS phase mission reliability can be expressed in terms of the
reliabilities of the remaining components. A detailed example is provided in [85].
Concept of coherent structures: this method uses a binary indicator variable, xi, to
represent the status of each system. The binary variable, xi equals to 1, indicates that the
system i is functioning and xi equals to 0, indicates that the system is failed. Then the
binary variable 𝜙 represents the state of the SoS mission during phase m, which is a
function of x=(x1, x2,…,xn), where n represents the number of systems involved in this
phase. The function 𝜙(𝑥) will then be presented using the concept of minimal paths and
minimal cuts [85].
6.4.4. Estimation of Lower Bound Mission Reliability for SoS Missions
The SoS mission reliability can be calculated at any point of time during the
mission and for the entire mission. This value can then be used during mission planning
and execution. This value can also be translated into number of failed missions per 1,000
attempts for comparison and trade-studies. Even though, SoS mission reliability for the
entire mission is required for selecting the preferred SoS, information about SoS mission
reliability at different times during the mission can provide decision makers with valuable
information that can be used for mission planning.

104

SoS"Mission"
Phases"
1"

…"

2"

…"

k"

…"

…"

…"

…"

…"
R1out1n"
Figure 42: SoS Mission RBD

The RBD for the entire SoS mission is developed to represent SoS mission success
for the entire mission. If there is at least one success path, connection between input and
output point of the SoS mission RBD, it means that the SoS mission essential functions
are accomplished.

tm#1%

SoS"Mission"Phases""

T1"

T2"

…"

1"

2"

…"

tm%
t"
m"

…"

k"

Figure 43: SoS Mission Reliability at Time t

The SoS mission reliability for a given time t during phase m is the conditional
probability of SoS mission success given that SoS has performed all SoS mission
essential functions successfully in all of its previous phases (1,2,…,m-1). This value can
be calculated as:

R SoS (t) = RSoS, p1 (T1 )*... * RSoS, pm−1 (Tm−1 )* RSoS, pm (t − tm−1 )
105

(6-7)

where Ti is the length of phase i and tm-1 < t < tm . If an SoS performing a k-phase
mission, the SoS mission reliability for the entire SoS mission can be calculated using for
tk. This value reflects the probability of SoS mission success at the end of phase k, tk,
given that SoS has performed all of its mission essential functions successfully from
phase 1 to k-1.

tk#

SoS"Mission"Phases""

T1"

T2"

…"

Tk"

1"

2"

…"

k"

Figure 44: SoS Mission Reliability for the Entire Mission

R SoS (t) = RSoS, p1 (T1 )*... * RSoS, pm−1 (Tk−1 )* RSoS, pm (Tk )

(6-8)

Since calculating the probability of SoS mission success accounts for the SoS
mission success during all phases, my approach provides a lower bound mission
reliability, which is equal to or less than the actual SoS reliability (R). The lower bound
for the SoS mission reliability is shown as R’:

R'SoS (t) = RSoS, p1 (T1 )*... * RSoS, pm−1 (Tm−1 )* RSoS, pm (t − tm−1 )

(6-9)

The main reason that I chose to take this approach is that not in all SoS missions,
systems involved in the first phase stay involved throughout the mission. However, as
mentioned in the discussion of the SoS operational environment, systems may join or
leave the SoS during different phases and also even if they are required in more than one
106

phase, their mission critical subsystems and failure rates may change from one phase to
another depending on their operating mode and the environment (Figure 45).
SoS"Mission"
Phases"

2"

1"
S1"

S2"

S3"

S4"
S5"

Figure 45: Hypothetical SoS - Example (1)

If constituent systems of an SoS as well as their mission critical subsystems were
fixed throughout the mission (which does not seem possible), calculating the mission
reliability for the last phase of the mission while considering systems global mission time
would yield the value of the SoS mission reliability. This is due to the fact that regardless
of the SoS configuration during previous phases, all the constituent systems should
survive for their global mission time for the SoS mission to be successful. For example,
in the case shown in Figure 46. System 1 is required for both phases of a hypothetical
SoS mission. Let’s assume that subsystems A and B during phase one and subsystems B
and C during phase two are mission critical subsystems of system one. Failure of these
subsystems when they are required for performing the assigned mission essential
functions lead to the failure of system 1 and as a result, SoS mission. Here, regardless of
SoS configuration, both systems must survive during phase one for the mission to be
successful. System one may be operating during phase two if subsystems B and C survive
phase one. However, if subsystem A fails during the first phase, system 1 fails and the

107

mission fails even though this system is capable of accomplishing its mission essential
functions during phase two.
SoS"Mission"
Phases"

2"

1"
S1"
A"

S2"

S1"
B"

B"

C"

S2"

Figure 46: Hypothetical SoS - Example (2)

In order to account for mission success during all phases, (i.e., that the mission is
not failed during previous phases), I considered mission reliability of all phases for
systems mission global time. For cases in which systems involved in the first phase are
also involved throughout the mission, this approach yields lower bound mission
reliability due to the multiple consideration of reliability values for each constituent
system of SoS. But it ensures that it does not ignore the cases in which the mission is
failed in early phases (phase 1) and operating in following phases (phase 2). This
phenomenon is explained in detail for a single system in [ref. Esary’s work]. Here it is
explained for an SoS mission. This lower bound is closer to the exact mission reliability
value when the number of mission phases is small and systems join and leave the SoS
during various phases.

108

6.5. SoS Mission Reliability Modeling and Analysis of a Phased-Mission SoS
with Data Sharing Capability
The series reliability configuration is the most widely used configuration for SoS
missions. In this configuration, as stated before, calculation of SoS mission reliability
depends on the reliability of all the systems involved in the SoS mission. This
configuration is very limiting for SoS missions as an increase in the number of systems
involved in the mission decreases the SoS mission reliability. In order to improve SoS
mission reliability, redundant systems can be added to the SoS configuration for those
systems that are mission critical or those systems with low reliability.
SoS"Mission"
Phases"
1"
…"

SoS"Mission"
Phases"
1"
…"

2"
…"

2"
…"

…"

k"

…"

…"
…"

…"

k"
…"

Figure 47: Improving SoS Mission Reliability via Adding Redundancy

The problem is, adding a redundant system in an SoS mission configuration
increases cost, may affect time to IOC, and reduces SoS MTBF (Basic Reliability). To
address this issue in this dissertation, the function of data generation and sharing is
defined and considered as a redundant capability. The data generation and sharing
capability can improve the probability of success for SoS missions by adding redundancy
109

for systems to have access to required data and it is most likely cheaper than adding a
redundant system. This capability is defined in this chapter and incorporated in the
presented method for estimating the lower bound mission reliability of system of
systems.
6.5.1. Data-Sharing Capability in System-of-Systems
Accomplishing an SoS mission depends on its systems having access to real time
and up to date data. This requires the systems to be able to communicate with each other
and share data, and without that the SoS effectiveness will be marginalized. Data sharing
capability in this dissertation refers to transferring the data collected by one system to the
other systems involved in the SoS mission. Connecting systems of an SoS by providing
each system with the required capability i.e. sensors, and datalinks enables data exchange
among systems. Data sharing capability ensures that systems can be provided with the
required data even if they are not capable of generating data through their own
capabilities (e.g. sensor failure).
The data sharing that can be considered for an SoS mission may include data
sharing among systems involved in the mission through ground stations or satellites. For
example, systems sensor data can be sent from systems to other systems and ground
stations through a satellite and navigation and command and control data can be sent
from ground station to each system. In this work, direct system-to-system data sharing
capability is considered for the total SoS mission time. For example, data sharing in a
mission such as a search and rescue operation is across aircrafts, ships, and boats. Here,
each system of SAR SoS should be capable of generating sensor data including video,
110

images and system’s location and providing it to other systems throughout the mission
(during search and rescue) when needed. For simplicity, it is also assumed that all
systems are equipped with the same type of datalink that is composed of a transmitter,
receiver and processor.
Today, not all systems are capable of sharing information. Some legacy systems
were not designed to connect with other systems and they cannot be equipped with the
required data sharing devices. Also systems that are capable of data sharing with other
systems are provided with different type of data sharing systems (data links).
Assumptions made for this study may not be fully operational at this point but this
method can be modified to assist decision makers for the future use.
SoS"Mission"Phases"
S1"
S2"

I"
I"

1"

2"

…"

k"

1"

2"

…"

k"

1"

…"

…"

…"

…"

…"

…"

I"

S n"

…"

2"

…"

k"

Figure 48: SoS Mission Profile with Data Sharing Capability
Dashed arrows indicate data sharing among systems within each phase of the SoS mission

6.5.2. Mission Reliability Model for Data Generation and Sharing Function
As stated before, systems can either be provided with the required data via their
own sensors (such as radar, sonar, radio, etc) or can access data generated by other
systems. For the latter, the SoS systems must be linked using datalinks to share
111

information. Datalinks enable systems to view, on their displays, and use the same data
that other systems are generating using their sensors. This will greatly improve mission
reliability because the datalink performs as a redundant capability. Multiple datalinks can
be integrated into a single system to provide the system with various types of data such as
navigation, weather and traffic. In this work, a single datalink is considered on each
constituent system of SoS to enable data sharing among the SoS systems.
We first review the structure of the datalink and then model the reliability of the
data generation and sharing function. This function ensures that SoS systems are
provided with the required data throughout the mission. A datalink includes a transmitter,
receiver, processor and antenna. A general structure of the data link for a single system is
shown in Figure 49. As shown in this Figure, data provided by sensors of each system is
sent to the transmitter via a processor and then transmitted to the other systems via
antenna. Also, data generated by other systems is received by the receiver through
antenna, analyzed by the processor and displayed via systems interface (display). Even
though display is not part of a datalink structure, it is considered as a critical element due
to its necessity in showing the information received through the receiver.
Sensors
System
Interfaces
(e.g., display)

Data link
Processor
Data link
Transmitter

Data link
Receiver

Data link
Antenna

Figure 49: Data Link (DL) Structure for a Single System

112

A closed-from mathematical model for the reliability of the data generation and
sharing function is developed. The data generation and sharing function is required for all
SoS mission phases throughout the mission. Since this function is an essential function,
which is common throughout the mission, it is referred to as Common Mission Essential
Function (CMEF). If there are n systems required for the SoS mission, each equipped
with a datalink, then SoS mission success requires data to be generated by system’s
sensors or be provided by other linked systems. Hence, the mission is considered to be
failed if all the systems of SoS cannot access the required data in any one of the phases.
Let RDGi be the reliability of the data generator (such as sensor) on system i and QDGi be
the unreliability of the same sensor. The reliability of CMEF can be calculated using
equation (6-10).
n

n

RCMEF (t) = ∏ RDGi (t) + ∑{QDGi (t). R DRi (t). A(t)} (6-10)
i=1

i=1

where

QDGi (t) = 1− RDGi (t)

(6-11)

n

A(t) = 1− ∏ (1− RDS j (t))
j=1
j≠i

(6-12)

RDRi (t) is the probability of system i successfully receiving data from other systems
and RDSj (t) is the probability of system j successfully generating and transmitting data to
other systems. These two reliabilities can be computed using equations (6-13) and (6-14).

R DRi (t) = R Ai (t). R Ri (t) . R Pi (t). R Di (t)
113

(6-13)

R DS j (t) = RDG j (t). R Pj (t). R Tj (t). R A j (t)

(6-14)

As shown in equation (6-13), to successfully receive data, antenna (RA), receiver
(RR), processor (RP) and display (RD) is required for system i. And as shown in equation
(6-14), in order to generate and share data, the data generator (RDG), processor,
transmitter (RT) and antenna is required.
Note that j=i has been skipped in calculation of A(t) in Equation (6-12). This
increases the complexity of calculation since n-1 values must be multiplied together for n
times (for each i). Calculating this expression is time-consuming and computationally
inefficient for a large n. for a more efficient calculation, we have re-written expression A
as:
n

A(t) = 1− ∏ (1− RDS j (t)) = 1−
j=1
j≠i

IRsys − RDSi

(6-15)

1− RDSi

for RDSi ≠1, where
n

IRsys = ∏ (1− RDS j (t))

(6-16)

j=1

The correctness of Equation (6-10) is verified using a truth table considering an
SoS with three systems (Chapter 9, Methodology Verification and Validation). Note that
CMEF defined in this work is independent of the SoS phase configuration. For example,
in phase 2 of the SAR example, ship requires having access to data during standby mode
and contributes in providing other systems with data during standby mode.

114

6.5.3 Lower Bound Mission Reliability for a Phased-Mission SoS with Data Sharing
Capability
The data generation and sharing function is considered as an independent essential
function throughout the SoS mission. The reliability of this function is modeled and
estimated separately and integrated with the result of SoS mission reliability calculation
to obtain mission reliability of a phased mission SoS with data sharing capability (see
Figure 50).
For'each'phase'of'system’s'
mission:'

N1'

Develop'RBD'for'subDsystem'1'

For'each'phase'of'system’s'
mission'

Develop'RBD'for'subDsystem'2'

Develop'RBD'for'system'1'

…'

Develop'RBD'for'subDsystem'm1'

Develop'RBD'for'subDsystem'1'

Nk'

Develop'RBD'for'subDsystem'2'

…'
…'
…'
…'
…'

Develop'RBD'
for'SoS''
(by'SoS'
mission'
Phase)'

Model'and'
Es6mate'
Reliability'for'
Common'
Mission'
Essen6al'
Func6ons'
(Data'
Genera6on'
and'Sharing'
Func6on)'

Model'and'
Es6mate'SoS'
PhaseD
Reliabili6es'

Model'and'
Es6mate'
SoS'
Mission'
Reliability'

Develop'RBD'for'system'k'

…'
Develop'RBD'for'subDsystem'mk'

Model'and'
Es6mate'Reliability'
for'subDsystem'f'
k

Nj

∑∑ m

i, j

Model'and'Es6mate'
Reliability'for'system'
j'
j=1,2,…,k'

j=1 i=1

Figure 50: SoS Mission Reliability Estimation Prcoess: Considering Data Sharing Capability

As stated before, the data generation and sharing function or the Common Mission
Essential Function (CMEF) is required throughout the mission. The failure of this CMEF
results in SoS mission failure and it is considered to be independent of SoS phase
configuration. The SoS mission reliability model for the entire mission can be modified
as:

115

R 'SoS (t) = RCMEF (t)*
[RSoS, p1 (T1 )*... * RSoS, pm−1 (Tm−1 )* RSoS, pm (t − tm−1 )]

(6-17)

where RCMEF(t) can be calculated from mathematical models developed in section
6.5.2.
6.6. Summary
Reliability evaluation of an SoS operating in a multi-phase mission has unique
challenges. This chapter presented an efficient methodology and mathematical
framework to estimate the mission reliability of a phased mission SoS with data sharing
capability. The mathematical derivation was developed to extract a lower bound mission
reliability for an SoS, performing a phased mission. A reliability expression was
developed for evaluating the reliability of the data generation and sharing function where
systems of the SoS are linked via datalink. This expression is combined with the
reliability estimation of the phased mission SoS to calculate the SoS mission reliability
with data sharing capability. The approach presented in this paper is a simple practical
approach that is an integral part of the methodology for selecting systems for an SoS. The
methodology presented in this chapter has wide applicability in planning an SoS
capability using existing systems as well as development of future SoSs. Data generation
and sharing concepts, such as moving the data generation from certain systems to other
means, can readily be evaluated in terms of SoS mission reliability.

116

CHAPTER 7
SELECTING THE PREFERRED SOS SOLUTION
Selecting the preferred SoS solution from a set of generated feasible SoS solutions
is the final step in the methodology developed in this work. An SoS solutions library has
been developed in the previous steps of the methodology that contains estimated values
of the decision attributes for each feasible SoS solution. The preferred SoS solution is the
most acceptable solution to stakeholders from the library of feasible solutions. As stated
before, stakeholders include SoS management team, systems owners, systems operators
and etc. The analyst is the one who conducts the analysis and helps the stakeholders
through the decision making process while selecting the preferred solution.
One of the major differences between systems and systems of systems in
engineering a solution is “Stakeholders involvement”. In engineering a system, there is a
clear set of stakeholders, however, in an SoS, there are stakeholders at both system level
and SoS-levels, including system owners with competing interests and priorities. Since
the SoS mission is often dynamic, stakeholders may change throughout the SoS life
cycle. Sometimes the system stakeholder has no vested interest in the SoS and all
stakeholders may not even be recognized during final selection [90]. As stated by Barry
Boehm, “Key to successful SOS development is the ability to achieve timely decisions
with a potentially diverse set of stakeholders, quickly resolve conflicting needs, and

117

coordinate the activities of multiple vendors who are currently working together to
provide capabilities for the SOS” [91].
The challenges that one would face in selecting the most suitable SoS solution are:
(1) multiple stakeholders with diverse interests, (2) multiple objectives and decision
attributes, usually unequally preferred, and (3) a large and complex solution space as
even for a small set of candidate systems, the number of SoS solutions can become quite
large. The problem of selecting the preferred SoS can be approached in many different
technical ways as discussed in chapter 4.
The objective of this chapter is to present a hybrid approach for comparing feasible
SoS solutions in order to select the preferred option that involves stakeholders and
considers their priorities. Since the problem of selecting the preferred SoS involves five
decision attributes and a finite set of candidate SoS solutions, where the objective is to
evaluate, compare and select an SoS solutions that satisfies stakeholders, it is considered
a Multi-Criteria Decision-Making problem. According to [92], MCDM is all the
“concepts, approaches, models and methods, to help the decision makers to describe,
evaluate, sort, rank, select or reject objects on the basis of evaluation according to
several criteria”. These criteria may be goals, objectives, utility, etc. There are two main
classes of methods for this purpose: (1) multi-objective methods and (2) multi-attribute
methods. The result of my literature search shows that both multi-objective methods and
multi-attribute methods have been used for related problems. In multi-attribute methods,
a set of finite objects is considered for decision-making. The multi-objective methods can
be viewed as mathematical programming in which the decision space is continuous,
118

several objective functions are considered simultaneously and decision variables are
bounded by mathematical constraints.
The traditional approach for SoS system selection is shown in Figure 51 In this
approach, the analysts first determine all possible SoS solutions with little input from
stakeholders. The Stakeholders’ preferences are then captured in detail as attributes and
represented by weights or utility functions. These preferences are only preliminary and
may change once the final selection by these methods has been made. The preferred SoS
is selected by comparing all the candidate solutions according to the initial stakeholders
preferences. Once the results are known, stakeholders can fully evaluate the solution and
revise their initial preferences if needed. The entire selection process may need to be
repeated multiple times before satisfying all the stakeholders. This often increases SoS
time to achieve IOC.

119

Start
By Analyst(s)

Capture Stakeholders
Input

Develop a Mathematical
Form of Stakeholders
Preferences
(Weights, Utility, etc)

Determine
Possible SoS
Candidates

Select the Best
SoS Candidate

Accepted by
Stakeholders

No

Yes

End

Figure 51: Traditional Approach for SoS System Selection

As evidenced in my literature search, there is a great interest for involving
stakeholders in the decision-making process [93],[94],[95]. According to U.S.
Department of Transportation, stakeholders’ involvement ensures that their needs are
prioritized and addressed in making the final decision [96].
Having the stakeholders involved in the decision-making from the beginning of the
process can decrease the decision-making time, i.e. the time to reach a consensus.
Increased participation of stakeholders results in their greater understanding of the
solution space and consequently improved level of acceptance of the final selected SoS. It
also avoids repetition of the entire selection process as shown in Figure 52.
120

Start

Further Analysis Select the Preferred
SoS Candidate

End

Communications
Consensus

Analyst(s)

Stakeholders

Determine
Possible SoS
Solutions

Select the Preferred
set of Solutions

Figure 52: Proposed SoS Selection Approach

Most existing methods do not involve stakeholders from the beginning of the
decision-making process. These methods require stakeholder’s preferences as inputs and
provide them with a selected set of optimum solution without involving them in the
decision making process. Also, stakeholders often find it difficult to express their
preferences in terms of a single value or utility functions. They do not have enough
information about the solution space, available options and possible trade-offs, therefore
they cannot finalize their preferences prior to starting the system selection process.
In this dissertation, an approach is presented that combines data analysis and multiattribute decision-making (MADM) methods to assist decision-makers in selecting the
preferred SoS while having stakeholders involved. The solution space is often complex
and is therefore difficult to understand in terms of decision-making. Data visualization
121

and analysis techniques are used to simplify the solution space and extract useful
information and patterns for stakeholders’ understanding of the available trade-offs. Then
MCDM is used to rank options and select the preferred SoS solution. This approach
reduces the order of the solution space to a manageable level to enable communication
among stakeholders. It simplifies the process and saves time for both stakeholders and
analysts by providing a smaller palette of solutions that can be effectively negotiated and
compared in terms of the estimated decision attributes to select a preferred final SoS.
Providing stakeholders with a simplified version of the solution helps them to better
understand the available options and identification of trade-offs and enables them to
finalize their preferences prior to starting the system selection process. Even though the
solution found may not be the optimal solution of the total solution space, it will most
likely satisfy most stakeholders and saves time.
7.1. The Three-Phase Approach for Selecting the Preferred SoS Solution
Selecting the preferred solution from a set of feasible candidates that best satisfies
stakeholders’ needs is a challenging task. This is due to the fact that the number of
feasible SoS solutions (solution space size) and the number of decision attributes
(solution space dimensions) are often large. My objective was to develop a methodology
that could be used in many application areas. However, depending on the application, the
solution space could be different in terms of: (1) the size of the solution space (the
number of the data points (feasible SoS solutions), (2) the number of dimensions
(decision attributes/variables), and (3) the structure of the solution space or the patterns of
the data points (SoS solutions). Moreover, real data did not exist for any specific
122

application that we could use to define a special bounded problem. Therefore, a general
approach was formulated to address the problem of selecting the preferred SoS solution
that can be widely applicable.
The approach presented in this dissertation combines statistical data analysis and
multi-attribute decision making (MADM) methods to identify trends and patterns in the
solution space, simplify the solution space to an understandable level so that it can be
used by stakeholders for communication, and select the most preferred SoS solution.
This method consists of three phases as shown in Figure 53. To better understand
the solution space, identification of trade-offs and existing patterns and trends, principal
component analysis (PCA) is used in the first phase. The second phase involves reducing
the order of the solution space and providing a simplified version of the space for
stakeholders. For this phase, statistical data clustering and data envelopment analysis are
utilized. In the last phase, ranking SoS solutions, an outranking method of PROMETHEE
is used to comparatively rank SoS solutions of the reduced order space considering
stakeholders’ preferences.
The strengths of this approach are that (1) it does not require extensive
computational resources, (2) it is simple to implement, (3) provides a smaller palette of
the solution space for communication among stakeholders and analysts, and (4) involves
stakeholders throughout the decision-making process. Systems of systems operate in
dynamic mission environments where the mission requirements and the preferences of
stakeholders may change over time. Using the presented approach, the SoS solution

123

space can be rapidly evaluated and the preferred SoS can be re-selected. This approach is
discussed in four sections, starting from the inputs of the approach.
Stakeholders

Phase 2

Phase 1

Data
Visualization
and Analysis

Start

Data Structure
and Patterns

1

Solution Space
Simplification

A Smaller Palette of
Solution Space

Phase 3

Weightings of Decision
Attributes

Ranking SoS
Solutions of the
Simplified Solution
Space

2

End

Figure 53: A Framework for Selecting the Preferred SoS Solution

Inputs to the Three-Phase Approach
A library of feasible SoS solutions is generated (described in chapter 4) for use in
this step of the methodology. Let S be a set of n SoS solutions that are capable of meeting
SoS mission and program requirements. Here, each SoSi is characterized by five values
of decision attributes, where each decision-attribute represents a dimension on the
solution space.
SoSi = {MRi, BRi, CCi, Ti, PLIi}
S is an n×5 matrix where each row represesnts an SoS solution and each column
represents a decision attribute. The objective is to analyze the solution space (S) and
evaluate and compare feasible SoS solutions to select a preferred option that satisfies
most stakeholders.

124

Phase 1: Data Visualization and Analysis
It has been proved that visual communication is the most powerful tool for
transferring information due to the fact that human brain finds it difficult to comprehend
numbers but understands images instantly. Data visualization enables clear and effective
communication of information through graphics [97], as in most cases, information is
better interpreted and more understandable when using graphical concepts and elements.
In this method, data visualization is used for establishing a communication
platform among stakeholders to support decision-making.

Data visualization and

analysis provides insight into the SoS solution space and directly contributes to the
decision making process. Graphical representation of existing SoS candidates assist
stakeholders and decision-makers to obtain a better understanding of the solution space.
It is essential for SoS stakeholders to realize existing options and trade-offs as well as the
benefits and consequences of various options within a large and complex solution space
to set priorities and provide analysts and DMs with a basis for selecting the preferred
option. It also allows decision-makers and stakeholders to quickly assess the solution
space, observe patterns, correlations and trends, discuss alternatives and exchange ideas,
and influence the final decision. Stakeholders and decision-makers need to interact with
each other and communicate different alternatives to identify those regions of the solution
space that benefits the majority of them.
Figure 54 illustrates the flow chart for the first phase of this method. The library of
SoS feasible solutions, prepared in previous steps, is the input of this phase. As shown in

125

the flow chart, data visualization is the first action step that is followed by the analysis of
solution apace using the visualization results.
Stakeholders

Phase 2

Phase 1
Start

Data
Visualization
and Analysis

Data Structure
and Patterns

1

Solution Space
Simplification

A Smaller Palette of
Solution Space

Phase 3

Weightings of Decision
Attributes

Ranking SoS
Solutions of the
Simplified Solution
Space

2

End

Start
Library of Feasible SoS
Solutions

Visualize the Solution Space

Plot Data

Yes

Number of Decision
Attributes (dimensions-d)
d <= 3

No

Conduct Principal
Component
Analysis

Analyze Data
(SoS Solutions)
1

Figure 54: Phase 1- Data Visualization Process

In the first action step, analysts graphically present the solution space, existing
relationships and information to SoS stakeholders in an effective way. When there is only
a pair of decision attributes, tools such as scatter plots and contour plots can be used to
126

visualize the solution space and explore relationships. Even for a problem with three
dimensions (decision attributes), 3D plots can be used for graphical representation.
However, when dealing with large amount of data with more than three dimensions,
visualization of data analysis becomes challenging and of great use for stakeholders and
analysts. Even though there are tools to display data with multiple attributes (e.g.,
scatterplot matrix, trellis plot, parallel coordinates plots and icon plots), they are often
difficult to read and fail to capture the global information as they represent too many
details as shown in Figure 55 [98].

(a)

(b)

(c)

(d)

Figure 55: (a) Scatter plot matrix, (b) trellis plot, (c) parallel coordinates plot, (d) icon plot
Adopted from: (a): sas.com, (b) http://www.theusrus.de/blog/understanding-area-based-plots-trellis-displays/,
(c) https://github.com/ggobi/cranvas/wiki/Parallel-coordinates-plot
(d) http://documentation.statsoft.com/STATISTICAHelp.aspx?path=glossary/GlossaryTwo/2dgraphs/2DIconPlotsSunRays

127

Patterns are difficult to find in data of high dimension, where graphical
representation is not possible. Especially when there is a large number of variables
(dimensions), it is very likely that subsets of variables to be correlated with each other.
When this happens, one can take advantage of this redundancy of information and
simplify the problem by replacing a group of variables with a single new variable [99]. In
this method, Principal Component Analysis (PCA) is suggested for visualization of the
solution space, as there are five decision attributes (dimensions) in the problem of
selecting the preferred SoS. In general, there are usually multiple variables involved in
decision making and PCA helps to project the data into a 2D or 3D subspace while
retaining most of the variance in the solution space. In such problems, there may be many
correlated variables in the selection process. For the problem of selecting the preferred
SoS to provide a new capability, it is highly likely that the selected five decision
attributes be correlated with each other, e.g., basic reliability drives cost and priority
impacts capability cost. When the correlation among variables is high, PCA constructs
independent new variables, which are linear combinations of the original variables. These
new set of variables are called principal components. Each principal component is a
single axis in the space and all the principal components are orthogonal to each other.
This means that there is no redundant information in the new space. The total number of
principal components equals the total number of the original set of variables [99].
This method provides a low dimensional summary of the solution space, and helps
detect patterns and outliers without much loss of information [100]. PCA enables us to
identify some “hidden” aspects that determine the characteristics of the SoS solution
128

space by reducing the number of dimensions (attributes) [98]. In the literature, PCA is
sometimes applied as a preprocessing step to extract data structure before conducting any
type of further analysis. For example, in [101], PCA was used to determine the number of
clusters prior to cluster analysis. According to [100], removing features with low variance
using PCA acts as a filter that results in a distance metric that provides a more robust
clustering.
It has been proved that PCA is the best linear dimension reduction technique in the
mean square sense [102]. PCA obtains a reduced dimension subspace of the data by
finding a few orthogonal linear combinations of the original features with the largest
variance. Since the variance depends on the scale of the variables, it is customary to first
standardize each variable. In the problem of selecting the most preferred SoS, since all of
the selected decision attributes were not in the same units, data normalization was used.

Application of PCA for Analyzing the Feasible SoS Solution Space
The objective is to transform a set of n-dimensional vectors X = {x1, x2, x3, . . . ,
xm} into another set Y = {y1, y2, . . . , ym} of the same dimensionality, in a way that most
of the information content in the original space be stored in the first few dimensions in
the new space. In this problem, m is the number of feasible SoS solutions and n equals to
5, which represents the selected five decision attributes. By making this transformation,
the data set will be reduced to a smaller number of dimensions with minimum
information loss, where high information in this method corresponds to high variance.
In order to reduce a set of input dimensions X to a single dimension Y, matrix
129

computation is used for transforming X into Y:
Y=AŊX

(7-1)

In other words, A should be chosen in a way that Y has the largest variance
possible for a given data set. In this case, Y obtained in this transformation, which is a
single dimension, can be called the first principal component. Y is an axis in the space,
which is in the direction of maximum variance. This axis minimizes the distance of the
sum of squares between data points (SoS solutions) and their projections on the
component axis.
In practice, directly calculating matrix A is not possible, therefore the covariance
matrix S should first be computed as a first step. Matrix S is defined as:
𝑆!×! = 1 (𝑛 − 1)

!
𝑗!!

!

𝑥! − 𝑥 ! (𝑥! − 𝑥 ! )

(7-2)

where
𝑥 ! = (1 𝑛)

!
!!! 𝑥!

(7-3)

The next step is calculating the eigenvalues of the covariance matrix S for the given
data. Ultimately, a linear transformation from the n-dimensional space to an mdimensional space can be made using this information as the m eigenvectors
corresponding to the m largest eigenvalues of S define this linear transformation. In the
new space, the features are uncorrelated. Matrix S also has the following characteristics:
1. The eigenvalues of S n×n are λ1, λ2, . . . , λn, where λ1 ≥λ2 ≥...≥λn ≥0.
2. The eigenvectors e1, e2, . . . , en are called the principal axes.
3. The eigenvectors e1, e2, . . . , en correspond to eigenvalues λ1, λ2, . . . , λn.
Principal axes constitute the new space, which are transformed from the n130

dimensional space. In the new space, the new variables are uncorrelated and the variance
for the ith component is equal to the ith eigenvalue. In matrix S, λi’s are sorted; therefore,
most of the information about the data set can be found in a few first-principal
components.
In order to decide how many of the principal components to consider, the sum of
the first m eigenvalues can be divided by the sum of all the variances (all eigenvalues).
This provides a percentage that can be used as a measure of the quality of representation
using the first m principal components. For example, if the result (percentage) shows that
the projection on the first m principal components account for 90% of the total variance,
considering the first m principal components is considered to be good. As stated in [102],
“The criterion for feature selection is based on the ratio of the sum of the m largest
eigenvalues of S to the trace of S. That is a fraction of the variance retained in the mdimensional space”. The ratio can be written as:
𝑅=

!
!!! 𝜆!

!
!!! 𝜆!

(7-4)

where λ1 ≥ λ2 ≥ . . . ≥ λn are the eigenvalues of S.
The first m principal components are said to be a good representation of the ndimensionality space, when the ratio R is sufficiently large [102]. In general, there are
different ways to decide how many principal components to select (m), e.g., cumulative
percentage of total variation (discussed above), use of scree plots, kaiser rule, crossvalidation and etc [103]. However, the choice of the number of principal components to
select is subjective and is based on analyst’s judgment. It is commonplace to say that the
first m PCs is a good representation of the original space if it explains 80-90% of the
131

variation, which is called (80-90% rule).
Scatter plots of principal component scores (the projection of the data point on the
new subspace) can be constructed. Then we can identify those regions that have high
values for a given principal components (e.g. first PC). When a high dimensional solution
space is projected into a 2D or 3D subspace, patterns, trends and outliers can be analyzed
in the PCA graphical representation. By examining the scatter plots of principal
component scores, analysts and stakeholders often develop a deeper understanding of the
driving attributes that generated the original SoS solution space. The results of PCA on
the solution space show those variables that move in the same direction. It also shows
those principal component scores that have high/low values in a given principal
component. This type of information helps both the analysts and stakeholders to better
understand the solution space and take further actions if necessary. Sometimes outliers
impact the result of further statistical data analysis. Therefore, outliers identified in this
step can be analyzed separately or be treated differently in the following steps.
Phase 2: Solution Space Simplification
Size and complexity of SoS solution space often makes it difficult for stakeholders
to observe the possible options. Therefore, in phase 2, simplifying the SoS solution space
is recommended that can be performed on either the original SoS solutions set or on the
principal component scores (results of PCA). Simplifying the SoS solution space by
removing those solutions that are either inefficient or not preferable by the key
stakeholders yields a reduced order solution space (data set), which consists of some

132

selected SoS solutions that benefit most stakeholders. The preferred SoS will then be
selected from this set of selected solutions in phase 3.
Figure 56 describes the flow diagram for phase two of the developed approach.
This method suggests application of one or a combination of the following techniques for
reducing the order of the solution space. As shown in Figure 7-6., based on the results of
the data visualization in phase 1, the following methods can be used in this step:
1. Statistical Clustering Analysis (CA) – For data with patterns and notion of center
2. Data Envelopment Analysis (DEA) – for scattered data
3. A combination of both CA and DEA – for a large set of data within clusters and
large number of efficient frontiers

133

Stakeholders

Phase 2

Phase 1
Start

Data Structure
and Patterns

Data
Visualization
and Analysis

1

Solution Space
Simplification

A Smaller Palette of
Solution Space

Phase 3

Weightings of Decision
Attributes

Ranking SoS
Solutions of the
Simplified Solution
Space

2

Cluster SoS Solutions
based on Their
Similarities

1
Results of SoS Data
Analysis
Is there a
notion of center
in the solution
space?

Negotiate Results with
Stakeholders Using
Cluster Representatives
Yes

Yes

Is there a
notion of center in
the efficient frontier
space?

No
Apply Data Envelopment Analysis
To Determine
Efficient SoS Solutions
Yes
Large number of
Efficient SoS
Solutions?

Select the Best AgreedUpon Cluster
No

Is there a
large number of
solutions within the
selected cluster?

Yes
No
Provide Stakeholders
with Simplified Solution Space
for Communication

No

2

Figure 56: Phase 2 - Simplifying the Solution Space

134

End

1. Cluster Analysis for Solution Space Simplification
If the scatter plots (either on original data set or on principal component scores),
created in phase one, show structure and patterns, I suggest conducting clustering
analysis in the second phase. Clustering is a technique in statistical data analysis that
groups a set of data in such a way that data in the same cluster show more similarity to
each other than to those in other clusters. One can take data clustering as the first action
step in phase two if one can recognize a notion of center or cluster structure by observing
the scatter plots (Gives best result when SoS solutions are distinct or well separated from
each other). Using the locations of SoS solutions in the 3D plot or in the new subspace
(principal components), one should look for those regions of the space that the data
points are either closer to each other (show more similarity) compared to other data
points or completely separated. For example, using the result of PCA, we can look for
those regions with high levels of a given component or low levels of that component that
can be grouped into a cluster.
The four major clustering techniques are: Partitioning, Hierarchical, Model-based
and Density-based [104]. The most commonly used partitioning representative-based
method is called k-means clustering, in which n observations are partitioned into k
clusters, (s1,s2,…,sk). Each observation belongs to the cluster with the nearest mean (µ) or
center (C), serving as a prototype of the cluster.
Partitioning the SoS solution space into several groups based on the values of
different decision attributes provides analysts and stakeholders with a simplified version
of the reduced solution space that presents a set of representatives instead of a total
135

solution space where representative of each group (cluster) reflects characteristics of the
SoS solutions within that group. This technique generates groups of SoS solutions based
on the natural cluster structure of the solution space, totally independent from any driving
objective functions. Therefore, it can be used to analyze the options on different target
attributes. Using clustering analysis, those SoS solutions that tend to be related based on
one or some decision attributes are grouped together. Each group is represented by a
cluster representative. Cluster representative of each group are then be found to be
presented to stakeholders for discussion and communication. Using clusters’
representatives instead of the total solution space provides a simplified version of the
solution space that enables stakeholders to attain a better understanding of the space,
communicate their interests and finalize their priorities. The cluster representatives are
compared to select the best group/cluster according to stakeholders’ common interests.
For example, one cluster representative might have the highest mission reliability level
and high capability cost. One cluster may have the minimum time to IOC and capability
cost, however, it may have a small priority level (capability level). Some cluster may be
eliminated from analysis if their representative is totally dominated by other cluster
representatives.
After removing the SoS solutions within those clusters that are not as valuable to
stakeholders, a smaller pallet of the solution space will be produced in which the
remained SoS solutions are more focused around stakeholders’ common interest in some
certain types of decision attributes. The selected group will then be ranked using

136

stakeholders preference functions (MCDM technique) to find the most preferred SoS
solution.
Cluster SoS Solutions
based on Their
Similarities

1
Results of SoS Data
Analysis
Is there a
notion of center
in the solution
space?

Negotiate Results with
Stakeholders Using
Cluster Representatives
Yes

Select the Best AgreedUpon Cluster

Is there a
notion of center in
the efficient frontier
space?

No
Apply Data Envelopment Analysis
To Determine
Efficient SoS Solutions
Yes
Large number of
Efficient SoS
Solutions?

Yes

No

Is there a
large number of
solutions within the
selected cluster?

Yes
No
Provide Stakeholders
with Simplified Solution Space
for Communication

No

2

Figure 57: Phase 2 - Simplifying the Solution Space using Clustering Analysis

Application of Data Clustering on Simplifying the SoS Solution Space
In this step, the k-means clustering technique is applied for partitioning the solution
space. The k-means algorithm adopts an iterative technique and starts with selecting k
centroids and assigning each data point to the cluster whose mean yields the least withincluster sum of squares (WCSS). The algorithm continues with calculating the new means

137

to be the centroids of the data in the new clusters and stops when there is no further
change in assignment of data points to the clusters.
This technique attempts to minimize the within cluster sum of squares using the
following objective function:
arg  min!

!
!!!

!! ∈!!

𝑥! − 𝜇!

!

.

(7-5)

where S is the database, k is the number of clusters, si is the ith cluster, µi is the
cluster mean and xj is a data vector within cluster i.
For partitioning the set of feasible SoS solutions, (x1,x2,…,xn), into k cluster sets
(s1,s2,…,sk), n is the total number of SoS solutions and k<n. Each SoS solution is
represented through a multi-dimensional vector in which each dimension represents a
decision attribute of mission reliability, basic reliability, capability cost, time to IOC and
priority.
Unsupervised learning methods like K-means start by randomly choosing initial
number of cluster. Therefore, the results obtained in this way are dependent on the chosen
number of clusters. Most clustering algorithms generate a clustering even if the data has
no inherent cluster structure. According to [105], random selection of the cluster center
may not lead us to the effective clustering results. Using PCA as a pre-processing step to
clustering analysis enables us to visualize the five dimensional solution space, predict the
anticipated number of cluster and as a result generate more robust clusters. Here, the
results of data visualization and analysis are used for selecting the number of clusters.
But in order to validate the effectiveness of clustering and the quality of the generated
clusters, a cluster validity index, called Silhouette index, is selected in this work for
138

selecting the number of clusters (k) as the algorithm input from several methods available
[106]. The Silhouette index (SI) for k clusters is calculated using the following equation:
!

𝑆𝐼 = !

!
!!! 𝑆𝑊!

(7-6)

where SWi is the Silhouette width for each data point i (SoS candidate solution)
and n is the total number of SoS candidate solutions. The Silhouette width (SWi) for each
candidate solution (xj) can be calculated using the following equation:
! !!

!
!
𝑆𝑊! = !"#(!
,! )
!

(7-7)

!

where ai is the average distance of the ith candidate from all the other candidates in
its cluster, and bi is the average distance of the ith candidate from all the candidates in the
nearest neighbor cluster. The SWi belongs to the interval of (-1,+1). Candidates with the
silhouette width of +1 are well-clustered and candidates with the silhouette width of -1 is
assigned to the wrong cluster. Candidates with SWi of 0 tend to lie between clusters
[107]. The higher silhouette index indicates the better-defined clusters.
The results of clustering analysis are influenced by the choice of a similarity
measure and clustering algorithm. Using different clustering algorithms and similarity
measures to analyze the same data set can lead to different clustering results and
conclusions. The most popular distance measures are Euclidean distance, Manhattan
distance, Chebyshev distance and Minkowski distance function.
Euclidean distance is the most commonly used which calculates the root of square
differences between coordinates of two objects.
𝐷!" =

!
!!!(𝑥!"

− 𝑥!! )!
139

(7-8)  

Manhattan distance or city block distance reflects distance between two points in a
city road grid. The absolute differences between coordinates of two objects are computed
in this approach as:
𝐷!" =

!
!!!

𝑥!" − 𝑥!"

(7-9)

Chebyshev distance, which is also known as Maximum value distance is the
calculated absolute magnitude of the differences between coordinates of two objects:
𝐷!" = 𝑀𝑎𝑥! 𝑥!" − 𝑥!"

(7-10)

Minkowski distance is shown below. This distance function transforms to
Euclidean distance when p=2 and represent city block distance when p=1.
𝐷!" = (

!
!!!

𝑥!" − 𝑥!"

!

! !

)

(7-11)

Also, Chebyshev distance is a special case of Minkowski distance with p=∞ [108].
According to [105] and [109], the K-means, which is implemented using Euclidean
distance metric gives best result and is used in this approach.
Also, the results of k-means clustering are highly influenced/corrupted by the
addition of noise and existence of outliers [110]. Conducting the data visualization and
analysis in the first step allows finding the outliers in the SoS solution space and analyse
them separately so that they do not impact the clustering results.

2. Data Envelopment Analysis for Solution Space Simplification

140

If the visual inspection of scatter plots (original data or PCs) shows no structure,
DEA is recommended in this work for reducing the order of the solution space (Figure
58). This approach has been used for many years in evaluating efficiency/performance of
firms or entities [111]. The reason that DEA was used for this approach (this step of the
decision making) is that this method does not require stakeholders input (preference) to
find the SoS efficient frontiers. This advantage of DEA makes it suitable for this phase of
the decision making as stakeholders inputs may still not be available. This method can
also handle inputs and outputs with different measurement units. Here, efficient SoS
solutions are determined based on their calculated efficiency scores and the SoS solutions
on the efficient frontiers are used for communication among stakeholders and selecting
the most preferred SoS. Removing the inefficient SoS solutions provides the stakeholders
and decision-makers with a screened/censored version of the solution space that includes
a smaller numbers of SoS solutions and are easier to understand and communicate.
Using this approach guarantees that the final selection of SoS solution is made from
the best set of existing SoS solutions in the solution space. This is due to the fact that the
selected SoS solutions for the simplified solution space are better candidates (relatively
more efficient) compared to those that have been removed from the analysis.

141

Cluster SoS Solutions
based on Their
Similarities

1
Results of SoS Data
Analysis
Is there a
notion of center
in the solution
space?

Negotiate Results with
Stakeholders Using
Cluster Representatives
Yes

Select the Best AgreedUpon Cluster

Is there a
notion of center in
the efficient frontier
space?

No
Apply Data Envelopment Analysis
To Determine
Efficient SoS Solutions
Yes
Large number of
Efficient SoS
Solutions?

Yes

No

Is there a
large number of
solutions within the
selected cluster?

Yes
No
Provide Stakeholders
with Simplified Solution Space
for Communication

No

2
Figure 58: Phase 2 - Simplifying the Solution Space using DEA

Application of Data Envelopment Analysis on Simplifying the SoS Solution Space
Data Envelopment Analysis (DEA), first introduced in Charnes et al. [112], is a
linear programming technique that evaluates the relative efficiency of objects (called
Decision Making Units (DMUs)) which contain some nonhomogeneous input and output
[111]. Outputs are those criteria (decision attributes) that need to be maximized and
inputs are those attributes that need to be minimized. The efficiency score of each object
142

is calculated relative to the efficiency frontier. Those objects that are located on the
efficient frontier have an efficiency score of one and the ones that fall beneath the
efficiency frontier have an score below 1. Efficiency of SoS solution is defined as the
ratio of the weighted sum of its outputs to the weighted sum of its inputs.
A DEA model can be input or output oriented. In an input-oriented model, the
score of an inefficient object indicates how much it can decrease its input to reach a given
level of output, while in an output-oriented model, the score indicates how much an
object can increase its output for a given level of input. The choice of input or output
model depends on the application and also analysts’s control over variables (input or
output). However, the efficient frontier will be the same in both input and output
orientation within each DEA model. In other words, those objects that are located on the
efficient frontier in input orientation will also be on the frontier of output orientation.
Therefore, for the application of this dissertation, any of the abovementioned two
orientations could be used.
There are also two basic DEA models: constant returns to scale (CRS) and variable
returns to scale (VRS). These two models form two different efficient frontiers, as shown
for a case study in [111] (Figure 59). The VRS model forms multiple planes that
envelope the data more tightly than CRS and provides efficiency scores that are higher
than or equal to those found in the CRS model [113].

143

Figure 59: CRS and VRS Frontiers [114]

The classical DEA model (CRS-input oriented, Multiplier form) is shown in the
equations (7-12)-(7-14) [115]. Here, the efficiency of SoS solutions are evaluated in
terms of their evaluated decision attributes. These inputs and outputs reflect
characteristics of each object, in this case, SoS solutions. Mission reliability, basic
reliability and priority values of each SoS solution are considered as outputs as they need
to be maximized and time to IOC and capability cost are the inputs as they need to be
minimized. Assume that there are n SoS solutions indexed by xi (i=1,2,…,n) to be
evaluated. The xi has x different outputs and y different inputs.

144

𝑀𝑎𝑥  𝜃! =
s.t.

!
!!! 𝑢! 𝑦!"#

!
!!! 𝜈! 𝑥!"#

=1

!
!!! 𝑢! 𝑦!"

−

(7-12)
(7-13)

!
!!! 𝜈! 𝑥!"

≤ 0  , 𝑗 = 1,2, … , 𝑛

(7-14)

𝑢!   , 𝜈!    ≥ 0  𝑓𝑜𝑟  𝑎𝑙𝑙  𝑟  𝑎𝑛𝑑  𝑖

where:
j is the DMU (SoS solution) index (j=1,2,…,n),
r is the output index (r=1,2,…,s) ,
i is the input index (i=1,2,…,m)
yrj is the value of rth output for the jth DMU
xij is the value of ith input for jth DMU
ur is the weight given to the rth output
νi is the weight given to the ith output
θ0 is the relative efficiency of DMU0
The model assigns weights for each input and each output in such a way that
provides the highest possible efficiency score for each DMU that is allowed by the
constraints [116]. Therefore, each DMU is allowed to choose weights that maximize its
efficiency score. The input and output weights can vary between DEA models.
The DEA CRS can be easily modified to account for VRS by adding a convexity
matrix:

145

VRS$Model$–$Input$Oriented$
Mul3plier$Form$

Envelopment$Form$

s.t.$

s.t.$

Figure 60: Multiplier Form and Envelopment Form of Input-Oriented VRS Model [117]

Since the CRS model is more restrictive and often yields a fewer number of
efficient objects compared to VRS, we used VRS model to ensure that all the possible
efficient SoS solutions were considered for selecting the most preferred one.
This model has to be solved for every SoS solution to calculate an efficiency score
for each SoS solution. As SoS solution with efficiency score of 1 is considered efficient
relative to other SoS solutions in the solution space. Increase in the number of inputs and
outputs impact (increase) the number of efficient SoS solutions on the frontier. At the
same time, the method is not capable of showing efficient objects when there are too few
inputs and outputs [118]. Also no correlation between inputs and outputs may result in
loss of power of DEA in distinguishing SoS solutions as it views each SoS as unique and
efficient [119].
146

3. A Hybrid Approach for Solution Space Simplification
In the hybrid approach, a combination of clustering analysis and DEA is suggested
for reducing the order of the solution space. The hybrid approach is suitable for the
following two scenarios that the analysts may face during this step.
− The first scenario is when the results of data analysis show no inherent cluster
structure and the analyst starts with DEA but he finds a large number of
efficient SoS solutions on the frontier. Even though the inefficient frontiers
have been removed, it is still not easy for stakeholders to understand the
remaining of the solution space and discuss their priorities. In this situation,
application of clustering analysis is useful for further simplifying the solution
space. Clustering analysis can be used for grouping similar efficient SoS
solutions and selecting the best cluster.
− The second scenario is when the clustering analysis path is taken for simplifying
the solution space but the number of candidates in the selected (stakeholders’
agreed upon) cluster is too large.

In this case, DEA can be taken as an

additional step to reduce the number of SoS candidates for use in the next phase.
Efficient SoS solution within the selected cluster will be found to represent the
simplified solution space.

147

Phase 3: Ranking SoS Solutions
In this phase, the simplified version of the solution space that includes a relatively
small number of SoS solutions as well as stakeholders defined priorities (in the form of
weightings of decision attributes) will include the inputs of this phase. The objective of
this phase is to rank SoS solutions based on stakeholders’ preferences to select the
preferred SoS solution. Among the MCDM methods, utility-based methods and
outranking methods consider stakeholders’ preferences and have been used in a variety of
applications [120]. The outranking methods are capable of handling both qualitative and
quantitative criteria and they are suitable when pairwise comparison of a set of finite and
discrete alternatives are required. Outranking methods that are based on pair-wise
comparison of the alternatives, have been widely used in many engineering projects
[121]. Two of the most widely used outranking methods are: ELECTRE (ELimination Et
Choix Traduisant la REalité) and PROMETHEE (Preference Ranking Organization
Method for Enrichment Evaluations). ELECTRE was presented by Bernard Roy in 1960
as a decision making tool and it is based on two major concepts: concordance and
discordance. The concordance degree can be calculated using difference and indifference
thresholds and discordance degree can be calculated using veto threshold. This method is
explained in detail in [111]. This method been extended to several methods, e.g.
ELECTRE I, II, III, IV, Is, Tri [111]. The advantage of ELECTRE is that it takes into
account uncertainty and vagueness [122], and for that reason it constitutes one of the
main branches in the family of outranking methods [111]. However, its process and
outcomes are hard to explain [122]. In addition, it does not identify the strengths and
148

weakness of each alternative [122]. The process in using this method is complex and
lengthy. Therefore, with an increase in the number of alternatives, the amount of
calculations increases rapidly [123].
The PROMETHEE was developed by Brans et al. in 1984 and it is based on the
computation of the preference degrees [111]. In selecting the most preferred SoS
solution, PROMETHEE method has been adopted due to its simplicity and inexpensive
computational resources required. Also the information required to run this method is
clear and understandable for users (analysts) [124]. This method requires the information
on the relative importance of each decision attribute (in the form of weights) and also
information on the stakeholders’ preference functions, which will be used in comparing
different candidates in terms of each decision attribute. [111].
This method has also been extended to new methods, PROMETHEE I and II.
These extended methods (for both ELECTRE and PROMETHEE) are slightly different
in a way that they determine the outranking relations among alternatives and the final
ranking of the alternatives [124]. PROMETHEE I provides a partial pre-order ranking of
alternatives. In other words, using PROMETHEE I, some alternatives may not be
included in complete ranking as they cannot be compared [125]. This means that this
method requires more evaluation efforts from analysts and stakeholders to address this
problem. However, PROMETHEE II provides a complete ranking of the alternatives
based on the net flows and it has been used in this work.
There are three inputs for this phase. For each SoS stakeholder, the importance of
each decision attribute and preference function are captured and also stakeholders’
149

relative power (importance) should be defined by SoS management team. Figure 7-10
depicts the flow diagram of this phase. As shown in Figure 61 this phase starts with
conducting the pairwise comparison of the SoS solutions remained on the simplified
version of the total solution space for each stakeholder. Then individual net flow
(preference index) of each SoS solution will be calculated for different stakeholders.
Then the global net flow will be calculated for each SoS solution using weighted sum of
the preference indexes (individual net flows) using stakeholders’ relative power
(importance of stakeholders). The SoS solution with the highest global net flow
(preference index) is the most preferred SoS solution.

150

Stakeholders

Phase 2

Phase 1
Start

Data
Visualization
and Analysis

Data Structure
and Patterns

1

Solution Space
Simplification

A Smaller Palette of
Solution Space

Phase 3

Weightings of Decision
Attributes

Ranking SoS
Solutions of the
Simplified Solution
Space

2

End

2
For each SoS Stakeholder, Define:
- Weightings of Each Decision
Attribute
- Stakeholder’s Preference Function

Conduct Pairwise Comparison of
SoS Solutions (Simplified Version)
Calculate Individual Net Flows
(Preference Index) For Each SoS
Solution
Calculate Global Net Flows
(Preference Index) For Each SoS
Solution

SoS Management Team
Relative Power of each
Stakeholder
(Importance of each Stakeholder)

Rank SoS Solutions
End

Figure 61: Phase 3 - Selecting the Preferred SoS Solution

Application of the PROMETHEE for Selecting the Preferred SoS
The problem of selecting the preferred SoS considers a set of feasible SoS solution
A = {a, b, ...} that should be evaluated and compared in terms of k criteria. Criteria are
151

the selected decision attributes, such as capability cost.
Each stakeholder expresses his preference of SoS solution a over solution b
considering the decision attribute fj by computing a single-criterion preference degree
Pj(a, b). The preference degree for each SoS solution is a value between 0 and 1 that
indicates how much one SoS solution is preferred over another solution in terms of an
specific decision attribute [111],[126]. This value directly reflects the stakeholders and
decision-makers’ preferences. A preference value of 1 indicates an strong preference of
one SoS solution over another for an specific decision attribute, while the preference
value of 0 shows no preference. A preference value between 0 and 1 shows some
preference but not a strong one. In order to calculate a preference degree, preference
functions are required [111]
There are six specific shapes of preference function as shown in Figure 62 that has
been proposed by (Brans et al. 1986). Different types of preference functions depend on
up to two thresholds: indifference threshold (q), preference threshold (p) and Gaussian
threshold (s). For example, in pairwise comparison of SoS solution using a linear
preference function, if the difference between two evaluations is smaller than the
indifference threshold, the analysts can perceive no difference between two SoS
solutions. However, if the difference is larger than the preference threshold, the
preference will be strong. In linear preference function, the value of the function is the
value of preference of differences between indifference and preference threshold. The
preference and indifference threshold values should be defined for each decision
attribute.
152

Figure 62: Six Types of Preference Functions

The PROMETHEE requires computation of preference values for every pair of SoS
alternatives on each decision attribute, computation of unicriterion flows (positive and
negative flows) and computation of net flows for each SoS alternative. The computation
of these values are shown in equations (7-15)-(7-19). Let Stkr (r=1,2,…,R) be the R SoS
stakeholders and 𝑊!! ,𝑊!! ,…, 𝑊!! be the weights associated to the k criterion by
stakeholder r. In the PROMETHEE method no guidance has been provided on how to
determine weights of each criterion. But various methods have been discussed in the
literature [127],[128]. In [125], analytic hierarchy process (AHP) was used for
153

determination of weights. Here, it is assumed that stakeholders are able to weight the
criteria appropriately.
For each SoS solution a, belonging to the set A of feasible SoS solution, 𝜋 ! 𝑎, 𝑏 is
the preference of a over b based on all decision attributes for stakeholder r.
!
!
!!! 𝑝! (𝑎, 𝑏)𝑤!

𝜋 ! 𝑎, 𝑏 =

(7-15)

where Pj(a, b) indicates the preference of alternative a over b on each criterion and
wjr is the weight associated to each criterion by stakeholder r. The preference is
calculated using the selected preference function formula for each criterion.
The positive flow ϕ+(a) is a value between 0 and 1 that indicates how SoS solution
a dominates all the other SoS solution of A. the higher this value is, the more preferred
this SoS solution is over others.
𝜑!! 𝑎 =

!∈! 𝜋

!

(𝑎, 𝑏)

(7-16)

The negative flow ϕ-(a) is a value between 0 and 1 that shows that how much a is
dominated by all the other SoS solution of A. This value has to be minimized as it shows
the weakness of SoS solution.
𝜑!! 𝑎 =

!∈! 𝜋

!

(𝑏, 𝑎)

(7-17)

ϕ(a) represents the total outranking value. The higher value reflects a higher
attractiveness of SoS alternative a.
𝜑! 𝑎 = 𝜑!! − 𝜑!!

(7-18)

This value is the net flow of solutiona for stakeholder r. This value should be
calculated for each SoS solution for each stakeholder. Let 𝑤! ,𝑤! ,…, 𝑤! be the relative
power of each stakeholder. Then the global net flow of each SoS solution can be
154

calculated using the weighted sum of the individual net flows as shown below:
𝜑! 𝑎 =

!
!
!!! 𝜑

𝑎 𝑤!       

(7-19)

Based on the global net flow, ranking of SoS solutions can be attained [129].
7.2. Summary
The objective of this chapter was to develop a general method for selecting the
preferred SoS alternative (solution) from the set of feasible solutions defined in previous
steps of this methodology. The advantage of the approach presented in this chapter
compared to the optimization methods is in increased participation of stakeholders, which
has been emphasized in the literature. This method adopts data analysis techniques to
highlight preferable regions of the SoS solution space for stakeholders and consequently
enables informed decision-making. This method also applied clustering analysis and
DEA to select a set of preferred SoS solutions before selecting the most preferred option.
This set, which is the simplified version of the solution space, represents those areas of
the solution space that the majority of stakeholders would have considered beneficial.
This step improves the level of acceptance of the final SoS selection by stakeholders and
avoids repetition of SoS system selection (decision making) process. The complete
ranking of the selected (preferred) alternatives will then be obtained using outranking
methods, PROMETHEE II.

155

Stakeholders

Phase 2

Phase 1
Start

Data
Visualization
and Analysis

Data Structure
and Patterns

1

Solution Space
Simplification

A Smaller Palette of
Solution Space

Phase 3

Weightings of Decision
Attributes

Ranking SoS
Solutions of the
Simplified Solution
Space

2

End

2

Results of SoS Data
Analysis

Library of SoS Solutions

Yes

Number of Decision
Attributes (dimensions-d)
d <= 3

Analyze Data
(SoS Solutions)

Negotiate Results with
Stakeholders Using
Cluster Representatives

Is there a
notion of center
in the solution
space?

Visualize the Solution Space

Plot Data

Cluster SoS Solutions
based on Their
Similarities

1

Start

No

Conduct Principal
Component
Analysis

Yes

Select the Best AgreedUpon Cluster

Is there a
notion of center in
the efficient frontier
space?

No
Apply Data Envelopment Analysis
To Determine
Efficient SoS Solutions
Yes
Large number of
Efficient SoS
Solutions?

Yes

Conduct Pairwise Comparison of
SoS Solutions (Simplified Version)

No

Is there a
large number of
solutions within the
selected cluster?

Yes
No
No

For each SoS Stakeholder, Define:
- Weightings of Each Decision
Attribute
- Stakeholder’s Preference Function

Provide Stakeholders
with Simplified Solution Space
for Communication

Calculate Individual Net Flows
(Preference Index) For Each SoS
Solution
Calculate Global Net Flows
(Preference Index) For Each SoS
Solution

SoS Management Team
Relative Power of each
Stakeholder
(Importance of each Stakeholder)

Rank SoS Solutions

1
2

End

Figure 63: Summary of the Three-Phase Approach for Selecting the Preferred SoS Solution

156

CHAPTER 8
NUMERICAL EXPERIMENTS

Having developed a methodology for selecting the preferred SoS solution from a
set of generated feasible solutions, the next step was to test the methodology to explore
its strengths and limits. Since data did not exist for a real application of this methodology,
simulation has been used to generate data for a hypothetical case of a search and rescue
operation to explore and investigate the methodology and model’s behavior. Simulation
was used to represent some possible ways that the SoS solution space may appear in realworld applications and the result of each adjustment was analyzed. In generating
simulation results for some selected scenarios, MATLAB was used. Correlations were
considered among decision attributes, using copula functions. For each scenario, suitable
techniques (clustering analysis or DEA) was used to simplify the solution space and the
preferred SoS was selected for an specific case.
8.1. Hypothetical Example of a Search and Rescue Operation (SAR)
In order to explore and illustrate the methodology and model for selecting the
preferred SoS solution, a hypothetical example of a Search and Rescue (SAR) mission
was used in this chapter to evaluate the results of experiments conducted in this research.
In an SAR mission, multiple operationally independent systems (capabilities) cooperate
to accomplish the SAR mission objectives. The selected scenario starts with a distress
157

call from a party in danger and a mission to rescue this party. This mission is represented
in Figure 64. The mission objective is to successfully complete the mission by initiating
the mission, conducting a search, rescuing survivors and delivering them to a place of
safety. This mission consists of two consecutive, non-overlapping phases of (1) Search,
(2) Rescue and Transfer of survivors to a place of safety.
Helicopter Located
in U.S.C.G Base II

Airplane Located in
U.S.C.G Base I

Ship

Search Area

Figure 64: SoS Mission Representation for an SAR Mission

SoS Mission
Starting Point

SAR SoS
Mission

t0
Mission Initiation
Phase
ts,j
TI-A/P

Airplane
(A/P)
Ship
(S)

SoS Mission
End Point
t1

t2

T1

T2

Phase 1
Search

Phase 2
Rescue

TI-S
TI-H

Helicopter
(H)

Figure 65: SoS Mission Profile for an SAR Mission(dashed arrows reflects the data sharing
among systems)

158

Systems required for each phase of the SAR mission are defined based on the size of
the search area, type of search (visual or electronic), time to and from the search area,
mission duration, systems fuel load, systems’ range and speed. Based on the result of
developed capability objectives and requirements, in phase one of the SAR mission, one
aircraft, one ship and one helicopter are required to be allocated to search three sub-areas
to complete the search phase. When the search object is located, the rescue phase starts.
During the rescue phase, an aircraft is required to stay in the area to drop equipment, and
provide radio signals for direction finding, etc. As necessary. Either a ship or a helicopter
is required to conduct the rescue in phase two. The assigned helicopter begins its rescue
attempt first while the ship takes position at a safe distance and stands by as a backup. If
the helicopter is unable to complete the rescue and aborts the attempt, the pilot indicates
that the assistance from the ship is required to complete rescue. If the helicopter makes
the rescue, it also provides rapid delivery of survivors to a medical facility. If the ship
makes the rescue, survivors are provided with medical assistance, as transfer to the
hospital takes longer. Data sharing is required among the aircraft, helicopter and ship
throughout the mission.
As shown in SAR mission profile in Figure 65, the SoS does not exist before the
mission-starting point at t0. Each system individually performs its own initiation phase to
prepare, launch and transit from its base/current location to the search area to join the
SoS. Transfer from base to search area may take longer for some systems due to their
capabilities, which requires them to start their mission initiation phase earlier. In this
hypothetical mission, it is assumed that both helicopter and airplane are almost at the
159

same distance from the search area. Since the helicopter is slower than the airplane, it
starts its mission before the airplane starts its initiation phase. By the time that the search
phase starts (at t0), all systems of SoS are present in the area. Indeed this is the point in
which the SAR SoS forms and the SoS mission starts. The first phase of the SAR SoS
mission, the search, is completed when the mission object is located by at least one of the
systems involved in this phase. Therefore the duration of the search phase is the same for
all three systems (T1). In practice, the duration of each phase, i.e. search phase, is
variable. For example, locating a missing object in an SAR mission may stretch from
hours to weeks. The required data sharing capability among systems throughout the
mission is shown as dashed arrows in Figure 65. By the time that the rescue phase is
completed, the SoS mission goals are accomplished. Systems, e.g., helicopter, may have
to return to their bases after rescuing and transferring survivors to a place of safety.
However, their return has not been defined as a part of the SAR SoS mission and it will
not be considered in the mission reliability analysis of the SoS mission, even though it is
considered in estimating the SoS capability cost as dispersal cost.
Table 4 illustrates a list of existing capable candidate systems including ships,
helicopters and aircrafts that are available to engage in the SAR mission. For the
simplicity, it is assumed that systems that are selected for the first phase of the SAR
mission will continue the mission to complete the second phase as well. This may not be
the case in real SAR situations as different systems may be used for various phases of a
single SoS mission. However, the methodology still is applicable for cases in which
systems involved in the mission are different in phase one and two. As shown in Table 8160

1, the SAR SoS solutions are being formed from the existing U.S. Coast Guard’s assets,
and those systems that are available for lease from other organizations. A ship is
considered as a boat either a small boat or a large one.
Table 4: The hypothetical number and types of available systems (including SAR assets and Volunteer
assets) – U.S. Coast Guard Report

U.S. Coast
Guard Assets

Available
Systems
Aircraft

Category
Ø

Type

Helicopter

Ø

Ship (Small
and Large
Boats)

Ø
Ø
Ø

Fixed wing
aircraft
Rotating wing
aircraft
Life boat
Motor life boat
Small boats

Ship (Large
Boats)

Ø

Large boats

§
§
§
§
§

§
§
§
§

HC-130 Hercules
HC-144 Ocean Sentry
HH-65 Dolphin
HH-60 Jayhawk
21'- 64' Aids to
Navigation Boats
41' Utility Boats
47' Motor Life Boat
210' Medium
Endurance Cutter
282' Medium
Endurance Cutter
75' River Buoy Tender
65' Small Harbor Tug
65' River Buoy Tender
Variable

§

Variable

2

§
§

Variable
Variable

3
1

§
§
§
§

Volunteer
Systems
(Borrowed or
Leased)

Aircraft

Ø

Helicopter

Ø

Ship
Ship

Ø
Ø

Fixed wing
aircraft
Rotating wing
aircraft
Small Boat
Large boats

Total
Number
2
2
3

5

2

Since there are 4 candidate aircraft, 4 candidate helicopters, 6 small and 6 large
candidate boats, all possible combinations of these systems for accomplishing the SAR
mission equals to 576, which defines our data set, S, the set of all possible SoS candidate
solutions that are assumed feasible in this hypothetical case.
According to [130], each SAR resource/unit should be ready to proceed within 30
minutes of notification of a distress. The SAR mission response shall not be greater than
a two-hour total response time for any one system. This time is calculated from time of
notification of the Coast Guard until the time of arrival on scene, including 30 minutes of
161

preparation time (i.e. a total of 90 minutes from underway to on-scene). The SAR
mission response time in this example reflects the selected decision attribute of SoS time
to operational capability.
8.2. Estimation of Decision Attributes for SAR Mission
In the developed methodology, five decision attributes were selected for comparing
SoS solutions and selecting the most preferred one. Estimation of the selected attributes is
explained in chapter 5. Since data for a real SAR mission did not exist, the SAR SoS
solution was simulated by generating values for each decision attribute using an
appropriate distribution. The simulation of the SAR solution space is explained in detail
in section 8.3.
Since a core part of the developed methodology was a process for SoS mission
reliability modeling and analysis, and to test the developed method for SoS mission
reliability modeling and analysis, this decision attribute is modeled and calculated for a
hypothetical SAR SoS in this section.
Here, mission reliability analysis of a phased mission-SAR SoS with data sharing
capability is numerically illustrated. The failure time distribution of airplane, ship and
helicopter in each phase is exponential. The parameter values and duration of phases are
given in Table 5.

162

Table 5: Systems Parameters and Duration of Phases
Initiation	  Phase	  
	  
	  
Phase	  
A/P	   S	  
H	  
Duration	  
10	   30	   20	  
(min.)	  
A/P	  
0.001	  
Failure	  
Rate	  
S	  
0.0005	  
(λ)	  
H	  
0.00005	  

Phase	  1	  

Phase	  2	  

120	  

60	  

0.00002	  
0.00005	  

0.00001	  
A	  

SB	  

0.00005	   0.00003	  

0.00003	  

0.00008	  

	  
Table 6: Data link Parameters (Data Generator (DG))
	  	  

Failure	  Rate	  (	  λ)	  
DG	  

Antenna	   Processor	   Receiver	   Transmitter	  	   Display	  

Airplane	  

0.0001	  

0.0003	  

0.0004	  

0.0003	  

0.0002	  

0.0001	  

Ship	  

0.0002	  

0.0001	  

0.0004	  

0.0001	  

0.0001	  

0.0002	  

Helicopter	  

0.0003	  

0.0003	  

0.0002	  

0.0001	  

0.0001	  

0.0003	  

	  

Phase 2

Phase 1
A/P$

S$

H$

H$

A/P$

S$

	  

Figure 66: RBD for the SAR Mission Example

	  
Using the developed methodology in chapter 6, the reliability of airplane,
helicopter and ship at the starting point of SAR SoS mission is calculated. These values
are calculated based on the given values shown in Table 5 as RA/P(TI=10)=0.99,
RS(TI=30)=0.985 and RH(TI=20)= 0.999. The reliability of CMEF, for the entire SoS
mission is also calculated separately. This value for the SAR mission reliability is
computed from t0 (SoS mission starting point) based on the given values for failure rates

163

shown in Table 5. RCMEF(t) was then combined with the mission reliability of SoS at time
t during the mission.
For this simple case, the accurate SoS mission reliability can be calculated by
computing the SoS mission reliability of phase two, considering systems total operating
time in the mission. Figure 67 compares the accurate mission reliability, with and without
data sharing capability, to the estimated values. In calculating SoS mission reliability
without data sharing, it is assumed that the required data for each system can only be
provided for the systems by their own capabilities (data generators, e.g. sensors). The
accurate and estimated mission reliabilities are equal through the end of phase one
(t=120). The estimated SoS mission reliability (t=180) is 1.7% and 2% smaller than the
accurate values with and without data sharing, respectively. The difference will become
higher if the number of phases increases. The difference between the estimated and the
accurate mission reliability for the entire duration of the mission (t=180) is due to the
reason that systems involved in phase one are also required for phase 2 and in series
during phase one. If the systems involved in the first phase are not all required for the
second phase, or the configuration of systems in phase one is parallel or hybrid, the
presented approach provides a closer estimate to the accurate mission reliability. To
further evaluate the effect of data sharing capability and phase-configurations on the
estimated lower bound mission reliability, performing design of experiments is
considered in the future work.

164

1%
0.98%

SoS Mission
Reliability (MR)

0.96%
0.94%
0.92%

Estimated lower bound MR_ W/O
Data Sharing Capability
Estimated lower bound MR_with
Data Sharing Capability
Accurate MR_With DS Capability

0.9%
0.88%
0.86%

Accurate MR_W/O DS Cap.

0.84%
0%

20%

40%

60%

80%

100%

120%

140%

160%

180%

200%

Mission&Time&(t)&

Figure 67: Impact of Data Sharing on SoS Mission Reliability – Reliability at t=0 is smaller than 1 because
at this point, systems have completed their own initiation phase and started the SoS mission. Phase 2
(rescue) starts at t=120

As shown in Figure 67, data sharing dramatically improves SoS mission reliability.
The SAR SoS mission reliability without data sharing in 0.86 which is improved to 0.97.
This further highlights the benefit of utilizing data sharing as a redundant capability.
8.3. Simulation of SAR Solution Space
Let S be the set of feasible SoS solutions for the SAR mission, which defines the
solution space: S={SoS1, SoS2,…, SoS576}. Here, each SoSi, which belongs to S is
characterized by five decision attributes: SoSi = {MRi, BRi, CCi, DTi, PLIi}.
In order to generate data set S, suitable distribution was selected for each of the
decision attributes. According to [131], there are four shapes for the density functions
that cost elements typically follow: uniform, triangular, normal and beta distributions.
Among these four, triangular distribution seems to be the most widely used distribution
for simulating cost and duration data [132]. Therefore, the triangular distribution was
165

used for simulating both SAR capability cost and time to IOC. Another reason for
choosing this distribution is that its properties can be easily derived. The triangular
distributions for SoS capability cost was characterized by three numbers, the best case,
the most likely and a worst-case cost of 5, 7 and 9 million dollars. The triangular
distribution of time to IOC was also characterized by three numbers of 1, 2 and 5 hours.
Beta distribution was used for generating mission reliability data as the beta distribution
could be set to take numbers between two values (minimum and maximum) and the
reliability of SAR SoS solutions were anticipated to be between 0.9 and 1. The
parameters of the beta distribution was selected as A=5 and B=2 > 1. The parameters
selected provided a density that is left-skewed which made it suitable for the application
of this work as shown in Figure 68.

Percent of
Total
Frequency

Histogram

	  

Figure	  68:	  Beta	  Distribution	  with	  Parameters	  A=5	  and	  B=2
For basic reliability, the normal distribution was used where the mean basic
reliability was considered to be 150 hours. For this decision attribute, unlike mission
reliability, a pre-determined bound could not be predicted. In addition, there is no
evidence that the distribution of basic reliability is either left or right skewed. For those
166

reasons, the normal distribution seemed to be a good fit to represent basic reliability due
to its symmetry. The unifrom distribution was selected for PLI as there was no
information about the relative likelihood of possible outcomes.
Having selected a single distribution for each individual attribute (variable), the
next step was to define dependencies that might exist among variables. For example,
basic reliability and priority-level (as a function of constituent systems’ capabilities)
directly impact SoS capability cost. Therefore, considering the selected decision
attributes totally independent from each other could lead to wrong conclusions. To
prevent this, correlations were considered among mission reliability, basic reliability,
capability cost and priority level index. These correlations were considered in the
simulation by defining a covariance matrix.
Since the distributions selected for each attribute (variable) were different and the
decision attributes selected for this methodology were not independent from each other in
real-world problems, generating a multivariate distribution was required for all the
marginal distributions.
It was a challenging task to generate dependent random inputs (variables) when
they have distributions that are not from a standard multivariate distribution. To deal with
this issue, copulas functions were used to describe dependencies among attributes
(variables), and provide a way to create distributions to model correlated multivariate
data. Using a copula, one can construct a multivariate distribution by specifying marginal
univariate distributions, and selecting a particular copula to provide a correlation
structure between variables [133].
167

To simulate dependent multivariate data using copula, the followings needed to be
specified:
1) The copula family (Gaussian copula and t copula)
2) The rank correlation among attributes (variables)
3) The marginal distributions for each variable
Here for five sets of input data, the objective was to conduct a simulation with
inputs that follow different distributions. The objective was to construct a multivariate
copula, which is defined as a probability distribution function on five random variables,
each of whose marginal distributions is uniform. The five variables can be set to be
independent, completely correlated or something in between. The family of Gaussian
copulas that is used here is parameterized by Rho, the linear correlation matrix. This
matrix, as shown below, reflects the dependence between variables (attributes):
1
𝑟ℎ𝑜
Rho = 𝑟ℎ𝑜
𝑟ℎ𝑜
𝑟ℎ𝑜

𝑟ℎ𝑜
1
𝑟ℎ𝑜
𝑟ℎ𝑜
𝑟ℎ𝑜

𝑟ℎ𝑜
𝑟ℎ𝑜
1
𝑟ℎ𝑜
𝑟ℎ𝑜

𝑟ℎ𝑜
𝑟ℎ𝑜
𝑟ℎ𝑜
1
𝑟ℎ𝑜

𝑟ℎ𝑜
𝑟ℎ𝑜
𝑟ℎ𝑜
𝑟ℎ𝑜
1

where the rho is the correlation parameter. Here expert judgment was used to create rank
correlation matrix by choosing suitable rho parameters. A strong correlation was
considered among (1) mission reliability and basic reliability (positive) and (2) basic
reliability and capability cost (negative). A rho in the interval of (0.8, 1) shows an strong
correlation. A moderate correlation was considered among (1) mission reliability and
capability cost (negative) and (2) priority and capability cost (positive). These
correlations were selected from the interval of (0.5 to 0.8) for the correlation matrix. Also
168

weak correlation was considered among time to IOC and all of the other four decision
attributes. Weak correlation is represented through rhos from the interval of (0, 0.5).
MR

BR

CC

  1               𝑆 −𝑀
    𝑆               1 −𝑆
Rho= −𝑀 −𝑆 1
0
0 𝑀
𝑊
𝑊 𝑊
MR

BR

P

T

0 𝑊
0 𝑊
𝑀 𝑊
1 𝑊
𝑊 1
CC

P

T

1                   0.9   −0.7 0     0.3
0.9                 1 −0.8 0     0.3
0.7 0.3
Rho= −0.7     −0.8     1
0            
0
0.7
1 0.3
0.3        
0.3
0.3 0.3 1
Two variables reach linear dependence as the rho approach to +/-1 and they
approach independence as rho gets close to zero. The selected covariance matrix had to
be positive semi-definite which means that its eigenvalues had to be all real and positive
and the eigenvectors that belong to distinct eigenvalues had to be orthogonal.
Using copulas, the dependence between variables is independent from the marginal
distributions. Variables can be given any marginal distributions and still have the same
rank correlations. Copulas’ allowing separate specification of dependence and marginal
distribution, is listed as the main strength of this technique.
This technique requires a two-step transformation to be applied to each variable of
a standard multivariate normal, creating dependent random variables (r.v.’s) with
arbitrary marginal distributions. Since the transformation works on each component
separately, the resulting r.v.’s don’t need to have the same marginal distributions.

169

It is defined that applying the normal CDF to a standard normal random variable
results in a r.v. that is uniform on the interval [0,1]. Also it is known from theory (named
Inversion Method) that applying the inverse CDF of any distribution F to a U(0,1)
random variables results in a r.v. whose distribution is F. Using these two
transformations, here is how the simulation data has been generated:
Z=[Z1 Z2 Z3 Z4 Z5];
U=[PHI(Z1) PHI(Z2) PHI(Z3) PHI(Z4) PHI(Z5)];
X=[G1(U1) G2(U2) G3(U3) G4(U4) G5(U5)];
Where PHI indicates applying the normal CDF and G1 to G5 are inverse CDFs of
different distributions that were selected for SoS decision attributes, e.g., beta distribution
for mission reliability and triangular distributions for capability cost and time to IOC
[133].
The result of this simulation yields the SAR SoS solution space as a matrix (n*m)
in which each row represents a solution (n=576), each column represents a decision
attribute (m=5) and there exist correlation among the decision attributes of mission
reliability and basic reliability, basic reliability and capability cost, and capability cost
and priority. Figure 69 shows the histograms of simulated values/data for each decision
attribute.

170

Figure 69: Histograms of Simulated Data for Each Decision Attribute

Figure 70-73 illustrates scatter plots of simulated inputs for every two correlated
variables. The histograms have also been included in these plots alongside the scatter
plots to show both the marginal distributions, and the dependence between variables.

Figure 70: Simulated Dependent Values of Mission Reliability and Basic Reliability

171

	  
Figure 71: Simulated Dependent Values of Basic Reliability and Capability Cost

	  
	  

Figure 72: Simulated Dependent Values of Capability Cost and Priority

Since the simulated data is five dimensional, it cannot be graphically displayed. For
illustrative purposes, Figure 73 shows the 3D plot for mission reliability, basic reliability
and capability cost.

172

Figure 73: 3D Plot of Simulated Data

8.4. SAR Solution Space - Results of Data Visualization and Analysis
The simulated solution space for the hypothetical SAR SoS could not be
graphically displayed since there were five decision attributes (dimensions). Therefore,
principal component analysis was used for data visualization and analysis of the solution
space. This method projected the simulated solution space that had five dimensions into a
lower dimensional space (e.g., 3D). To perform the analysis, MATLAB code was
developed. The results are discussed in this section. In order to conduct the PCA on the
simulated solution space, the data had to be normalized first. This is a pre-processing step
as the PCA tend to give more weights to those variables that have higher variances than
to those variables that have very low variances. It’s been suggested that a PCA should
only be used with the raw data if all variables have the same units of measure. Since the
variables of the simulated data were in different units, normalization of the data (use of
weights) was required.
173

The primary purpose of PCA is descriptive and the type of analysis conducted on
the results (the interpretations of the results) is based on what is important in the context
of the problem. In this case, we were looking for patterns or those data points (SoS
solutions) that were outliers (noise) and could affect the further analysis of the solution
space in the following step which is the solution space simplification.
In order to perform PCA on the simulated solution space, the following command
was used in MATLAB, where X is the simulated solution space and coeff, score, and
latent are the outputs of the PCA:
[coeff, score, latent] = pca(X)
The first output of the PCA contains the computed principal components and the
variance accounted for by each component (coefficients of PC). The five decisionattribute (variables) of this problem provided five principal components as shown in
Table 7:
Table 7: Principal Components and Variances computed for each Decision Attribute for the Simulated
Solution Space
Decision Attributes
(Variables)
Mission Reliability
Basic Reliability
Capability Cost
Priority-Level
Time to IOC

1

2

0.5503
0.5699
-0.5607
-0.2354
0.0497

0.2776
0.2426
0.3247
0.5967
0.6345

Principal Component
3
-0.1496
-0.1599
0.0286
-0.6521
0.7252

4

5

0.7663
-0.5936
0.1920
-0.1229
-0.0909

0.1026
0.4880
0.7365
-0.3849
-0.2464

Each column shows relative magnitude of each variable on each principal
component. The Interpretation of the results (principal components) is based on finding
which decision attributes are most strongly correlated with each component. The large
174

numbers within each column of Table 7 show those decision attributes that drive the
principal component.
The first principal component is a measure of mission reliability, basic reliability
and capability cost. As shown in Table 7, basic reliability and capability cost are
negatively related which means that improvement in basic reliability will result in lower
capability cost. The role of other attributes in the first component is trivial as the numbers
are small. The second PC is primarily a measure of priority level and time to IOC. Other
attributes also play a role to some extent in shaping this component as their values in
Table 7 is not insignificant. The third principal component is also a measure of priority
level and time to IOC. The fourth component is a also a measure of mission reliability
and basic reliability while the fifth component is a measure of basic reliability and
capability cost.
The other output of PCA is called “latent” which is a vector containing the
principal component variances. In other words, this output of PCA returns the
eigenvalues of the correlation matrix X (simulate data). The latent values returned by
MATLAB for this problem is presented in Table 8.
Table 8:Computed Latent Values for Each PC
PC
1
2
3
4
5

Latent
2.5813
1.6933
0.5900
0.1268
0.0085

The latent values were then used to decide how many principal components to
consider for this problem. In order to make a decision, we needed the percentage of the
175

total variance explained by each principal component. MATLAB calculates a vector
containing these percentages called explained (ans), which is presented in Table 9.
Table 9: Percentage of the Total Variances Explained by Each Principal Component
PC
1
2
3
4
5

ans
0.5163
0.8549
0.9729
0.9983
1.0000

According to the above vector, the first principal component explains about 52% of
the variation. Furthermore, the first three principal components explain 97%, while the
first four principal components explain 99.8% of the variation. The number of principal
components to consider depends on how much of the variation needs to be explained.
Here, the first three principal components are selected as it covers 97% of the variation.
The other output of this analysis is called components’ scores, which is a matrix
that is the same size as the input data matrix. The principal component scores is the
representation of X, the simulated data, in the principal component space. These scores
contain the coordinates of the original data in the new coordinate system that is defined
by the principal components. Figure 74 visualizes the first three principal components
score for this problem where the red dots represent each original (simulated data) on the
first three principal components. All five variables are represented in this 3D plot by a
vector where the direction and length of the vector indicate how each variable contribute
to the first three principal components.

176

Figure 74: 3D Plot of Simulated Data on the New Subspace

The result of PCA on the simulated data also shows which variables (attributes)
move together. For further analysis, one can plot the principal components against one
another (biplot) and explore the location of certain solutions (Figures 75-77).
Biplots reveal several characteristics of the dataset, which are useful in better
understanding the space. What can be learned from biplots includes high correlation
among variables (attributes), outliers and cluster structures. The latter two can be also
found using the PC score plot [134].
For example, Figure 75 illustrates SoS solutions in a 2D space; principal
component 1 (X - horizontal axis) and principal component 2 (Y vertical axis). In this
Figure, the positions of the data points (SoS solutions), shown in red dots, approximate
the scores of the SoS solutions on the first two principal components.
177

In this Figure, each attribute is shown in blue arrow. The length of the arrows
approximates the variances of the attribute. Also, the angle between the arrows,
approximates the correlation between the variables they represent. The closer the angle is
to 90, or 270 degrees, the smaller the correlation. An angle of 0 or 180 degrees reflects a
correlation of 1 or −1, respectively [134]. It can be seen that the angle between mission
reliability and basic reliability is very small. In other words, these two attributes move in
the same direction. This is due to the reason that there is a strong correlation between
these two variables (attributes). Mission reliability, basic reliability and time to IOC are
directed into the upper right part of the graph and capability cost is directed to the upper
left part of the graph. In other words, the first principal component, on the horizontal
axis, has positive coefficients for mission reliability, basic reliability and time to IOC and
has negative coefficients for capability cost. Those points (SoS solutions) that are located
near the left edge of this plot have the lowest scores for the first principal component.
This indicates that the first component distinguishes among SoS solutions that have high
values for mission reliability, basic reliability and time to IOC variables and low for the
capability cost. The second principal component, on the vertical axis, has positive
coefficients for all five variables.

178

Figure 75: The 2D View of the Simulated Data on Principal Component 1 and 2

Figure 76 shows the second principal component against the third principal
component. As can be seen in this figure, time to IOC (T) and priority (p) have high
variances compared to the other variables in the biplot. All the variables are positive on
the second principal component. However, the third principal component has positive
coefficients for capability cost and time to IOC and negative coefficients for the
remaining variables.

179

Figure 76: The 2D View of the Simulated Data on Principal Component 2 and 3

The 3D plot is rotated to view the first principal component against the third
principal component, Figure 77. This biplot illustrates strong correlation between mission
reliability, basic reliability and capability cost. It also shows a small correlation between
these attributes and time to IOC. No outlier or cluster structure has been detected in
Figures 75-77. This information can be used for selecting the solution space
simplification method.

180

Figure 77: The 2D View of the Simulated Data on Principal Component 1 and 3

8.5. SAR Solution Space – Simplifying the Solution Space
The approach needed for simplifying the SAR SoS solution space depends on the
results of the previous phase, data visualization. Depending on the structure of the
solution space, clustering analysis, data envelopment analysis or a combination of both
could be used. Here, the result of data visualization on the simulated solution space did
not show a cluster structure; therefore, DEA was used for solution space simplification on
the simulated data. Also a different set of data was simulated in which clustering analysis
was the better approach for reducing the order of the solution space to enable
communication among stakeholders. The simulation was conducted so that that the
solution space had a cluster structure and used to show the application of clustering
analysis in solution space simplification.

181

8.5.1 SAR SoS Mission Solution Space Simplification using DEA
Since the result of data visualization from the previous phase did not show a notion
of center, DEA was used on the simulated original data set to simplify the SAR SoS
solution space.
The results of DEA method on simulated solution space are given in Table 10.
Using Matlab, the input-oriented BCC data envelopment analysis on the simulated data
resulted in 19 efficient SoS solutions. The relative efficiency score of these SoS solutions
was very close to 1 which means that these solutions are relatively more efficient
compared to other solutions in the solution space in terms of inputs and outputs. Only
three SoS solutions had the efficiency score of exactly one. Since the objective was to
simplify the solution space for stakeholders communication, I selected those SoS
solutions that were relatively more efficient than others with the efficiency score of 0.999
and above (0.999-1). Matlab returned the efficient solutions as shown in Table 10.
The efficient SoS solutions could not be graphically displayed, as there were five
decision attributes. However, a 2D plot was created to show the efficient SoS solutions in
terms of mission reliability and capability cost.

182

Table 10: Results of DEA on Simulated Solution Space

SoS Solution ID
2
79
87
95
112
132
156
185
189
203
241
286
330
347
364
404
443
464
553

Efficient SoS Solutions
Decision Attributes (Variables)
Mission
Basic
Capability
Reliability Reliability Cost (M$)
0.9865
150.9158
7.3812
0.9743
149.8619
6.9640
0.9995
153.0217
5.3942
0.9969
152.0098
5.5123
0.9950
151.4827
5.3979
0.9983
152.8407
5.9863
0.9644
149.9817
5.7219
0.9333
147.4317
7.9675
0.9313
148.7680
8.3062
0.9843
149.6858
5.3921
0.9626
148.6432
8.5017
0.9406
147.9302
8.8582
0.9820
151.0470
6.9510
0.9848
150.6458
8.2802
0.9913
151.9424
5.2955
0.9987
152.8902
5.6883
0.9902
150.6344
7.3050
0.9949
152.2231
5.0191
0.9938
152.4997
5.7500

Priority
Level
0.9882
0.8524
0.6676
0.6029
0.3389
0.9348
0.1226
0.4530
0.9716
0.0214
0.9904
0.9948
0.9778
0.9989
0.3726
0.8274
0.9746
0.0004
0.8801

Time to
IOC
2.6360
1.3200
3.3852
1.9116
1.4573
3.6596
1.0716
1.1546
1.3496
1.0525
1.8520
2.1664
1.8090
4.0734
1.3419
3.5454
2.5320
1.6432
2.0889

	  
	  
	  

Figure 78: The 3D view of the DEA results (the red dots show the efficient SoS solutions)

183

8.5.2. SAR SoS Mission Solution Space Simplification using Data Clustering
In this section, a special case was developed for the application of data clustering
for solution space simplification. In this case, the data was simulated for an SAR mission
in which more than 1000 SoS solutions were generated and the result of data
visualization revealed a notion of center. In order to simulate a solution space with a
cluster structure, six points on the solution space were selected and about 200 data points
were generated around these six points (Figure 79). Note that the results cannot be
graphically displayed when the number of attributes is greater than three. However, the
results can be discussed among stakeholders and analysts using a vector representation of
the cluster centroids. Since the results could not be graphically displayed due to the
number of dimensions, only three attributes of mission reliability, basic reliability and
capability cost was used to display a 3D view of the solution space in Figure 79.

Figure 79: A 3D view of the Normalized SoS solution space

184

A MATLAB code was developed to perform the steps of k-means algorithm. The
algorithm was run for different number of means starting from two and the optimal
number of clusters was selected according to the calculated Silhouette Index shown in
Table 11.
Table 11: Silhouette Index for various number of clusters

Silhouette Index
# of clusters
Accuracy
2
0.38891
3
0.48198
4
0.46722
5
0.49388
6
0.52329
7
0.47897
8
0.43803
9
0.36164
10
0.28181

Figure 80 shows the number of clusters and their calculated Silhouette index.
Highest Silhouette index, as shown in this figure, resulted in 6 clusters that represents the
optimal number of clusters.

185

Figure 80: Silhouette Index for Various Number of Clusters

	  
The best total sum of distances was achieved in replicate 3 and after 15 iterations as
shown in Table 12:
Table 12:The Calculated Total Sum of Distances for Various Replicates and Iterations
Replicate
1
2
3
4
5

Iterations
22
6
15
7
13

Total Sum of Distances
621.645
626.463
606.801
614.871
611.522

The clustered solution space is also shown in Figure 81 where each cluster is
presented in a different color. Each cluster is represented by a single representative,
which reflects the characteristics of the candidate SoS solutions within that cluster. Six
representatives of the six clusters are shown in Table 13.

186

Figure 81: Clustered SAR SoS Solutions using K-means Algorithm

Table 13: k-means Clusters Representatives for SAR Mission Considering Five Attributes
(dimensions)
Cluster
Number

Mission
Reliability

Basic
Reliability

Capability
Cost

Priority

Time to
IOC

Cluster
1

0.4570

0.3547

0.4404

0.8403

0.2639

Cluster
2

0.6981

0.6917

0.6966

0.3110

0.9929

Cluster
3

0.8299

0.3179

0.9852

0.6129

0.2153

Cluster
4

0.8099

0.9999

0.7908

0.3062

0.5057

Cluster
5

0.2630

0.6986

0.2753

0.7960

0.9719

Cluster
6

0.6777

0.3624

0.9026

0.6654

0.2667

Here, the objective was to simplify the solution space by selecting one or more
clusters for further analysis of the solution space. It would be easier to use the cluster
187

representatives for communication among stakeholders than the total solution space.
Trade-offs can be identified and discussed using the results shown in Table 13. The
results show that representative of cluster 3, which reflects the characteristics of SoS
solutions within this cluster, has the highest mission reliability at the cost of a high
capability cost. SoS solutions within clusters 1 has a small time to IOC and capability
cost, however, they have a small mission and basic reliability. SoS solutions within
cluster 4 have the highest reliability values for both mission and basic reliability while
they suffer from high capability cost.
The Box plot of different clusters for each decision attribute can also be developed
and used by the analyst for better communication among stakeholders (see Figure 82). A
Box plot may provide a better understanding of different clusters for stakeholders as it
depicts a range for each decision attribute in a cluster instead of only the cluster
representatives. For example, if stakeholders were interested on selecting the best cluster
in terms of mission reliability, cluster 3 and 4 respectively have the highest range of
mission reliability compare to the other cluster. If mission reliability is more important in
selecting the preferred cluster, cluster 5 can be easily removed from the analysis as the
median mission reliability of the SoS solutions within this cluster is about 0.25. In terms
of basic reliability and priority, cluster 4 has the highest median in both attributes.
However, as shown in Figure 82, SoS solutions within cluster 3 seem more suitable when
capability cost and time to IOC are stakeholders’ priorities. The result of this analysis can
be summarized by the analyst and be presented to the stakeholders. The results enable

188

them to set priorities through better understanding of the solution space and trade offs and
select the best cluster that is beneficial to the majority of stakeholders.

Figure 82: Box Plot per Decision Attributes

189

8.6. Selecting the Preferred SAR SoS
The ultimate objective was to select the preferred SoS solution from the simplified
solution-space considering the five decision attributes of MR, BR, CC, T and P and
stakeholders’ preferences. Here, the DEA results, efficient SoS solutions, were used as
the simplified solution space and for selecting the preferred SoS as shown in Table 14.
Stakeholders’ priorities and preferences are captured and used for selecting the SoS that
best matches their preferences in this step.
Table 14:DEA Results – Simplified Solution Space

If only two attributes of mission reliability and time to IOC are important to the
stakeholders and requirements are defined as:
•

SoS mission reliability shall be greater than 0.99
190

•

SoS time to IOC shall be less that two weeks

Feasible SoS solutions can be listed based on these two attributes to identify those
solutions that meet both requirements as shown in Table 15. The yellow highlighted cells
are associated with those SoS solutions that meet mission reliability requirement and the
green cells display those solutions that meet time to IOC requirement. Therefore, SoS
solutions that meet both requirements (ID 95, 464, 112 and 364) define the set of
preferred SoS solutions.
Table 15: The set of Preferred SoS solutions considering mission reliability and time to IOC
SoS#Solution#ID#No. Mission#Reliability
347
0.9848
132
0.9983
404
0.9987
87
0.9995
2
0.9865
443
0.9902
286
0.9406
553
0.9938
95
0.9969
241
0.9626
330
0.982
464
0.9949
112
0.995
189
0.9313
364
0.9913
79
0.9743
185
0.9333
156
0.9644
203
0.9843

Time#to#IOC
4.0734
3.6596
3.5454
3.3852
2.636
2.532
2.1664
2.0889
1.9116
1.852
1.809
1.6432
1.4573
1.3496
1.3419
1.32
1.1546
1.0716
1.0525

For complete ranking of SoS solutions when there are more decision attributes
involved in the decision making and there are no pre-defined requirements, the
PROMETHEE II method can be used. The results of communication among stakeholders
enable analysts to select a suitable preference function and define difference and

191

indifference thresholds. The selected preference functions and thresholds are shown in
Table 16.
Table 16:Inputs of PROMETHEE II

Here, SmartPicker software is used to evaluate and rank SoS solutions. The
positive flow, negative flow and net flow values obtained from the evaluation is shown in
Tables 17. The net flow values were then used in complete ranking of SoS solutions and
identifying the preferred option. The ranking of SoS solutions based on equal weights is
shown in Table 17.

192

Table 17:The Result of PROMETHEE II – Complete Ranking

Based on the net flow, SoS solution 132 (ID) is selected as the preferred SoS
solution and the second and third preferred solutions are respectively 347 and 404. Also
SoS 203 is the least desirable solution with the net score of 0.1546. These results are
valid for a case in which stakeholders agree upon the same set of weightings, preference
functions and thresholds and they possess equal power in making the final decision.
Using SmartPicker software, we could easily change the weight of each criterion
and observe its impact on the final results. Stakeholders can be provided with the result of
sensitivity analysis and quickly re-evaluate the preferred solution chosen from the
analysis. For example if stakeholders give a higher weighting to capability cost, the
preferred SoS solution will change to 347 from 132 and the ranking of SoS solutions
change as shown in Table 18.
193

Table 18:The Result of PROMETHEE II – Complete Ranking

By giving higher importance to mission reliability, the best SoS solution would still
be ID 132, however, the second and third best options will respectively be ID 404 and 87.
As shown in this section, the advantage of this approach is that it is flexible and
provides a wide range of candidates that can be easily evaluated and compared instead of
a single optimum solution.
8.7. Summary
The objective of this chapter was to numerically illustrate the developed
methodology, its performance and flexibility in selecting the preferred SoS when a new
capability need is acknowledged. A hypothetical search and rescue mission was used in
which constituent systems were operating a phased mission. SAR SoS mission reliability
calculation was shown for one alternative (solution) for two cases, (1) the SoS was
capable of data sharing, and (2) the SoS constituent systems could only generate data
194

through their own data generators. Then simulation was used to generate a SoS solution
space that would show different structures. The method’s flexibility was also illustrated
through using suitable techniques to select the preferred SoS for different structures of
the solution space.

195

CHAPTER 9
METHODOLOGY VERIFICATION AND VALIDATION

The verification and validation (V&V) is a critical step in developing a product, i.e
the methodology for selecting the preferred SoS. The objective of this chapter is to verify
and validate the methodology, including the models, for selecting the preferred SoS using
existing systems. In other words, the objective is to answer the question of whether this
methodology meets the defined requirements and accomplishes its planned objectives.
The methodology verification and validation is presented as two independent actions in
sections 9-1 and 9-2.
According to Systems Engineering Fundamentals, 2001, verification and validation
are defined as:
“Verification is the process of determining that a model implementation
accurately represents the developer’s conceptual description and specifications
that the model was designed to.”
“Validation is the process of determining the manner and degree to which a
model is an accurate representation of the real world from the perspective of the
intended uses of the model, and of establishing the level of confidence that should
be placed on this assessment”

196

Conduct SoS Literature
Review
Identify the
Gap

Define Methodology
Requirements

Verify and Validate the
Methodology and Model

Methodology Preliminary
Design
Develop Methodology
Framework

Document the Need for a
Methodology to Select
Develop a
the Preferred SoS
Response to the
Need

Methodology Integration
Develop an Approach for
Selecting the Preferred SoS

Methodology Detailed Design
Model the Decision attributes
Model Mission Reliability
Model Basic Reliability
Model Capability Cost
Model Priority Level Index
Estimate Time to IOC

Draft Summary
and Conclusion

List Future Work

Figure 83:Methodology Development Process

9.1. Verification of SoS system selection methodology
The objective of the verification is to answer the question of if the product, which
is the presented methodology in this work, meets its requirements and conforms to its
design. In other words, we need to make sure that the methodology developed is capable
of selecting the preferred SoS for an specific mission to support the provision of a new
capability. In general, systems engineers have fours types of verification methods:
Analysis, Inspection, Demonstration and Test [135].
1. Inspection: utilizes visual examination of the product, drawings, etc to verify
conformance to specified requirements.
2. Analysis: includes review or analysis of collected data for a quantitative
evaluation of a complete system.
3. Demonstration: includes illustration of a product’s compliance with requirements
by observation. Does not include measurement results.
197

•

Testing: illustrates that the product complies with requirements using precision
measurements or instrumentation.
Besides, theses methods, similarity is another verification method that has also

been found beneficial in some cases [135]. Selecting a suitable verification method
depends on the product and available cost-time resources. According to [135],
verification method can range from a simple visual inspection to complex testing that
also requires analysis. Testing can be the most expensive verification method (depending
on testing complexity) while analysis is often the preferred one, especially when testing is
infeasible or expensive. The similarity method is suitable if similar solutions to the one
that is being verified exist. One or a combination of these methods could be used for
verifying a methodology. A time-cost driven verification method selection process is
borrowed from [135] and illustrated in Figure 84. This process was considered for
selecting the appropriate verification method for this work.

198

Figure 84: Verification Method Selection Process – Adopted from [135] – P. 376

Similarity was not an option since similar methodologies could not be found. Here
a combination of inspection, demonstration, testing and analysis were used for the
verification of the presented methodology
Verification by Inspection
The requirements that were defined for developing the presented methodology were
listed in chapter 4. The objective of this section is to use inspection to verify that the
methodology developed satisfies the requirements defined at the beginning of the
methodology development process. The defined requirements were:
i.
ii.

The methodology shall translate the mission description into SoS needed
capability objectives.
The methodology shall determine SoS requirements/technical objectives
using the SoS needed capability objectives
199

iii.
iv.
v.
vi.
vii.
viii.
ix.
x.
xi.
xii.

The Methodology shall determine systems that are key to SoS objectives
based on systems operational capabilities and mission key functions.
The methodology shall determine the relationships of essential systems.
The methodology shall identify options to address SoS needed capability
objectives.
The methodology shall represent options in terms of constituent systems
and their configuration.
The methodology shall evaluate the operational capabilities of options/SoS
candidates with respect to the needed SoS capabilities.
The methodology shall enable evaluation of options in terms of decision
attributes.
The methodology shall enable comparison of options vs. mission
requirements.
The methodology shall identify and involve stakeholders in decisionmaking.
The methodology shall enable comparison of the options in terms of
decision attributes.
The methodology shall enable the selection of preferred option, which best
matches the situation and is closest to ideal solution.

By inspection, we can verify that the requirements defined in chapter 4 have been
met throughout the methodology development and they have been addressed in different
chapters as follows:
Requirements i - vii and requirement ix -> Chapter 3, Methodology Framework
Overview.
Requirement viii -> Chapter 5 and 6, Estimation of Decision Attributes.
Requirements x-xii -> Chapter 8, Selecting the Preferred SoS Solution.
Verification by demonstration
The developed methodology including the models and the approaches presented for
estimating the selected decision attributes and selecting the preferred SoS, was
200

demonstrated for a hypothetical case of a search and rescue in the previous chapter. The
main reason that the SAR SoS was chosen for this purpose was due to its similarity to
the characteristics of SoS based on Maier’s definition of SoS. In demonstration of the
methodology, the focus was more on the reliability estimation of the SAR mission and
selecting the preferred SAR SoS as these two were the two integral parts of the method.
As illustrated in the previous chapter, the methodology works as expected and provides a
step-by-step process in which the defined requirements are satisfied. The results of the
methodology demonstration illustrate that each step of the methodology yields reasonable
outputs using the inputs, which are the outputs of the previous phase.
Verification by Testing - Scenarios tested
As stated before, the objective of this step is to investigate whether the
methodology produces feasible and realistic results. In other words, the objective is to
ensure that the results are reasonable relative to inputs. Here, we used verification via
testing to ensure that the model developed for estimating lower bound mission reliability
and also for calculating the reliability of data generation and sharing function produces
reasonable results.
In addition, various scenarios were tested via simulation to verify the flexibility of
methodology in selecting the preferred SoS. The result of simulation discussed in chapter
8 shows that this approach is applicable to a variety of situations for selecting the
preferred SoS, e.g., various SoS solution-spaces with different structures. Simulation was
used to replicate (mimic) substantial aspects of a real-world problem in generating the
SoS solution space for various scenarios. This was done by using suitable distributions
201

and defining the likely correlations among the selected decision attributes to create a
representation of a real-world problem. The scenarios tested were cases in which SoS
solution space showed: (1) no structure, and (2) notion of center.

Verification of the reliability model
For verifying the developed approach for estimating the lower bound SoS mission
reliability, the model’s output for a specific case was examined for reasonableness.
Having SoS lower bound mission reliability calculated as a function of time for two cases
(SoS with and without data sharing capability), Figure 85 shows that the SoS reliability at
t=0 equals to 1 and this value as t approaches infinity approaches zero. It can also be
verified that considering data sharing capability as a redundant capability improves
mission reliability.

Figure 85: Impact of Data Sharing on SoS Mission Reliability

In order to verify the reliability model developed for the function of data generation
and sharing, we tested the model using an SoS with two systems equipped with data
generators, receivers and transmitters using the truth table as shown in Table 19.

202

Table 19:Testing the CMEF Reliability Model Using a Simple Case
RDG1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0

System 1
R1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

T1
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1

RDG2
0
0
0
0
1
1
1
1
0
0
0
0
1
1
1
1
0
0
0
0
1
1
1
1
0
0
0
0
1
1
1
1

System2
R2
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1

T2
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1

RDG1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

System 1
R1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

T1
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1

RDG2
0
0
0
0
1
1
1
1
0
0
0
0
1
1
1
1
0
0
0
0
1
1
1
1
0
0
0
0
1
1
1
1

System2
R2
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1

T2
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1

The success and failure of this function for each possible outcome was evaluated as
shown in Table 20. All success events were then replaced by 0.9 and all failure events
were replaced by 0.1 to calculate the probability of success for each outcome and finally
the reliability of data generation and sharing function for this notional test case. The sum
of the probabilities of all success paths (shown in red) was calculated as 0.955. This value
was also calculated using equation (6-10) from chapter 6 as 0.955.

203

Table 20:Estimated Probability of Success for CMEF Function for the Notional SoS

0.9

0.9

0.9

0.531441

0.1

R0.
1
0.9

0.9

0.9

0.9

0.9

0.9

0.9

0.9

0.9

0.9

0.1

0.059049

0.1

0.9

0.9

0.9

0.9

0.1

0.9

0.9

0.9

0.9

0.1

0.9

0.059049

0.1

0.9

0.9

0.9

0.1

0.9

0.9

0.9

0.9

0.9

0.1

0.1

0.006561

0.1

0.9

0.9

0.9

0.1

0.1

Prob.
of
Succes
0.0590
s
49
F
0.0065
61
F

0.9

0.9

0.9

0.1

0.9

0.9

0.059049

0.1

0.9

0.9

0.1

0.9

0.9

F

0.9

0.9

0.9

0.1

0.9

0.1

0.006561

0.1

0.9

0.9

0.1

0.9

0.1

F

0.9

0.9

0.9

0.1

0.1

0.9

F

0.1

0.9

0.9

0.1

0.1

0.9

F

0.9

0.9

0.9

0.1

0.1

0.1

F

0.1

0.9

0.9

0.1

0.1

0.1

0.9

0.9

0.1

0.9

0.9

0.9

0.059049

0.1

0.9

0.1

0.9

0.9

0.9

0.9

0.9

0.1

0.9

0.9

0.1

0.006561

0.1

0.9

0.1

0.9

0.9

0.1

0.9

0.9

0.1

0.9

0.1

0.9

0.006561

0.1

0.9

0.1

0.9

0.1

0.9

0.9

0.9

0.1

0.9

0.1

0.1

0.000729

0.1

0.9

0.1

0.9

0.1

0.1

F
0.0065
61
F
0.0007
29
F

0.9

0.9

0.1

0.1

0.9

0.9

F

0.1

0.9

0.1

0.1

0.9

0.9

F

0.9

0.9

0.1

0.1

0.9

0.1

F

0.1

0.9

0.1

0.1

0.9

0.1

F

0.9

0.9

0.1

0.1

0.1

0.9

F

0.1

0.9

0.1

0.1

0.1

0.9

F

0.9

0.9

0.1

0.1

0.1

0.1

F

0.1

0.9

0.1

0.1

0.1

0.1

F

0.9

0.1

0.9

0.9

0.9

0.9

0.059049

0.1

0.1

0.9

0.9

0.9

0.9

F

0.9

0.1

0.9

0.9

0.9

0.1

0.006561

0.1

0.1

0.9

0.9

0.9

0.1

F

0.9

0.1

0.9

0.9

0.1

0.9

0.006561

0.1

0.1

0.9

0.9

0.1

0.9

F

0.9

0.1

0.9

0.9

0.1

0.1

0.000729

0.1

0.1

0.9

0.9

0.1

0.1

F

0.9

0.1

0.9

0.1

0.9

0.9

0.006561

0.1

0.1

0.9

0.1

0.9

0.9

F

0.9

0.1

0.9

0.1

0.9

0.1

0.000729

0.1

0.1

0.9

0.1

0.9

0.1

F

0.9

0.1

0.9

0.1

0.1

0.9

F

0.1

0.1

0.9

0.1

0.1

0.9

F

0.9

0.1

0.9

0.1

0.1

0.1

F

0.1

0.1

0.9

0.1

0.1

0.1

F

0.9

0.1

0.1

0.9

0.9

0.9

0.006561

0.1

0.1

0.1

0.9

0.9

0.9

F

0.9

0.1

0.1

0.9

0.9

0.1

0.000729

0.1

0.1

0.1

0.9

0.9

0.1

F

0.9

0.1

0.1

0.9

0.1

0.9

0.000729

0.1

0.1

0.1

0.9

0.1

0.9

F

0.9

0.1

0.1

0.9

0.1

0.1

0.000081

0.1

0.1

0.1

0.9

0.1

0.1

F

0.9

0.1

0.1

0.1

0.9

0.9

F

0.1

0.1

0.1

0.1

0.9

0.9

F

0.9

0.1

0.1

0.1

0.9

0.1

F

0.1

0.1

0.1

0.1

0.9

0.1

F

0.9

0.1

0.1

0.1

0.1

0.9

F

0.1

0.1

0.1

0.1

0.1

0.9

F

0.9

0.1

0.1

0.1

0.1

0.1

F

0.1

0.1

0.1

0.1

0.1

0.1

F

RDG
0.1
0.9

System 1
R0.
T0.1
1
0.9
0.9

System2
RDG2

R2

T2

Prob. of
Success

RDG0.1

T0.1

RDG2

R2

T2

The result of this calculation verifies the developed model as the probability of
success for this function is shown to be the same in both approaches.

204

Since we could show that the methodology for selecting the preferred SoS performs
reasonably for various scenarios, we can conclude that the methodology was flexible and
the output of the methodology could provide value to the user, which verifies the
methodology.

9.2. Validation of the Developed Methodology
As stated before, validation is a process determines the degree to which a model or
simulation and its associated data are an accurate representation of the real world from
the perspective of the intended uses of the model. In order to validate the developed
methodology, we need to ensure that the methodology is the accurate representation of
the defined need in chapter 3.
According to [136], by validation, we mean the comparison of the modeling and
simulation behavior and results to the data obtained from another credible domain. The
credible domain can be (1) the real-world, that has been proven to closely approximate
the real world, (2) a source that is recognized as expert on the relevant characteristics of
the real world. Some typical real world data sources are subject matter experts, laboratory
test, developmental and operational test and comparison with historical values. There are
also some technical methods for validating a product, which is summarized in Table 21.

205

Table 21:Model Validation Methods (Source: Systems Engineering Guide – MITRE Corporation)
Model Validation Method

Description

Comparison to Other Models

Face Validity
Historical Data Validation

Parameter
Variability
Sensitivity Analysis

Predictive Validation

–

Various results (e.g., outputs) of the simulation model being validated are
compared to results of other (valid) models. For example, (1) simple cases of a
simulation model are compared to known results of analytic models and (2) the
simulation model is compared to other simulation models that have been validated.
Asking individuals knowledgeable about the system whether the model and/or its
behavior are reasonable. For example, is the logic in the conceptual model correct
and are the model’s input-output relationships reasonable?
If historical data exist (e.g., data collected on a system specifically for building and
testing a model), part of the data are used to build the model and the remaining data
are used to determine (test) whether the model behaves as the system does.
This technique consists of changing the values of the input and internal parameters
of a model to determine the effect on the model’s behavior of output. The same
relations should occur in the model as in the real system. This technique can be
used qualitatively—directions only of outputs—and quantitatively—both directions
and (precise) magnitudes of outputs. Those parameters that are sensitive (i.e., cause
significant changes in the model’s behavior or output) should be made sufficiently
accurate prior to using the model.
The model is used to predict (forecast) the system’s behavior, and then the
system’s behavior and the model’s forecast are compared to determine if they are
the same. The system’s data may come from an operational system or be obtained
by conducting experiments on the system, e.g., field tests.

The best way to validate the developed methodology was to have actual users
implement the methodology and its models on a specific case of an SoS mission to
determine if the method would provide value to the users and could provide a strong
basis for decision-making during mission planning. However, this was not a feasible
option and was not achievable for the period of this work. The other options as listed in
Table 9-3, was to assess sufficient historical data and conduct comparison of models.
However, historical data did not exit for a real SoS mission to enable historical data
validation or the predictive validation. In addition, a holistic method did not exist for
selecting the preferred SoS solution that would start from the mission description and
requirements for comparison. Therefore, face validation was used due to its practicality
for the purpose of validation of the presented methodology.

206

Face validation
Face validation is “the extent to which a model, its assumptions, and applications
correspond to current science and evidence, as judged by people who have expertise in
the problem” [137]. In face validation, experts are asked to review the method and
compare its behavior to real-world situations. In order to validate the methodology using
this approach, we started with the first round of peer-review, in which the methodology
was submitted as a journal paper to the IEEE systems journal where four knowledgeable
experts in the area of system of systems reviewed the paper and provided comments
regarding the methodology and its added value.
As the second and final round, subject matter experts were asked to review the
methodology and to provide feedback in response to the following questions:
§

The level of detail of the methodology

§

if it is sufficient for the purpose it was developed

§

if it provides the desired value to the user of the methodology

The results of the methodology face validation indicate that the methodology
presented in this work provides value to the users of the methodology. Hence, we can
conclude that the method met the objectives of this study and it is validated.
9.3. Summary
The intent of this chapter was to verify and validate the developed methodology
for selecting the preferred SoS solution. For verification of the methodology, methods of
inspection, demonstration, testing and analysis were used. The results showed that the

207

developed methodology performs reasonably for various scenarios and provide value to
the user.
Among the listed option for validation of the methodology, face validation was the
feasible, practical option. For validation, a group of experts were asked to review the
methodology. Their feedback indicated that the methodology contain enough level of
details and meets the objective it’s been developed for. Since our options were limited for
the validation of the methodology, I plan to seek feedback from user application of this
methodology.

208

CHAPTER 10
SUMMARY, CONCLUSIONS AND FUTURE WORK

In today’s environment, achieving new capabilities often require integrating
different existing systems and new developments. The question is how to achieve a new
capability that meets the program technical and non-technical objectives and takes into
account stakeholders’ expectations. This involves complex decision-makings that require
trading various objectives, often conflicting, against one another. This was my motivation
to embark on this research. This chapter briefly summarizes the contributions of this
work to the SE and SoS SE body of knowledge and presents an outline of possible
directions for future research.
10.1. Summary of contributions
The methodology presented in the dissertation provides a framework for additional
research and application in the SoS research areas and was in response to a critical need
as the result of increased attention to the use of system of systems by different
organizations. The objective of this dissertation was to develop a methodology including
models for selecting the preferred SoS solution from existing systems when a new
capability need is acknowledged. The methodology was designed to assist users and
decision-makers in generating SoS solutions and selecting the preferred SoS for a specific
mission in an organized and structured way. It starts from SoS mission requirements and
includes identifying and selecting feasible candidate systems, generating and evaluating
209

SoS solutions and selecting the preferred option, while considering a variety of factors.
The application of this methodology is during SoS mission planning, acquisition planning
and SoS development. The methodology developed in this work is unique for three main
reasons.
(1) This methodology provides a SE-based framework for repeatedly generating
SoS solutions and selecting the preferred one that starts with the top-level mission and
capability requirements. It addresses various aspect of SoS capability in selection of the
preferred solution such as mission effectiveness; sustainability and affordability that have
not been considered in previous work. It presents a new measure of mission priority and
models SoS capability cost to evaluate candidate systems and compare SoS solutions
from the stakeholders’ point of view.
(2) Another uniqueness of this methodology is in SoS mission reliability modeling
and analysis of SoS solutions. The approach presented for this purpose estimates lower
bound mission reliability for an SoS in which SoS is operating a phased-mission and its
constituent systems are capable of exchanging data via datalinks. This approach is based
on defining and describing the mission of an SoS in terms of phases, i.e. durations,
mission essential functions and success criteria. An integral part of the method for SoS
mission reliability modeling was to model the function of data sharing among the
constituent systems based on the functional dependencies of the elements. This function
is the key enabler of SoS operation and dramatically improves the SoS mission reliability,
which further highlights the benefits and importance of this method.

210

(3) Having all feasible SoS solutions identified and evaluated in terms of decision
attributes, the challenge was to come up with an efficient selection and ranking procedure
to scan through a large number of SoS solutions in a five-dimensional space and present
the best option to the stakeholders. A hybrid three-phase approach that combined data
analysis methods and multi-criteria decision analysis was developed for the purpose of
this methodology for selecting the preferred option. In this approach, techniques such as
principal component analysis, statistical data clustering and data envelopment analysis
were used to visualize the solution space in a projected lower dimensional space and to
remove the less preferred SoS solutions. An outranking MADM method was then
utilized to provide a complete ranking of the remaining solutions based on the
stakeholders’ preferences.
This work will provide a significant contribution to the systems engineering and
SoS development body of knowledge and can be applied to current SoS development
problems. It also provides a baseline for improving the methodology through application
and additional research.
10.2. Future Research
There are numerous future research directions that may be pursued. An outline of
these directions is discussed in this section.
Number of factors considered: In selecting systems for an SoS mission, a variety of
factors could be considered as discussed in chapter 5. In this research, factors such as
safety, security, adaptability, vulnerability, etc, were not considered in development of

211

the methodology. The number of factors considered for selecting the preferred SoS can
be expanded and screened to determine the most important ones.
Risk analysis: Risk analysis can also be conducted on SoS solutions performance to
consider the risk of the mission failure for each solution and select the best option to
minimize the identified risks.
SoS Life Cycle Capability Sustainment: An area that could benefit from more
research is the SoS life cycle capability sustainment. A capability solution requires
sustainment over its life cycle for three main reasons: (1) change in operational
environment, or threat and (2) advances in technology that increase effectiveness or
affordability and (3) capability degradation due to obsolescence [138]. Constituent
systems of an SoS are at different stages of their life cycles. When the preferred SoS
solution is selected, there is a need to identify those systems that are subject to
obsolescence to avoid degraded capability. For that reason, SoS capability performance
should be continuously monitored to ensure successful achievement of SoS performance
targets. Also the SoS operational environment and threats constantly change over time. A
selected SoS solution should be monitored to identify and address capability gaps to
ensure that SoS can continue its operation to face new operational requirements and
threats. Discussed above requires analysis and assessment of SoS capability over its life
cycle which could be addressed in future SoS research.
Mission reliability estimation for specific applications and configurations of SoS:
One of the areas that can benefit from further investigation is generating SoS solutions
based on mission reliability of solutions where constituent systems of an SoS are required
212

to exchange information to accomplish the mission success. In this work, mission
reliability estimation for an SoS with data sharing capability has been addressed for a
general case. This problem can be further developed for specific configurations and
applications. Moreover, providing each mission system with data sharing capability may
not be cost-efficient. Conducting trade studies between capability, reliability and
affordability in analysis of various alternatives is also required in generating SoS
solutions.
Determining the degree of autonomy in SoS solutions: Next generation systems
especially in avionics and automotive application involve unmanned autonomous
systems. Autonomy means machines make decisions, not humans, and behaving in ways
that are not preplanned and pre-programmed as in automated systems (rule based). The
challenge is to determine the degree of automation in an SoS mission, which ranges from
all systems being autonomous systems to all systems being legacy systems.
Methodologies and models are required to systematically define the degree of automation
(man vs machine) in SoS missions based on SoS performance and cost.
Methodology validation via a real case: Since the actual data for an SoS mission
did not exist for the application of this methodology, the framework and model have not
been validated against actual SoS data. Implementing this methodology on SoS
development programs is the only way to evaluate the developed methodology as to its
utility and to identify needed improvements.

213

REFERENCES

1. W. A. Crossley, “System of Systems: An Introduction of Purdue University
Schools of Engineering's Signature Area,” presented at the Engineering Systems
Symposium, MIT Engineering Systems Division, Cambridge, 2004.
2. T. V. Huynh, and J. S. Osmundson, “An Integrated Systems Engineering
Methodology for Analyzing Systems of Systems Architectures,” in Proceedings of
The Asia-Pacific Systems Engineering Conference, Singapore, 2007.
3. Madni, A.M. and Sievers, M. “System of Systems Integration: Key Considerations
and Challenges,” Systems Engineering, Volume 17, Number 2, 2014.
4. D. A. Fisher, “An Emergent Perspective on Interoperation in Systems of Systems”,
(CMU/SEI-2006-TR-003). Software Engineering Institute, Carnegie Mellon
University, 2006.
5. J. Boardman and B. Sauser, “System of systems: The meaning of of,” in Proc.
IEEE/SMC Int. Conf. Syst. Syst. Eng., Apr. 2006, p. 6.
6. W. C. Baldwin and B. Sauser, “Modeling the characteristics of system of systems,”
in Proc. IEEE Int. Conf. SoSE, May–Jun. 2009, pp. 1–6.
7. M. W. Maier, “Architecting principles for system-of-systems,” Systems
Engineering, vol. 1, no. 4, pp. 267-284, 1998.
8. A. P. Sage, “Conflict and risk management in complex system of systems issues”,
IEEE International Conference on Systems, Man and Cybernetics, vol. 4, pp. 3296
– 3301, 2003.
214

9. H. Dogan, C. Ncube, Soo Ling Lim, M. Henshaw, C. Siemieniuch, M. Sinclair, V.
Barot, S. Henson, M. Jamshidi and D. DeLaurentis, “Economic and Societal
Significance of the Systems of Systems Research Agenda,” IEEE International
Conference on Systems, Man, and Cybernetics, 2013, pp. 1715-1720.
10. J.S. Dahmann, G. Rebovich, and J.A. Lane., "Systems Engineering for
Capabilities." CrossTalk (The Journal of Defense Software Engineering) 21
(November): 4–9, 2008.
11. J. A. Lane, “What is a System of Systems and Why Should I care”, USC-CSSE2013-001.
12. G. A. Orndorff, and B. F. Zink, “A Constellation Architecture for National
Security Space Systems”, John Hopkins APL Digest, Vol. 29, No. 3, 2010.
13. N. Wickramasinghe, S. Chalasani, R. V. Boppana, and A. M. Madni, “Health care
system of systems,” System of System Engineering: Innovations for the 21st
century, M. Jamshidi, Ed. Hoboken, NJ, USA: Wiley, 2008, pp. 542–550.
14. A. Kim, M. Kim, M. Sevcovic, and D. DeLaurentis, “A System-of-Systems
Framework for the Improved Capability of Insurgent Tracking Missions Involving
Unmanned Aerial Vehicles”, 2010 5th International Conference on System of
Systems Engineering (SoSE), June 22-24, Loughborough, U.K., pp. 1-6.
15. Road2SoS: Roadmaps for System-of-Systems Engineering, Newsletter No.1,
Available

at:

project.eu/cms/upload/documents/Road2SoS_First_Newsletter.pdf

215

http://road2sos-

16. Center

for

Systems

and

Software

Engineering,

USC,

Available

at:

http://csse.usc.edu/csse/research/SoSE/
17. B. Boehm and J.A. Lane, “Putting Systems to Work: Processes for Expanding
System Capabilities Through System of Systems Acquisitions,” in Complex
Systems Engineering Symposium, 2007.
18. Systems Engineering and Analysis, 4th Edition, by B. Blanchard and W. Fabrycky.
Prentice Hall, 2006, ISBN 0-13-186977-9.
19. J. Dahmann and K. Baldwin, “Implication of System of Systems on System Design
and Engineering”, Proceedings of the IEEE 6th International Conference on
System of Systems Engineering, June 27-30, 2011 (Albuquerque, NM).
20. J. Dahmann, “Taming Complexity: A System of Systems Challenge,” Presentation,
Complex Adaptive Conference, 2013.
21. Sheard, S. A., & Mostashari, A. (2009). Principles of Complex Systems for
Systems engineering. Systems Engineering, 12(4), 295-311.
22. F. Zapata, A. Akundi, R. Pineda, and E. Smith, “Basis Path Analysis for Testing
Complex System of Systems,” Procedia Computer Science, Vol. 20, pp. 256–261,
Elsevier, 2013.
23. Kludze (2004), Honour (2002) (Honour (2004) “Understanding the Value of
Systems Engineering”. Proceedings of the 14th Annual INCOSE International
Symposium, Toulouse, France, 2004.

216

24. K. Dykes and R. Meadows, “Applications of systems engineering to the research,
design, and development of wind energy systems,” National Renewable Energy
Laboratory, Golden, CO, Tech. Rep. NREL/TP-5000-52616, Dec. 2011.
25. International Space Station, Systems Engineering Case Study, Dr. Bill Stockman,
Joe Boyle and Dr.John Bacon.
26. T. F. Bersson, “A Framework for Application of Systems Engineering Process
Models to Sustainable Design of High Performance Buildings”, Environment,
Energy, & Sustainability Symposium May, 2011.
27. R. E. Volkert, “A methodology for predicting the operational performance during
development of a system of systems,” Ph.D. dissertation, Southern Methodist
University, Dallas, TX, 2013.
28. S. C. Skinner, “A systems engineering methodology for the integration of
subsystems into complex systems,” Ph.D. dissertation, Southern Methodist
University, Dallas, TX, 2007.
29. D. Astaphnko and L. M. Bartlett, “Phased mission system design optimization
using genetic algorithms,” International Journal of Performability Engineering,
vol, 5, no. 4, pp 313-324, Jul. 2009.
30. D. Chattopadhyay, “A method for tradespace exploration of systems of systems,”
M.S. thesis, Massachusetts Institute of Technology, Cambridge, MA, Jun. 2009.
31. M. G. Richards, “Multi-attribute tradespace exploration for survivability,” Ph.D.
dissertation, Massachusetts Institute of Technology, Cambridge, MA, 2009.

217

32. M. Azam, F. Tu, and K. Pattipati, “Multi-phase reliability analysis of complex
systems,” in Proceedings of SPIE, vol. 5107, 2003, pp. 27-43.
33. D. Warshawsky and D. Mavri, “Choosing aggregation functions for modeling
system of systems performance,” in Proceedings of Conference on Systems
Engineering Research, 2013, pp. 236-244.
34. E. Ryen, “Overview of Systems Engineering Process”, North Dakota Department
of Transportation, March 2008.
35. A. T. Bahill and S. J. Henderson, “Requirements Development, Verification, and
Validation Exhibited in Famous Failures”, Systems Engineering, Vol. 8, No. 1,
2005, pp.1-4.
36. A.M. Madni and S. Jackson, “Towards a conceptual framework for resilience
engineering”, IEEE Systems Journal, 3(2) (2009).
37. M. J. DiMario, “System of systems interoperability types and characteristics in
joint command and control,” in Proceedings of IEEE/SMC International
Conference on System of Systems Engineering, 2006.
38. Ricci, Nicola, Adam M. Ross, and D. H. Rhodes. Developing a Dynamic PortfolioBased Approach for Systems-of-Systems Composition. SEAri Working Paper WP2012-2-1, http://seari. mit. edu/papers. php [cited 12-01-2012], 2012.
39. A. Kinder, C. Siemieniuch, V. Barot, M. Henshaw, “System of systems: defining
the system of interest,” in Proceedings of International Conference on System of
Systems Engineering, Jul. 2012, pp. 463-468.

218

40. H. A. Taboada and D. W. Coit, “Data Clustering of Solutions for Multiple
Objective System Reliability Optimization Problems,” Quality Technology &
Quantitative Management, vol. 4, No. 2, pp. 191-210, 2007.
41. Adam M. Ross and D. E. Hastings, “The tradespace exploration paradigm,” in
Proceeding of INCOSE International Symposium, 2005.
42. Interim DoD Instruction 5000.02, Operation of the Defense Acquisition System,
November 25, 2013.
43. R. McNutt, “Reducing DoD Product Development Time: The Role of the Schedule
Development Process,” Ph.D. dissertation, Massachusetts Institute of Technology,
Cambridge, MA, 1998.
44. J. A. Vitkevich, “Analyzing the Costs of System-of-Systems Year 2000 Problem
Resolution,” Software Engineering & Economics Conference The MITRE
Corporation, 1997.
45. A. F. Minkiewicz, “Tackling Cost Challenges of Systems of Systems,” Systems
and Software Technology Conference, 2006, pp. 10-14.
46. Department of the Army (2005, Oct.). Memorandum of agreement on operational
suitability terminology and definitions to be used in operational
47. L. Page, C. Dagli, “Assessing Robustness in System of Systems MetaArchitectures”, Procedia Computer Science, 20 (2013) 262-269.
48. M. Doherty, “Cost Methodology Framework”, Cost Estimating Conference,
Australian Government Department of Defense.

219

49. A. Jacob, S. Hoesly, S. Huseth, S. Krider, J. Lamb, C. Martin, V. Medina, J.
Medina, M. Nguyen, J. Patel, K. Rangi, T. Schoen, K. Trinh, and R. Willis.
Architecting Joint Command and Control System of System Capability
Certifications. No. NPS-SE-07-006. NAVAL POSTGRADUATE SCHOOL
MONTEREY CA, 2007.
50. Operating and Support Cost Estimating Guide, Office of the Secretary of Defense,
Cost Assessment and Program Evaluation, March 2014.
51. GAO Cost Estimating and Assessment Guide, Best Practices for Developing and
Managing Capital Program Costs, United States Government Accountability
Office, March 2009, GAO-09-3SP.
52. R. Valerdi, “The Constructive Systems Engineering Cost Model (COSYSMO),”
Ph.D. dissertation, University of Southern California, Los Angeles, CA, 2005.
53. “Systems of Systems Engineering – Principles and Application”, Edited by Mo
Jamshidi, 1st ed, CRC Press, Taylor and Francis Group, 2009
54. Command and control, Dictionary of Military and Associated Terms, Available:
www.dtic.mil.
55. “The World Wide Military Command and Control System--Major Changes Needed
in Its Automated Data Processing Management and Direction,” U.S. Government
Accountability Office, LCD-80-22: Published: Dec 14, 1979. Publicly Released:
Dec 14, 1979.
56. NASA Cost Estimating Handbook, Version 4.0, Available at: www.nasa.gov.

220

57. E. P. Bontas, C. Tempich, and Y. Sure,“ONTOCOM: A Cost Estimation Model for
Ontology Engineering,” Proceedings of the 5th International Semantic Web
Conference (ISWC 2006), 625—639.
58. “Cost Estimating Methodologies”, Teaching Notes, Defense Acquisition
University, Business, Cost Estimating and Financial Management Department,
Professor Tomeka S. Williams, CDFM, PCEA Professor Ellen Barber, CDFM,
CCE/A.
59. J. L. Cook, “System of Systems Reliability for Multi-State Systems,” The Annual
Reliability and Maintainability Symposium, Jan 26-29, 2009, Fort Worth, Texas,
pp.13-18.
60. Seung Yeob Han, K. Marais, and D. DeLaurentis, “Evaluating System of Systems
Resilience using Interdependency Analysis,” 2012 IEEE International Conference
on Systems, Man and Cybernetics (SMC), Seoul, pp. 1251-1256.
61. E. Morris, L. Levine, C. Meyers, P. Place, and D. Plakosh, “System of Systems
Interoperability (SOSI): Final Report,” Carnegie Mellon Software Engineering
Institute, Pittsburgh, PA, Tech. Rep. CMU/SEI-2004-TR-004 ESC-TR-2004-004,
Apr. 2004.
62. IEEE standard computer dictionary: a compilation of IEEE standard computer
glossaries. New York: Institute of Electrical and Electronics Engineers; 1990.
63. D. Prescott, and J. Andrews, “A reliability-based approach to mission planning in
multi-platform phased missions,” 8th International Conference on Reliability,
Maintainability and Safety (ICRMS), 20-24 July 2009, Chengdu, pp.617-620.
221

64. H. Eisner, J. Marciniak, and R. MacMillan, “Computer-aided System of Systems
Engineering”, IEEE International Conference on Systems, Man and Cybernetics,
13-16 Oct. 1991, Charlottesville, VA, vol.1, pp. 531-537.
65. Y. Ou and J. B. Dugan, “Modular solution of dynamic multi-phase systems,” IEEE
Trans. on Reliability, 53(4): 499-508, 2004.
66. L. Xing, S. V. Amari, “Reliability of Phased-Mission Systems,” Handbook on
Performability Engineering (Editor: K. B. Misra), Springer, 2008, pp 349-368.
67. J. D. Esary and H. Ziehms, “Reliability analysis of phased missions,” in
Proceedings of the Conference on Reliability and Fault Tree Analysis, 1975, pp.
213–236.
68. J. Andrews, R. Remenyte-Prescott, D. Prescott, “Reliability analysis of missions
with cooperating platforms”, Proc. Ann. Reliability & Maintainability Symp., (Jan.)
2010, pp 1-6.
69. H. Zhou, F. Li, H. Weng, “A Simulation Model for Multi-platform Phased Mission
System Reliability Analysis,” Int. Conf. Reliability, Maintainability and Safety
(June) 2011, pp 84-89.
70. C. Yang, J. Yang, P. Dong, M. Li, “Reliability Model of Multiplatform Phased
Mission System Based on CPN,” IEEE Int. Conf. Ind. Eng. & Eng. Mgmt. (Dec.)
2010, pp 2224-2227.
71. M. Alam, M. Song, S. L. Hester, and T. A. Seliga, “Reliability Analysis of PhasedMission Systems: A Practical Approach”, Proc. Ann. Reliability & Maintainability
Symp., (Jan.) 2006, pp. 551-558.
222

72. J. Andrews and R. Remenyte, “Fault Tree Conversion to Binary Decision
Diagram”, 2005.
73. S. Distefano, and A. Puliafito, “Dynamic Reliability Block Diagrams: Overview of
a Methodology,” Risk, Reliability and Societal Safety, 2007 Taylor and Francis
Group, London.
74. B. Dugan, S. J. Bavuso, and M.A. Boyd, “Dynamic Fault Tree Models for FaultTolerant Computer Systems”, IEEE Transaction on Reliability, 1992 pp.363-377.
75. S. Distefano, and L. Xing, “A New Approach to Modeling the System Reliability:
Dynamic Reliability Block Diagrams”, Proc. Ann. Reliability & Maintainability
Symp., (Jan.) 2006, pp. 189-195.
76. S. Distefano and A. Puliafito, “System Modeling with Dynamic Reliability Block
Diagrams,” Proc. European Safety and Reliability Conf. (ESREL '06), ESRA, Sept.
2006.
77. H. Guo, A. Mettas, and A. Monteforte, “Reliability Evaluation and Application for
Systems with Different Phases”, Proc. Ann. Reliability & Maintainability Symp.,
(Jan.) 2008, pp. 1-7.
78. D. Marquez, M. Neil, and NE. Fenton, “A new Bayesian network approach to
reliability modeling,” 5th International Mathematical Methods in Reliability
Conference (MMR 07), Glasgow, July 2007.
79. P. Weber, G. Medina-Oliva, C. Simon and B. Iung, “Overview on Bayesian
networks applications for dependability, risk analysis and maintenance areas,”

223

Engineering Applications of Articial Intelligence, Iternational Federation of
Automatic Control, 2012, 25(4), pp.671-682.
80. H. Langseth, and L. Portinale, “Applications of Bayesian Networks in Reliability
Analysis,” Reliability Engineering and System Safety, 2007, Elsevier.
81. S. Distefano, “How to capture dynamic behaviours of dependable systems,”
International Journal of Parallel Emergent and Distributed Systems 04/2009;
24:127-150.
82. A. Shrestha, L. Xing, Y. Dai, “Reliability Analysis of Multistate Phased-Mission
Systems With Unordered and Ordered States,” IEEE Trans. Reliability, vol. 41,
(Jul.) 2011, pp. 625-636.
83. J. Esary, Ziehms, H., “Reliability Analysis of Phased Missions,” Monterey,
California : Naval Postgraduate School, 1975.
84. A. Somani, K. Triverdi, “Phased-Mission System Analysis Using Boolean
Algebric Methods,” NASA Contractor Report, ICASE Report No. 93-84,
November 1993.
85. K. C. Kapur, and M. Pecht, “Reliability Engineering,” Wiley Series in Systems
Engineering and Management, 2014, ISBN: 978-1-118-14067-3.
86. “Reliability Prediction Basics,” 2007, ITEM Software, Inc. Available at:
http://www.itemsoft.com/index.html
87. E. Bauer, X. Zhang, and D. Kimber, “Practical System Reliability,” John Wiley &
Sons, Mar 27, 2009.

224

88. R. Mohammad, A. Kalam, S. Amari, “Reliability of Phased Mission Systems with
Warm Standby Subsystems,” Proc. Ann. Reliability & Maintainability Symp.,
(Jan.) 2013, pp 1–5.
89. M. L. Shooman, Probabilistic reliability: An Engineering Approach, 2nd Ed.
Krieger Pub Co, (August 1990).
90. Department of Defense, Systems Engineering Guide for System of Systems
Summary, Director of Systems Engineering Office of the Director, Defense
Research and Engineering, Dec. 2010.
91. B. Boehm, and J. A. Lane, “Putting Systems to Work: Processes for Expanding
System Capabilities Through System of Systems Acquisitions” Interfaces 30
(2007): 300.
92. Colson, Gerard, and Christian De Bruyn. "Models and methods in multiple
objectives decision making." Mathematical and Computer Modelling 12.10 (1989):
1201-1211.
93. G. S. Parnell, P. J. Driscoll, and D. L. Henderson, Ed., Decision Making in Systems
Engineering and Management. 2nd ed. John Wiley and Sons, Inc, 2011.
94. A. Mostashari, J. Sussman, “Engaging Stakeholders in Engineering Systems
Representation and Modeling,” in Proceedings of The Engineering Systems
Symposium, Massachusetts Institute of Technology, Cambridge, MA, 2004.
95. Guidance for ISO national standards bodies: Engaging stakeholders and building
consensus. [online]. Available: http://www.iso.org/iso/guidance_nsb.pdf

225

96. U.S. Department of Transportation, Federal Highway Administration. Available:
http://www.fhwa.dot.gov/cadiv/segb/views/document/sections/section3/3_9_1.cfm
97. T. Holland, Data Visualization and Analytic Decision Making, SAS Best Practices,
May 2013.
98. Data Mining: Visualizing and Exploring Data, Lecture Notes by Ming Li,
Department of Computer Science and Technology Nanjing University, Fall 2011.
99. Feature Transformation, Principal Component Analysis (PCA), MathWorks,
Available

at:

http://www.mathworks.com/help/stats/feature-

transformation.html#f75476
100. Ben-Hur, Asa, and Isabelle Guyon. "Detecting stable clusters using principal
component analysis." Functional Genomics. Humana press, 2003. 159-182.
101. Yeung, Ka Yee, and Walter L. Ruzzo. An empirical study on principal component
analysis for clustering gene expression data. Technical report, Department of
Computer Science and Engineering, University of Washington, 2000.
102. Kantardzic, Mehmed. Data mining: concepts, models, methods, and algorithms.
John Wiley & Sons, 2011.
103. Jolliffe IT. Principal Component Analysis. New York: Springer; 2002.
104. J. Han, and M. Kamber, Data Mining: Concepts and Techniques, 3rd edition,
Morgan Kaufmann, 2011.
105. A. Sing, A. Yadav, and A. Rana, “K-Means with three Different Distance
Metrics,”International Journal of Computer Applications (0975-8887), Volume 67,
No.10, April 2013.
226

106. D. T. Pham, S. S. Dimov, and C. D. Nguyen, “Selection of K in K-means
clustering,” in Proceedings of The Institute of Mechanical Engineers, vol. 219,
2005, pp. 103-119.
107. H. A. Taboada and D. W. Coit, “Data Clustering of Solutions for Multiple
Objective System Reliability Optimization Problems,” Quality Technology &
Quantitative Management, vol. 4, No. 2, pp. 191-210, 2007.
108. K. Kouser, and Suinta, “A Comparative Study of K Means Algorithm by
Different Distance Measures,” International Journal of Innovative Research in
Computer and Communication Engineering, Vol. 1, Issue 9, Nov. 2013, pp.24432447.
109. P. Grabusts, “The Choice of Metrics for Clustering Algorithms, Proceedings of
the 8th International Scientific and Practical Conference. Volume II, 2011. pp.7076.
110. Liu, Chuanren, et al. "Stochastic Unsupervised Learning on Unlabeled Data."
ICML Unsupervised and Transfer Learning. 2012.
111. Ishizaka, Alessio, and Philippe Nemery. Multi-criteria decision analysis: methods
and software. John Wiley & Sons, 2013.
112. Charnes, Abraham, William W. Cooper, and Edwardo Rhodes. "Measuring the
efficiency of decision making units." European journal of operational research 2.6
(1978): 429-444.

227

113. Coelli, Tim. A Guide to DEAP Version 2.1: A Data Envelopment Analysis
Program, Centre for Efficiency and Productivity Analysis (CEPA). Working Paper
96/08, 1996.
114. Azadeh, Ali, et al. "Integration of analytic hierarchy process and data
envelopment analysis for assessment and optimization of personnel productivity in
a large industrial bank." Expert Systems with Applications 38.5 (2011): 5212-5225.
115. Li, Xiao-Bai, and Gary R. Reeves. "A multiple criteria approach to data
envelopment analysis." European Journal of Operational Research 115.3 (1999):
507-517.
116. Ha, Sung Ho, and Ramayya Krishnan. "A hybrid approach to supplier selection
for the maintenance of a competitive supply chain." Expert Systems with
Applications 34.2 (2008): 1303-1311.
117. Banker, R.D., Charnes, A., Cooper, W.W. (1984) Some models for estimating
technical scale inefficiencies in data envelopment analysis Management Science,
30 (9), 1078-1092.
118. Morita, Hiroshi, and Necmi K. Avkiran. "Selecting inputs and outputs in data
envelopment analysis by designing statistical experiments." Journal of the
Operations Research Society of Japan 52.2 (2009): 163.
119. Data Envelop Analysis: The International Benchmarking Network for Water
Utilities,

Available

at:

https://www.ib-

net.org/en/texts.php?folder_id=130&mat_id=108&L=1&S=2&ss=3

228

120. Kodikara, P. N., B. J. C. Perera, and M. D. U. P. Kularathna. "Stakeholder
preference modelling in multi-objective operation of urban water supply systems-A
case study on Melbourne water supply system." MODSIM 2005 International
Congress on Modelling and Simulation. 2005.
121. Rogers, M.; Breen, M.; Maystre, L. 2000. ELECTRE and Decision Support.
Kluwer, Massachusetts, USA.
122. Velasquez, Mark, and Patrick T. Hester. "An analysis of multi-criteria decision
making methods." International Journal of Operations Research 10.2 (2013): 5666.
123. Rao, R. Venkata. "A decision making methodology for material selection using an
improved compromise ranking method." Materials & Design 29.10 (2008): 19491954.
124. K. Charandabi, A. Alesheikh, and M. Karimi, “Using Outranking Methods for
Optimum Setting of Air Pollution Monitoring Stations,” Journal of Environmental
Studies, Vol. 38, No.62, 2012.
125. Macharis, Cathy, et al. "PROMETHEE and AHP: The design of operational
synergies in multicriteria analysis.: Strengthening PROMETHEE with ideas of
AHP." European Journal of Operational Research 153.2 (2004): 307-317.
126. Ishizaka, Alessio, and Philippe Nemery. "Selecting the best statistical distribution
with PROMETHEE and GAIA." Computers & Industrial Engineering 61.4 (2011):
958-969.

229

127. R. T. Eckenrode, Weighting multiple criteria. Management Science, 1965, 12
(3),180–192.
128. P. Nijkamp, P. Rietveld, H. Voogd, Multi-criteria Evaluation in Physical
Planning. Elsevier Science Publishers, Amsterdam.
129. C. Mahcris, and J. P. Brans, The GDSS PROMETHEE PROCEDURE, Journal of
decision systems, Volume 7 – page 283-307
130. U.S.

Coast

Guard

Website,

Available

at:

http://www.uscg.mil/hq/cg5/cg534/SAR_Program_Info.asp
131. Lecture notes for “Introduction to Cost Risk Analysis”, Lesson 5: Cost as a
Probability Distribution, DAU.
132. Larham, R. "Project Costing with the Triangular Distribution and Moment
Matching." Math Help Forum Journal. 2010.
133. Mathworks, Simulating Dependent Random Variables Using Copulas, Available
at http://www.mathworks.com/help/stats/examples/simulating-dependent-randomvariables-using-copulas.html
134. Kohler, Ulrich, and Magdalena Luniak. "Data inspection using biplots." Stata
Journal 5.2 (2005): 208.
135. Wasson, Charles S. System analysis, design, and development: Concepts,
principles, and practices. Vol. 22. John Wiley & Sons, 2006.
136. Verification, Validation, and Accreditation of Army Models and Simulations,
PAM

5-11,

1999,

http://www.apd.army.mil/jw2/xmldemo/p5_11/main.asp
230

Available

at:

137. David M. Ed., W. Hollingworth, , J. Jaime Caro, J. Tsevat, K. M. McDonald, J. B.
Wong, on Behalf of the ISPOR−SMDM Modeling Good Research Practices Task
Force, "Model transparency and validation a report of the ISPOR-SMDM
Modeling Good Research Practices Task Force–7." Medical Decision Making 32.5
(2012): 733-743.
138. United States Coast Guard Publication 7.0, capability management, May 2013,
Available at: https://www.uscg.mil/doctrine/CGPub/CG_Pub_7_0.pdf

231

One blank page at the end.

232

