INFORMATION LITERACY: CORRELATION OF SELF-EFFICACY AND
PROFICIENCY

A Dissertation
Submitted to the School of Graduate Studies and Research
in Partial Fulfillment of the
Requirements for the Degree
Doctor of Philosophy

Camille M. Wendekier
Indiana University of Pennsylvania
May 2015

UMI Number: 3686082

All rights reserved
INFORMATION TO ALL USERS
The quality of this reproduction is dependent upon the quality of the copy submitted.
In the unlikely event that the author did not send a complete manuscript
and there are missing pages, these will be noted. Also, if material had to be removed,
a note will indicate the deletion.

UMI 3686082
Published by ProQuest LLC (2015). Copyright in the Dissertation held by the Author.
Microform Edition © ProQuest LLC.
All rights reserved. This work is protected against
unauthorized copying under Title 17, United States Code

ProQuest LLC.
789 East Eisenhower Parkway
P.O. Box 1346
Ann Arbor, MI 48106 - 1346

© 2015 Camille M. Wendekier
All Rights Reserved

ii

Indiana University of Pennsylvania
School of Graduate Studies and Research
Department of Nursing and Allied Health Professions

We hereby approve the dissertation of
Camille M. Wendekier
Candidate for the degree of Doctor of Philosophy

January 16, 2015

Signature on File
Theresa Gropelli, Ph.D.
Associate Professor of Nursing and Allied Health
Professions, Advisor

January 16, 2015

Signature on File
Mary E. Williams, Ph.D.
Professor of Nursing and Allied Health Professions

January 16, 2015

Signature on File
Theresa McDevitt, Ph.D.
Professor, IUP Libraries

ACCEPTED

Signature on File
Timothy P. Mack, Ph.D.
Dean
School of Graduate Studies and Research

__________________

iii

Title: Information Literacy: Correlation of Self-Efficacy and Proficiency
Author: Camille M. Wendekier
Dissertation Chair: Dr. Theresa Gropelli
Dissertation Committee Members:

Dr. Mary E. Williams
Dr. Theresa McDevitt

Information literacy (IL) is a vital component in evidenced-based practice (EBP)
due to its role in research utilization. The literature review indicated that undergraduate
college students could harbor negative perceptions regarding IL and compartmentalize IL
to classroom activities and assignments. These negative perceptions can influence
students’ IL self-efficacy, which refers to their belief they can successfully complete IL
related tasks. Weiner’s attributional theory of motivation suggests IL self-efficacy can
motivate people to engage in IL related behavior. The purpose of this study was twofold.
First, it intended to investigate if a relationship was present between IL self-efficacy and
knowledge. Second, it assessed the ability of IL self-efficacy to act as a predictor IL
proficiency. The researcher collected data using the 28-item and 17-item Information
Literacy Efficacy Scales and the Richard Stockton College of New Jersey Information
Literacy Test. Results indicated a moderate relationship between self-efficacy and
knowledge for both the ILSES 28-item scale (r = .334, p = .003) and the 17-item scale (r
= .321, p = .003). After controlling for gender and GPA, the ILSES 28-item scale
explained 10.4% of the variance in knowledge (F (3,75) = 3.160, p=0.29) while the
ILSES 17-item scale accounted for 8.3% of the variance in knowledge (F (3,77) = 3.553,
p=.018). The ability of the ILSES to predict knowledge indicates that nurse educator
should include affective domain learning activities to promote positive IL self-efficacy
iv

levels. Although the study’s limitations restricted the generalizability of the results,
results indicated the ILSES and The Richard Stockton College of New Jersey Information
Literacy Test could serve as valid tools for collecting student data to improve individual
and aggregate student outcomes.

Keywords: information literacy, information literacy self-efficacy, information
literacy proficiency, research utilization, evidence-based practice

v

ACKNOWLEDGEMENTS
First, I want to thank God because He made it possible for me to embark on this
incredible journey. Next, I want to thank my awesome dissertation committee, Dr.
Theresa Gropelli, Dr. Mary Williams, and Dr. Theresa McDevitt. I had the “dream team”
of dissertation committees. Dr. Gropelli, thank you for always finding time to help me
despite all your other conflicting demands. Your words of encouragement and positive
outlook helped me persevere despite the many delays and challenges that occurred during
the execution of my study. Dr. Williams and Dr. McDevitt, thank you for all your words
of wisdom and insight that enabled me to better understand the many facets of
information literacy. You helped me step out of my worldview and look at information
literacy through a new lens. I am blessed to have you all as mentors, colleagues, and
treasured friends. I hope I have the honor to work with you on future research projects.
I want to thank my family for all their love and support that provided me with the
courage necessary to obtain my PhD. Through the many years, you lovingly endured my
struggles with meeting the demands of family, work and school. I would not be here
without you. Mark, words cannot express how much I truly appreciate your love and
support. Thank you for all the times you would stay up late to proof my papers. You
continually helped me improve my writing skills even though information literacy was
not your favorite subject. Courtney, Katy, and Kristyn, you are my heroes. When I
became discouraged doing my homework or working on my dissertation, I would think of
all the challenges you overcame in your lives. Your courage and perseverance in
achieving your goals motivated me to do my best. Every night I worked on my
dissertation, I would read the plaque you gave me, “Don’t Quit.”

vi

This acknowledgement would not be complete without thanking my mother and
father-in-law Mary Ellen and Ray Wendekier. I would never have become a nurse if it
was not for them. Words cannot express how much I appreciate their help and love. If
anyone would ask me to describe a perfect person or couple, I would describe Mary Ellen
and Ray. Everything they do is based on love and their willingness to help people. Since
I met them, they have always been my idols.
Throughout the past four years, I would go to my mother’s house to complete my
homework and dissertation. My mother’s cheerful attitude provided an excellent
environment for writing papers. Thank you mom for your belief in me and all your
prayers for my success in obtaining my PhD. When you were home, your company
helped me persist in completing course assignments and papers. Whether you were
helping me with spelling or playing “Yes Sir That’s My Baby” on the piano, your love
always shined through. That is why I could not wait to see you after I successfully
defended my dissertation on December 11, 2014. Even though you went home to heaven
on January 26, 2015, I still feel your love and support. I will truly treasure your love for
eternity.
Being the youngest of 16 children has great advantages. All my brothers and
sisters helped me survive the many demands I faced these past four years. To my brother
Pat, thank you so much for always making sure that I had a place to work on my
dissertation. You will never know how much I appreciate all the little things you did to
make sure I could work comfortably at my computer. These deeds brightened my days.
Thank you for being a great brother. To my sisters Annie and Agnes, thank you for all
those long conversations that helped me keep focused on my ultimate goal, completing

vii

my dissertation. Ag, thank you for your precious time, your help is a treasured gift.
Annie, I especially treasure all the times you helped me de-stress by spending time with
me, Tim and our friends on Friday nights. When I started my coursework, I didn’t realize
how these nights would light up my life. I am looking forward to continuing this
tradition with Annie, Tim, and all of our friends. Thank you Ed and Becky for all the
great times we shared together. Our weekends together help balance out all the pressure I
faced completing this degree. Mary and Betsy, thank you for your belief in me. Even
though we do not see each other as often as we would like, you are always with me in
spirit. Mary, I am looking forward to our trip to the beach this summer – thank you. Jim
and Matt, what can I say? Our superlative celebrations of life helped me through all the
rough times. Ron, P.J., Bernard, Jane, John, and Vince, thank you for all your love and
encouragement. I am lucky to be your sister. I wish I could have written more about my
amazing family, but that would be a book in itself.
I also want to thank my extended family for all their support. Steph, Rob, Sue,
and Turk, thank you so very much for helping me. You were always there whenever I
needed help. Your help made it possible for me to survive 2013. Mike, Ray, Jen, David,
Mary, and Joe, thank you for the support you gave my family throughout the past four
years.
I could not have completed this journey without the help of my colleagues. To
my department chair, Dr. Rita Trofino, thank you so very much for all your support. You
helped me complete my dissertation in countless ways. I will never forget how you
helped me problem-solve to overcome the obstacles I faced when executing my study.
Your help in time management was instrumental in my ability to complete my

viii

dissertation in 2014. It is a privilege to work with you. I want to thank all the SFU
nursing faculty for their helping me through stay focused and motivated. Cindy, Heather,
Judy, and Kim were always there to help me through the hard times. To Dr. Laurie
Grosik, thank you for your constant encouragement. Your words of wisdom helped me
tackle my dissertation “one bite at a time.” Also, thanks for sharing your expertise in
formatting word documents. The ability to master the table of contents was a major
victory for me. Finally, to my SFU friends, Gabrielle Cronin, Brenda Guzic, Ed
Mihelcic, Don Walkovich, and Theresa Wilson, thanks for putting up with me. You
deserve an award for enduring my highs and lows that occurred during the past four
years. Not only were you there in my troubled times, you always brought out the best in
me during these times. Words cannot describe how much I appreciate my friends and
colleagues at SFU.
I want to thank my amazing friend, JoEllen Blue. She continuously pushed me to
stay on track with my writing. JoEllen’s faithful friendship helped me stay positive and
perform beyond my expectations. You friendship is a true blessing.
I want to express thanks to my IUP colleagues. The new friendships I developed
in the pursuit of my doctorate are invaluable. Darlene, thank you for being my homework buddy and for helping me to the end. Looking back, we had many priceless
moments, especially in Savannah. I look forward to our continued friendship and our
new endeavors. Anna, Chris, Christine, Lynn, and Susan, thank you for all the inspiring
telephone conversations. These calls were vital to my ability to persevere in the
coursework and in my dissertation.

ix

All of the support and love described above played a vital role in the completion
my doctorate degree. These people helped me trust, believe, and have patience to
cultivate this dream. Although this degree is a huge milestone in my life, it is not my sole
definition of success. My success is measured by my ability to help my colleagues,
family, and friends in the same ways they helped me.

x

TABLE OF CONTENTS
Chapter
ONE

Page
INTRODUCTION ............................................................................................ 1
Information Literacy: Correlation of Self-Efficacy and Proficiency ................ 1
Background ....................................................................................................... 4
Statement of the Problem .................................................................................. 7
Purpose of the Study ......................................................................................... 9
Research Questions ............................................................................... 10
Definitions of Terms.............................................................................. 10
Conceptual Framework ................................................................................... 11
Information Literacy Self-Efficacy ....................................................... 12
Information Literacy Proficiency .......................................................... 13
Assumptions .................................................................................................... 13
Delimitations ................................................................................................... 14
Limitations ...................................................................................................... 15
Study Methodology ......................................................................................... 16
Significance of Research ................................................................................. 16
Chapter Summary............................................................................................ 17

TWO

LITERATURE REVIEW................................................................................ 19
The Technology Revolution and Information Literacy .................................. 20
Development of Computer Technology ................................................ 22
Student Perceptions of Communication Technology in Relation
to Information Literacy.......................................................................... 25
Use of the Internet to Retrieve Information .......................................... 28
Information Literacy in Nursing Education .................................................... 35
Delivery of Information Literacy Education in Baccalaureate
Nursing Programs .................................................................................. 35
Information Literacy Proficiency of Pre-Licensure Undergraduate
Nursing Students ................................................................................... 37
Student Perceptions and Attitudes Regarding Information
Literacy .................................................................................................. 41
Gaps in the Research Related to IL Education on Baccalaureate
Curriculums ........................................................................................... 44
Assessment Tools ............................................................................................ 44
Information Literacy Self-Efficacy Surveys ......................................... 45
Information Literacy Knowledge Surveys ............................................ 49
Conceptual Framework ................................................................................... 54
Attributional Theory of Motivation and Emotion ................................. 55
Self-Efficacy as an Attribution .............................................................. 61
Gaps in Research Related to IL Self-Efficacy and Motivation
Theory.................................................................................................... 65
Chapter Summary............................................................................................ 66
xi

Chapter

Page

THREE

METHODOLOGY .......................................................................................... 68
Design ............................................................................................................. 68
Setting and Study Sample ............................................................................... 68
Data-Collection Tools ..................................................................................... 70
Demographics ........................................................................................ 70
The Information Literacy Self-Efficacy Scale ...................................... 71
Richard Stockton College of New Jersey Information Literacy
Test ........................................................................................................ 75
Study Methodology ......................................................................................... 77
Pilot Study ............................................................................................. 79
Survey Administration........................................................................... 83
Protection of Human Subjects ............................................................... 85
Data Analysis......................................................................................... 88
Chapter Summary............................................................................................ 90

FOUR

RESULTS ....................................................................................................... 91
Pilot Study Results .......................................................................................... 91
Pilot Study Preliminary Analysis .......................................................... 92
Pilot Study Reliability Data ................................................................... 96
Sample Description ......................................................................................... 96
Preliminary Analysis of Study Dataset ........................................................... 98
Reliability Data .................................................................................... 101
Research Questions ....................................................................................... 101
Question One ....................................................................................... 101
Question Two ...................................................................................... 102
Question Three .................................................................................... 104
Question Four ...................................................................................... 105
Summary of Findings .................................................................................... 107

FIVE

DISCUSSION AND IMPLICATIONS ........................................................ 108
Review of Pilot Study ................................................................................... 108
Discussion ..................................................................................................... 109
Study Sample ....................................................................................... 109
Evaluation of the Preliminary Data Analysis ...................................... 114
Research Question One: What Is the IL Self-Efficacy of
Pre-Licensure Baccalaureate Nursing Students as Measured
by the Information Literacy Self-Efficacy Scale? ............................... 115
Research Question Two: What Is the IL Proficiency Level for
Pre-Licensure Baccalaureate Nursing Students as Measured
by the Richard Stockton College of New Jersey Information
Literacy Test? ...................................................................................... 117
xii

Chapter

Page
Research Question Three: What Is the Relationship Between
Each IL Self-Efficacy Score (28-Item Scale and 17-Item Scale)
and the IL Knowledge of Pre-Licensure Baccalaureate Nursing
Students?.............................................................................................. 119
Research Question Four: After Controlling for Demographic
Variables, Can IL Self-Efficacy Levels Act as Predictors for IL
Knowledge? ......................................................................................... 120
Limitations .................................................................................................... 122
Implications ................................................................................................... 125
Use of Data Collection Instruments in Nursing Education ................. 125
Dynamic Nature of Self-Efficacy as an Attribution for
Behavior .............................................................................................. 130
Recommendations ......................................................................................... 131
Conclusion .................................................................................................... 133
Dissertation Summary ................................................................................... 134

REFERENCES................................................................................................................ 136
APPENDICES ................................................................................................................ 151
Appendix A - Information Literacy Self-Efficacy Scale
(28-Item Survey) ........................................................................................... 151
Appendix B - Letter of Permission to Use the Information
Literacy Self-Efficacy Scale ......................................................................... 153
Appendix C - Richard Stockton College of New Jersey
Information Literacy Test: 2005 ................................................................... 155
Appendix D - Richard Stockton College of New Jersey
Information Literacy Test: 2013 ................................................................... 164
Appendix E - Revised Version of Richard Stockton College of
New Jersey Information Literacy Test Used in Study .................................. 169
Appendix F - Letter of Permission to Use the Revised Version
of Richard Stockton College of New Jersey Information Literacy
Test ................................................................................................................ 180
Appendix G - Cover Letter to Institutions – Pilot Study
Participant Recruitment ................................................................................. 181
Appendix H - Cover Letter to Institutions –Participant
Recruitment ................................................................................................... 183
Appendix I - Informed Consent for Pilot Study ........................................... 193
Appendix J - Email to Potential Study Participants ..................................... 195
Appendix K - Consent Statement on Qualtrix Survey ................................. 196
Appendix L - IRB Approval: Indiana University of
Pennsylvania ................................................................................................. 197
Appendix M - IRB Approval: Wilkes University, Carlow
University, Drexel University, and Mansfield University ............................ 199
xiii

Chapter

Page
Wilkes University Approval for Pilot Study....................................... 199
Carlow University ............................................................................... 200
Drexel University ................................................................................ 202
Mansfield University .......................................................................... 203
Appendix N - Change of Protocol Approval for Recruiting Study
Participants From Indiana University of Pennsylvania ................................. 204
Appendix O - Change of Protocol Approval for Recruiting Study
Participants From Pennsylvania State University ......................................... 205
IUP Letter of Approval ....................................................................... 205
Pennsylvania State University Letter of Approval ............................. 207
Appendix P - Change of Protocol Approval for Recruiting Study
Participants From Saint Francis University .................................................. 210
IUP Letter of Approval...................................................................... 210
Saint Francis University Letter of Approval ..................................... 211

xiv

LIST OF TABLES
Table

Page

1

Crosswalk of Evidence-Based Practice (EBP), Information Literacy
(IL), and Nursing Practice ....................................................................... 21

2

Comparison of Question Objectives in Information Literacy
Surveys Used to Assess Pedagogical Interventions………………...….. 52

3

Comparison of Evidence-Based Practice, IL Competency
Standards, and Questions in Knowledge Test………………………….. 53

4

Discriminant Validity for ILSES-28 and ILSES-17…………………… 73

5

Likert Scale Responses in the ILSES………………………………….. 74

6

Pilot Study Descriptives……………………………………………….. 93

7

Pilot Study Tests of Normality………………………………………… 94

8

ILSES Measures of Internal Consistency – Pilot Test………………… 96

9

Participant Demographics……………………………………………... 97

10

Descriptives……………………………………………………………. 99

11

Tests of Normality……………………………………………………... 99

12

Descriptive Statistics for ILSES……………………………………….. 102

13

Descriptive Statistics for Knowledge Composite Scores……………… 103

14

Correlations Between the ILSES-28 and Knowledge……..................... 104

15

Correlations Between ILSES-17 and Knowledge……………………... 104

16

Adjusted R Squared Values for Knowledge and ILSES-28…………… 106

xv

Table

Page

17

Adjusted R Squared Values for Knowledge and ILSES-17…………… 106

18

Comparison of ILSES Scores: No Knowledge Scores vs.
Knowledge Scores……………………………………………………... 113

19

Comparison of ILSES Scores by Gender……………………………… 116

20

Comparison of Knowledge Scores by Gender………………………… 118

21

Crosswalk of EBP, IL Competencies, Knowledge Test, and ILSES
28-Item Scale …...………………………………………………........... 129

xvi

LIST OF FIGURES
Figure

Page

1

Conceptual framework…………………………………………….…… 12

2

Timeline depicting the development of web-based communication
platforms………………………………………………………………...23

3

The three dimensions of causality and behavior engagement…….……. 59

4

The interrelationship between the three dimensions of causality ............ 61

5

Comparison of pilot test normal Q-Q plots for ILSES ............................ 94

6

Comparison of pilot test normal Q-Q plots for knowledge ..................... 95

7

Comparison of pilot scatterplot graphs for ILSES .................................. 95

8

Pilot test scatterplot graph for knowledge ............................................... 95

9

Participant affiliation ............................................................................... 98

10

Comparison of normal Q-Q plots for ILSES ........................................... 100

11

Normal Q-Q plot for knowledge ............................................................. 100

12

Comparison of ILSES 17 and 28 scatterplot graphs................................ 101

13

Frequency of ILSES composite scores .................................................... 102

14

Frequency of knowledge composite score............................................... 103

xvii

CHAPTER ONE
INTRODUCTION
Information Literacy: Correlation of Self-Efficacy and Proficiency
A report published by the Institute of Medicine (IOM, 2001) identified evidencebased practice (EBP) as the key for providing quality patient care. Evidence-based
practice consists of three basic elements: the best research evidence, the best clinical
experience, and practices consistent with patient values (IOM, 2001). Research in EBP
verifies that nurses use the best possible practices to promote patient health and safety.
The use of EBP requires proficiency in information literacy (IL) skills. The American
Library Association (ALA) defines IL as “the ability to recognize when information is
needed and have the ability to locate, evaluate, and effectively use the needed
information” (ALA, 1989, para 3). The skills associated with IL directly align with the
literature review process conducted by nursing students and nursing professionals. This
process involves the ability to identify when information is needed, define the void in
information in the form of one or more questions or problems, retrieve published research
pertaining to the question(s) or problem(s), critique the validity and reliability of the
scholarly manuscripts, summarize the information in the published literature, and
synthesize the information in the published literature to develop new knowledge that
addresses the question(s) or problem(s) (ALA, 1989; Polit & Beck, 2012).
Evidenced-based practice implies that nurses must engage in a life-long pursuit of
personal development to achieve excellence in practice (Nayda & Rankin, 2008).
Consequently, proficiency in IL is paramount for using research associated with EBP.
Nayda and Rankin (2008) demonstrated how baccalaureate nursing students failed to

1

understand how IL skills interact with competent nursing practice. These students
interpreted IL as getting information from people, such as librarians and their peers, and,
some students believed that IL was limited to reading, comprehension, and writing
(Nayda & Rankin, 2008). Because IL skills play a vital role in EBP, nursing faculty must
address issues affecting students’ abilities to learn and apply IL skills.
The published literature fails to explain the reason for the divide between students
and IL. The affective learning domain may play a role in this divide. Students who
harbor negative attitudes towards IL may compartmentalize to academic assignments and
subsequently isolate IL from life-long learning and competent nursing practice. The
affective domain incorporates factual knowledge with attitudes, values, and behaviors
(Shephard, 2008), connecting mindsets and behaviors with emotions (Krathwohl, Bloom,
& Masia, 1964). These mindsets reveal themselves through the engagement in or
avoidance of behaviors (Krathwohl et al., 1964). Negative attitudes towards IL may act
as motivators for avoiding the use of IL practices outside of school assignments. The
affective domain also enables an individual to develop and commit to novel behaviors in
light of new evidence or factual knowledge (Neumann & Forsyth, 2008; Shephard,
2008). Thus, the ability to cultivate positive attitudes towards IL may help students
connect it to life-long learning and competent practice.
Emotions associated with perceptions and attitudes regarding a behavior can
impact one’s self-efficacy in performing this behavior. Self-efficacy is defined as a
person’s perceived ability to effectively perform a behavior; it influences one’s attitude
about success (Bandura, 1986, 1997). These perspectives, in turn, can affect a person’s
self-efficacy beliefs based on the perceived emotional reward (Bandura, 1986, 1997).

2

Perceived emotional rewards include reactions or social reinforcement displayed by other
people when the subject engages in a particular behavior. These rewards can be positive
or negative and can generate positive or negative emotions associated with the specific
behavior. Positive emotions may catalyze engagement of behavior, while negative
emotions prompt avoidance responses (Bandura, 1997; Krathwohl et al., 1964).
Published research examining the relationship between the affective domain and
IL self-efficacy is lacking. However, findings from qualitative studies revealed that
students associated feelings of frustration, doubt, confusion, and anxiety with IL (Duncan
& Holtslander, 2012; Klentzin, 2010). These attitudes can negatively reinforce students
and diminish their belief in their capabilities for performing IL tasks. The attitudes
associated with IL-related frustration and failure may cause the students to avoid
assignments or tasks involving IL. In that self-efficacy entails a person’s belief in their
ability to perform a behavior successfully, it may affect nursing students’ abilities to
appreciate and apply IL knowledge to nursing practice.
The following content provides an overview of this study investigating the
relationship between IL self-efficacy and IL proficiency. First, the background section
discusses IL in the context of nursing education. Next, the problem statement describes
the study’s context and provides a rationale for its purpose. The section describing the
purpose of the study presents the research questions and definitions of terms. Four
sections follow offering the study’s conceptual framework, assumptions, delimitations,
and limitations. The final two sections describe the methodology and significance of the
study.

3

Background
Since nursing practice centers on the use of empirical evidence to identify the
most efficient methods for providing patient care, it follows that nursing students must
demonstrate the capability to identify, interpret, and apply scholarly information.
Therefore, prior to graduation, nursing students should demonstrate competence in IL so
they can use published research effectively in the context of evidence-based nursing care.
The American Association of Colleges of Nursing (AACN) deems IL crucial to the future
of nursing and expects baccalaureate graduates to display basic competency in IL
(AACN, 2008). Accordingly, nursing programs should provide education in the skills of
inquiry, analysis, and IL (AACN, 2008). Another accrediting body, the Accreditation
Commission for Education in Nursing (ACEN, 2013), attests to the importance of IL in
nursing education by mandating expertise in IL for all its program evaluators. ACEN
(2013) adopts the ALA’s (1989) and the Association of College and Research Libraries’
(ACRL) definition of IL (ACRL, 2000). Although the AACN fails to endorse a
particular definition of IL, it specifically identifies IL as a key component in two of the
nine Essentials of Baccalaureate Education for Professional Nursing Practice (AACN,
2008).
Despite the AACN’s and the NLNAC’s substantiation of the role of IL in nursing
education, research findings indicate students may not possess the attitudes and values for
internalizing IL in their nursing practice. Tanner, Pierce, and Pravikoff (2004),
investigating nurses’ IL skills, identified ignorance of electronic databases and a lack of
skills for evaluating scholarly manuscripts as the major barriers to using published
research to augment nursing practice. Although study participants received IL education

4

prior to graduating, they did not retain skills related to attaining and reading scholarly
information.
Poor self-efficacy may contribute to the loss of IL knowledge and skills after
graduation (Bandura, 1997; Weiner, 1986). Self-efficacy is a belief in one’s ability to
master a particular experience or behavior (Bandura, 1977, 1986, 2012). Bandura (1977,
1986, 2012) more specifically defines self-efficacy as a belief in one’s own performance
capability to obtain particular outcomes, which impacts an individual’s feelings,
cognitions, motivation, and behavior in particular situations.
Mastery experiences and social modeling shape self-efficacy, which can debilitate
or enable a person’s propensity to engage in particular behaviors (Bandura, 2012). Social
modeling occurs when people’s aspirations and beliefs in their own capabilities improve
when they observe peers persevere and succeed despite the presence of many obstacles.
Research has indicated students who perceived support from parents, teachers, and
friends had more positive attitudes and self-efficacy in math and science (Rice, Barth,
Guadagno, Smith, & McCallum, 2013). Thus, the ability to master IL skills and
knowledge can improve nursing students’ IL self-efficacy. Conversely, increased IL selfefficacy could motivate nursing students to retain and use IL knowledge and skills.
Antecedents for positive self-efficacy levels center on positive experiences, such
as earning high grades on a scholarly manuscript. As well, the published literature
indicates negative experiences can act as antecedents for developing poor IL selfefficacy. For instance, in Duncan and Holtslander’s (2012) qualitative research project,
students reported they felt frustrated when conducting a literature review to acquire
information for an assignment; eight of nine participants specifically used the word

5

“frustration.” Frustration related to the selection and use of keywords, navigating
databases, filtering relevant information from thousands of results, and locating full text
files of articles. This frustration could have stemmed from students’ poor understanding
of IL skills; students may not have known, for example, they could conduct searches with
subject headings (Duncan & Holtslander, 2012). The students advised their peers to
choose easy topics for assignments to avoid the same frustration, creating a negative
feedback loop hindering IL tasks and behaviors (Duncan & Holtslander, 2012).
Weiner’s (1985, 1986, 2006, 2010) attributional theory of motivation explains
how self-efficacy is involved in shaping a person’s behavior. Weiner (1985, 1986, 2006,
2010) stated that behaviors can be attributed to control, stability, and controllability.
Control relates to the amount of power an individual has in shaping a specific outcome.
This power originates from internal drives and thought processes. Stability refers to the
consistency or dependability of a situation. For example, students can predict
expectations related to writing assignments when they have a teacher for successive
courses. In contrast, students may experience grading conflicts when they submit writing
assignments to several new adjunct clinical instructors within a semester. Finally,
controllability refers to the impact of external factors in a given situation. Controllability
can be illustrated using clinical assignments, such as evidence-based care plans. Students
who have the same patient who were assigned to them the previous day have more
control over their ability to provide care due to the extra time they have to prepare an
evidence-based care plan. Students who, unexpectedly, receive a new assignment when
arriving at clinical have less control over their ability to provide evidence-based care
because they cannot prepare a care plan prior to working with the patient.

6

Self-efficacy can determine a person’s locus of control and can influence a
person’s perception of controllability (Bandura, 1977, 2012; Weiner, 1985, 2006). A
person’s self-efficacy can influence how he or she perceives internal and external
motivators and how these motivators affect outcomes related to specific behaviors
(Bandura, 1977, 2012; Weiner, 1985, 2006). Thus, a person’s perceptions of internal and
external motivators can determine how much control the person has over a specific
situation or event (Bandura, 1977, 2012; Weiner, 1985, 2006). Positive self-efficacy is
usually associated with an internal locus of control, an ability to control external
situations, a high sense of power, and a positive motivation for engaging in a behavior.
Negative self-efficacy accompanies an external locus of control, an inability to control
external situations, a poor sense of power, a negative motivation, and avoidance of a
behavior. Therefore, self-efficacy can stimulate nursing students to incorporate IL in
nursing practice.
Statement of the Problem
The researcher’s observations from teaching undergraduates indicate that students
view IL as a boring task limited to academic assignments. When completing a scholarly
assignment requiring the use of IL, students’ focus was limited to getting a good grade.
They continuously worried about their abilities to complete the assignment, in some cases
to the extent that negative thinking inhibited them from doing so. These students, who
complained that they should not have to do “library tasks” in a clinical course,
subsequently, earned poor grades for the assignment because they focused on minute
details instead of concentrating on the assignment objectives. These informal findings
are limited due to their subjective interpretation and a lack of empirical evidence.

7

However, these inferences raise questions regarding best practices in the education of IL
skills, research utilization, and EBP.
Because IL plays a key role in the research utilization associated with EBP, it is
essential to enhancing quality patient care. Self-efficacy can act as a negative or positive
motivator in students’ performance of IL related skills. Knowing how self-efficacy
affects IL performance can help nursing faculty tailor their teaching strategies to student
needs. Additionally, such knowledge may help educators improve students’ abilities to
perform and apply IL skills related to nursing practice.
A lack of resiliency, as well as an inability to manage failure, may be associated
with low self-efficacy. Previous research has shown that students experienced frustration
and lacked resiliency when they encountered problems in obtaining research articles
pertinent to their assignment topics (Duncan & Holtslander, 2012). Rather than learning
to manage failure, these students chose to take the path of least resistance and selected
easy topics and approaches for completing their assignment (Duncan & Holtslander,
2012).
Nursing literature indicates that self-efficacy can shape affective processes and
lead to student behaviors such as avoidance or selecting easy assignments (Robb, 2012).
Negative attitudes precede poor IL self-efficacy, create feelings of discouragement and,
hinder the adoption of IL skills and research utilization. To date, no published literature
addresses pre-licensure nursing students’ self-efficacy in relation to IL knowledge or
proficiency.
The most recent literature review produced just one study examining IL selfefficacy in nursing students (Stokes & Urquhart, 2011). While this study explored IL

8

self-efficacy levels regarding information-seeking behavior, it failed to address IL
knowledge or proficiency level of the nursing students. Further, no data exists regarding
IL proficiency levels of pre-licensure baccalaureate nursing students. While some
published literature described undergraduate students’ IL behavior, no study addressed its
relationship to IL self-efficacy levels (Duncan & Holtslander, 2012; Shepard & Mullane,
2010). The mindsets and behaviors associated with a student’s self-efficacy perceptions
may act as motivators for engaging in or avoiding particular behaviors, such as the
application of IL skills to nursing practice.
Investigating the relationship between self-efficacy levels and IL proficiency may
yield data to help educators understand motivators for the use of IL skills. Furthermore,
the correlation of pre-licensure baccalaureate nursing students’ IL self-efficacy levels
with IL proficiency scores may enable nurse educators to identify any mindsets or
perceptions that can promote success in transferring IL knowledge to practice. This
process can also help educators identify mindsets that could catalyze the avoidance of the
use of IL skills. The ability to identify these mindsets or perceptions can help nurse
educators tailor IL education to their students’ needs. Improving proficiencies in IL skills
may lead to better use of resources for EBP, which, ultimately, may improve patient
outcomes.
Purpose of the Study
The purpose of this proposed study is two-fold. First, it sought to obtain baseline
data on pre-licensure baccalaureate nursing students’ self-efficacy and proficiency levels
in IL. Second, it intended to determine the relationship between IL self-efficacy and IL
proficiency levels.

9

Research Questions
This descriptive correlational study aimed to answer the following research
questions:
1. What is the IL self-efficacy of pre-licensure baccalaureate nursing students as
measured by the Information Literacy Self-Efficacy Scale (ILSES;
Kurbanoğlu, Akkoyunlu, & Umay, 2006)?
2. What is the IL proficiency level for pre-licensure baccalaureate nursing
students as measured by the Richard Stockton College of New Jersey
Information Literacy Test (Trail, Gutierrez, & Lechner, 2006)?
3. What is the relationship between each IL self-efficacy score (28-item scale
and 17-item scale) and the IL knowledge of pre-licensure baccalaureate
nursing students?
4. After controlling for demographic variables, can IL self-efficacy levels act as
predictors for IL knowledge?
Definitions of Terms
This study uses the following terms.
Attribution. The act of associating a cause to something (Attribution, 2013).
Controllability. The amount of power a person has over a situation, experience,
or behavior (Weiner, 1985, 2010).
External locus of control. The perception that extrinsic factors control a
situation or behavior (Weiner, 1985, 2010).
Information literacy proficiency. The mastery of IL knowledge and skills
(ACRL, 2000; Proficient, 2013).

10

Information literacy self-efficacy. A person’s belief in his or her ability to
recognize the need for information, locate information, evaluate information, and use the
information within the context of a question or a problem (ALA, 1989; Bandura, 1986,
1997).
Information literacy. “The ability to recognize when information is needed and
have the ability to locate, evaluate, and effectively use the needed information” (ALA,
1989, para. 3).
Internal locus of control. The perception that intrinsic factors control a situation
or behavior (Weiner, 1985, 2010).
Phenomenal causality. The lived experience of associating a particular feeling
or situation with specific outcomes (Weiner, 2011).
Self-efficacy. A person’s belief in his or her ability to perform in specific
situations (Bandura, 1986, 1997).
Stability. The lack of change over time (Weiner, 1985, 2010).
Conceptual Framework
The attribution-based theory of motivation attempts to explain behavior (Weiner,
1985, 1986, 2006, 2010). According to this theory, self-efficacy can influence whether a
person embraces or avoids the use of IL knowledge and skills (Bandura, 1977, 2012;
Weiner, 1985, 2006). Self-efficacy can function as an attribution due to its ability to
stimulate pessimistic or optimistic thinking as well as a catalyst for either giving up or
persevering in an activity (Bandura, 1977, 2012; Weiner, 1985, 2006). Self-efficacy, as
an attribution, may help clarify why pre-licensure nursing students either abandon or
persevere in the use of IL skills.

11

The conceptual framework centers on the dynamic interplay between IL selfefficacy and IL proficiency. Weiner (1985, 1986, 2006, 2010) classified attributions
according to three causal dimensions: locus, control, and stability. These causal
dimensions are the driving forces in the interaction between IL self-efficacy and IL
proficiency. Figure 1 illustrates the conceptual framework for this study; it shows how
the researcher views the interaction of motivating constructs, IL self-efficacy, and IL
proficiency. Information literacy self-efficacy is operationalized according to
Kurbanoğlu, Akkoyunlu, and Umay’s (2006) ILSES. The ILSES is a 25-item, multiplechoice test based on ACRL’s competency standards (Trail et al., 2006).
Locus

ation Li
t
rm

cy
era

Info

y
ac

l f- Effic
Se

Figure 1. Conceptual framework. This figure demonstrates the interconnection between
self-efficacy and IL proficiency.
Information Literacy Self-Efficacy
Bandura (1977) defined self-efficacy as a person’s belief in his or her ability to
successfully perform situation-specific behaviors. Self-efficacy develops through selfmastery, social modeling, social persuasion, and resolve (Bandura, 1977). In this context,
cognitive, affective, and decisional processes affect a nursing student’s self-efficacy to
engage in research utilization. These processes may play a vital role in goal-setting, goal
attainment, and perceived success or failure when nursing students practice IL skills
12

(Bandura, 1977). Kurbanoğlu et al. (2006) developed both a 28-item and a 17-item
Likert scale survey assessment of IL self-efficacy based on Bandura’s definition of selfefficacy.
Information Literacy Proficiency
The present study measures IL proficiency using a 25-item, multiple-choice test
published by Trail, Gutierrez, and Lechner (2006). They developed the Richard Stockton
College of New Jersey Information Literacy Test to validate the use of an IL workbook.
The test set performance indicators and outcomes according to the five IL standards for
higher education (ALA, 2000; Trail et al., 2006). The researchers developed this test by
identifying the performance indicators and outcomes of ACRL’s competency standards
associated with basic IL skills. These skills focused on identifying key concepts, key
terms, and characteristics of potential resources. The IL test focused on the ability to use
various electronic information resources to find information within these database
systems.
Assumptions
The researcher assumes Weiner’s attribution theory accurately describes the
relationship between IL self-efficacy and IL proficiency (Weiner, 1985, 1986, 2006,
2010). Information literacy self-efficacy acts as either a positive or negative motivator
for mastering IL knowledge and skills. Students will choose to engage in IL-related
clinical activities based upon their perceived levels of IL self-efficacy. This study also
assumes that the ILSES (Kurbanoğlu et al., 2006) and IL proficiency test (Trail et al.,
2006) accurately measure the study variables and that the data-collection instruments will

13

consistently collect valid data. Regarding data analysis, the researcher assumed the
statistical tests she used were appropriate, permitting accurate interpretation of the data.
The final assumptions center on the study participants. The researcher assumes
the study participants accurately reported their IL self-efficacy, IL proficiency, and
demographic information by honestly answering the questions in the data collection tools.
For example, the participants submitted self-reported grade point averages (GPAs). The
researcher assumed the self-reported GPAs reflected the official GPAs.
Delimitations
This study has three delimitations. First, the restriction of the study sample to
senior pre-licensure baccalaureate nursing students may make it difficult to generalize the
study results to all undergraduate pre-licensure nursing students. Freshmen through
junior nursing students may experience different relationships with IL proficiency and IL
self-efficacy because of their limited educational experience.
The second delimitation of this study centers on the convenience sample. This
study used a consecutive sampling technique. The researcher contacted pre-licensure
baccalaureate nursing program administrators within Pennsylvania to recruit participants
until 88 students completed the questionnaires. Recruitment required the use of several
institutions to receive 88 complete questionnaires. Including the pilot study, participants
were from seven universities -- three public and four private. Nursing students who
matriculated in public institutions or who attended schools in other geographic areas may
have different experiences, which may have influenced the study’s results.
The final delimitation of the study centers on the participants’ academic
backgrounds. Different high school experiences and curricula may have influenced the

14

participants’ ability to learn and perform IL related activities in college. Therefore,
students who entered college with negative experience or little IL education may harbor
adverse feelings toward IL, and these feelings may hinder their ability to perform IL
related activities in college.
Limitations
This study is limited to data collected from senior pre-licensure baccalaureate
nursing students matriculating in seven different Pennsylvania universities. This research
limits the study population to senior pre-licensure students for two main reasons. First,
pre-licensure baccalaureate students typically have had previous exposure to IL
instruction in their general education and clinical courses. These students, therefore,
enter their senior year with the foundational IL knowledge to bridge nursing theory,
research utilization, and nursing practice. Second, the exclusion of licensed
baccalaureate students may introduce bias into the dataset. Experience working as a
registered nurse will expose licensed baccalaureate students to policies and situations that
require IL proficiencies. According to the attribution-based theory of motivation, these
experiences could form values and motivations associated with IL skills and EBP
(Weiner, 2010). Antecedents for licensed baccalaureate nursing students may drastically
differ from pre-licensure students. Finally, the IL proficiency tool does not address the
fourth standard, the ability to use the information proficiently in the task that precipitated
the need to gather information. A multiple-choice test, true/false test cannot adequately
assess this fourth standard.

15

Study Methodology
This correlational research study used a simple survey format. At the time of the
pilot study, it was not known whether a relationship existed between IL knowledge and
IL self-efficacy. Therefore, the pilot study did not identify specific independent or
dependent variables. The pilot test, completed in spring 2014, assessed reliability of the
ILSES (Kurbanoğlu et al., 2006) and the Richard Stockton College of New Jersey
Information Literacy Test in a population of baccalaureate pre-licensure nursing students.
This pilot study required administering the test and retest within a two to three-week
timeframe. The pilot test used paper surveys instead of electronic surveys; the researcher
did not include data collected from the pilot study in the study’s database.
The execution of the study required only one data collection point. The
researcher administered the survey to participants using Qualtrics. The completion of
these surveys took approximately 15 minutes. Data collection was completed during the
2014 spring and fall semesters. The researcher then entered the data from Qualtrics into
the Statistical Package for Social Science ® (SPSS), version 22 for analysis.
Significance of Research
Evidence-based nursing practice centers on the use of empirical evidence to
identify the most efficient methods for providing patient care. Prior to graduation,
nursing students must demonstrate the ability to apply published research effectively in
their practice to assure the provision of quality, safe, patient-centered care. Therefore, IL
education in nursing programs must focus on the ability to identify pertinent publications
from multiple sources of information, analyze the validity of the information, synthesize

16

information from various sources to develop new knowledge, and transfer this knowledge
into practice.
Although published studies have illustrated how educational interventions
improve students’ proficiency in IL (Courey, Benson-Soros, Deemer, & Zeller, 2006;
Freeman & Lynd-Balta, 2010; Henderson, Nunez-Rodriguez, & Casari, 2011), practicing
nurses report barriers that inhibit their ability to engage in EBP (Schoonover, 2009;
Tanner, Pierce, & Pravikoff, 2004). These barriers include: lack of research awareness,
inability to locate research articles, and inability to understand research articles
(Schoonover, 2009; Tanner et al., 2004). Nurses in these studies may have experienced
situations that could have negatively affected their self-efficacy in using IL skills and
knowledge.
Because self-efficacy can affect whether a person engages in a particular behavior
(Bandura, 1977), poor self-efficacy in IL may have caused these nurses to lose the IL
knowledge and skills they obtained in their nursing education. Research investigating the
link between self-efficacy and IL proficiency may help nurse educators provide IL
instruction that could create positive predispositions in pre-licensure students. This new
instruction may improve student nurses’ ability to engage in research utilization and EBP
after graduation.
Chapter Summary
Information literacy self-efficacy may directly relate to nursing students’ abilities
to appreciate and apply IL knowledge to nursing practice. The investigation of the
relationship between self-efficacy levels and IL proficiency may help educators tailor
their pedagogical interventions to improve IL self-efficacy. Positive IL self-efficacy may

17

motivate students to master IL skills beyond the classroom and reinforce positive
mindsets about using IL in EBP.
This correlational study used paper-based instruments to collect reliability data on
IL self-efficacy and knowledge surveys. The study used electronic surveys to determine
if a relationship exists between IL self-efficacy and proficiency. Weiner’s (1985, 1986,
2006, 2010) attributional theory of achievement served as the theoretical framework for
this investigation. The study assessed whether positive IL self-efficacy acted as a
motivator for becoming proficient in IL.
Because research has found that IL self-efficacy motivates the mastery of IL
knowledge and skills, educators need to develop pedagogical interventions to promote
positive IL self-efficacy. These positive perceptions may help students improve their
ability to engage in IL-based assignments and help them better understand the
relationship between IL and EBP. This study may generate future research projects to
would help nursing students understand how IL proficiency facilitates competent,
evidence-based nursing practice.

18

CHAPTER TWO
LITERATURE REVIEW
This chapter reviews published literature related to IL self-efficacy and IL
knowledge and examines IL in the context of EBP and nursing education. The review
covers articles from Academic Search Complete; Cumulative Index to Nursing and
Allied Health Literature (CINAHL); Communication & Mass Media Complete;
Computers & Applied Sciences Complete; Education Full Text; Education Research
Complete; Education Source; ERIC, Health Source: Nursing/Academic Edition; Library
& Information Source; Library Literature & Information Science Index; Library
Information Science & Technology Abstracts; and MEDLINE. The literature search used
the key words of IL and undergraduate nursing education and, initially, included only
articles published within the last three years. Because of the lack of articles focusing on
IL and nursing education, the researcher expanded the literature review to include any
pertinent articles published after 2000. The review used additional key words such as IL,
undergraduate education, and attribution theory to retrieve information regarding the
instruction of IL within the higher education system. Some references dated prior to
2000 were included because they contained essential information helping the reader
understand the importance of IL in nursing education.
The literature review begins by discussing IL education in relation to the
technology revolution and EBP. The advent of information technology (IT) created an
increased need for students to employ IL skills proficiently. The discussion examines
published studies on IL, using undergraduate nursing students and traditional
undergraduate populations. The researcher included other studies of generic

19

undergraduate student populations if the studies provided insight on IL education within
undergraduate nursing programs. This chapter concludes by discussing the literature
related to the theoretical framework and instruments for data collection related to IL selfefficacy and knowledge.
The Technology Revolution and Information Literacy
Developed in 1989, IL is a relatively new concept in education. The Presidential
Committee on Information Literacy’s final report stated that IL was vital for individuals,
businesses, and citizens (ALA, 1989). Society’s complexities demand that people remain
informed so they can solve problems relating to business, citizenship, and society (ALA,
1989). Since the publication of the ALA’s report, IL has become a crucial element in
society and in health care.
The technology revolution exponentially increased the complexities of society.
Current IT platforms allow people to access a wealth of global information within
seconds. The ability to evaluate and identify accurate information has become essential
for everyone, particularly for those who engage in EBP. Seeking information is a key
element of EBP and a mainstay of IL. Table 1 demonstrates similarities in activities
associated with EBP and IL.

20

Table 1
Crosswalk of Evidence-Based Practice (EBP), Information Literacy (IL), and Nursing Practice
Steps in EBP

IL competencies

Relationship to Nursing Practice

Ask the clinical question.

Know when information is
needed.

Recognize when to validate existing
practices or investigate the use of
new practices in nursing care—
create a clinical question.

Research for the best evidence.

Ability to access the needed
information through activities
such as database searches.

Understand how research utilization
relates to systematic improvement in
the provision of patient care.

Critically appraise evidence.

Evaluate all information
obtained and determine what
information is pertinent to the
particular need.

Recognize what constitutes a robust
study and how it relates to the
clinical question.

Address the sufficiency of the
evidence for implementation
into practice.

Proficiently use the
information in the task that
precipitated the need to gather
information.

Learn when and how to use
empirical evidence to improve
personal practice and institutional
policies.

Evaluate the outcome of
evidence implementation.

Use the new information
according to legal and ethical
standards.

Acknowledge resources that support
the new practice or protocol and
evaluate the effects of the new
practice or protocol within the
standards of practice.

Note. Adapted from Information literacy competency standards for higher education by American
Library Association, 2000, Chicago, IL: American Library Association. Retrieved from
http://www.ala.org/acrl/sites/ala.org.acrl/files/content/standards/standards.pdf and “Transforming health
care from the inside out: Advancing evidence-based practice in the 21st Century” by E. FineoutOverholt and B. M. Melnyk, 2005, Journal of Professional Nursing, 21(6), 335–343.
doi:10.1016/j.profnurs.2005.10.005.

As discussed in Chapter 1, IL is the keystone of EBP because EBP entails the use
of the best research evidence (Institute of Medicine [IOM], 2001). Research utilization
requires the ability to retrieve and evaluate scholarly articles from a variety of sources.
Current trends in computer technology and Internet use produce an abundance of
available information for nursing students. The Technology Informatics Guiding
Education Reform (TIGER) Initiative created an action plan to help nurse educators and
nursing students keep pace with the IT explosion (Hebda & Calderone, 2010). While
guides provided by groups, such as TIGER, have helped faculty and students improve
their use of IT to retrieve published research, students often remain confused about the
21

nature of reliable scholarly information (Henderson et al., 2011; Salisbury & Karasmanis,
2011). This confusion stems from the sheer amount of information obtained through
electronic sources, such as the Internet (Henderson et al., 2011; Salisbury & Karasmanis,
2011). The following section reviews literature addressing the historical impact of
technology on IL and information retrieval via the Internet.
Development of Computer Technology
Technology’s tremendous growth in the last two decades has affected the
instruction and application of IL competencies. Prior to the Internet era, students would
go to the library to obtain scholarly material. Students easily could differentiate scholarly
journals housed in the library from entertainment magazines sold in stores. Electronic
sources of information, such as the Internet, do not clearly categorize scholarly and nonscholarly information. In addition, physical presence in the library affords students the
opportunity to obtain help from librarians when looking for scholarly information.
Computer technology revolutionized the storage and communication of
information. The newfound abilities to store information digitally and send information
electronically created an ideal format for an expansive dissemination of knowledge. The
percentage of available information stored digitally grew from 1% in 1986 to 94% in
2007 (Hilbert & López, 2011). In 1986, nearly 100% of information telecommunication
occurred through the telephone (Hilbert & López, 2011). This is in stark contrast to
2007, when 97% of information telecommunication occurred through the Internet.
Digital storage, coupled with instant Internet access, created a wealth of information
previously unavailable to students. These changes transformed IL competencies related
to retrieval and dissemination of information. For example, the introduction of Web 2.0

22

in 1994 created a trend of retrieving information through search engines such as Google
(O’Reilly, 2005) and harnessing information from multiple websites.
Development of social media. Web 2.0 also made the use of collective
intelligence possible to allow Internet users to communicate through applications such as
blogs, wikis, and social media sites such as Facebook and Twitter (O’Reilly, 2005).
Figure 2 illustrates the introduction of communication platforms that many now consider
common communication tools.

Figure 2. Timeline depicting the development of web-based communication platforms.
(Facebook Inc., 2012; Google Company, n.d.-b; Hilbert & López, 2011; Lunden, 2012;
O’Reilly, 2005).
The use of these platforms has grown exponentially. For example, in January
2008, Facebook recorded more than 60 million users in the United States (Eldon, 2008).
That number grew to 140 million active users in December 2008 (Eldon, 2008), and
according to the Pew Reports, 67% of adults in the United States currently use Facebook
(Rainie, Smith, & Duggan, 2013). The trend is similar with Twitter. As of July 2012,
141.8 million U.S. residents had Twitter accounts (Lunden, 2012).
Social media and information literacy. The increased use of social media
suggests people are exposed to larger amounts of information of questionable credibility.
23

A grounded theory study investigated the role of social media platforms in the awareness
of communication during a public emergency, the Queensland floods (Bunce, Partridge,
& Davis, 2012). Findings indicated that social media users go beyond personal
communication. At the onset of a crisis, the four participants in this pilot qualitative
study used social media for communication, becoming aware of information, affirming
information, and monitoring information (Bunce et al., 2012).
Witek and Grettano (2012) substantiated the results obtained by Bunce et al.
(2012) by analyzing students’ use of Facebook concerning the ACRL’s (2000) IL
competencies. The authors based their conceptual paper on behaviors they observed via
Facebook. Although the article contained no information regarding the quality or the
amount of observations, Witek and Grettano (2012) highlighted interesting correlations
between social media and IL. The authors aligned ACRL’s Information Literacy
Competency Standards with common Facebook behaviors and connected these behaviors
with the process of conducting research for an academic assignment. The authors
observed that students’ use of news feeds in Facebook correlated well with ACRL’s IL
competency Standards 2 and 3. For example, ACRL’s Standard 2 requires students to
extract, record, and manage information and information sources. The newsfeed on
Facebook acts as a traditional library catalog or online database. Not only can students
extract information from the newsfeed on Facebook, they can manage the information
through the Facebook Timeline. Witek and Grettano (2012) observed students engaging
in ACRL’s Standard 3, the ability to evaluate and appraise information critically, when
using Facebook’s share and like functions. Even though Witek and Grettano’s article

24

was an observational report rather than a research study, the authors highlighted the
intersection between social media use and IL.
The articles published by Witek and Grettano (2012) and Bunce et al. (2012)
demonstrate that students apply IL skills when using social media platforms. Because of
the abundance of information available through these platforms, students need to possess
IL skills and knowledge so that they can effectively use or ignore information posted on
the sites. This literature review did not identify any other article addressing social media
use within the context of IL.
Student Perceptions of Communication Technology in Relation to Information
Literacy
While students have reported proficient communication technology skills in their
use of the Internet, e-mail, chat, Microsoft Word, and Microsoft Excel (Biddix, Chung, &
Park, 2011; Bond, 2010; Özkul & Kaya, 2009; Salisbury & Karasmanis, 2011), they have
failed to recognize the connections among information communication technology, IL,
and EBP (Courey et al., 2006; Levett-Jones et al., 2009). This is particularly interesting,
given the research conducted by Erdem (2007) and Tuncer (2013). While Tuncer (2013)
investigated the presence and strength of correlations between IL self-efficacy, computer
self-efficacy, and scientific research self-efficacy among prospective teachers (n = 197),
Erdem (2007) investigated the relationship between IL self-efficacy and computer
literacy self-efficacy among teachers in the public school system (n = 68). Tuncer’s
study indicated computer self-efficacy had a positive effect on IL self-efficacy (β = 0.42;
p = .001), while Erdem asserted that computer literacy self-efficacy and IL self-efficacy
positively correlated. Erdem (2007) made this assertion by comparing frequency

25

distributions, although data analysis did not include any inferential statistics. Tuncer’s
analysis also indicated that computer self-efficacy positively affected scientific research
self-efficacy (β = 0.25; p = .003). These results must be interpreted with caution because
the participant pools comprised undergraduate student teachers in Turkey (Erdem, 2007;
Tuncer, 2013). Characteristics specific to the study population and Turkish culture may
limit the study’s generalizability to a U.S. population.
Levett-Jones et al. (2009) explored how students understood the relationship
between information communication technology and clinical practice. The researchers
used a cross-sectional survey of first-year undergraduate nursing students who attended
three Australian universities. From a population of 1500, the study had nearly a 65%
response rate. Over 25% of the participants stated that they did not understand the
relationship between information communication technology and clinical nursing
practices. Qualitative responses collected from focus group interviews supported the
study’s purpose of identifying nursing students’ attitudes and perceptions related to
information and communication technology and its relevance to clinical practice.


“I can’t see the point in all this IT and online learning . . . . I wanted to do
nursing . . . not computer studies.”



“Nurses want to work with people and learn from people . . . . I don’t see how
using IT fits in at all.” (Levett-Jones et al., 2009, p. 614)

These findings directly contradict IOM (2003, 2008) recommendations regarding
the use of informatics and EBP and found that students view IT and nursing care as two
distinct entities (Levett-Jones et al., 2009). The students did not understand how IT could
affect the delivery of nursing care (Levett-Jones et al., 2009). In 2003, the IOM

26

recommended nurses receive education in IT so that they could employ information
communication technology to deliver quality, safe, patient-centered care. Furthermore,
the IOM (2011a, pp. 85-86) later stated, “Virtually everything done clinically—from
gathering a history and a physical, to working through differential diagnoses, managing
preventive measures, and, most importantly, accessing the wealth of extant medical
knowledge—involves information.” The IOM’s 2011 report discusses how clinicians
access this information through health information systems. The extent of information
related to the provision of care mandates the mastery of IT and IL skills. The study’s
findings may have conflicted with IOM (2003, 2008, 2011a) recommendations regarding
EBP because the research was conducted in Australia (Levett-Jones et al., 2009).
This study might have yielded different results if the sample had represented a
more diverse study population. Approximately 42% of the population reported their ages
as over 23 years (Levett-Jones et al., 2009). The ages of the participants in this study,
possibly, could possibly explain why the students viewed IT as an isolated entity from
nursing. The reported age range for all participants was 17-60 (Levett-Jones et al., 2009).
Students born in or after 1981 -- those in the millennial generation -- reported a high level
of competence in the use of IT, including the Internet (Bussert, 2011; Folley, 2010).
Participants in the previous studies had mean ages of 20.75 (Özkul & Kaya, 2009) and
20.49 (Biddix et al., 2011). Salisbury and Karasmanis’ (2011) article did not include a
mean age, but they stated 84.3% of their study sample reported ages between 16 and 21.
The age difference between the participant populations could have generated the
conflicting results among Levett-Jones et al. (2009), Biddix, Chung, and Park (2011),
Henderson, Nunez-Rodriguez, and Casari (2011), Özkul and Kaya (2009), and Salisbury

27

and Karasmanis (2011). According to the PEW Research Center (2010), people born
after 1980 (the millennials) believed their generation is distinctive because of their use of
technology. The rapid advances in technology may have caused this cohort effect.
Use of the Internet to Retrieve Information
The common use of communication technologies allows nursing students to
access an overabundance of information. Unlike the time they need to obtain information
from books, they can instantly retrieve an abundance of information from the Internet.
Information retrieved through the Internet may appear scholarly, even though it may
contain misinformation. For example, a private website may use all the correct
terminology related to a condition or diagnosis, but may not have references to validate
the information or recommendations regarding the condition or disease. Therefore,
nursing students must know how to evaluate the validity of information retrieved from
the Internet. The flood of available information for use in school assignments and
nursing practice can hinder the acquisition and assessment of quality information. The
following two subsections discuss:


Qualitative studies describing how undergraduate study participants used the
Internet as a resource for information; and



Research specifically investigating the use of Google, a popular Internet
search engine, as a resource of information.

The Internet as an information resource. Research has indicated that
undergraduate students perceive websites as an important source of credible information
(Biddix et al., 2011; Ferguson, Neely, & Sullivan, 2006; Henderson et al., 2011;
Salisbury & Karasmanis, 2011). Biddix et al. (2011) collected qualitative information

28

regarding Internet use. The participants were undergraduate students in a northeastern
university located in the United States (Biddix et al., 2011). The majority were female
(59%), and 97% of them used English as their primary language (Biddix et al., 2011).
Biddix et al. (2011) analyzed social network and Internet use to identify structures
and concepts in a set of responses. In this study, students provided narrative descriptions
of their processes for obtaining study-related information from the Internet (Biddix et al.,
2011). Using computer software, the researchers identified clusters of related words in
the students’ responses. Examples of the clusters that emerged from student replies
include website-use-search-source-reliable-research-engine, find-information-Google,
and know-topic-Wikipedia (Biddix et al., 2011). The researchers identified word clusters
such as find-look-Google, accurate-article-.edu, academic-depend-Wikipedia-know, and
friend-search from students’ descriptions of their process for determining the credibility
of information (Biddix et al., 2011). In contrast to Klausegger, Sinkovics, and Zou
(2007), Biddix et al. (2011) did not discuss the timeframe within which they administered
the qualitative questionnaires (Biddix et al., 2011). The lack of a data collection
timeframe prohibits the reader from identifying any situational confounds, such as
whether they collected information during the summer or the week of finals. This
limitation further precludes accurate evaluation of the study’s results in relation to the
current information-communication technology trends and standards. The publication
date, 2011, does not guarantee this research was conducted within the past five years.
Despite this limitation, the research produced telling results. Data analysis
indicated that students’ choices for information sources centered on the type of task and
time associated with information retrieval (Biddix et al., 2011). Study participants

29

reported they only used library resources for projects, such as research papers, because of
the increased time needed to retrieve information. They reserved these practices for tasks
they considered scholarly. Data analysis also indicated participants used Internet search
engines for non-research-related assignments because they could access and download
the information quickly and easily (Biddix et al., 2011).
Yet, participant responses to Ferguson, Neely, and Sullivan’s (2006) study
contradicted the results found by Biddix et al. (2011). Out of 143 participants, 126
students indicated they used websites as resources for information when completing a
research project or paper (Ferguson et al., 2006). Ferguson, Neely, and Sullivan’s (2006)
study results should be interpreted with caution, however, due to issues regarding both
sampling and generalization as well as validity of the instrumentation measure. Although
these researchers developed the data-collection tool for the study to parallel ACRL’s
competency standards, the article contained no information regarding the validity and
reliability of the data-collection tool (Ferguson et al., 2006). The lack of survey
information in the article limited the reader’s ability to critique the study (Ferguson et al.,
2006).
In addition, the article implied the study results were specific to biology students
(Ferguson et al., 2006). However, the researchers intended to collect data portraying the
IL knowledge of the entire freshmen class. They opened the online survey to students in
biology, computer science and engineering, English, history, and psychology. The
authors stated that 427 students logged into their survey. Of the 427 students, 424
answered the questions in the survey (Ferguson et al., 2006). However, only 151 students
who began the survey identified themselves as biology students (Ferguson et al., 2006).

30

The article insinuated that not all of the 151 students completed the survey (Ferguson et
al., 2006). The article lacked demographic data for students who were not biology
majors. The lack of consistency in the description of the study sample and dataset raises
concerns regarding the generalizability of the data.
Contrary to the prior study, only 41.3% of Turkish undergraduate nursing students
(N = 432) in Özkul and Kaya’s (2009) study used the computer to search for information.
Students used computer technology for e-mail, to chat with friends, read news, use
software such as Microsoft Word and Excel, listen to music, and surf the Internet. Only
41.3% stated they used the computer to search for information (Özkul & Kaya, 2009).
Other than the students’ year of study in the nursing program, the article did not contain
any detailed statistical information describing the study population (Özkul & Kaya,
2009). As in the study conducted by Levett-Jones and colleagues (2009), the inclusion of
non-traditional students could have affected computer use for personal and academic
tasks. In addition, cultural differences may have influenced how nursing students used
and reported their use of computer and IT.
Use of Google as an information resource. Although the prior two studies
provide interesting data regarding Internet usage by undergraduate students, they fail to
provide specific information regarding sites the students used as information resources.
The over-abundance of information available through the Internet may tempt students to
use information from non-scholarly sites such as Google. Many studies investigated the
use of Google because it has become a standard for conducting Internet searches. Google
has over one billion unique visitors (comScore Data Mine, 2011), and it conducts over
one billion worldwide searches every day (Google Company, n.d.-a). Although no

31

studies in the literature review specifically investigated why students use Google as an
information source, research has indicated that students view Google as a source of
scholarly information (Henderson et al., 2011; Salisbury & Karasmanis, 2011).
Salisbury and Karasmanis (2011) found that undergraduate students’ first, second,
and third preferences for information retrieval were Google, peers, and books,
respectively. Over one third (35%) of these students reported they used Google to find
scholarly information (Salisbury & Karasmanis, 2011). Only 14% of the students stated
they used databases for finding scholarly information. A large proportion of these
students (36%) stated they physically went to the library to find scholarly information.
These results support earlier assertions that students experienced increased confusion in
identifying scholarly information retrieved from electronic sources. The physical
presence of scholarly information in the library may have helped the students
differentiate scholarly from non-scholarly information.
Like Özkul and Kaya (2009), Salisbury and Karasmanis’ (2011) findings must be
interpreted with caution because of cultural differences and no comprehensive statistical
comparisons and reporting. While the questionnaire had 11 excellent questions assessing
students’ IL knowledge, the authors only reported the frequencies of student responses
(Salisbury & Karasmanis, 2011).
Similar to the previously discussed studies, undergraduate students in Henderson,
Nunez-Rodriguez, and Casari’s (2011) mixed-methods study reported using Google to
obtain scholarly information. Although the background information in the article
discussed freshmen students, the authors failed to report whether the research participants
were freshmen. They did state the participants were enrolled in the first two courses in a

32

sequence of biological science classes required for science majors; they registered in two
successive general biology courses, and were required to complete course assignments
that included the use of IL skills. By analyzing pre- and post-test surveys in conjunction
with course assignments, the researchers concluded that students’ use of Google for
completing assignments increased as their IL knowledge improved. The use of search
engines, such as Google, may create confusion in students’ searches for scholarly
information, however. Websites that contain blogs or wikis often appear scholarly
because the information contains medical terminology and several references, but
students may be unable to critique the references or accuracy of information.
Information overload. Klausegger et al. (2007) conducted a study using a
dataset collected from business managers residing in the United Kingdom, the United
States, Hong Kong, and Singapore. This research supported the notion that information
overload plays a role in students’ literature search confusion and misjudgments. Study
respondents indicated that too much information may prohibit the efficient use of
information and interferes with fulfilling core tasks related to an assignment (40.4%)
(Klausegger et al., 2007).
Collecting data using telephone surveys, Klausegger et al. (2007) noted people
faced with information overload skimmed the material and discarded what that they
considered irrelevant. They used information only if they perceived it as important, a
perception which was formed during a quick review of the material (Klausegger et al.,
2007). The researchers concluded the overabundance of information may lead to
increased risk of missing vital, accurate data, and further highlights the need to provide

33

support in identifying proper information, distinguishing its relevance, and evaluating its
quality (Klausegger et al., 2007).
Klausegger et al. (2007) conducted this study using data collected in 1996. The
tremendous growth of information communication technology in the past two decades
has exponentially increased the amount of information students can retrieve in a matter of
seconds. At that time, only 35% of the respondents reported that the Internet was a
significant influence on information retrieval (Klausegger et al., 2007). In the era in
which the data were retrieved, the Internet only accounted for 1% of the information
retrieved through telecommunication (Hilbert & López, 2011).
Bond (2010) provides additional indication of the difficulty students experience in
finding reputable information. This study collected self-reported Internet use data by prelicensure English nursing students in 2007 (Bond, 2010). Bond (2010) replicated a
previous study she had conducted in 2001. Overall, students in both studies reported
proficient Internet skills, with 30.8% of the 2001 and 40% of the 2007 respondents
reporting expert Internet skills. Despite reporting proficient Internet skills, 60.15% of the
2001 respondents and 54.4% of the 2007 respondents reported encountering too much
irrelevant information when completing tasks on the Internet (Bond, 2010). While the
differences between the 2001 and 2007 responses were not statistically significant, the
results demonstrate that students had continued to experience information overload
throughout the decade.
These studies lead to the conclusion that the development of communication
technology drastically heightened the importance of IL education. After the advent of the
Internet and search engines, such as Google, students could easily and instantly access

34

worldwide information. Research indicates that computer literacy increased students’
beliefs in their ability to engage in IL activities. Although easy access to information
helped students retrieve information in a more efficient manner, students still reported
that they obtained too much irrelevant information from the Internet. The overabundance
of information could cause students to miss appropriate, accurate articles (Klausegger et
al., 2007). The difficulty in finding relevant, scholarly information may constitute a
primary reason students avoid engaging in IL activities unless required to do so. In
addition, the information overload may contribute to students’ inability to see the
connections between communication technology, IL, and EBP. Helping students master
ACRL’s (2000) second and third IL competencies may help them retrieve appropriate,
accurate information in a more timely manner.
Information Literacy in Nursing Education
The following section provides an overview of IL in relation to nursing education.
This segment begins by discussing survey data that assesses the prevalence of IL
education in nursing curricula and then proceeds to discuss empirical evidence portraying
the current IL knowledge of nursing students. The following section discusses data
collected from surveys that gather baseline data for IL knowledge. It is followed by a
presentation of research assessing the impact of educational interventions on IL
knowledge.
Delivery of Information Literacy Education in Baccalaureate Nursing Programs
Only one study provides research data on the inclusion of IL education in
baccalaureate nursing education (McNeil et al., 2003; McNeil et al. 2005; McNeil,
Elfrink, Beyea, Pierce, & Bickford, 2006; McNeil, Elfrink, & Pierce, 2004). Four articles

35

(McNeil et al., 2003; McNeil et al. 2005; McNeil et al., 2006; McNeil et al., 2004)
discuss this national survey study. The study assessed nursing educators’ views
regarding the extent to which IT tools and competencies affect EBP. Through the use of
an electronic survey, a minority of the participants (N = 268) reported that they expected
students to enter their nursing program with basic IL skills, focusing on traditional
bibliographic sources and the Internet (McNeil et al., 2003; McNeil et al., 2005; McNeil
et al., 2004). However, almost 80% of the respondents, reportedly, expected students to
exhibit IL proficiency in bibliographic retrieval and the use of the Internet (McNeil et al.,
2003; McNeil et al., 2005; McNeil et al., 2004). Although these articles discuss how the
respondents evaluated computer literacy at graduation, the authors provided no
information on IL evaluation prior to graduation (McNeil et al., 2003; McNeil et al.,
2005; McNeil et al., 2004).
While this study provides useful information on the administration of IL
education, it has several limitations regarding how the study operationalized IL. The
authors listed IL as a key word for the study and stated one of their goals was to collect
information about IL education. Nevertheless, none of the study’s research questions
contained the words “information literacy.” It appears as though the researchers assessed
IL indirectly in the survey. The name of the survey, the Information Technology
Education in Nursing Curricula Survey (ITENCS), creates concerns regarding
congruence between the dataset and the authors’ assertions. Using a table that displays
intercorrelations for the 37 survey questions and 11 content categories, the reader has to
infer where and how the study assessed IL (McNeil et al., 2005). All 11 content
categories focused on IT (McNeil et al., 2005).

36

The final limitations to this study center on the validity of the survey because the
researchers created it for the research study (McNeil et al., 2003; McNeil et al., 2005;
McNeil et al., 2004). The authors only addressed content validity. The researchers
discussed how they created the survey questions from the literature and they noted that
nursing informatics experts reviewed the questions. However, the article did not discuss
how the experts reviewed the survey’s content nor did it address the survey’s reliability
(McNeil et al., 2003; McNeil et al., 2005; McNeil et al., 2004).
Despite these limitations, the information obtained from this study sets the stage
for IL education in nursing programs. McNeil et al. (2003, 2004, 2005) produced the
only published studies that collected data regarding the instruction of IL in undergraduate
nursing programs. The researchers collected data from nursing education programs
located throughout the United States. Results indicate that nursing students received IL
education and should have mastered basic IL competencies prior to graduation.
Information Literacy Proficiency of Pre-Licensure Undergraduate Nursing
Students
Many published articles that address IL knowledge, skills, or competencies of
nursing students have assessed IL proficiency in relation to educational intervention
(Courey et al., 2006; Jacobsen & Andenæs, 2011; Ku, Sheu, & Kuo, 2007; Wallace,
Shorten, & Crookes, 2000). While these articles provide pertinent information, data
analysis focused on improvement of performance rather than baseline IL proficiency.
This section initially discusses three studies measuring baseline IL proficiency (Ferguson
et al., 2006; Özkul & Kaya, 2009; Salisbury & Karasmanis, 2011) and presents data from

37

studies examining the effect of educational interventions on IL knowledge (Courey et al.,
2006; Jacobsen & Andenæs, 2011; Ku et al., 2007; Wallace et al., 2000).
Assessment of overall information literacy knowledge. The literature reviewed
includes three manuscripts addressing baseline IL data from undergraduate students
(Ferguson et al., 2006; Özkul & Kaya, 2009; Salisbury & Karasmanis, 2011). Only one
study focused exclusively on nursing students (Özkul & Kaya, 2009), but this study
failed to assess the students’ abilities to perform IL competencies. Özkul and Kaya
(2009) collected data measuring students’ views regarding their IL skills. The authors
concluded nursing students in their population believed they were proficient in IL. The
authors reported that students with increased perceptions of computer literacy also had
increased perceptions of IL.
Salisbury and Karasmanis (2011) and Ferguson et al. (2006) collected baseline IL
data from a general undergraduate student population just entering higher education.
Salisbury and Karasmanis (2011) reported participant knowledge (N = 1000) regarding
search strategies, identifying information relevant to an assignment, citation recognition,
referencing, and peer-reviewed journal articles. Except for the use of key words, less
than 50% of the participants chose correct answers for all questions in these categories
(Salisbury & Karasmanis, 2011).
Like Salisbury and Karasmanis (2011), Ferguson et al. (2006) reported that their
American study population of students (N = 424) struggled with IL skills. For example,
less than 12% of participants could correctly identify elements of specific journal
citations (Ferguson et al., 2006). However, the participant responses to the knowledgebased questions in this study conflicted with the results of Salisbury and Karasmanis’

38

(2011) study. The majority of American students who answered questions regarding
paraphrasing and citations gave correct responses to the survey questions (Ferguson et al.,
2006); while only 28.3% of Australian students answered similar questions correctly
(Salisbury & Karasmanis, 2011). The lack of data in both articles prevented the reader
from discerning if these differences were due to different sample sizes, cultural practices,
or both.
Missing data, also, may have biased these results. As previously described,
Ferguson et al. (2006) did not report the number of complete datasets. Instead, they
reported on a question-by-question basis and only reported data according to the number
of responses for each particular question (Ferguson et al., 2006). Missing data could
have skewed the analysis and caused a misrepresentation of the study population’s IL
knowledge.
Information literacy education and knowledge. Courey, Benson-Soros,
Deemer, and Zeller (2006), Jacobsen and Andenæs (2011), Ku, Sheu, and Kuo (2007),
and Wallace, Shorten, and Crookes (2000) described research assessing the ability of
pedagogical interventions to improve nursing students’ abilities to use information
resources for retrieving scholarly information. Although all three publications focused on
the effect of pedagogical interventions on IL knowledge, they investigated the construct
using different approaches. Courey et al. (2006) assessed student perceptions regarding
students’ use of information resources and experience on IL knowledge. They also
surveyed student perceptions regarding the value of nursing literature (Courey et al.,
2006). Jacobsen and Andenæs’s (2011) survey also measured students’ self-assessment
of IL, but specifically focused on skill sets delineated by ACRL’s (2000) competency

39

standards for higher education. Unlike the other authors, Ku et al.’s (2007) survey
assessed the ability to apply, analyze, and present information.
All four studies used a pre- and post-test design, collecting data at the beginning
and end of a semester to measure the change in knowledge (Courey et al., 2006; Jacobsen
& Andenæs, 2011; Ku et al., 2007; Wallace et al., 2000). Using inferential statistics,
three of the four studies suggest IL proficiency improves with educational intervention
(Courey et al., 2006; Ku et al., 2007; Wallace et al., 2000). Courey et al. (2006) executed
a one-day IL instruction program for freshmen students (N = 58). Students in the
experimental group continued to receive IL-focused assignments in a nursing
fundamentals course throughout the semester. The authors reported an increase of
student access to information and concluded the effect accounted for 69% of the variance
(Courey et al., 2006). Like Courey et al., Wallace et al. (2000) assessed students’ (N =
55) abilities to locate and retrieve literature, but they extended their intervention
throughout the curriculum. Collecting pre- and post-test data from a freshmen cohort,
Wallace and colleagues (2000) conducted data analysis using a Wilcoxon two-sample
test. These authors determined that first-year nursing students who received the IL
education performed better (p < .001) than first-year nursing students who did not
receive the educational intervention (Wallace et al., 2000).
Ku et al.’s (2007) experimental methodology (N = 75) required instruction of IL
throughout a women’s health course offered to licensed baccalaureate students. While the
study had a similar methodology to Courey et al. (2006), it also collected data on the
integration, analysis, application, and presentation of information. Results indicated that
the experimental group’s pre- and post-test scores (Wilks’ Lambda F = 4.78; p < .005)

40

showed a statistically significant improvement over the control group’s scores (Wilks’
Lambda F = 2.80; p < .005).
While Jacobson and Andenæs (2011) did not intend to show any causal
relationships, their descriptive study shed light on the students’ abilities to transfer IL
knowledge and skills to new situations. Although both groups demonstrated difficulty in
understanding search strategies, such as Boolean operators, students tended to isolate the
use of bibliographic and Internet search strategies according to assignment characteristics
(Jacobsen & Andenæs, 2011). Students who completed conventional writing
assignments used bibliographic search strategies, while students who completed revised
assignments frequently used the Internet to find information (Jacobsen & Andenæs,
2011). Conventional assignments only required students to find and evaluate articles in
nursing or research journals (Jacobsen & Andenæs, 2011). However, the revised
assignments required students to use their existing Internet skills to find information and
use it in a short nursing paper or patient situation (Jacobsen & Andenæs, 2011). The
inability to transfer existing Internet knowledge and skills to academic use may suggest
that students only view IL as a component of academic tasks.
Student Perceptions and Attitudes Regarding Information Literacy
Few publications addressed nursing students’ attitudes toward IL. Consequently,
this review includes qualitative studies that interviewed generic undergraduate students.
Research indicated college students do not understand the true definition of IL (Gross &
Latham, 2009; Nayda & Rankin, 2008). None of the students in either of Gross and
Latham’s (2009, 2011a) studies could define IL. When asked to describe their
information-seeking behaviors, these first-year students referred to curiosity,

41

perseverance, and synthesizing information (Gross & Latham, 2009). These students
never used words such as “Boolean logic” or “databases” when describing their
information-seeking behaviors (Gross & Latham, 2009). Students with below
proficiency IL levels had difficulty articulating the processes involved in information
seeking (Gross & Latham, 2011a).
Nayda and Rankin (2008) conducted a descriptive qualitative study in Australia.
Results indicated study participants had a better command of IL than participants in
Gross and Latham’s (2009) study. Students in Nayda and Rankin’s (2008) study
interpreted IL skills as getting information from librarians and completing writing
assignments. These students restricted IL to library activities, which may have prevented
them from understanding the relationship between IL and EBP (Nayda & Rankin, 2008).
The following quote from Gross and Latham’s (2009) study exemplifies the
uncertainties associated with IL. “What is there to know? . . . I honestly don’t know how
much greater information literacy needs to be. . . . I think once you learn the basic level
there isn’t a ton of room for improvement” (Gross & Latham, 2009, p. 342).
Attitudes such as those demonstrated in these qualitative studies may have
affected students’ abilities to incorporate IL in EBP. Although the nursing students in
Courey et al.’s (2006) research demonstrated gains in knowledge, they also reported a
decrease in positive attitudes toward IL (F = 20.140; df = 1; p < .001) as measured by the
pre- and post-tests methods discussed in the previous section of this chapter. Students
receiving educational intervention displayed more negative attitudes towards IL
compared to the control group (F = 9.521; df = 1.58; p = .003).

42

The data collected in these quantitative studies focused on information retrieval.
However, use of IL skills in EBP goes beyond the ability to retrieve information.
Evidence-based practice requires students to summarize, synthesize, apply, and use
information effectively. Researchers need to collect more data addressing ACRL’s
(2000) IL competency standards for higher education:


determine the nature and extent of the information needed;



access needed information effectively and efficiently;



summarize the main ideas to be extracted from the information gathered;



use information effectively to accomplish a specific purpose;



understand economic, legal, and social issues surrounding the use of
information and access and use information ethically and legally.

In addition, research has revealed that undergraduate students misperceive IL’s
definition and its relationship to EBP. Students who did not know the definition of IL
may not have provided accurate information when filling out IL surveys.
Misunderstandings of IL may have caused students to compartmentalize it to schoolrelated assignments.
The studies published by Jacobsen and Andenæs (2011), Ku et al. (2007), and
Wallace et al. (2000) were conducted in Norway, Taiwan, and Australia, respectively.
While the articles referred to ACRL’s (2000) IL competency standards for higher
education, nursing programs listed in these articles were not required to provide IL
education according to these standards. Therefore, these nursing programs may have
implemented IL education competencies and evaluation to a lesser or greater degree than
undergraduate curriculums in the United States.

43

Gaps in the Research Related to IL Education on Baccalaureate Curriculums
Survey data collected by McNeil et al. (2003, 2004, 2005) reported that nursing
curriculums expect baccalaureate students to display basic IL-proficiency skills at
graduation. The empirical baseline data indicates that many students struggle with IL
skills. However, research assessing the effects of educational interventions on IL
knowledge has had promising results. These studies indicated educational interventions
have improved IL knowledge in nursing students.
The literature review revealed three main areas for future research of IL in
nursing education. First, the majority of empirical IL evidence in nursing education
focused on the ability to access information. In addition to accessing information,
nursing students must also be able to summarize, synthesize, apply, and use information
effectively to engage in EBP. The collection of baseline knowledge data on all IL
proficiencies can help educators to plan and deliver nursing education effectively.
Second, the review revealed a lack of empirical evidence regarding nursing students’
self-efficacy in relation to actual IL skills. A study conducted by Stokes and Urquhart
(2011) investigated nursing students’ IL self-efficacy, but it did not address actual IL
knowledge. Finally, the literature review only yielded one IL study with a U.S. nursing
student population (Courey et al., 2006). Further research must assess the IL knowledge
of U.S. nursing students.
Assessment Tools
Measurement of IL self-efficacy and knowledge is necessary to develop
pedagogical interventions to help students learn IL and prevent doubt and frustration
regarding IL. By fostering positive feelings toward IL and the ability to use IL skills and

44

knowledge, educators can shape student behaviors through emotional motivators and
attitudes associated with self-efficacy (Bandura, 1997; Krathwohl et al., 1964). To shift
the paradigm of IL education, nurse educators should investigate the use of new
assessment tools and educational interventions specific to IL self-efficacy and
knowledge. The following content reviews published survey instruments measuring IL
self-efficacy and IL knowledge. This review explains why the proposed research study
will use the ILSES (Kurbanoğlu et al., 2006) and the Richard Stockton College of New
Jersey Information Literacy Test (Trail et al., 2006) to operationalize IL self-efficacy and
knowledge.
Information Literacy Self-Efficacy Surveys
The literature review revealed only three data-collection tools that measured selfefficacy within the context of IL (Adetoro, Simisaye, & Oyefuga, 2010; Kurbanoğlu et
al., 2006; Pinto, 2010). These tools were developed in Spain (Pinto, 2010, 2011), Nigeria
(Adetoro et al., 2010), and Turkey (Kurbanoğlu et al., 2006). The surveys developed in
Spain and Nigeria did not reflect IL education in the United States. For example, Pinto’s
(2011) survey assessed the ability of respondents to install computer programs and use
statistical programs. These tasks relate to informatics rather than IL. Kurbanoğlu et al.’s
(2006) tool was the only one relating to IL education in the United States.
Validity of surveys. All three survey tools professed to collect valid information
on students’ perceptions of IL self-efficacy (Adetoro et al., 2010; Kurbanoğlu et al.,
2006; Pinto, 2010). Despite this common objective, the surveys operationalized IL selfefficacy differently. These differences raised questions concerning the ability of the

45

surveys to capture robust data that would enhance the instruction of IL to pre-licensure
baccalaureate nursing students in the United States.
For example, Pinto (2010, 2011) discussed how knowledge, skills, and attitudes
relate to IL self-efficacy and IL education. She also referred to Bandura’s (1997)
definition of self-efficacy, but she did not use primary resources to define IL self-efficacy
as it related to her study. Rather, Pinto (2010, 2011) referenced publications such as
Kurbanoğlu et al. (2006) when discussing self-efficacy and how it related to IL education
in Spain and Portugal. Furthermore, Pinto’s (2010, 2011) tool did not provide a basic
definition of self-efficacy for students to use when completing the survey. She listed IL
competencies or abilities and asked participants to use a rating scale to report their levels
of self-efficacy rather than actually measuring IL self-efficacy levels. Because she did
not formally operationalize IL self-efficacy, the participants may have interpreted selfefficacy in diverse ways, which may account for inconsistent findings, particularly in
studies with participants sampled from different population and cultures.
Adetoro, Simisaye, and Oyefuga (2010) also adopted Bandura’s (1997) definition
of self-efficacy for their Self-Efficacy and Information Literacy Questionnaire (SILQ).
An expert psychologist and librarians helped determine the content validity of the SILQ.
Using a rating scale, the SILQ operationalized IL self-efficacy by asking students to rate
their abilities to perform tasks such as providing new ideas, leading groups, completing
academic assignments independently, problem-solving independently, and handling
school assignments. The survey also asked participants to rate perceptions, such as
ability to do work, ability to reason rapidly, success in school activities, obsession with

46

training, applying knowledge, learning, school satisfaction, as well as emotions and stress
related to school attendance.
The article insufficiently described the SILQ (Adetoro et al., 2010). It lacked
critical information on the SILQ, and it was evident the IL-self efficacy questions were
not based on ACRL’s (2000) IL competency standards (ACRL, 2000; Adetoro et al.,
2010). It appears that the survey created by Adetoro et al. (2010) assesses IL selfefficacy by asking questions regarding generic experiences related to completing school
work. The survey does not list any IL skills or proficiencies as defined by the ALA
(1989).
Unlike Pinto (2010, 2011) and Adetoro et al. (2010), Kurbanoğlu et al. (2006)
explained how they used item discrimination indices and a principal component analysis
to validate the ability of their survey, the ILSES, to operationalize IL self-efficacy. Not
only did the validity information show promise, but the face validity of the scale relates
well with the ACRL (2000) IL competency standards. Kurbanoğlu et al. identified items
in the ILSES related to ACRL’s (2000) IL competency standards. Although Kurbanoğlu
et al. did not provide an operational definition of self-efficacy for their tool, they used
Bandura’s (1997) definition of self-efficacy to develop the ILSES. The ILSES instructs
participants to rate their confidence in completing IL-related tasks. This method provides
a simple way for the survey users to interpret the questions and yields consistent data
related to IL self-efficacy.
Utility of self-efficacy surveys. While all three surveys address self-efficacy in
relation to IL, they were created for Turkish (Kurbanoğlu et al., 2006), Spanish (Pinto,
2010, 2011), and Nigerian (Adetoro et al., 2010) cultures. Only Kurbanoğlu et al. (2006)

47

adopted ALA’s (1989) definition of IL and ACRL’s (2000) IL competencies as a basis
for their self-efficacy scale, as evidenced in the structure and content of the survey.
Kurbanoğlu et al. (2006) categorized their survey items by IL tasks.
Published research illustrates how the ILSES was used to compile and analyze IL
self-efficacy data (Akkoyunlu & Yilmaz, 2011; Demiralay & Karadeniz, 2010; Erdem,
2007; Geçer, 2012; Kiliç-Çakmak, 2010; Stokes & Urquhart, 2011; Tuncer, 2013;
Yilmaz, 2008). Only one study used the ILSES with a nursing student population (Stokes
& Urquhart, 2011). The other studies investigated IL self-efficacy in undergraduate
student teachers (Demiralay & Karadeniz, 2010; Erdem, 2007; Tuncer, 2013; Yilmaz,
2008).
Contrary to the ILSES, Pinto’s (2010, 2011) and Adetoro et al.’s (2010) surveys
were used solely in their own work. The lack of research using these tools severely
constrained the comparison of reliability statistics for each tool. Research conducted by
Geçer (2012) and Tuncer (2013) reported ILSES Cronbach alpha levels of 0.87 and
0.861, respectively. These findings support the reliability of this survey for measuring IL
self-efficacy and the use of the ILSES for this research project.
Reliability of the ILSES. Internal consistency for the ILSES has been assessed
using Cronbach’s alpha. Polit and Beck (2012) described internal consistency as the
ability to measure the same trait. The ILSES had a Cronbach alpha level of 0.91 for the
28-item English scale (Kurbanoğlu et al., 2006). According to Pallant (2010), the ILSES
reported excellent internal consistency. Cronbach’s alpha values above 0.80 are usually
preferred (Pallant, 2010). Kurbanoğlu and colleagues (2006) also demonstrated that both
the ILSES 28-item English scale (r = .91) and 17-item English scale (r = 0.81) performed

48

consistently. None of the research using the ILSES reported any test-retest reliability
data. Consequently, the literature review could not establish the ability of the ILSES to
perform consistently over time (Polit & Beck, 2012).
Information Literacy Knowledge Surveys
This section discusses surveys used to assess student IL knowledge. It reviews
standardized surveys and IL questionnaires created for specific research projects. The
discussion concludes by reviewing how the knowledge surveys compare to concepts in
EBP.
Standardized information literacy knowledge-assessment tools. The literature
review revealed two standardized IL knowledge-assessment tests used in higher
education. These tests are the Information Literacy Test (ILT) and the Standardized
Assessment of Information Literacy Skills (SAILS). Researchers at James Madison
University (JMU) developed the ILT, and researchers at Kent State University developed
the SAILS (Kent State University, 2014a; Madison Assessment, 2013a). Both
assessments use a multiple-choice format and can be delivered electronically (Kent State
University, 2014a; Madison Assessment, 2013a). Although both assessments were
created according to ACRL’s (2000) IL competency standards, performance indicators,
and outcomes; neither test assesses the fourth IL competency standard (Madison
Assessment, 2013a; Radcliff, Salem, O’Connor, & Gedeon, 2007). The fourth
competency standard requires students to perform tasks that involve reflection,
journaling, communication, and the incorporation of design principles (ACRL, 2000). A
mulitiple-choice test cannot objectively measure these tasks.

49

The creators of the SAILS used item response theory to create a bank of test
questions varying in difficulty level (Kent State University, 2014e). Kent State
University researchers did not indicate how many questions were in the item bank but
claimed higher education faculty can use the individual score tests to assess student
outcomes and they can use the cohort test to measure institutional benchmarks. While
institutions can use the ILT for individual student or program assessment, the school’s
Web site only lists one version of the Madison assessment (2013a).
Utility of the ILT and the SAILS. Both the ILT and the SAILS demonstrated
good reliability and validity for assessing IL knowledge (Cameron, Wise, & Lottridge,
2007; Kent State University, 2012). However, both tests incur costs for administration
and require a significant amount of time for students to complete. To administer these
tests, institutions must pay $8.00 per student per test for the ILT (Madison Assessment,
2013b) and $6.00 per student per test for the SAILS (Kent State University, 2014b).
While these costs initially appear nominal, they can escalate readily and potentially
constrain departmental and institutional budgets.
The ILT, a 65-item test, requires approximately 75 minutes to complete (Wise,
Cameron, Yang, & Davis, 2009). Kent State University’s Web site (2014a, 2014b,
2014c, 2014d) claims the 55-item individual SAILS test takes approximately 45 minutes
to complete and that the 45-item cohort test takes approximately 35 minutes to complete.
However, personal communication with librarians indicated some students require up to
60 minutes when completing the SAILS. The costs associated with test administration
and the time students need to complete the ILT or the SAILS made both of these tools
impractical for use in this research project.

50

Information literacy questionnaires created for specific research projects.
The following content reviews five IL tests created for use in specific research projects.
These five instruments assess student knowledge of IL skills and activities (Courey et al.,
2006; Jacobsen & Andenæs, 2011; Ku et al., 2007; Trail et al., 2006; Wallace et al.,
2000). While each of these tools had items that assessed knowledge, not all measure
objective knowledge-based data. Questionnaires created by Courey et al. (2006),
Jacobsen and Andenæs (2011), Wallace et al. (2000), and Ku et al. (2007) used Likert
scale responses requiring students to provide a self-evaluation of their IL skills.
Data reflecting students’ self-reports could skew the data. Gross and Latham
(2011b) found undergraduate students with below-proficient IL scores enrolled in entrylevel English courses overestimated their IL knowledge. Using two subject populations,
Gross and Latham administered the ILT at two schools. Students in school 1 anticipated
an average ILT score of 75.43%, but actually scored 43.13% on average. Similarly,
students in school 2 anticipated an ILT score of 77.56%, but earned 49.39%. Because of
the discrepancies, the present researcher did not use the surveys created by Courey et al.
(2006), Jacobsen and Andenæs (2011), Wallace et al. (2000), and Ku et al. (2007).
Furthermore, these surveys only focus on a few specific IL-related tasks.
In contrast, the Richard Stockton College of New Jersey Information Literacy
Test, created by Trail et al. (2006), measures undergraduates students’ IL knowledge
according to ACRL’s (2000) IL-competency standards. Tables 2 and 3 illustrate the
comparisons made among these five surveys.

51

Table 2
Comparison of Question Objectives in Information Literacy Surveys Used to Assess Pedagogical
Interventions
Courey et al.
(2006)

Jacobsen and Andenæs (2011)

Wallace et al.
(2000)

Ku et al.
(2007)

Trail et
al. (2006)

Type of
Survey
Items

4-point Likert
scale

Five
multiplechoice
questions
measuring
knowledge

Dichotomous
or Likert scale
(5- or 7-point
scale)

Assumed to be
5-point Likert
scale items
(based on
presentation of
results)

10-point
Likert scale
items

Multiplechoice
test

Number
of
Survey
Items

22

5

18

Not reported

23

26

Recognize
and access
nursing
journals and
articles from
library
resources

Boolean
operators
and
truncation

Only stated
that questions
measured
student selfassessment of
IL capabilities

Use of and
response to
commands in
the library
catalog

Searching
and
screening

Know where
and how to
access
professional
nursing
journals and
articles from
the Internet

Identify
appropriate
databases
for finding a
book and a
white paper

Selecting
appropriate
sources for
information

Information
integration

Know the
difference
between a
professional
nursing
website and
general
websites

Know the
difference
between
“open” and
“closed”
Internet

Locating a
journal article
related to a
specific topic

Information
analysis

Use of
bibliographic
citations to
locate and
retrieve
articles

Application
and
presentation

Question Objectives

52

Table 3
Comparison of Evidence-Based Practice, IL Competency Standards, and Questions in Knowledge Test
Steps in EvidenceBased Practice

ACRL IL Competency Standards

Question in IL Knowledge
Test

Ask the Clinical
Question

Know when information is needed.

2, 4, 5, 6, 7, 8, 9, 11, 16

Search for the Best
Evidence

Demonstrate the ability to access the needed
information through activities such as database
searches.

1, 3, 8, 9, 10, 11, 13, 14,
15, 16, 17, 18, 19, 21, 22

Critically Appraise the
Evidence

Evaluate all information obtained and determine
what information is pertinent to the identified
need.

4

Address the
Sufficiency of the
Evidence

Proficiently use the information in the task that
precipitated the need to gather information.

12, 20, 23, 24, 25

Use the new information according to legal and
ethical standards.

Evaluate the Outcome
(ACRL, 2000; Fineout-Overholt & Melnyk, 2005; Trail et al., 2006).

The literature review failed to produce a single study reporting reliability data for
the Richard Stockton College of New Jersey Information Literacy Test (Trail et al.,
2006). However, the benefits of using this survey outweigh the lack of reliability data.
First, participants can complete the survey in a reasonable amount of time. Unlike the
ILT and the SAILS, the Richard Stockton College of New Jersey Information Literacy
Test (Trail et al., 2006) has only 26 multiple-choice questions. Second, the Richard
Stockton College of New Jersey Information Literacy Test (Trail et al., 2006) does not
charge any licensing fees. Like the ILT and the SAILS, this survey assesses knowledge
on four of the five ACRL’s (2000) competency standards.

53

The literature review examined three tools measuring IL self-efficacy. Of these,
only one, the ILSES, correlated with ACRL’s (2000) competency standards. Unlike the
other two IL self-efficacy scales, several studies have use the ILSES and it has
demonstrated consistent reliability. Therefore, this study uses the ILSES to
operationalize IL self-efficacy.
Two standardized IL proficiency tests, the ILT and the SAILS, have demonstrated
good validity and reliability in measuring IL knowledge but take too long to complete.
The time needed and costs incurred to use these tests created major concerns for use in
this study. The analysis of other tools used in IL research revealed only one test that
objectively measured IL knowledge in relation to ACRL’s (2000) competency standards.
This tool, the Richard Stockton College of New Jersey Information Literacy Test (Trail et
al., 2006), has significantly fewer questions than the ILT and the SAILS and would not
incur any costs for administration. Therefore, due to its practical utility, this study used
the Richard Stockton College of New Jersey Information Literacy Test (Trail et al., 2006)
to operationalize IL proficiency.
Conceptual Framework
Heider (1958) introduced attribution theory, believing any action or event was the
consequence of a particular trigger or cause. He proposed that people’s perceptions,
beliefs, and interpretations about events acted as triggers and would dictate behavior. In
other words, people’s perceptions, even if incorrect, determine how they act in a given
situation. Building on Heider, scholars such as Weiner (2008) and Jones et al. (1972)
introduced attribution theory to mainstream psychology. They introduced new constructs

54

further explaining how attributions (perceptions or beliefs) shape behavior. Examples of
these constructs include verb causality and causal dimensions.
Attributional Theory of Motivation and Emotion
In 1986, Weiner introduced his attributional theory of motivation and emotion. In
this theory, Weiner asserted that a motivational theory must acknowledge principles
beyond homeostasis and hedonism. The premise of his theory integrates conscious
experience, inclusion of the self, acknowledgment of emotions, and sequential (historical)
causal relations. Weiner believed that an attributional theory of motivation must stem
from general laws accounting for rational and irrational actions. These laws needed to
explain strivings for achievement and affiliative goals (Weiner, 1986).
Weiner’s (1985, 1986, 2006, 2010) attributional theory of achievement aimed to
explain motivation by crediting behavior to causality. He identified the three dimensions
of causality as locus of control, stability, and controllability (Weiner, 1985, 1986, 2006,
2010). This theory assumed a behavior must be observed or perceived, be determined to
be intentional, and be attributed to internal or external causes (Weiner, 1986). In this
theory, an attribution is defined as a perceived cause or antecedent to a specific behavior
(Weiner, 1985, 1986, 2006, 2010).
This theory focuses on intrapersonal and interpersonal attributes. Intrapersonal
attributes include achievement strivings and thoughts and emotions concerning the self
(Weiner, 1986, 2006). The intrapersonal aspect of this theory assumes actions are based
on behaviors that will benefit the self, such as striving for success (Weiner, 1986, 2006).
Interpersonal attributes address social phenomena, such as compliance (Weiner, 1986,
2006). Weiner stated that interpersonal attributes motivate behaviors that focus on others

55

(Weiner, 1986, 2006). For example, the social status associated with high grades could
motivate a student to use IL skills in academic assignments.
Causal beliefs represented a fundamental aspect of Weiner’s (1986, 2006) theory.
Weiner (1986, 2006) defined causal beliefs as a person’s perceptions of an event. These
perceptions include self-image, experience, and emotions (Weiner, 1986, 2006). Weiner
(1986, 2006) called these perceptions causal beliefs because they act as antecedents to
specific behaviors. Self-efficacy is a causal belief or a person’s perception of his or her
ability to engage effectively in a behavior or event. Positive self-efficacy, then, could act
as an antecedent for using IL skills, while, conversely, negative self-efficacy could
prevent a student from engaging in IL-related behaviors.
Phenomenal causality. Weiner further expanded causal beliefs in terms of
phenomenal causality (Weiner, 1985, 1986, 2011). Phenomenal causality is the lived
experience of associating a particular situation with specific outcomes (Weiner, 2011).
Individuals generate distinct positive or negative emotions with phenomenal causality
(Weiner, 1985, 2011). They, then, transfer these positive or negative emotions to the
specific behavior resulting from the phenomenal causality, the effect causality (Weiner,
1985, 2011). Consequently, these outcome-generated emotions can act as stimuli or
deterrents for performing a particular behavior causality (Weiner, 1985, 2011). Further,
these outcome-generated emotions can shape a person’s self-efficacy with regard to a
particular behavior or event. For instance, students who received good grades on formal
writing assignments may have a higher propensity to use their IL skills in nursing
assignments, such as formal nursing care plans.

56

Duncan and Holtslander’s (2012) grounded theory research, conducted in Canada,
exemplifies the effect of phenomenal causality. While the researchers focused on the
process that students used to find and retrieve information, results indicated that students
felt frustrated when conducting literature reviews. This frustration acted as an attribution
and created a negative feedback loop. Students who experienced frustration picked easy
topics for their assignments so that they could avoid using IL skills (Duncan &
Holtslander, 2012). In this case, emotions related to frustration acted as motivators for
avoiding the use of IL skills.
Weiner (1986) used luck to illustrate phenomenal causality. He explained that
luck, an external causal attribution -- that is, a concept outside of a person’s control -may cause a behavior to result in either a positive or negative outcome (Weiner, 1986).
The following example illustrates how a student could use luck to justify particular
behaviors. A student who receives a poor grade on a formal writing assignment could
correlate the low grade to bad luck (an external causal attribution) instead of poor writing
skills (an internal causal attribution). The student’s belief that bad luck caused the low
grade could act as a motivator for not seeking help to complete future writing
assignments.
Three dimensions of causality. Weiner (1985, 1986) explained how locus of
control, stability, and controllability, shape behavior and objectives. Ability, effort,
difficulty of task, and luck can determine whether goals are achieved (Weiner, 1985,
1986, 2006, 2010). Luck could be measured as a success or failure unrelated to a
person’s actions. Weiner (2010) stated that ability, effort, difficulty of task, and luck
shape the success or failure of a given intentional behavior. These four constructs shape

57

an individual’s locus of causality, sense of stability, and sense of controllability (Weiner,
2010). Increased stability of an event and increased control over the event could act as
motivators for engaging in a behavior associated with an event. Thus, clear expectations
fostered by a grading rubric and access to library resources may increase a student’s
motivation to use IL skills when completing assignments related to nursing care.
Locus and control should not be interpreted as locus of control. Locus of control
is a general belief of where control comes from (Rotter, 1966, 1990). While locus of
control is outside the scope of this research project, Rotter’s research on this domain
specific variable led to the creation of domain specific measures -- locus and control -that Weiner (2010) used in his attribution theory. Weiner (2010) used these domainspecific measures to represent how the past can affect the future.
Locus concerns attributions related to self-image and emotion (i.e., self-efficacy)
while control deals with the amount of direct influence a person has over a situation
(Weiner, 1985, 1986, 2006, 2010). A person’s self-image and emotions associated with
past behaviors can either encourage or discourage him or her from engaging in the same
behaviors later. Furthermore, a person is more likely to engage in a behavior if they
perceive the situation is under his or her control (Rotter, 1966, 1990; Weiner, 2010).
Figure 3 demonstrates how these dimensions of causality affects a person’s choice to
engage in a particular behavior.

58

Figure 3. The three dimensions of causality and behavior engagement (Weiner, 1986).
Locus and causality. Locus of causality can be internal or external. Internal
locus of causality centers on a person’s ability to perform a behavior and the effort that a
person expends, while external locus of causality involves task difficulty and luck
(Weiner, 1985, 1986, 2006, 2010). Weiner (2010) associated internal locus of causality
with a strong sense of personal ability, a sense of stability, and controllability. He
associated external locus of causality with difficulty of task and luck because these two
constructs can create an unstable, uncontrollable situation (Weiner, 2010). For example,
students can attribute a bad grade on a test to a teacher. They may say the teacher
focuses on irrelevant material, and therefore, their ability to earn a good grade is outside
of their control. Therefore, success can be associated with internal locus of causality, a
strong sense of personal ability, and exertion of effort. Failure is usually accompanied by
external locus of causality, the perception of task difficulty, and luck. In this theory, luck
could be considered a random success or failure unrelated to a person’s actions.
Stability. While locus of control centers on a person’s ability, stability refers to
changes over time (Weiner, 1986). When assessing stability, a person evaluates the
59

probability of phenomenal causality changing over time. Weiner (1985, 1986, 2006,
2010) discussed a stable-unstable continuum in which stable, unchanging conditions
motivate people to repeat past behaviors to achieve previous outcomes. Weiner (1976,
1985, 1986) asserted that some internal causes remain stable while others constantly
fluctuate. This dimension of causality related to the expectancy of success or failure
(Weiner, 1976, 1985, 1986). Aptitude can act as a stable antecedent (Weiner, 1986). If a
student perceives that he or she has the aptitude to use references accurately in an
assignment, the student places emphasis on a factor within his or her locus of control,
such as finding appropriate references.
The student’s perceptions of stability, in relation to aptitude, can then influence
his or her expectations of success or failure. These perceptions of stability form from
past behavior, particularly the successes and social support associated with these
behaviors. For example, a student who has a high self-efficacy in relation to writing may
spend more time writing a paper and incorporating references than a student who feels as
if he or she is a poor writer. Because self-efficacy is primarily based on the mastery of
past experiences, the student who has low self-efficacy as a writer could think that he or
she will perform poorly on the writing assignment even if he or she has several pages of
references. Therefore, the student with low IL self-efficacy may not engage in IL
behaviors. Low self-efficacy can lead to a self-fulfilling prophecy.
Controllability. Controllability relates to the actual level of control a person has
over a situation or the phenomenal causality (Weiner, 1986). Control refers to both
internal and external attributes. Internal facets of control relate to constructs such as
writing aptitude and physical fatigue (Weiner, 1985, 1986). External aspects of control

60

relate to phenomena, such as availability of resources or luck. These examples provide
an easy-to-understand illustration of the dimension of control while also illustrating how
it relates to the other two dimensions: locus and stability (Figure 4).

Figure 4. The interrelationship between the three dimensions of causality (Weiner, 1985,
1986).
Self-Efficacy as an Attribution
Self-efficacy -- individuals’ beliefs about their abilities for successful
performance in specific situations (Bandura, 1986, 1997) -- functions as an attribution
due to its relationship to the dimensions of locus and control (Weiner, 1976, 1985, 1986).
Bandura (1986, 1997) stated that self-efficacy can change, depending on the situation and
the outcomes. Therefore, self-efficacy can be interpreted as an unstable attribution for
motivation. Depending on a person’s outlook, self-efficacy can shape his or her
phenomenal causality, the lived experience leading to assigning a behavior as good or
bad. This perception has the capability to motivate a person to engage in or avoid a
behavior. For example, students may believe that they could not satisfactorily complete
an assignment because they have never earned a good grade in the past. Consequently,
these students may spend little time on the assignment because they believe that the grade
61

is predetermined. However, another group of students who may have historically
received high grades on this particular assignment and are motivated to get on the dean’s
list, may persevere in completing the assignment despite their inability to access library
resources. The experiences of these students may have played a key part in their high
self-efficacy levels and their ability to complete the assignment despite the inability to
access school resources.
Self-efficacy can function as an attribution due to its relationship to the
dimensions of locus and control. High self-efficacy levels may help students attribute
success in IL related assignments with internal attributions such as intelligence and
perseverance. The ability to attribute success to internal attributions may then help the
students perceive an increased sense of control over the use of IL skills in school
assignments and nursing practice. By contrast, low self-efficacy could induce a student
to attribute low grades to attributes such as luck. These students would perceive that they
had no control over their grades. Self-efficacy can shape phenomenal causality -- the
lived experience leading to a behavior -- by altering the perception of the situation. As in
the previous example, self-efficacy can act as a facilitator for either giving up or
persevering, despite the presence of many obstacles (Bandura, 1977, 2012; Weiner, 1985,
2006). Therefore, self-efficacy, as an attribution, may help clarify why pre-licensure
nursing students abandon or persevere in the use of IL skills when completing
assignments.
Quantitative research investigating IL self-efficacy levels has produced
conflicting results (Geçer, 2012; Stokes & Urquhart, 2011). Stokes and Urquhart (2011)
used the ILSES (Kurbanoğlu et al., 2006) and the Approaches to Study Skills Inventory

62

for Student (ASSIST; Entwistle, 1997) to investigate the impact of relationships between
personality, IL self-efficacy, and learning styles. Stokes and Urquhart (2011) failed to
find any statistically significant relationships between self-efficacy (as measured by the
ILSES) and grade level in higher education (2[9, N = 194] = 0.28, p = .99) or between
self-efficacy and learning style (2[3, N = 194] = 8.68, p = .034). Contrary to these
results, Geçer’s (2012) found a statistically significant relationship between self-efficacy
(as measured by the ILSES) and grade level (F[3, 699] = 3.25, p < .05).
These conflicting results may have been due to the differences in the study
populations and the participants’ age ranges. Stokes and Urquhart (2011) studied nursing
students who were enrolled in undergraduate level courses, continuing education courses,
and master’s level courses. Geçer (2012) surveyed prospective teachers who were
between the ages of 18 and 26. Geçer (2012) found a statistically significant relationship
between IL self-efficacy levels and computer-use levels (F[2, 700] = 24.58, p < .001).
Therefore, one may question if attitudes related to age, given a varied group, could have
contributed to the conflicting results because research has indicated age could alter one’s
perceptions regarding computer technology (Kutluca, 2010; Reed, Doty, & May, 2005).
Using the computer attitudes scale, Kutluca (2010) found a statistically significant
difference in attitude scores (t[170] = 13.308, p < .001) between teachers aged 34 or less
and teachers aged 35 years and older. Younger participants reported more positive
attitudes as measured by the scale (Kutluca, 2010).
Information literacy self-efficacy has been related to learning (Stokes & Urquhart,
2011). Students who reported advanced self-efficacy had odds ratios of over 1.5 of
having a deep-learning style (Stokes & Urquhart, 2011). The researchers reported how

63

students with higher self-efficacy levels had a better chance of conducting tasks, such as
problem definition, identifying keywords, and using keywords (Stokes & Urquhart,
2011). Although this research did not investigate causality, it is possible self-efficacy
motivated self-regulated learning. Tuncer (2013), suggested that IL self-efficacy
positively impacted scientific research self-efficacy (β = 0.54; p = .001). The IOM
(2011b) stated that life-long learning is vital for competent practice, and the ACRL
(2000) asserted that IL is vital for life-long learning.
Pinto (2011) also found a statistically significant relationship between selfefficacy and motivation within the context of IL. Pinto conducted two-tailed t-tests on 26
corresponding motivation and self-efficacy concepts related to IL. Students rated their
motivation and self-efficacy on IL concepts such as knowing information search
strategies, using electronic sources for accessing primary information, and knowing the
laws on the use of information. Students ranked their levels of motivation and selfefficacy by using a five-point scale, with “one” representing low levels of motivation or
self-efficacy and “five” indicating high levels of motivation or self-efficacy. Pinto
(2011) asserted that a relationship exists between reported self-efficacy and motivation
for these IL concepts because the data analysis yielded statistically significant p values (p
< .001) for reported motivation and self-efficacy levels on all 26 items. While the t-tests
supported the connection between reported self-efficacy and motivation, the researcher
did not perform any additional inferential testing to determine the predictive value of
self-efficacy on motivation. The data-collection tool constituted a major limitation to this
study.

64

Weiner (1976, 1985, 1986) asserted that attributions serve as motivators for
behaviors. He defined attributions as perceptions or beliefs that shape a person’s
behavior. These attributions have a three-dimensional taxonomy: (a) locus of attribution,
(b) control of attribution, and (c) stability of attribution (Weiner, 1985, 1986). While the
locus of a motivating perception could be internal (e.g., commitment) or external (e.g.,
luck), internal motivators have been associated with successful outcomes (Weiner, 1985,
1986). Increased control and stability of an attribution have also been associated with
successful outcomes (Weiner, 1985, 1986).
Self-efficacy -- a person’s belief in his or her performance in a specific situations
(Bandura, 1986, 1997) -- can act as a motivator for engaging in particular behaviors.
Self-efficacy encompasses the dimensions of locus and control in Weiner’s (1976, 1985,
1986, 2006) attributional theory of motivation because it incorporates self-rated ability
with controllability of situations. Self-efficacy can provide motivation for performing a
task while the absence of self-efficacy can act as a deterrent for performing a behavior.
Therefore, the evaluation of IL self-efficacy in relation to IL knowledge may help explain
why undergraduate pre-licensure nursing students choose to engage in or avoid IL related
activities.
Gaps in Research Related to IL Self-Efficacy and Motivation Theory
While the published research provides valuable information on IL self-efficacy,
none of these studies were performed in the United States. As previously suggested,
cultural differences may impact views of nursing practice, IL education, and IL selfefficacy. Something as simple as access to the Internet or word-processing software

65

could change the way a person answers a self-efficacy questionnaire. These items are
often taken for granted in the United States.
The majority of research assessing self-efficacy, as measured by the ILSES, was
conducted on undergraduate student teachers. Information literacy may have different
connotations and meanings for student teachers than for pre-licensure undergraduate
student nurses. The assessment of IL self-efficacy in student nurses may help educators
to individualize pedagogical interventions that promote student success and positive
associations with IL. Positive experiences with IL may help students form attitudes and
values that foster their ability to connect IL, EBP, and competent practice (Krathwohl et
al., 1964).
Chapter Summary
The literature review reveals many interesting trends in IL education. First, it
highlights the importance of technology in IL education. The rapid pace of technology
advancements can help students with information-seeking behaviors but may also act as a
barrier to engaging in IL behaviors. For example, students reported information overload
and expressed how this experience created feelings of frustration.
Second, the literature review revealed that most students did not know the
definition of IL. Students must have good information on the definition and use of IL to
engage in EBP. The collection of baseline knowledge data on IL can help educators
effectively plan and deliver nursing education. Third, the majority of empirical IL
evidence in nursing education focused on the ability to access information. In addition to
accessing information, nursing students must be able to summarize, synthesize, apply,
and use information effectively to engage in EBP.

66

The conceptual framework for this study, Weiner’s (1985, 1986) attributional
theory of motivation, can explain how IL self-efficacy can act as a stimulus either to
participate in or to avoid IL-related behavior. Self-efficacy, a person’s belief concerning
his or her performance in specific situations (Bandura, 1986, 1997), can act as a
motivator for engaging in IL behaviors. The evaluation of IL self-efficacy in relation to
IL knowledge may help explain why undergraduate, pre-licensure nursing students
choose to engage in or avoid IL related activities.
Only one IL study used a population of American student nurses. All other ILspecific studies investigating either IL in nursing education or IL self-efficacy occurred in
Middle Eastern or European countries. Cultural and socioeconomic differences could
limit the generalizability of these study findings to student nurses in the United States.
Research relating IL knowledge and self-efficacy in American nursing students is
necessary before researchers can assess how they compare to nursing students in other
countries.
Based upon the literature review, this study used Kurbanoğlu et al.’s (2006)
ILSES and the Richard Stockton College of New Jersey Information Literacy Test (Trail
et al., 2006) to operationalize IL self-efficacy and IL proficiency. Both of these
instruments relate well to ACRL’s (2000) competency standards. Additionally, these
surveys have practical utility as they do not have any licensure fees and can be completed
in less than 10 minutes.

67

CHAPTER THREE
METHODOLOGY
This chapter on methodology begins by reviewing the purpose and design of the
study, the setting, the sample, and the data collection tools. The chapter ends by
outlining the procedures and data analysis.
Design
This quantitative correlational study analyzed the relationship between IL selfefficacy and IL knowledge to determine if an empirical relationship existed between
these two variables. The researcher did not intend the study to determine causality and
consequently chose a descriptive correlational design. If a relationship emerged between
these two variables, the researcher would conduct a multiple regression analysis to assess
the ability of IL self-efficacy to predict for IL knowledge.
Correlational research efficiently allowed collection and analysis of a large
amount of data, so it permitted easy replication of the study on large populations of senior
nursing students. The ease of replication may entice nursing schools to use this protocol
for collecting IL-related program outcomes.
Setting and Study Sample
The researcher conducted the study in Pennsylvania schools of higher education
that provide pre-licensure baccalaureate nursing education. The study population
consisted of senior pre-licensure baccalaureate nursing students because they have
foundational knowledge related to IL and nursing practice. The researcher recruited a
convenience sample from baccalaureate pre-licensure programs located at Wilkes
University, Carlow University, Drexel University, Indiana University of Pennsylvania

68

(IUP), Mansfield University, Pennsylvania State University (PSU), and Saint Francis
University (SFU), all located in Pennsylvania. Full- and part-time nursing students with
English proficiency were eligible to participate in this study.
Prior to study implementation, the investigator conducted a pilot test to determine
the reliability of the data-collection tools in a population of pre-licensure baccalaureate
senior nursing students. Nineteen students completed the pilot test. Favorable results
indicated that ILSES demonstrated internal consistency (Cronbach’s alpha > .80; Polit &
Beck, 2012) and stability (r > .50; Cohen, 1988). The pilot study also demonstrated that
the Richard Stockton College of New Jersey Information Literacy Test demonstrated
stability when used in a population of senior nursing students. Chapter 4 contains
detailed information regarding the data analysis for the pilot study. The study’s data
analysis did not include data collected during the pilot test.
The literature review failed to identify any relevant studies focusing on IL selfefficacy and knowledge. Because of the lack of data and information, a conventional
medium effect (ƒ2 = .13), as recommended by Polit and Beck (2012), was used to conduct
a power analysis for two hierarchical multiple regression models. Polit and Beck (2012)
stated that most nursing studies have modest effects.
The multiple regression models contained three predictors: IL self-efficacy scores,
gender, and self-reported GPAs. Using an online a priori sample size calculator for
multiple regression (Soper, 2013), this researcher determined that a minimum sample size
of 88 was necessary to detect a medium effect size with high probability (power = .80).
The power analysis used a power of .80 and a probability level of .05 to limit the

69

probability of committing a Type II error to 20% and a Type I error to 5%. This study
recruited 137 participants to help ensure 88 complete datasets.
Data-Collection Tools
As previously discussed, IL self-efficacy was measured with the ILSES 28-item
and 17-item scales (Kurbanoğlu et al., 2006) and the Richard Stockton College of New
Jersey Information Literacy Test (Trail et al., 2006). This study used the ILSES as
published in 2006. However, the Richard Stockton College of New Jersey Information
Literacy Test (Trail et al., 2006) used in this study had minor modifications of the
original test (Trail et al., 2005; M. A. Trail, personal communication, March 25, 2013).
The following sections discuss the collection of demographic data and background
information on the development, validity, and reliability of the data collection tools.
Demographics
The study collected demographic information in seven areas: age, gender, race,
ethnicity, self-reported GPA, enrollment status (full- or part-time), and institution of
attendance. Full-time enrollment status required students to be enrolled in 12 or more
credits at the time of data collection. Part-time students were enrolled in three to 11
credits. The researcher used this information to identify trends regarding self-efficacy or
knowledge related to age, race, ethnicity, GPA, and attendance status. To maintain
participant confidentiality, the researcher used self-reported GPAs rather than the official
GPA on the students’ transcripts. Although self-reported GPAs may not have been as
accurate as GPAs retrieved from student files, the use of self-reported data maintained
anonymity of the participants. Participants provided demographic information after they
completed the ILSES and IL knowledge test.

70

The Information Literacy Self-Efficacy Scale
Kurbanoğlu et al. (2006) developed the ILSES to measure self-efficacy within the
context of IL. These researchers based the ILSES on Bandura’s (1986, 1997) definition
of self-efficacy. Kurbanoğlu et al. (2006) believes that students’ tendencies to use IL
skills depend on their beliefs in their abilities rather than on their knowledge and
competency levels. Appendix B contains letters of permission to use the ILSES
(Kurbanoğlu et al., 2006).
The ILSES contained 28 items that required participants to rate their confidence
and competence in conducting IL tasks. Responses on the seven-point Likert scale
ranged from “1” being “almost never true” to “7” being “almost always true.”
Information literacy skills assessed on this scale included defining needed information,
determining where to find information, using library resources, using the Internet,
evaluating Internet sites, making citations, and preparing a bibliography. The authors
categorized the 28 items according to the following subscales (Kurbanoğlu et al., 2006).
Appendix A contains the complete ILSES scale.
A. Define the need for information;
B. Initiating the search strategy;
C. Locating and accessing the resources;
D. Accessing and comprehending information; interpreting;
E. Synthesizing and using information;
F. Communicating information; and
G. Evaluating the product and process.

71

Creation of the ILSES. The researchers developed this survey in five phases.
The survey, originally written in Turkish, was later translated into English in the final
phase of its development (Kurbanoğlu et al., 2006). The following information
summarizes the five phases and illustrates the development and evolution of the tool.
Phase one. During the first phase, Kurbanoğlu et al. (2006) developed 40 Likertscale questions from IL standards created by the American Association of School
Librarians and Association for Educational Communications and Technology (1998),
ACRL (2000), the Society of College, National, and University Libraries (2004), and the
Australian and New Zealand Institute for Information Literacy (2004). Kurbanoğlu et al.
calculated a Cronbach’s alpha of 0.84 for the initial 40 items through field-testing with
teachers from public and private schools (N = 374).
Phase two. The second phase of tool development entailed an item analysis.
After calculating item discrimination indices for each of the 40 items, Kurbanoğlu et al.
(2006) eliminated 12 items that had indices fewer than 0.20. After the deletion of these
12 items, the item validity for the remaining questions increased to 0.48 and Cronbach’s
alpha rose from 0.84 to 0.92 (Kurbanoğlu et al., 2006).
Phase three. The researchers conducted a factor analysis on the 28-item scale in
phase three. Kurbanoğlu et al. (2006) conducted a principal component factor analysis
along with a Varimax rotation. Items with an eigenvalues over 1.5 revealed three main
item clusters, or components, that accounted for the majority of the variation
(Kurbanoğlu et al., 2006). Component 1 focused on items related to defining, selecting,
interpreting, and communicating information and learning from experience (Kurbanoğlu
et al., 2006). The researchers labeled the skills associated with component 1 as

72

Intermediate IL Skills (Kurbanoğlu et al., 2006). Component 2, Basic IL Skills, addressed
finding and using information (Kurbanoğlu et al., 2006). Component 3, Advanced IL
Skills, centered on the synthesis and evaluation of information in the problem-solving
process (Kurbanoğlu et al., 2006). Only 17 of the 28 survey items explained the majority
of the variation in the three components.
Phase four. Although the component solution indicated that the scale should
consist of 17 items, discriminant validity statistics obtained in phase four supported the
use of a 28-item and a 17-item survey. Discriminant validity testing can determine that
each questionnaire subscale measures unrelated concepts. Both the 28-item and the 17item scale obtained discriminant validity for the aforementioned subscales ranging from
0.43 to 0.61 and 0.54 to 0.89, respectively. Table 4 outlines the discriminant validity
values for each of the subscales in the 28-item and the 17-item questionnaires.
Kurbanoğlu et al. (2006) did not report an r value for the B subscale for the 17-item
scale. Kurbanoğlu et al. (2006) stated that the 28-item and the 17-item scales adequately
assess IL self-efficacy.
Table 4
Discriminant Validity for ILSES-28 and ILSES-17.
Subscales
A

B

C

D

E

F

G

ILSES 28-item

.47

.57

.56

.46

.58

.61

.43

ILSES 17-item

.52

.72

.54

.60

.89

.57

(Kurbanoğlu et al., 2006)

Phase five. In phase five, Kurbanoğlu et al. (2006) translated the ILSES to
English and conducted reliability tests comparing the Turkish and English versions of the
73

survey. Students (N = 47) from the Department of English Translation and Interpretation
participated in the reliability study. These students completed the test and retest in
Turkish and English for both the 17- and the 28-item scale. The overall Cronbach’s alpha
coefficients were 0.81 and 0.91 for the 17- and the 28-item scales, respectively. It takes
students approximately five minutes to complete the final version of the 28-item scale.
Scoring the ILSES. The ILSES had Likert-scale responses and listed activities
associated with IL. The participants circled or clicked a number between 1 and 7 to
report their confidence in performing these skills. While one represented very little
confidence, seven represented extreme confidence in performing these activities. Table 5
illustrates the numerical label or value for each participant response.

Table 5
Likert Scale Responses in the ILSES
Numerical Label

Participant Perception

1

Almost never true.

2

Usually not true.

3

Infrequently true.

4

Occasionally true.

5

Often true.

6

Usually true.

7

Almost always true.

(Kurbanoğlu et al., 2006)

The numerical value for each response was totaled to determine a composite IL
self-efficacy score. Participants who completed the ILSES received scores ranging from
28 to 196 for the 28-item scale and 17 to 119 for the 17-item scale. As scores increased,
74

so did participant perceptions of IL self-efficacy. Low scores indicated a lack of IL selfefficacy. This study compared results obtained from both the 28-item and the 17-item
ILSES scale.
Richard Stockton College of New Jersey Information Literacy Test
This tool (Appendix C) contained 25 multiple-choice questions measuring student
knowledge of IL. While the test contained six true and false questions, it also required
students to recognize elements from a copyright excerpt and an electronic library catalog
entry. Other questions assessed student knowledge of key words, databases, information
retrieval, scholarly journals, and Internet resources.
Trail et al. (2006) developed this tool to validate the use of a workbook they
created and used as a self-study module in a freshman IL seminar course. The 25question tool operationalized performance indicators and outcomes according to four of
the five IL standards for higher education (ALA, 2000; Trail et al., 2006). This test did
not address the fourth IL proficiency standard, which would have required college
students to use the information proficiently in a task that precipitated the need to gather
information. The test authors chose to exclude standard four from the test because they
believed multiple-choice questions could not adequately assess it.
Reliability and validity. The authors created the Richard Stockton College of
New Jersey Information Literacy Test so that it would measure basic IL skills as outlined
by ACRL’s competency standards (Trail et al., 2006). Trail et al. began creating the test
in 2002. Between 2002 and 2005, the authors revised and tested multiple versions of the
test until they created the final product. The article that contained the 2005 version of the
IL pre- and post-test contained no information concerning the test’s reliability and

75

validity. However, the authors did state that several campus groups helped determine the
content validity of the test (Trail et al., 2006). They also stated that the director of the
Stockton Institute on the Study of College Teaching critiqued multiple drafts of the 2005
IL test (Trail et al., 2006).
Changes made in the test. Since its publication, Trail and Lechner (2012)
revised the tool for use in their IL seminar course and created a new version of the test.
Initially, students took the test using paper and pencil. Now, library science faculty
members administer the test using a PowerPoint presentation requiring students to use
clickers and software such as Turning Point (Trail & Lechner, 2012). The clickers allow
students to answer questions electronically during an interactive polling session. The
current version of the test only has 17 questions, many of which are different from the
original test (Trail & Lechner, 2012). Appendix D contains the current version of the
Richard Stockton College of New Jersey Information Literacy Test. As with the 2005
test, no reliability information is available for the current 17-item test.
Revisions of the test for this study. This study used the 2005 version of the test
with minor revisions. First, the researcher removed any reference to the Richard
Stockton College of New Jersey library. Second, she replaced the question assessing
reasons for citation with the revised question on the 2012 test. The responses on the
newer version were more detailed than those from 2005. Third, the researcher added a
new question from 2012 test assessing knowledge related to credibility of information
retrieved from the Internet. Fourth, the researcher replaced any references to specific
databases or library resources specific to the Richard Stockton College of New Jersey
library with common resources such as (CINAHL), Google, and Wikipedia. Appendix D

76

contains the version of the Richard Stockton College of New Jersey Information Literacy
Test used in this study. It took students approximately 10 to 15 minutes to answer all the
questions on the test listed in Appendix E. Appendix F contains a letter of permission to
use the modified version of the Richard Stockton College of New Jersey Information
Literacy Test (Trail et al., 2006).
Scoring the Richard Stockton College of New Jersey Information Literacy
Test. The test was be scored according to the number of questions each participant
correctly answered. Although the test only has 26 questions, the final question on the
tests requires students to identify two correct answers. Therefore, the scores could range
from 0 to 27.
Study Methodology
The following sections present the methods used for participant recruitment, data
collection, and data analysis for both the pilot test and the research study. After obtaining
approval from the Institutional Review Board (IRB) at IUP, the researcher sent the letter
in Appendix G to the Dean/Chair of the School of Nursing at Wilkes University. She
then sent the letters in Appendix H to the deans/chairs of the nursing departments located
at Drexel University, Mansfield University, Carlow University, Pennsylvania State
University, and Saint Francis University.
Because the ILSES and the Richard Stockton College of New Jersey Information
Literacy Test were developed for administration to a general undergraduate population, a
pilot study was conducted at Wilkes University to determine the reliability of these
surveys in the study population. The pilot study differed from the research project in four
ways. First, the pilot entailed two data collection points, while the research project only

77

required one data collection point. The second collection point allowed the researcher to
assess the reliability of the ILSES and the Richard Stockton College of New Jersey
Information Literacy Test when used in a population of pre-licensure baccalaureate
nursing students.
Second, the pilot study used paper surveys while the research study used
electronic surveys. The researcher administered paper-and-pencil surveys to pilot study
participants to obtain an adequate sample size for the pilot study. Third, the pilot study
required the collection of personal information on completed surveys so that the
researcher can match the test and re-test surveys. The use of the coversheet required the
researcher to assure confidentiality to participants in the pilot study rather than
anonymity. A gatekeeper (faculty member) at Wilkes University verbally explained the
study to potential participants and obtained informed consent from students who wanted
to enter the pilot study. Students who did not provide informed consent did not
participate in the pilot study.
Finally, the gatekeeper at Wilkes University personally recruited pilot study
participants while participants in the research project were recruited through email.
Although no identifying information was collected in the electronic survey, participants
in the research project were assured confidentiality because of the use of their email
address. Study participants did not need to provide any personal identifying information
in the electronic surveys because there was only one data-collection point. The only
identifier on the electronic surveys was the name of the institution where the participants
matriculated. The researcher forwarded the emails in Appendix H to a gatekeeper at
Drexel University, Mansfield University, and Carlow University. The gatekeeper then

78

sent this recruitment email to potential research participants. Participants accessed the
survey through a link in the email.
The remainder of the chapter discusses the methodology of the pilot study and
research project in detail. The following sections present the methods for the pilot study,
participant recruitment for the research project, survey administration, protection of
human rights, and data analysis. The chapter then concludes with a summary of the study
methodology.
Pilot Study
The researcher conducted the pilot study at Wilkes University. Before conducting
any participant recruitment or collecting any data, the researcher obtained IRB approval
at IUP and at the Wilkes University. Wilkes University recognized IUP as IRB of record.
The researcher then recruited 21 students to participate in the pilot study. She used no
flyers or advertisements for participant recruitment. Recruitment procedures began with
program administrators who identified a faculty member who could act as a gatekeeper to
the accessible population. Next, the researcher explained the pilot study methodology to
the gatekeeper through a telephone conversation. After meeting with the faculty member,
the researcher shipped the following items to the specific faculty member at Wilkes
University.


120 blank informed consents



60 blank surveys with a page header “Test”



60 blank surveys with a page header “Retest”
The paper survey contained a cover sheet, the ILSES, the Richard Stockton

College of New Jersey Information Literacy Test, and demographic questions. The

79

students recorded their name and email address on the cover sheet. The researcher used
the coversheets to pair the test and retest surveys. After receiving the package in the
mail, the faculty member obtained informed consent (Appendix I) and administered the
survey two times in a three-week timeframe. The faculty member determined the time
and place to obtain informed consent, administer the test, and administer the retest. The
only limitation on administering the surveys was that the retest was administered three
weeks after administering the test. Although a two-week time frame would have been
ideal to minimize any experiences that could have affected the students’ attitudes,
knowledge, or perceptions towards IL, the tests could only be administered in a threeweek time frame due to spring break.
Pilot study survey administration. First, the researcher shipped through United
Parcel Service (UPS) 100 copies of the informed consents and 60 surveys marked “Test”
to the gatekeeper. The package also contained a prepaid return shipping label. The
researcher shipped these quantities to ensure the faculty member would not run out of
informed consents or paper surveys.
After explaining the study, the faculty member obtained informed consent
(Appendix G) from students wanting to participate in the study. These students received
two copies of the informed consent. They signed one consent and returned it to the
faculty member while they kept a blank consent form for their records.
Once the students submitted a signed consent form, they received a paper survey
with a header containing the word “Test.” When the students completed the surveys,
they returned the paper survey to the Wilkes University faculty member. The faculty

80

member then used the return shipping label to return the signed consents and completed
surveys to the researcher.
The researcher shipped 60 surveys marked as “Retest” in a separate package,
using UPS. The researcher shipped this quantity to ensure the Wilkes faculty member
would not run out of retest surveys. This package also contained a prepaid return
shipping label to streamline the return of the surveys to the researcher.
After a period of 14 to 21 days, the faculty member asked study participants to
complete the survey labeled “Retest.” University events, such as spring break, prohibited
all students from completing the retest in a two-week period. Students returned
completed retest surveys to the faculty member. The faculty member sent the retest
surveys to the researcher through UPS. The researcher kept all completed surveys and
informed consents filed in a locked safe.
After receiving the test and retest surveys, the researcher paired the completed
surveys using the student names on the coversheets. Once paired, the investigator
removed the cover sheets and stapled the surveys together. The researcher coded the
surveys with numerical identifiers after she removed all the coversheets. The researcher
used sequential numbers (1, 2, 3…) as identifiers for the surveys. The initial survey
submissions were identified by adding the letter “a” to the numbers (1a, 2a, 3a…) and the
retest surveys were identified by adding the letter b to the numbering code (1b, 2b, 3b…).
The use of alphanumerical identifiers allowed SPSS to differentiate between the test and
retest. No documentation can link the alphanumeric identifiers to student names. The
researcher could not associate individual responses with specific students.

81

The researcher used the cover sheets of students who submitted both the test and
re-test as entries for a $50 Visa gift card drawing. When the pilot study data collection
was completed, the researcher used cover sheets from any participant who completed the
test and re-test as a drawing entry. The cover sheets were stored in a separate locked file
until the gift card was awarded. The researcher notified the winner via e-mail. The
winner responded within 24 hours to the notification email and included his or her name
and mailing address in the response. The researcher then delivered the gift card to the
winner through the United States Postal Service (USPS) via certified, priority, flat rate
mail. Once the researcher received confirmation from the USPS that it delivered the gift
card, she shredded and disposed of the cover pages using the local waste management
company.
Pilot study data analysis. The pilot study participants submitted their responses
on paper surveys. The researcher entered the data for the surveys into a Qualtrics survey
entitled “Pilot Study.” Once the she entered participants’ submissions into Qualtrics, she
loaded the data directly into SPSS. The researcher then validated the data by cross
validating the original files with the Qualtrics and SPSS database to conduct data
analysis. She used the numbering system discussed in the previous section as identifiers
for the test and retest.
When calculating the score for the ILSES, the researcher totaled the Likert-scale
responses for the 28-item scale and the 17-item scale. Scores for the ILSES 17-item scale
could range from 17 to 119 and scores for the 28-item scale could range from 28 to 196.
The researcher calculated scores for the Richard Stockton College of New Jersey
Information Literacy Test by adding the number of correct answers. Scores for this tool

82

could range from 0 to 27. A correct answer was denoted as a “1” in the SPSS and an
incorrect answer was denoted as a “0.”
Data analysis entailed the calculation of Cronbach’s alpha coefficient and Pearson
Product-Moment Correlation. Cronbach’s alpha coefficient determined the internal
consistency of the items within the ILSES and the Pearson Product-Moment Correlation
determined whether the self-efficacy survey and the knowledge test could consistently
collect reliable data. A Cronbach’s alpha coefficient could not be calculated on the
knowledge test because the questions did not have a consistent response format. The test
contained multiple-choice items, true/false questions, and one “select all that apply”
question. The multiple choice question responses ranged from four to six answers. The
researcher used Skewness values, Kurtosis values, Kolmogorov-Smirnov results, and
Shapiro-Wilk results to test for violations of normality. Q-Q plots and scatter plots tested
the linearity and homoscedasticity of the data, respectively. Finally, the researcher
correlated the scores of the 17-item scale with the scores of the 28-item scale to
determine whether the different scales obtained similar results.
Survey Administration
The researcher administered the surveys electronically with Qualtrics. A
gatekeeper in each traditional baccalaureate nursing program distributed the email in
Appendix J to potential participants. A gatekeeper was defined as administrative or
teaching faculty who worked for Carlow University, Drexel University, IUP, PSU, and
SFU. Initially, the researcher recruited students from Carlow University, Drexel
University, and Mansfield University, as approved in the IRB proposal. Due to a poor

83

response rate, changes of protocol were submitted to and approved by IUP’s IRB to allow
the researcher to recruit students from IUP, PSU, and SFU.
Each individual school of nursing identified the gatekeepers. The researcher
forwarded the emails in Appendix J to each gatekeeper. The gatekeeper then forwarded
the email to senior students in the traditional pre-licensure baccalaureate nursing
program. The gatekeepers for each nursing program determined how to distribute the
email to potential participants. The gatekeepers did not divulge data regarding the email
distribution to the researcher to maintain participant confidentiality.
Students who chose to complete the survey accessed the Qualtrics questionnaire
through a link in the email. The Qualtrics questionnaire began with a short informed
consent (Appendix K). The informed consent used a multiple-choice question format and
the students selected either yes (I agree to participate) or no (I do not want to participate).
The researcher designed the question to elicit a forced response. In that the
question was a forced response, students were not be able to proceed to the actual survey
questions until they submitted consent. Students who selected no were directed to a
statement that thanked them for looking at the survey. These students were not able to
answer any questions on the ILSES, the Richard Stockton College of New Jersey
Information Literacy Test, or the demographic questions.
Students who answered yes were directed to the first question on the ILSES.
Once they completed the ILSES, students answered the questions on the Richard
Stockton College of New Jersey Information Literacy Test. After completing the
knowledge test, students provided demographic information in the Qualtrics survey.

84

The researcher was not able to correlate any survey responses to any student
email addresses. Qualtrics assigned a numeric identifier to each survey submission that
could not be traced to any student email address or Internet Protocol (IP) addresses.
Therefore, study participation remained confidential due. Neither the researcher nor
nursing faculty members were able to identify who did participated in the study.
Any student who submitted a completed survey had the option to enter a drawing
for two $50 Visa gift cards. Once study participants completed the survey, they chose
whether to participate in the drawing. Students who chose to participate in the drawing
were redirected to a different web address where they entered their name and email
address in a separate Qualtrics survey. There was no way to link the information
students’ submitted for the Visa gift card drawing to survey responses.
Once data collection was completed, the researcher downloaded the entries for the
gift cards to an Excel spreadsheet and stored it on her computer’s hard drive. The
researcher used a formula that would pick a random cell to identify the gift card winners.
She notified the gift card winners via email. The investigator delivered the gift cards to
the winners using the USPS via certified, priority, flat rate mail. Once the researcher
received confirmation that the USPS delivered the gift card to the winners’ mailing
addresses, she deleted the Excel spreadsheet from her computer’s hard drive.
Protection of Human Subjects
Informed consent was obtained prior to distributing the surveys to the students. In
the pilot study, the gatekeeper distributed blank copies of the informed consent. Each
student received two copies of the informed consent (Appendix I). Any student who
decided to participate in the study signed one consent form and returned it to the

85

gatekeeper. Participants kept the second copy of the informed consent so that they had
the contact information for the researcher and details of the research project. In the
research project, students provided informed consent through Qualtrics (Appendix I).
These students had the researcher’s contact information and an explanation of the
research project in their recruitment email.
Students who participated in the pilot study were assured confidentiality. The
surveys used in the pilot test had a cover page containing the student’s name. The
researcher removed the coversheets after pairing the test and retest. She then stored the
coversheets were in a separate location from the surveys and used them to randomly pick
a winner for a $50 Visa gift card. Once the researcher matched the test and re-test
surveys at the end of the pilot test and delivered the Visa gift card to a winner, she
shredded the cover page with identifying information. The researcher had no way to link
the completed pilot test surveys to student names. For data analysis, an alphanumerical
code was used to identify each participant’s initial and second survey submissions.
Any student in the pilot test who did not submit two completed surveys were
excluded from the study. Students could withdraw from the pilot study any time before
the cover sheets with the identifying information were removed from the test and retest.
If a student wanted to withdraw from the pilot study, he or she could have contacted the
researcher by cell phone or email and state that they wanted to withdraw. The researcher
would have then shredded their completed surveys and excluded their responses from the
data analysis. Students who participated in the research study were not obligated to turn
in a completed survey.

86

Students who participated in the study were recruited through the use of email.
Although electronic survey submissions could not be linked to specific email addresses,
the researcher still assured participant confidentiality. If a student decided to withdraw
from the survey, they could exit the Qualtrics survey any time before they clicked on the
submission link. Data from incomplete surveys were not included in analysis. When
students submitted their responses in the electronic survey, Qualtrics de-identified all
student responses and assigned numeric identifiers for each survey submission. The
researcher had no way of removing student data if they wished to withdraw from the
study after submitting a completed survey into Qualtrics. The informed consent
explained the conditions for withdrawing from the study.
This study entailed minimal risk for the students who completed the surveys.
Although pregnant students could have completed the survey, this study did not target
data specific to pregnant women. Since there was no way to determine if a participant
was pregnant, the researcher assumed data obtained from a pregnant subject was
homogeneous with the data from other participants. The data collected in this study
targeted pre-licensure, baccalaureate, nursing students. Completion of the surveys did
not impose any risk greater than those encountered in the daily life of a nursing student.
The knowledge-based questions in the Richard Stockton College of New Jersey
Information Literacy Test assessed knowledge to which the students were previously
exposed in their nursing education.
Study participants were not obligated to complete every answer in one or both
data collection tools. If a subject did not like a question on either data collection tool, he
or she could have left the answer blank. If any students would have become upset when

87

answering the knowledge-questions, they could have withdrawn from the study by not
submitting the survey to the researcher. There were no reports of students getting
emotionally upset while completing the survey. Had a student become upset, he or she
could have been referred to university health or counseling services. Students were
assured that their choice whether to participate would not be shared with other faculty
members or administration within their nursing education program. Students were also
assured that their participation in this study had no positive or negative consequences on
their grades or coursework.
The researcher stored participant entries for the two Visa gift cards on her
computer’s hard drive. This computer was dedicated for the execution of the study. The
researcher secured the information stored on the computer through the use of a user name
and password. The researcher did not disclose her username and password on the
computer until she deleted the information for the Visa gift card entries from the hard
drive and this dissertation was completed.
Data Analysis
As in the pilot study, the researcher used SPSS for data analysis. Data from the
pilot study did not factor into the data analysis for the research project. The researcher
imported the data into SPSS directly from Qualtrics and calculated frequency
distributions for all demographic variables. Scores were calculated for the ILSES and the
Richard Stockton College of New Jersey Information Literacy Test as described below.
When calculating the score for the ILSES, the researcher totaled Likert-scale for
the 28-item scale and the 17-item scale. Data analysis focused on both versions of the
ILSES to assess if there was a difference in their relationship with IL knowledge or if

88

there were differences in their ability to predict IL knowledge. Although the data
analysis assessed both versions of the ILSES, students only had to complete the 28-item
survey because the questions in the 17-item scale are also in the 28-item scale.
Scores for the ILSES 17-item scale could have ranged from 17 to 119 and scores
for the 28-item scale could have ranged from 28 to 196. The researcher calculated scores
for the Richard Stockton College of New Jersey Information Literacy Test by adding the
number of correct answers. Scores for this tool could have range from 0 to 27. These
scores were tested for violations of normality, linearity, and homoscedasticity as
described in the pilot study. The researcher used the data analysis to answer the
following study questions.
1. What is the IL self-efficacy of pre-licensure baccalaureate nursing students as
measured by the Information Literacy Self-Efficacy Scale (Kurbanoğlu et al.,
2006)? Frequency distributions, measures of central tendency, and variability
were calculated with data collected from the ILSES.
2. What is the IL proficiency level for pre-licensure baccalaureate nursing
students as measured by the Richard Stockton College of New Jersey
Information Literacy Test? Frequency distributions, measures of central
tendency, and variability were calculated with data collected from the Richard
Stockton College of New Jersey Information Literacy Test.
3. What is the relationship between each IL self-efficacy score (28-item scale
and 17-item scale) and the IL knowledge of pre-licensure baccalaureate
nursing students? This relationship was assessed with Pearson ProductMoment Correlation.

89

4. After controlling for demographic variables, can IL self-efficacy levels act as
predictors for IL knowledge? Two hierarchical multiple regression models
assessed the ability each of the ILSES 28-item scale and the ILSES 17-item
scale to act as a predictor for IL knowledge scores.
Chapter Summary
This study measured the effect of IL self-efficacy on IL knowledge. The
researcher conducted a pilot test to determine the ability of the ILSES and the Richard
Stockton College of New Jersey Information Literacy Test to collect data reliably from a
population of pre-licensure baccalaureate nursing students. Once the researcher had
established the reliability of the data collection tools, she administered the surveys to the
study population until she obtained a minimum of 88 completed surveys. Data analysis
determined if a correlation existed between IL self-efficacy and IL knowledge. The
methodology included the calculation of a multiple regression to determine whether IL
self-efficacy scores acted as predictors to IL knowledge of senior pre-licensure
baccalaureate nursing students. The researcher calculated scores for both the 28-item and
17-item scale and used these scores in the data analysis to assess if there was a difference
between the two versions of the ILSES in assessing IL self-efficacy and predicting IL
knowledge.

90

CHAPTER FOUR
RESULTS
This chapter presents the results of the data analysis for the study. It begins with
the pilot study results addressing the reliability of the ILSES and the Richard Stockton
College of New Jersey Information Literacy Test. The chapter then describes the study’s
sample demographics and descriptive statistics for the self-efficacy and knowledge data.
Chapter 4 concludes by presenting the data analysis for answering the research questions
listed in Chapter 3.
Pilot Study Results
The reliability analysis used test-retest reliability to measure the dependability of
the ILSES and the revised Richard Stockton College of New Jersey Information Literacy
Test in repeated administrations (Polit & Beck, 2012). The study methodology employed
a 14- to 21- day window for the test-retest reliability measure to diminish the influence of
confounding variables on the study results. While memory reactivity effects present a
major weakness with this short time frame, the 14- to 21-day window aimed to minimize
the effect of student-professor interactions on attitudes towards IL (DeVon et al., 2007).
Initially, 21 students completed the ILSES 28-item scale and the Richard Stockton
College of New Jersey Information Literacy Test. Of the 21 participants, 19 students
completed the retest in 14 to 21 days. Participant ages (N=18) ranged from 21 to 24 with
a mean age of 22. Reported (N=18) grade point averages (GPA) ranged from 3.0 to 4.0,
the mean being 3.27. The majority of participants (86%) reported Caucasian race (N=18)
while 5% (n=19) reported having Hispanic, Latino, or Spanish ethnicity. All of the
participants (N=19) reported that they were full-time students.

91

Pilot Study Preliminary Analysis
The researcher conducted an exploratory analysis on 18 cases for the pretest
because one participant skipped a question in the ILSES and submitted two answers for
one multiple-choice question on the paper survey. This analysis includes all 19 retest
surveys. Table 6 contains exploratory data, while Table 7 delineates normality tests for
data collect by the ILSES and the Richard Stockton College of New Jersey Information
Literacy Test during the test and retest. Figures 5 and 6 compare the normal Q-Q plots
between the test and retest datasets. Figures 7 and 8 compare bivariate scatterplots for
the test and retest datasets.

92

Table 6
Pilot Study Descriptives
Statistic
A_ILSES_28

A_ILSES_17

Mean

148.2778

5% Trimmed Mean

147.3642

Std. Deviation

19.98177

B_ILSES_17

.479

.536

Kurtosis

-.467

1.038

Mean

89.8333

2.98717

5% Trimmed Mean

89.5370
12.67350

Skewness

.239

.536

Kurtosis

-.534

1.038

Mean

157.1579

4.10766

5% Trimmed Mean

157.2310

Std. Deviation

17.90488

Skewness

-.128

.524

Kurtosis

-.342

1.014

Mean

95.5789

2.57554

5% Trimmed Mean

95.9766

Std. Deviation

A_Knowledge

B_Knowledge

4.70975

Skewness

Std. Deviation

B_ILSES_28

Std. Error

11.22653

Skewness

-.461

.524

Kurtosis

.145

1.014

Mean

18.8889

.72260

5% Trimmed Mean

19.0432

Std. Deviation

3.06573

Skewness

-.737

.536

Kurtosis

.515

1.038

Mean

18.4211

.79588

5% Trimmed Mean

18.5789

Std. Deviation

3.46916

Skewness

-.781

.524

Kurtosis

.630

1.014

93

Table 7
Pilot Study Tests of Normality
Kolmogorov-Smirnova

Shapiro-Wilk

Statistic

df

Sig.

Statistic

df

Sig.

ILSES 28 (test)

.123

18

.200*

.952

18

.453

ILSES 17 (test)

.103

18

.200*

.973

18

.853

19

.200

*

.986

19

.989

*

.977

19

.896

ILSES 28 (retest)

.089

ILSES 17 (retest)

.099

19

.200

Knowledge (test)

.158

18

.200

.919

18

.125

Knowledge (retest)

.145

19

.200

.952

19

.430

a

Note. Lilliefors significance correction.

Figure 5. Comparison of pilot test normal Q-Q plots for ILSES.

94

Figure 6. Comparison of pilot test normal Q-Q Plots for knowledge.

Figure 7. Scatterplot Graphs for ILSES: Test – Retest

Figure 7. Comparison of pilot scatterplot graphs for ILSES.

Figure 8. Pilot test scatterplot graph for knowledge.
As stated in Chapter 3, the researcher analyzed the relationship between the
ILSES 28-item and 17-item test using a Pearson product-moment correlation coefficient.

95

The data associated with this analysis had no violation of the assumptions of normality,
linearity, and homoscedasticity. There was an excellent positive correlation between the
ILSES 28-item scale and 17-item scale for both the test (r=.964, n=18, p<.0005) and the
retest (r=.972, n=19, p<.0005).
Pilot Study Reliability Data
Data analysis indicated a positive correlation between the test and retest scores for
the knowledge test (r=.785, N=18, p<.0005), ILSES 28-item scale (r=.778, N=18,
p<.0005), and the ILSES 17-item scale (r=.722, N=18, p=.001). Table 8 delineates the
measures of internal consistency for the ILSES. The deletion of items did not improve
the r value in any of the datasets. Table 8 contains the measures of internal consistency
for all ILSES datasets.
Table 8
ILSES Measures of Internal Consistency—Pilot Test

ILSES 28 (test)

Cronbach's
Alpha
.933

Cronbach's Alpha based
on standardized items
.940

N
18

N of
items
28

ILSES 17 (test)

.890

.902

18

17

ILSES 28 (retest)

.951

.955

19

28

ILSES 17 (retest)

.915

.921

19

17

Sample Description
The researcher could not calculate the true response rate because of a lack of data
regarding the number of students who received the email invitation containing the link to
the Qualtrics survey. However, 137 students opened the survey and 88 participants
completed the survey, giving a completion rate of 64%. As discussed below, the
participant population was relatively homogeneous.

96

The participant demographics had little variance in age, gender, enrollment status,
and race. The majority of the study population were in their early 20s, female, white, and
Caucasian. Of the participants who reported their age (N=86), 96.5% reported being 20
to 24 years old. One participant reported an age of 28 and two participants stated they
were 57 years old. As with age, the reported GPA’s had little variability, ranging from
3.0 to 4.0 with a mean of 3.46 (SD=.327). Table 9 demonstrates study sample’s
homogeneity in gender, enrollment status, race, and ethnicity.
Table 9
Participant Demographics
Gender
Enrollment
Status
Race

Ethnicity

Male
Female
Fulltime
Part-time
African American
Asian
Caucasian
Hispanic
Non-Hispanic

N
10
78
85
3
2
3
83
1
87

Percent
11.4
88.6
96.6
3.4
2.3
3.4
94.3
1.1
98.9

Participants reported affiliation with IUP, Drexel University, Carlow University,
PSU, and SFU. None of the participants reported affiliation with Mansfield University.
Approximately 53% (N=47) of the sample matriculated at public universities and 47%
(N=41) attended private universities. Figure 9 breaks down the study sample according
to institution affiliation.

97

Figure 9. Participant affiliation.
Preliminary Analysis of Study Dataset
The following discussion, tables, and figures report information regarding the data
distribution, normality, linearity, and homoscedasticity. Tables 10 and 11 provide
descriptives and normality information for the study’s dataset. Figures 10 and 11 offer
Q-Q plots for the ILSES and the Richard Stockton College of New Jersey Information
Literacy Test. Figure 12 addresses the homoscedasticity regarding the dataset for each
hierarchical multiple regression model.

98

Table 10
Descriptives

ILSES_28

ILSES_17

Knowledge

Statistic

Std. Error

Mean

155.8556

1.93345

5% Trimmed Mean

156.4383

Std. Deviation

18.34229

Skewness

-.426

.254

Kurtosis

-.196

.503

Mean

93.6237

1.26668

5% Trimmed Mean

94.0544

Std. Deviation

12.21538

Skewness

-.493

.250

Kurtosis

-.207

.495

Mean

21.4767

.24574

5% Trimmed Mean

21.5129

Std. Deviation

2.27894

Skewness

-.171

.260

Kurtosis

-.399

.514

Table 11
Tests of Normality
Kolmogorov-Smirnova

Shapiro-Wilk

Statistic

df

Sig.

Statistic

df

Sig.

ILSES_28

.086

90

.198

.980

90

.186

ILSES_17

.070

93

.200

.974

93

.063

Knowledge

.109

86

.014

.972

86

.056

Note. a Lilliefors significance correction.

99

Figure 10. Comparison of normal Q-Q plots for ILSES.

Figure 11. Normal Q-Q plot for knowledge.

100

Figure 12. Comparison of ILSES 17 and 28 scatterplot graphs.
Reliability Data
As in the pilot study, the researcher did not calculate internal consistency for the
knowledge dataset because the questions in the Richard Stockton College of New Jersey
Information Literacy Test did not have a uniform format. The ILSES continued to show
very good internal consistency with a Cronbach’s Alpha of .89 for the ILSES 17-item
scale (N=93) and .93 for the ILSES 28-item scale (N=90)
Research Questions
Question One
This question asked, “What is the IL self-efficacy of pre-licensure baccalaureate
nursing students as measured by the Information Literacy Self-Efficacy Scale
(Kurbanoğlu et al., 2006)?” The ILSES measures IL self-efficacy by asking study
participants to rate on a seven-point Likert scale their confidence and competence in
conducting IL tasks. Responses on the Likert scale ranged from “1,” being “almost never
true,” to “7,” equaling “almost always true.” The researcher determined IL self-efficacy
levels by totaling responses for a composite score. As discussed in Chapter 3, there are
two versions of this scale, the 17-item scale and the 28-item scale. Information literacy
101

SES scores could have ranged from 17 to 119 for the 17-item scale and 28 to 196 for the
28-item scale. Higher scores indicated higher levels of IL self-efficacy. Table 12
contains descriptive statistics for datasets collected from both versions of the ILSES
scale. The histograms in Figure 13 represent the frequencies of participant ILSES
composite scores.
Table 12
Descriptive Statistics for ILSES
ILSES
17
ILSES
28

N

Min

Max

Mean

Std. Dev

Skewness

Kurtosis

93

59

117

93.624

12.215

-0.493

0.25

-0.207

0.495

90

108

194

155.856

18.342

-0.426

0.254

-0.196

0.503

Figure 13. Frequency of ILSES composite scores.
Question Two
This question asked, “What is the IL proficiency level for pre-licensure
baccalaureate nursing students as measured by the Richard Stockton College of New
Jersey Information Literacy Test?” This test measured participant knowledge by using
multiple choice, true/false, and “select-all-that-apply” questions relating to ALA’s
102

information literacy competency standards. The test had 26 questions, one of which was
“select-all-that-apply.” This question had two correct answers. Therefore, the test had 27
correct answers. The researcher calculated the knowledge composite scores by adding
the total number of correct answers. Scores could range from 0 to 27. Higher scores
indicated higher levels of IL knowledge related to ALA’s IL competencies. Table 13
contains descriptive statistics for the knowledge dataset collected using the Richard
Stockton College of New Jersey Information Literacy Test.
Table 13
Descriptive Statistics for Knowledge Composite Scores
N

Min

Max

Mean

Std. Dev

86

16

26

21.477

2.279

Skewness
-0.171

Figure 14. Frequency of knowledge composite scores.

103

0.26

Kurtosis
-0.399

0.514

Question Three
This question asked, “What is the relationship between each IL self-efficacy score
(28-item scale and 17-item scale) and the IL knowledge of pre-licensure baccalaureate
nursing students?” Prior to calculating the Pearson Product-Moment Correlation, the
researcher recalculated composite scores for the outliers identified in Figure 12. She
found no errors in these scores. There was a moderate positive correlation between
knowledge in relation to the ILSES 28-item scale (r = .334, p = .003) and 17-item scale (r
= .321, p = .003). Tables 14 and 15 contain the data related to the Pearson ProductMoment Correlations for the IL self-efficacy scores and knowledge.
Table 14
Correlations Between ILSES-28 and Knowledge
ILSES_28
ILSES_28

Pearson Correlation

Knowledge
1

Sig. (2-tailed)

.003

N
Knowledge

.334**

Pearson Correlation
Sig. (2-tailed)

90

79

.334**

1

.003

N

79

86

**. Correlation is significant at the 0.01 level (2-tailed).
Table 15
Correlations Between ILSES-17 and Knowledge
ILSES_17
ILSES_17

Pearson Correlation

Knowledge
1

Sig. (2-tailed)

.003

N
Knowledge

.321**

Pearson Correlation
Sig. (2-tailed)

93

82

.321**

1

.003

N

82

**. Correlation is significant at the 0.01 level (2-tailed).

104

86

Question Four
This question asked, “After controlling for demographic variables, can IL selfefficacy levels act as predictors for IL knowledge?” The researcher intended to ascertain
if IL self-efficacy levels, as measured by the ILSES, could act as a predictor for IL
knowledge, as measured by the Richard Stockton College of New Jersey Information
Literacy Test. The researcher used two hierarchical multiple regression models to answer
this question regarding the ILSES 28-item and 17-item scales. The use of two models
eliminated the concern of multicollinearity and singularity. The two scales violated the
assumption of multicollinearity because they had r values of .89 and .93 in the pilot
study. The scales also violated the assumption of singularity because the 17-item scale is
actually part of the 28-item scale.
The researcher entered independent variables in two blocks to better explore the
ability of IL self-efficacy to predict IL knowledge. Gender and GPA, constant variables,
were entered into the first block of each model. In the first model, the ILSES 28-item
scale was entered into the second independent variable block. The ILSES 17-item scale
was entered into the second independent variable block in the second hierarchical
regression model. The researcher entered knowledge as the dependent variable in both
models.
Preliminary analysis of both models revealed no overt outliers. The scatterplots
(Figure 12) identified three questionable response sets but the Mahalanobis distances for
all the participants were below the critical value of 16.266 (df = 3, p < .001). The
evaluation for each of the models began by assessing R Square values in the first model
summary. The constant predictors, gender and GPA, accounted for only .8% of the

105

variance (p=.741) in the model. However, when the researcher added the ILSES-28 to
the model, this self-efficacy scale accounted for 10.4% (p=.004) of the variance in
knowledge scores (Table 16). This model as a whole was significant (F (3,75) = 3.160,
p=.029) when including ILSES 28-item scale as a predictor.
The second model had similar results as the first model. Gender and GPA
accounted for 3.9% (p=.216) of the variance in knowledge scores while the ILSES 17item scale accounted for 8.3% (p=.009) of the variance in knowledge scores (Table 17).
Just like the ILSES 28 model, this model was significant (F (3,77) = 3.553, p=.018) when
it included the ILSES-17 item scale as a predictor.
Table 16
Adjusted R Squared Values for Knowledge and ILSES 28
Change Statistics
Model
1
2

R

Adjusted

Std. Error of

R Square

Square

R Square

the Estimate

Change

Sig. F
F Change

df1

df2

Change

a

.008

-.018

2.29966

.008

.300

2

76

.741

b

.112

.077

2.18979

.104

8.817

1

75

.004

.089
.335

R

Note. aPredictors: (Constant), GPA, gender new. bPredictors: (Constant), GPA, gender new, ILSES 28.

Table 17
Adjusted R Squared Values for Knowledge and ILSES-17
Change Statistics
Model
1
2

R

Adjusted

Std. Error of

R Square

Square

R Square

the Estimate

Change

Sig. F
F Change

df1

df2

Change

a

.008

-.017

2.29854

.008

.312

2

79

.733

b

.104

.069

2.19846

.096

8.356

1

78

.005

.089
.322

R

Note. aPredictors: (Constant), GPA, gender new. bPredictors: (Constant), GPA, gender new, ILSES 28.

106

Summary of Findings
This chapter presented the results of the statistical analysis assessing IL selfefficacy as measured by the ILSES (Kurbanoğlu et al., 2006) and IL knowledge as
measured by the Richard Stockton College of New Jersey Information Literacy Test
(Trail et al., 2006). The chapter began with the results of a pilot test, which tested the
reliability of the ILSES and the Richard Stockton College of New Jersey Information
Literacy Test. The chapter discussed descriptive and inferential statistics related to the
four study questions introduced in Chapter 3. The data analysis indicated a moderate
relationship between IL self-efficacy and IL knowledge. It further suggested IL selfefficacy impacted the variance of the IL knowledge scores. The following chapter will
address this data analysis in relation to the literature review and explore areas for further
research in relation to IL self-efficacy and knowledge.

107

CHAPTER FIVE
DISCUSSION AND IMPLICATIONS
Chapter 5 will present discussions of the pilot study, research questions, study
limitations and implications. The chapter will conclude by presenting recommendations
for future research and a summary of the study results.
Review of Pilot Study
The results of the pilot study supported the study’s use of the ILSES and the
Richard Stockton College of New Jersey Information Literacy Test. Although the dataset
was small, it did not violate any of the assumptions associated with the Pearson productmoment correlation coefficient. The following information discusses the results of the
preliminary data analysis and the reliability studies.
Preliminary examination indicated the pilot study dataset had no gross violations
of normality, linearity, or homoscedasticity. The normal Q-Q plots, in Figures 5 and 6,
illustrated the normality of the data sets collected in the pilot study. Normality was
further evidenced though the kurtosis, skewness, Kolmogorov-Smirnov, and the ShapiroWilk values. The kurtosis and skewness values for the datasets listed in Table 6 fell
between -1 and +1, indicating the ILSES and the Richard Stockton College of New
Jersey Information Literacy Test datasets contained a peak and had a relatively
symmetrical distribution (Mertler & Vannatta, 2013). The Kolmogorov-Smirnov and the
Shapiro-Wilk values listed in Table 7 had insignificant results, indicating a normal
distribution. The scatterplot graphs indicated no gross violations regarding assumptions
of linearity and homoscedasticity.

108

The ability of the pilot study data to meet these assumptions improved the rigor of
the reliability studies. The internal validity of the ILSES was excellent, as evidenced by
Cronbach’s alpha values ranging from .890 to .951. The ILSES demonstrated fair
reliability as indicated by r values of .778 (n=18, p<.0005) for the 28-item scale and .722
(n=18, p=.001) for the 17-item scale. The knowledge test, the Richard Stockton College
of New Jersey Information Literacy Test, also demonstrated fair reliability (r=.758, n=18,
p<.0005).
Although a larger sample may have resulted in improved r values, the findings
from this study support the use of these tools in English speaking, pre-licensure,
baccalaureate nursing students. Polit and Beck (2012) recommend having a correlation
of .8 or greater, but they stated a correlation of .7 is acceptable. The results of the pilot
study indicated that the ILSES and the Richard Stockton College of New Jersey
Information Literacy Test could collect reliable data with no additional revisions.
Discussion
This section will present discussions on the findings as presented in Chapter 4.
These discussions will begin with the study sample and missing data. Next, this section
will review the preliminary data analysis in terms of the assumptions relating to the
statistical analysis of the data. The discussion section will conclude with a review of the
data in relation to each study question.
Study Sample
As stated in Chapter 4, there was no way to calculate response rate. The
researcher did not collect data regarding the number of students who received the link to
the survey. However, one can conclude that the response rate was low due to the

109

difficulty in obtaining 88 completed surveys, as evidenced by the average number of
first-time NCLEX-RN test takers. Although the reported averages of first time NCLEXRN test takes does not reflect class sizes in the 2014 spring and fall semesters, this data
does reflect the size of the programs.
In mid to late April, the survey was initially distributed to pre-licensure, senior,
baccalaureate nursing students who matriculated at Carlow, Drexel, and Mansfield
Universities. Eight participants completed the survey. The average number of first time
NCLEX-RN candidates from 2010 to 2013 for these schools was 49.75, 341.25, and 33,
respectively (Pennsylvania State Board of Nursing, 2013).
Due to the poor response rate, the IRB approved a change of protocol to collect
data from IUP students. IUP’s average of first time NCLEX-RN test takers from 2010 to
2013 was 106.5 (Pennsylvania State Board of Nursing, 2013). At the end of the spring
semester, the researcher collected 37 completed surveys despite sending the survey link
to students enrolled in four different schools of nursing. She re-distributed the survey at
the beginning of the fall semester to senior students who matriculated at these four
nursing programs. Four weeks after disseminating the link to the students, 22 additional
students completed the survey. The IRB approved two more protocol changes so that the
researcher could recruit participants from PSU and SFU who had averages of 137.5 and
14.5 for first time NCLEX-RN test takers from 2010 to 2013 (Pennsylvania State Board
of Nursing, 2013). The researcher completed data collection on October 23, 2014, when
88 students submitted completed surveys.
This poor response rate raised questions regarding the ability of the study sample
to represent the overall population of pre-licensure, senior, baccalaureate nursing

110

students. The literature review indicated that nursing students have reported negative
perceptions regarding IL. Qualitative studies examined undergraduate views of IL and
reported that students associated feelings of frustration, doubt, confusion, and anxiety
with IL (Duncan & Holtslander, 2012; Klentzin, 2010).
The researcher wonders if negative feelings and perceptions deterred students
from participating in the study. Negative thoughts could have caused the students to
assume that the action of completing the survey would not benefit them. These negative
perceptions, or causal beliefs, could have acted as an antecedent for not participating in
the research study (Weiner, 1986, 2006). This raised questions as to whether students
with negative perceptions to IL also had IL negative self-efficacy levels.
If this were the case, the participant responses could only represent highly
motivated students, which could skew the data. The median value for the ILSES 17-item
scale (5.588) and 28-item scale (5.607) demonstrated the study population had positive IL
self-efficacy levels. The inclusion of students who had negative perceptions towards IL
could have lowered the median values. Therefore, the study results may not have
represented base-line IL self-efficacy levels for pre-licensure BSN students.
In addition, the literature review indicated some students lacked knowledge
regarding the definition of IL (Gross & Latham, 2009, 2011a; Nayda & Rankin, 2008). If
a student had an inaccurate perception of IL, they may not have been able to make the
connection between IL and evidence-based nursing practice. Participants in Nayda’s and
Rankin’s (2008) study compartmentalized IL to gaining information from librarians,
academics, and their peers. The students who opted not to participate in this study could
have viewed the research as irrelevant to their education and future practice. This

111

compartmentalization of IL could have been a factor in not participating in the study
(Weiner, 1986, 2006).
Incomplete datasets. As stated in Chapter 4, the completion rate of the Qualtrics
survey was 64%. Although all 137 participants provided consent to take the survey, the
majority of the participants who did not complete it exited the survey after reading the
first question. These students may have experienced some of the issues discussed
regarding the poor response rate such as lack of perceived benefits and negative
perceptions regarding IL. The poor completion rate substantiates the concerns regarding
the ability of the study results to reflect baseline IL self-efficacy and knowledge levels of
nursing students.
Four participants completed the ILSES, but did not answer the knowledge
questions. This behavior raised questions regarding the students’ use of intrinsic goal
orientation, which correlates with Weiner’s concept of internal facets of control (1985,
1986, 2000). As Table 18 illustrates, the mean ILSES 28-item and 17-item survey scores
for participants who did not complete the knowledge portion of the survey were lower
than participants who did complete the knowledge questions. Although the low sample
sizes raised concern when interpreting these statistics, the differences in mean scores
could be attributed to issues with internal facets of control unique to the students who
only completed the ILSES. Aptitude is an example of an internal facet of control. These
participants may have perceived themselves as proficient in IL skills but then became
overwhelmed with the knowledge questions because they did not know the answers.

112

Table 18
Comparison of ILSES Scores: No Knowledge Scores vs. Knowledge Scores
Mean
Score

Std. Error

Standard
Deviation

Minimum

Maximum

Range

ILSES 28

146.5000

12.05888

24.117

112

168

56

ILSES 17

90.2500

7.79289

15.585

68

102

34

ILSES 28

156.2907

1.95124

18.095

108

194

96

ILSES 17

94.5349

1.23920

11.491

67

117

50

No
Knowledge
Data
(N=4)

Completed
Knowledge
Data
(N=86)

Comparison of participant demographics. The demographic questions were at
the end of the survey; therefore, the following data only pertains to the students who
completed the ILSES and the knowledge portion of the survey. The study population had
little variance in terms of their demographic data. With the majority of participants
reporting ages 24 or younger, the researcher deduced that the study participants were
traditional college students since they are matriculating in a pre-licensure program.
Although gender demographics appeared skewed, they were similar to the National
League for Nursing’s (NLN) statistical data for general baccalaureate nursing students.
The NLN (2012) reported that 14% of students enrolled in basic baccalaureate nursing
programs were male. This was similar to the study population in that 10% of the
participants were male. While the study results may not have provided a robust
representation regarding male nursing students’ IL self-efficacy and knowledge, these
results could be reflective of the overall population’s IL self-efficacy and knowledge.

113

Evaluation of the Preliminary Data Analysis
The researcher conducted an exploratory analysis to evaluate the ability of the
dataset to meet the assumptions related to a multiple regression analysis. The preliminary
analysis addressed multicollinearity and singularity, outliers, linearity, homoscedasticity,
sample size, and normality. Data analysis indicated no overt violations in
multicollinearity and singularity, outliers, linearity, and homoscedasticity. Conversely,
there were minor concerns regarding the assumptions related to sample size and
normality.
Sample size. While 88 participants completed the survey, the researcher
completed the multiple regression with 86 response sets because two participants did not
answer approximately five knowledge questions in their surveys. Although the power
analysis required 88 participants for a conventional medium effect (ƒ2 = .13), 86
participants meet the needs of a power analysis for a conventional effect. According to
Polit and Beck (2012, pp. 423, 442), a conventional effect could have been achieved with
a Cohen's ƒ2 of .15. A power analysis with a Cohen's ƒ2 of .15, a power of .80 and a
probability of .05 required a sample size of 76. Therefore, the dataset satisfied the
assumption regarding the sample size for a multiple regression analysis.
Normality. As in the pilot study, the kurtosis and skewness values for the ILSES
and knowledge datasets fell between -1 and +1, indicating these datasets contained a peak
and had a relatively symmetrical distribution (Mertler & Vannatta, 2013). Normality
tests for the ILSES were all normal. The normality concern centered on the knowledge
dataset. The Kolmogorov-Smirnov value for the knowledge dataset was significant
(p=.014). The significant results for the Kolmogorov-Smirnov test did not raise serious

114

concerns because this test is usually used for larger populations (n>2,000). In contrast,
the Shapiro-Wilk value for the knowledge dataset was insignificant (p=.56). Even though
the results of the Shapiro-Wilk test indicated a normal distribution for the knowledge
data, the near significant p value raised concerns regarding the normality of the
knowledge dataset.
Research Question One: What Is the IL Self-Efficacy of Pre-Licensure
Baccalaureate Nursing Students as Measured by the Information Literacy SelfEfficacy Scale (Kurbanoğlu et al., 2006)?
The mean scores were similar for the two versions of the ILSES scale. To
compare these means to each other and to the scale’s connotations, the researcher
recalculated summative scores in relation to the 7-point Likert scale. A score of 5 and
higher indicated positive self-efficacy levels for the participants. The 28-item scale had a
mean of 5.566 (N=90) and the 17-item scale had a mean of 5.507 (N=93). The majority
of the subjects reported positive IL self-efficacy levels. Using the results of the 28-item
scale, approximately 52% of the population’s scores ranged from 5 to 5.965 and 28% of
the population raged from 6 to 6.92. The small sample size prohibited analyzing ILSES
scores by genders, but Table 19 delineates these test scores by gender.

115

Table 19
Comparison of ILSES Scores by Gender
Mean
Score

Likert
Score

Std.
Error

Standard
Deviation

Minimum

Maximum

Range

GPA
ILSES
28
ILSES
17

3.52
144.3

5.142

.084
6.175

.265
19.528

3
108

4
174

1
66

86.4

5.082

4.025

12.729

67

107

40

GPA
ILSES
28
ILSES
17

3.45
157.671

5.631

0.38
2.110

.264
17.656

3
117

4
194

1
77

94.411

5.553

1.401

11.973

59

117

58

Male

Female

Stokes and Urquhart (2011) administered the 28-item ILSES to nursing students
who matriculated in the UK, but baseline scores could not be compared because the
article only reported inferential statistics. The mean ILSES scores were higher than mean
scores reported by Akkoyunlu and Yilmaz (2011), Demıralay and Karadenız (2010),
Erdem (2007), and Geçer (2012). These studies assessed the self-efficacy levels of
prospective Turkish teachers using the 28-item scale.
In contrast, the mean ILSES score of the study participants fell below that of
Kiliç-Çakmak’s (2010) study population, who had a mean score of 5.64. Kiliç-Çakmak
(2010) administered the ILSES to Turkish distance education students who majored in
Computer Technologies and Programming and Business Administration. Kiliç-Çakmak
(2010) stated that some of the participants held jobs, but did not provide any
demographic data regarding non-traditional students. Information literacy self-efficacy
levels for non-traditional working students may be higher because of their responsibilities
and experiences related to their jobs. Traditional undergraduate students may have lower
IL self-efficacy levels because of their inexperience in working with information.
116

Research Question Two: What Is the IL Proficiency Level for Pre-Licensure
Baccalaureate Nursing Students as Measured by the Richard Stockton College of
New Jersey Information Literacy Test?
Overall, according to the Richard Stockton College of New Jersey Information
Literacy Test (Trail et al., 2006), study participants demonstrated a general proficiency in
IL knowledge. The mean score for the knowledge test was 21, which equals a 77%. The
majority of students scored between 70% and 89%. Forty three percent of the students
had scores ranging from 70 to 78, 42% of the students’ scores ranged from 81% to 88%,
while only 7% of the students had scores of 92% or greater. The literature review did not
reveal a standard for knowledge scores, but the SAILS uses a score of 70% to determine
that a student is proficient in IL and 85% to determine if a student mastered the IL
competencies (Kent State University, 2014a).
Table 20 differentiates knowledge scores according to gender. The GPA was
higher in males but the IL knowledge score was higher in females. However, the small
male sample (N=10) prohibited any analysis with inferential statistical tests. These
results directly contradicted Adetoro and colleagues (2010) study, in which males
demonstrated a significant higher level of IL knowledge (t(98)=2.26, p=0.026). Other
studies assessing IL knowledge did not report any data according to gender (Courey et
al., 2006; Ferguson et al., 2006; Freeman & Lynd-Balta, 2010; Henderson et al., 2011;
Jacobsen & Andenæs, 2011; Salisbury & Karasmanis, 2011). This lack of research
demonstrates the need for more IL studies that assess baseline knowledge levels between
genders. Knowing the nuances of IL proficiency could help nurse educators

117

individualize instruction to the specific needs of their student population. This is
particularly important with more males entering the nursing profession.
Table 20
Comparison of Knowledge Scores by Gender
Mean
Score

Std.
Error

Standard
Deviation

Minimum

Maximum

Range

GPA
Knowledge

3.52
20.889

.084
.806

.265
2.420

3
17

4
24

1
7

GPA
Knowledge

3.45
21.539

0.38
.261

.264
2.282

3
16

4
26

1
10

Male
Female

The mean knowledge score for the study population was much higher than the
results published by Trail and colleagues (2006). Students (N=175) who took the
Richard Stockton College of New Jersey Information Literacy Test as a pre- and post-test
had mean scores of 66.3% and 74.13% respectively. The difference between the current
study’s mean knowledge scores and those reported by Trail and colleagues (2006) could
be related to the amount of higher education the students had. Participants in Trail and
colleagues’ (2006) study were traditional freshman students compared to the senior
baccalaureate nursing students who participated in this study.
These differences in IL knowledge scores could also be due to differences in
educational experiences. Accredited nursing schools are required to provide IL education
to nursing students as part of their preparation for EBP. Other undergraduate majors may
not have been exposed to the same type or amount of IL education embedded in a nursing
curriculum.
Although other published research assessed IL knowledge in college students,
they used a different knowledge test and reported knowledge data in terms of
improvement (Courey et al., 2006; Ferguson et al., 2006; Freeman & Lynd-Balta, 2010;
118

Henderson et al., 2011; Jacobsen & Andenæs, 2011; Salisbury & Karasmanis, 2011).
Consequently, the researcher could not make comparisons between this study and the
published literature assessing IL knowledge. The lack of standardized data demonstrated
a need for validating a tool, such as the Richard Stockton College of New Jersey, for use
in nursing education to compare standardized outcome data between nursing student
populations.
Research Question Three: What Is the Relationship Between Each IL Self-Efficacy
Score (28-Item Scale and 17-Item Scale) and the IL Knowledge of Pre-Licensure
Baccalaureate Nursing Students?
The correlational analysis yielded significant results for both the ILSES 28-item
scale (r = .334, p = .003) and the 17-item scale (r = .321, p = .003). Adetoro and
colleagues (2010) achieved similar results for the correlational analysis between IL selfefficacy and proficiency (r = .329, p < .01). Adetoro and colleagues (2010) conducted
their ex-post facto study on 100 Nigerian, undergraduate, science majors. Lack of
detailed information regarding the IL knowledge results in the ex-post facto study
prohibited the researcher from conducting a direct comparison of the knowledge data
collected in this study to the research conducted by Adetoro et al. (2010). However, it
appeared both study samples yielded similar results in knowledge levels, average or
slightly above average.
The observation that both studies obtained similar results indicated an interplay
between IL self-efficacy and IL proficiency, as demonstrated in the conceptual
framework presented in Chapter 1. While the positive nature of the correlation indicated

119

that self-efficacy has a relationship with IL proficiency, the correlation did not address
the nature of the association between these two variables.
While the ILSES was used to test IL self-efficacy levels in college students,
published studies using the ILSES mainly assessed IL self-efficacy in relation to
proficiency in using technology to acquire information (Akkoyunlu & Yİlmaz, 2011;
Demıralay & Karadenız, 2010; Erdem, 2007; Geçer, 2012; Kiliç-Çakmak, 2010; Stokes
& Urquhart, 2011). Although IL proficiency requires the ability to use technology to
obtain information, the researcher did not compare the inferential statistics in the
aforementioned studies to the results reported in Chapter 4. These studies investigated
the ability to use technology in Turkish undergraduate students. The prevalence of
technology may be different for Turkish college students compared to American students.
This difference could drastically influence an interpretation of the relationship between
technology use and IL self-efficacy.
Research Question Four: After Controlling for Demographic Variables, Can IL
Self-Efficacy Levels Act as Predictors for IL Knowledge?
The researcher used two hierarchical multiple regression models to assess the
ability of gender, GPA, and IL self-efficacy to predict IL knowledge scores. Although
both models demonstrated the ability of the ILSES to predict knowledge scores, the 28item scale accounted for more of the variance in knowledge than the ILSES 17-item
scale. After controlling for gender and GPA, the ILSES 28-item scale explained 10.4%
of the variance in knowledge (F (3,75) = 3.160, p=0.29) while the ILSES 17-item scale
accounted for 8.3% of the variance in knowledge (F (3,77) = 3.553, p=.018). These
results demonstrated that IL self-efficacy acted as a valid predictor for IL knowledge.

120

The ability of the ILSES to act as a predictor for IL knowledge supported the
assertion that IL self-efficacy may act as an intrapersonal attribute according to Weiner’s
(1985, 1986, 2000) attributional theory of motivation. The ILSES data indicated the
participants had positive beliefs supporting their success in performing IL related tasks,
as measured in the knowledge test. Positive IL self-efficacy levels, as reported by the
study participants, can act as an intrapersonal attribute.
Information literacy self-efficacy as an intrapersonal attribute may help nursing
students transfer the IL knowledge they gain in their undergraduate education to research
utilization in practice. Knowing this, nurse educators can better incorporate learning
activities that address the affective domain when teaching IL skills. Addressing the
affective learning domain in relation to IL education may help improve students’
perceptions and generate positive emotions associated with the use of IL skills to acquire,
critique, and apply research studies to their personal practice. This would help the
students generate positive emotion phenomenal causality, as it relates to IL (Weiner,
1985, 2011).
The provision of achievable IL learning activities in environments such as clinical
conferences may help foster an improved sense of control as defined by Weiner (1985,
1986). For example, a student could be required to present a research article of interest to
his or her classmates during a clinical post-conference. The ability to choose the topic for
the article and the use of a grading rubric could foster the students’ sense of control and
stability over attributions, such as IL self-efficacy, that motivate them to use IL skills.
Control would be positively influenced by allowing the student to find a research article
and use of a rubric to assess the student’s presentation in two ways. First, maximization

121

of control could occur by allowing the student to compare the grading rubric to the
content of an article and subsequently choose an article that he or she believed they could
master. Second, choosing the article relating to a topic of interest would further invest
the student in the assignment and help him or her take ownership of the content.
Promoting an internal locus of causality and stability could also foster control
regarding a student’s perception of IL education. An internal locus of causality would be
fostered through the use of a rubric to grade the clinical post-conference presentation
while stability would be fostered through the provision of IL education in the clinical
environment. The rubric would communicate the expectations for the student’s
performance. The clear expectations could improve the student’s ability to prepare for
and conduct the presentation in relation to his or her clinical experiences. The
incorporation of past experiences in the presentation will further shape the student’s
perceptions of the event through personalization.
Expanding IL education to places such as the clinical arena would help the
student to expect the use of IL skills in all areas of their nursing education. As Weiner
(1976, 1985, 1986) explained, a stable expectation for the use of IL skills in unchanging
conditions could motivate students to repeat past behaviors that required the use of IL
skills. Positive learning experiences in multiple settings shape the phenomenal causality,
which, in turn, shapes self-efficacy. Figure 1, Conceptual Framework, demonstrated this
dynamic process.
Limitations
Although the data analysis was able to address the research questions, there were
three main limitations to the study. First, the poor response rate and low completion rate

122

limits the generalizability of the study results. Next, the lack of knowledge data for four
participants could have skewed the hierarchical multiple regression analysis. Finally, the
homogeneous characteristics of the study population limit the ability to generalize the
results.
The poor response rate and low completion rate caused the researcher to question
the ability to generalize the study results. The data analysis may only reflect students
who have high self-efficacy levels that would foster a positive internal locus of causality.
The data specific to the students who did not respond or complete the survey could have
drastically changed the study results. This missing data may have provided evidence that
there was a negative correlation between IL self-efficacy and knowledge. If this were the
case, the implications for practice would differ from those presented in the following
section.
An additional limitation is the lack of knowledge data for the students who
completed the ILSES. Even though these students reported positive self-efficacy levels,
they may have become overwhelmed when they saw the knowledge questions. The
literature review indicated that students often overestimated their proficiency in IL
proficiency (Gross & Latham, 2011a, 2011b; Henderson et al., 2011; Jacobsen &
Andenæs, 2011). A phenomenographic study found that students with below proficient
skills believed that they had above average skills and there was nothing that teachers had
to offer them in terms of information seeking (Gross & Latham, 2011a). If this were the
case, IL self-efficacy would not have been able to act as a predictor for IL knowledge
levels. Students with these characteristics may not respond to current pedagogical
practices for the instruction of IL.

123

The remaining study limitations center on the homogeneity of the participant
population regarding class rank within the pre-licensure baccalaureate nursing program,
age, and gender. As for class rank within a nursing program, inclusion criteria mandated
that study participants have senior status within a pre-licensure baccalaureate nursing
program. Because of this requirement, the study results do not reflect IL self-efficacy or
knowledge levels of freshmen, sophomore, or junior nursing students. Although previous
research indicated that the amount of education may have no impact on IL self-efficacy
levels in nursing students (Stokes & Urquhart, 2011), the ability of IL self-efficacy to act
as a predictor may change depending on students’ class rank. Experiences unique to
freshman, sophomore, or junior levels of nursing education could act as antecedents for
forming values and motivations associated with IL self-efficacy or knowledge levels
(Weiner, 2010). The impact of class rank on IL self-efficacy as a predictor for
knowledge would need to be determined through a longitudinal or a cross-sectional
study.
All but three participants reported ages between 20 and 24. The remaining three
participants reported their age as 28 (N=1) and 57 (N=2). The inclusion of additional
participants with ages over 24 could have caused differences in participant outcomes, as
in the study conducted by Levett-Jones and colleagues (2009). Life experiences such as
illness, marriage, family, and work can influence a nursing student’s perceptions of IL in
relation to the need for and use of information. These perceptions would have a direct
impact on his or her phenomenal causality, which in turn can generate causal beliefs
regarding the individual’s ability to engage in IL related behavior (Weiner, 1985, 1986,
2011). Geçer’s (2012) study results support this postulation. In this study, a significant

124

difference existed between the ILSES scores and the study population’s ages (Geçer,
2012). Study participants ages 24 and over had significantly higher ILSES scores (Geçer,
2012). Subsequently, an increased variance in age could change the ability of the ILSES
to act as a predictor for IL knowledge.
A larger study sample would also have helped increase the robustness of the
dataset by allowing the researcher to assess differences in IL self-efficacy and knowledge
scores between genders. The analysis for differences in IL self-efficacy and knowledge
scores between males and females yielded insignificant findings. The insignificant
findings could have been due to insufficient power related to the small sample of males
(N=10). Gender differences in the students’ perceptions of their lived experience could
affect Weiner’s concept of phenomenal causality, which in turn can generate behavior
rooted in emotions (Krathwohl et al., 1964; Weiner, 1986, 2006)
Implications
Implications of the study results center on the use of the data collection tools to
collect individual and aggregate outcomes. This outcome data can then be assessed to
improve the delivery of IL education to prospective nurses. This section ends by
discussing how the dynamic nature of self-efficacy as an attribution for behavior can
result in negative consequences for the nursing students.
Use of Data Collection Instruments in Nursing Education
Prior to this research, researchers used the ILSES only in Turkish populations.
This pilot study demonstrated the reliability of the ILSES in English-speaking, prelicensure, baccalaureate nursing students. Therefore, the pilot study, in conjunction with
the research results, indicate the ILSES can have implications for nursing education.

125

Nursing educators could use these tools to collect baseline data for creating learning
activities that address the affective domain. The use of the ILSES to collect individual
student data would allow an educator to tailor the course content to IL mindsets and
behaviors rooted in emotions (Krathwohl et al., 1964). These mindsets present as
individual perceptions, attitudes, and values affecting students’ locus of causality, which
could shape their IL self-efficacy (Krathwohl et al., 1964; Weiner, 1985, 1986). IL selfefficacy can act as an attribution for using and applying IL skills outside of the
classroom. Therefore, education shaping IL self-efficacy could theoretically impact a
student’s ability to engage in research utilization.
This was the first study to compare the utility of the 28-item test with that of the
17-item test. While the 17-item scale had good reliability (r=.722, N=18, p=.001) and
Cronbach’s Alpha values (.89 and .91), it had less predictive value than the 28-item scale.
The improved predictability coupled with higher reliability (r=.778, N=18, p<.0005) and
Cronbach's Alpha levels consistently greater than .93, make the use of the ILSES 28-item
scale preferable for measuring IL self-efficacy. It takes less than 10 minutes for students
to complete the ILSES 28-item scale. The scale could be administered either on paper or
electronically. The easy administration of this scale makes it a feasible option for
measuring IL self-efficacy levels in a nursing curriculum.
The published research identified in the literature review did not identify any
specific standardized tool for collecting data on IL knowledge in nursing students.
Several of these studies discussed their data collection tool, but did not report any validity
or reliability information regarding their data collection tools (Courey et al., 2006;
Ferguson et al., 2006; Freeman & Lynd-Balta, 2010; Henderson et al., 2011; Jacobsen &

126

Andenæs, 2011). Salisbury and Karasmanis (2011) included validity and reliability
information regarding their standardized tool, but did not conduct a pilot test after
updating the previously validated tool. The lack of a valid, reliable, standardized
collection tool prohibits the comparison of previous study results to identify best
practices in the instruction of IL.
In addition, the literature reviewed did not define a universal benchmark to
determine IL competency based upon test scores. However, the creators of the SAILS
determined that a score of 70% demonstrated proficiency in IL and a score of 85% or
greater demonstrated mastery of IL competencies (Kent State University, 2014a).
Although these benchmarks provide a good starting point, the content and structure of the
Richard Stockton College of New Jersey Information Literacy Test (Trail et al., 2006)
differed significantly from the SAILS.
The Richard Stockton College of New Jersey Information Literacy Test (Trail et
al., 2006) only had 27 questions and took approximately 10 to 15 minutes to administer
compared to the SAILS with 55 questions that took approximately 45 to administer (Kent
State University, 2014a). Although the SAILS has demonstrated reliability throughout
several years, it can be expensive to administer and lengthy for students.
The reliability of the Richard Stockton College of New Jersey Information
Literacy Test (r=.758, n=18, p<.0005) coupled with its ease of administration make it a
promising tool for collecting individual and aggregate IL knowledge data. The test could
be easily administered in any course because it takes less than 15 minutes to complete.
The questions in the test align with research utilization, which plays a vital role in EBP.
The short time frame for administration of this knowledge test would allow nurse

127

educators to incorporate it into courses use the data to tailor the course content to the
students’ needs.
While this knowledge test has practical applications for promoting individual
student outcomes, the collection of aggregate knowledge and self-efficacy data could also
help nursing programs demonstrate they meet their accreditor’s standards for nursing
education. For example, the AACN (2008) states information literacy is a crucial skill
for nursing graduates of baccalaureate nursing programs. The association specifically
identifies information literacy as a key component in two of the nine essentials in the
Essentials of Baccalaureate Education for Professional Nursing Practice (AACN, 2008).
This knowledge test could also be administered at different levels in a curriculum to
evidence students’ progression of knowledge in relation to IL and EBP. The aggregate
knowledge scores could be reported according to the framework presented in Table 21.

128

Table 21
Crosswalk of EBP, IL Competencies, Knowledge Test, and ILSES 28-Item Scale
Steps in EBP

IL competencies

Questions in
Knowledge Test

Questions
in ILSES

Ask the clinical question.

Know when information is
needed.

2, 4, 5, 6, 7, 8, 9,
11, 16

1

Research for the best evidence.

Ability to access the needed
information through activities
such as database searches.

1, 3, 8, 9, 10, 11,
13, 14, 15, 16, 17,
18, 19, 21, 22

2, 3, 4, 5,
6, 7, 8, 9,
10, 11, 12

Critically appraise evidence.

Evaluate all information
obtained and determine what
information is pertinent to the
particular need.

4, 26

13, 14, 15,
16, 17, 18,
19

Address the sufficiency of the
evidence for implementation into
practice.

Proficiently use the
information in the task that
precipitated the need to gather
information.

Evaluate the outcome of evidence
implementation.

Use the new information
according to legal and ethical
standards.

20, 21, 26

12, 22, 23, 24, 25

22, 23, 24,
25

Note. Adapted from Information literacy competency standards for higher education by
American Library Association, 2000, Chicago, IL: American Library Association.
Retrieved from
http://www.ala.org/acrl/sites/ala.org.acrl/files/content/standards/standards.pdf and
“Transforming health care from the inside out: Advancing evidence-based practice in the
21st Century” by E. Fineout-Overholt and B. M. Melnyk, 2005, Journal of Professional
Nursing, 21(6), 335–343. doi:10.1016/j.profnurs.2005.10.005.

The analysis and reporting of IL information in this manner can also delineate
how students meet EBP competencies as defined by the Quality and Safety Education for
Nurses (QSEN) project. The project stratifies EBP competencies according to
knowledge, skill, and attitude (Armstrong, Spencer, & Lenburg, 2009; Brady, 2011).
The knowledge test can reflect EBP knowledge outcomes and the ILSES could reflect
EBP attitude outcomes. While these tests cannot holistically evaluate student skills,
educators can use the Richard Stockton College of New Jersey Information Literacy Test
and the ILSES in combination with course and clinical assignments to determine EBP
skill outcomes.
129

Dynamic Nature of Self-Efficacy as an Attribution for Behavior
As previously discussed, the poor response and completion rate raised questions
regarding the participants’ attitudes and perceptions regarding IL. Negative attitudes and
perceptions could have acted as an antecedent for not completing the survey. The
missing data may have reflected these negative perceptions regarding IL education and
knowledge. Just as positive IL self-efficacy can act as an attribute for motivating
students to use IL knowledge in multiple settings, negative IL self-efficacy could inhibit
students from engaging in IL related behaviors.
A student’s self-efficacy can influence how he or she perceives internal and
external motivators and how these motivators affect outcomes related to specific
behaviors (Bandura, 1977, 2012; Weiner, 1985, 2006). Thus, a person’s perceptions of
internal and external motivators can determine how much control the person has over a
specific situation or event (Bandura, 1977, 2012; Weiner, 1985, 2006). Positive selfefficacy is usually associated with an internal locus of control, an ability to control
external situations, a high sense of power, and a positive motivation for engaging in a
behavior. Negative self-efficacy accompanies an external locus of control, an inability to
control external situations, a poor sense of power, a negative motivation, and avoidance
of a behavior.
Negative self-efficacy is usually accompanied by an extrinsic goal orientation
such as luck. The negative perceptions associated with low self-efficacy could shape
students’ phenomenal causality, which could cause them to engage in behaviors based on
extrinsic goal orientation. Therefore, students will be motivated to behave reactively to
learning experiences and knowledge assessment. This extrinsic goal orientation can

130

coincide with lack of perceived control, which may reinforce the students’ negative
attitudes regarding IL. These negative attitudes and perceptions could act as an attribute
for avoiding activities associated with IL.
This scenario, exemplifying extrinsic goal orientation, illustrates how the
relationship between IL self-efficacy and proficiency is dynamic. Positive self-efficacy,
coupled with control and intrinsic goal orientation, could act as an antecedent for
engaging in IL behaviors, moving the gears forward in Figure 1. Negative self-efficacy,
coupled with instability, lack of control, and extrinsic motivators, could prevent the
student from engaging in IL behaviors. Negative self-efficacy as an antecedent for IL
behaviors would coincide with the gears moving backward in Figure 1 (Chapter 1, page
12).
Nurse educators must be aware of the dynamic nature of IL self-efficacy and its
effect on motivation. Identification of negative behaviors would allow the educator to
engage students in learning activities that target the affective domain to generate positive
experiences and positive IL self-efficacy perceptions. These learning activities could
promote the use of intrinsic goal orientation. Improving attitudes and perceptions
associated with IL self-efficacy could improve the students’ willingness to embark in IL
related activities.
Recommendations
Kiliç-Çakmak’s (2010) study results raised questions regarding the differences in
scores between students matriculating in a traditional undergraduate program and
undergraduate distance education students. Further research could be conducted between
traditional and distance education students to determine if these two populations have a

131

significant difference in ILSES scores. These studies could also assess the relationship
between learning styles and IL self-efficacy. Stokes’ and Urquhart’s (2011) research
indicated a significant relationship between IL self-efficacy and learning styles (X2 (3, N
= 194) = 8.684, p =.034). Students enrolled in distance education courses could have had
different learning styles than students enrolled in traditional didactic courses.
Additional research on IL self-efficacy and knowledge could include the
assessment of motivation. For example, the Motivational Strategies for Learning
Questionnaire used by Stokes and Urquhart (2011) assess motivational orientations such
as intrinsic goal orientation, extrinsic goal orientation, and control belief of learning
(Pintrich, Smith, Garcia, & McKeachie, 1991). The use of a questionnaire assessing
intrinsic and extrinsic orientation will help researchers identify how Weiner’s (1985,
1986, 2006, 2010) attributional theory of motivation applies to IL self-efficacy and
knowledge. For example, assessing perceptions of goal orientation would help identify
the students’ locus of causality. Nurse educators could help improve students who
behave according to extrinsic goal orientations to develop intrinsic motivators that
improve their IL related behavior beyond nursing school.
Future research could also assess motivational behaviors through a mixed method
format. Data collection instruments could be used to collect data on motivational
behavior, learning behaviors, IL self-efficacy, and IL knowledge. Qualitative interviews
could then be conducted to assess student perceptions of IL and capture the essence of
their individual experiences related to IL phenomenal causality. This information could
shed light on the basic tenants of Weiner’s (1985, 1986, 2006, 2010) theory, locus of
causality, stability, and causality. Furthermore, the interviews could ascertain student

132

views of EBP and professionalism. Researchers could triangulate qualitative data with
survey data to identify how motivational attributes shape IL behavior. A mixed methods
study may provide better understanding of IL self-efficacy, proficiency, and research
utilization in relation to Weiner’s (1985, 1986, 2006, 2010) attributional theory of
motivation.
Conclusion
Although the study had limitations concerning missing data and a homogeneous
population, the study yielded favorable results. The study revealed the data collection
tools performed reliably in a population of American nursing students and IL selfefficacy could act as a predictor for variances in knowledge. Information literacy selfefficacy levels accounted for 8% to 10% of the variability in IL knowledge. This
information substantiated the need for nurse educators to include learning activities
specific to the affective domain because IL self-efficacy could act as a positive or
negative motivator for using IL skills. The emotions associated with self-efficacy are
ingrained within the affective learning domain. Addressing the affective learning domain
in nursing courses may foster improved perceptions of IL and improve the ability of
students to use intrinsic motivators for engaging in IL related tasks. The data collection
tools -- the ILSES and the Richard Stockton College of New Jersey Information Literacy
Test -- demonstrated reliability for collecting data in American, pre-licensure,
baccalaureate nursing schools. Researchers could use these tools to collect IL
information related to student outcomes and tailor IL education to students’ unique needs,
thereby improving programs.

133

Dissertation Summary
Information literacy is the keystone of evidence-based patient centered quality
care (IOM, 2001). Evidenced-based practice entails the use of best research evidence,
which requires IL proficiency (IOM, 2001). Qualitative research indicated nursing
students might compartmentalize IL behavior to classroom activities and harbor negative
attitudes towards IL. The literature review indicated that educational interventions
improved IL knowledge. However, these interventions did not necessarily improve
students’ perceptions of IL. Student perceptions of IL can shape their IL self-efficacy, as
well as their ability to succeed in IL related behaviors.
This study aimed to analyze the relationship between IL self-efficacy and IL
proficiency. Kurbanoğlu and colleagues’ (2006) ILSES operationalized IL self-efficacy
and the Richard Stockton College of New Jersey Information Literacy Test developed by
Trail et al. (2006) operationalized proficiency. A pilot study demonstrated the reliability
of both data collection tools. The pilot study also indicated the ILSES had excellent
internal consistency.
A correlational analysis indicated a moderate relationship between IL selfefficacy and IL knowledge (N=86). The two hierarchical multiple regression models also
revealed that IL self-efficacy accounted for 8% to 10% of the variance in knowledge
scores. These results indicated that IL self-efficacy could act as a positive or negative
motivator for the use of IL skills. The emotions associated with self-efficacy are
grounded in the affective learning domain. This information validated the need for nurse
educators to address IL self-efficacy by using learning activities operating in the affective
domain.

134

Limitations to the study included poor response rate and poor survey completion
rate. The information associated with the students who did not complete the survey could
reflect negative IL self-efficacy levels and lower knowledge scores. Therefore, the study
results may have only represented nursing students who have higher IL self-efficacy
levels. These concerns limit the generalizability of the study results. Another limitation
of the study centers on the homogeneous study population. The participant population
was mainly female Caucasian students. This further limits the generalizability of the
results.
The results suggest researchers in nursing education could use the ILSES and the
Richard Stockton College of New Jersey Information Literacy Test to collect individual
and aggregate data. Nurse educators could use individual IL self-efficacy data to tailor
IL education to the needs of students and improve individual student outcomes.
Educators could apply the aggregate data collected by these tools to foster continuous
program improvement in baccalaureate nursing programs.

135

References
Accreditation Commission for Education in Nursing. (2013). Accreditation Manual:
Section 1 - General Information. Atlanta, GA: Author.
Adetoro, N., Simisaye, O. O., & Oyefuga, A. B. (2010). Relationship between perceived
self-efficacy and information literacy among library and information science
undergraduates in a Nigerian university of education. Ife PsychologIA, 18(2),
172–191.
Akkoyunlu, B., & Yİlmaz, A. (2011). Prospective teachers’ digital empowerment and
their information literacy self-efficacy. Eurasian Journal of Educational
Research, (44), 33–50.
American Association of Colleges of Nursing. (2008). The essentials of baccalaureate
education for professional nursing practice. Washington, DC: Author.
American Association of School Librarians and Association for Educational
Communications and Technology. (1998). Information literacy standards for
student learning. Chicago, IL: American Library Association.
American Library Association. (1989). Presidential committee on information literacy:
Final report. Chicago, IL: American Library Association. Retrieved from
http://www.ala.org/ala/mgrps/divs/acrl/publications/whitepapers/presidential.cfm
American Library Association. (2000). Information literacy competency standards for
higher education. Chicago, IL: American Library Association. Retrieved from
http://www.ala.org/acrl/sites/ala.org.acrl/files/content/standards/standards.pdf

136

Armstrong, G. E., Spencer, T. S., & Lenburg, C. B. (2009). Using Quallity and Safety
Education for Nurses to enhance competency outcome performance assessment:
A synergistic approach that promotes patient safety and quality outcomes. Journal
of Nursing Education, 48(12), 686–693. doi:10.3928/01484834-20091113-02
Association of College and Research Libraries. (2000). Information literacy competency
standards for higher education. Chicago, IL: American Library Association.
Retrieved from http://www.ala.org/ala/mgrps/divs/acrl/standards/standards.pdf
Attribution. (2013). Dictionary.com. Retrieved from
http://dictionary.reference.com/browse/attribution
Australian and New Zealand Institute for Information Literacy. (2004). Australian and
New Zealand information literacy framework: Principles, standards, and
practices (2nd ed.). Adelaide, Australia: Anzil University of South Australia
Library.
Bandura, A. (1977). Self-efficacy: Toward a unifying theory of behaviour change.
Psychological Review, 84(2), 191–215.
Bandura, A. (1986). The explanatory and predictive scope of self-efficacy theory.
Journal of Social and Clinical Psychology, 4(3), 359–373.
Bandura, A. (1997). Self-efficacy: The exercise of control. New York, NY: W.H.
Freeman.
Bandura, A. (2012). On the functional properties of perceived self-efficacy revisited.
Journal of Management, 38(1), 9–44. doi:10.1177/0149206311410606

137

Biddix, J. P., Chung, C. J., & Park, H. W. (2011). Convenience or credibility? A study of
college student online research behaviors. Internet and Higher Education, 14(3),
175–182.
Bond, C. S. (2010). Surfing or still drowning? Student nurses’ Internet skills. Nurse
Education Today, 30(5), 485–488. doi:10.1016/j.nedt.2009.11.005
Brady, D. S. (2011). Using quality and safety education for nurses (QSEN) as a
pedagogical structure for course redesign and content. International Journal of
Nursing Education Scholarship, 8(1), 1–18. doi:10.2202/1548-923X.2147
Bunce, S., Partridge, H., & Davis, K. (2012). Exploring information experience using
social media during the 2011 Queensland floods: A pilot study. Australian
Library Journal, 61(1), 34–45.
Bussert, L. (2011). Millennial students’ online search strategies are associated with their
mental models of search. Evidence Based Library & Information Practice, 6(3),
77–81. doi:10.1016/j.acalib.2010.10.003
Cameron, L., Wise, S. L., & Lottridge, S. M. (2007). The development and validation of
the Information Literacy Test. College & Research Libraries, 68(3), 229–236.
Cohen, J. W. (1988). Statistical power analysis for the behavioral sciences (2nd ed.).
Hillsdale, NJ: Lawrence Erlbaum.
comScore Data Mine. (2011). Google Reaches 1 billion global visitors. Retrieved from
http://www.comscoredatamine.com/2011/06/google-reaches-1-billion-globalvisitors/

138

Courey, T., Benson-Soros, J., Deemer, K., & Zeller, R. (2006). The missing link:
Information literacy and evidence-based practice as a new challenge for nurse
educators. Nursing Education Perspectives, 27(6), 320–323.
Demıralay, R., & Karadenız, Ş. (2010). The effect of use of information and
communication technologies on elementary student teachers’ perceived
information literacy self-efficacy. Educational Sciences: Theory & Practice,
10(2), 841–851.
DeVon, H. A., Block, M. E., Moyle-Wright, P., Ernst, D. M., Hayden, S. J., Lazzara, D.
J., … Kostas-Polston, E. (2007). A psychometric toolbox for testing validity and
reliability. Journal of Nursing Scholarship, 39(2), 155–164.
doi:10.1111/j.1547-5069.2007.00161.x
Duncan, V., & Holtslander, L. (2012). Utilizing grounded theory to explore the
information-seeking behavior of senior nursing students. Journal of the Medical
Library Association, 100(1), 20–27. doi:10.3163/1536-5050.100.1.005
Eldon, E. (2008, December 18). 2008 growth puts Facebook in better position to make
money. Retrieved from http://venturebeat.com/2008/12/18/2008-growth-putsfacebook-in-better-position-to-make-money/
Entwistle, N. J. (1997). The approaches and study skills inventory for students (ASSIST).
University of Edinburgh: University of Edinburgh Centre for Research on
Learning and Instruction.
Erdem, M. (2007). Self-efficacy levels of teachers in information and computer literacy.
World Applied Sciences Journal, 2(4), 399–405.

139

Facebook Inc. (2012). Securities and Exchange Commission: Form 8-K. Retrieved from
http://pdf.secdatabase.com/700/0001193125-12-316895.pdf
Ferguson, J. E., Neely, T. Y., & Sullivan, K. (2006). A baseline information literacy
assessment of biology students. Reference & User Services Quarterly, 46(2), 61–
71.
Fineout-Overholt, E., & Melnyk, B. M. (2005). Transforming health care from the inside
out: Advancing evidence-based practice in the 21st Century. Journal of
Professional Nursing, 21(6), 335–343. doi:10.1016/j.profnurs.2005.10.005
Folley, D. (2010). The lecture is dead long live the e-lecture. Electronic Journal of ELearning, 8(2), 93–100.
Freeman, E., & Lynd-Balta, E. (2010). Developing information literacy skills early in an
undergraduate curriculum. College Teaching, 58(3), 109–115.
doi:10.1080/87567550903521272
Geçer, A. K. (2012). An examination of studying approaches and information literacy
self-efficacy perceptions of prospective teachers. Eurasian Journal of
Educational Research, (49), 151–172.
Google Company. (n.d.-a). Facts about Google and competition. Retrieved from
http://www.google.com/competition/howgooglesearchworks.html
Google Company. (n.d.-b). Google: Our history in depth. Retrieved from
http://www.google.com/about/company/history/
Gross, M., & Latham, D. (2009). Undergraduate perceptions of information literacy:
Defining, attaining, and self-assessing skills. College & Research Libraries,
70(4), 336–350.

140

Gross, M., & Latham, D. (2011a). Experiences with and perceptions of information: A
phenomenographic study of first-year college students. Library Quarterly, 81(2),
161–186.
Gross, M., & Latham, D. (2011b). What’s skill got to do with it? Information literacy
skills and self-views of ability among first-year college students. Journal of the
American Society for Information Science and Technology, 63(3), 574–583.
doi:10.1002/asi.21681
Hebda, T., & Calderone, T. L. (2010). What nurse educators need to know about the
TIGER initiative. Nurse Educator, 35(2), 56–60.
Heider, F. (1958). The psychology of interpersonal relations. New York, NY: Wiley.
Henderson, F., Nunez-Rodriguez, N., & Casari, W. (2011). Enhancing research skills and
information literacy in community college science students. American Biology
Teacher, 73(5), 27–275. doi:10.1525/abt.2011.73.5.5
Hilbert, M., & López, P. (2011). The world’s technological capacity to store,
communicate, and compute information. Science, 332(6025), 60–65.
doi:10.1126/science.1200970
Institute of Medicine. (2001). Crossing the quality chasm: A new health system for the
21st century. Washington, DC: The National Academies Press.
Institute of Medicine. (2003). Health professions education: A bridge to quality.
Washington, DC: The National Academies Press.
Institute of Medicine. (2008). Evidence-based medicine and the changing nature of
health care: 2007 IOM annual meeting summary. Washington, DC: The National
Academies Press.

141

Institute of Medicine. (2011a). Digital infrastructure for the learning health system: The
Foundation for Continuous Improvement in Health and Health Care: Workshop
series summary. Washington, DC: The National Academies Press.
Institute of Medicine. (2011b). The future of nursing: Leading change, advancing health.
Washington, DC: The National Academies Press.
Jacobsen, H. E., & Andenæs, R. (2011). Third year nursing students’ understanding of
how to find and evaluate information from bibliographic databases and Internet
sites. Nurse Education Today, 31(8), 898–903. doi:10.1016/j.nedt.2011.01.003
Jones, E. E., Kanhouse, D. E., Kelley, H. H., Nisbett, R. E., Valins, S., & Weiner, B.
(1972). Attribution: Perceiving the causes of behavior. Morristown, NJ: General
Learning Press.
Kent State University. (2012). Validity and reliability of our assessment: Testing based
on ACRL information literacy standards. Retrieved from
https://www.projectsails.org/Validity
Kent State University. (2014a). Project SAILS: The individual assessment of information
literacy. Retrieved from https://www.projectsails.org/IndividualTest
Kent State University. (2014b). Testing and measurement that respects your budget.
Retrieved from https://www.projectsails.org/Pricing
Kent State University. (2014c). The cohort assessment of information literacy. Retrieved
from https://www.projectsails.org/CohortTest
Kent State University. (2014d). The individual assessment of information literacy.
Retrieved from https://www.projectsails.org/IndividualTest

142

Kent State University. (2014e). The start of our information literacy assessment.
Retrieved from https://www.projectsails.org/Background
Kiliç-Çakmak, E. (2010). Learning strategies and motivational factors predicting
information literacy self-efficacy of e-learners. Australasian Journal of
Educational Technology, 26(2), 192–208.
Klausegger, C., Sinkovics, R. R., & Zou, H. (2007). Information overload: A crossnational investigation of influence factors and effects. Marketing Intelligence &
Planning, 25(7), 691–718. doi:10.1108/02634500710834179
Klentzin, J. C. (2010). The borderland of value: Examining student attitudes towards
secondary research. Reference Services Review, 38(4), 557–570.
doi:10.1108/00907321011090728
Krathwohl, D. R., Bloom, B. S., & Masia, B. B. (1964). Taxonomy of educational
objectives: The classification of educational goals, handbook II: Affective
domain. New York, NY: David McKay.
Kurbanoğlu, S. S., Akkoyunlu, B., & Umay, A. (2006). Developing the information
literacy self-efficacy scale. Journal of Documentation, 62(6), 730–743.
doi:10.1108/00220410610714949
Kutluca, T. (2010). Investigation of teachers’ computer usage profiles and attitudes
towards computers. International Online Journal of Educational Sciences, 2(1),
81–97.
Ku, Y., Sheu, S., & Kuo, S. (2007). Efficacy of integrating information literacy education
into a women’s health course on information literacy for RN-BSN students.
Journal of Nursing Research, 15(1), 67–77.

143

Levett-Jones, T., Kenny, R., Van der Riet, P., Hazelton, M., Kable, A., Bourgeois, S., &
Luxford, Y. (2009). Exploring the information and communication technology
competence and confidence of nursing students and their perception of its
relevance to clinical practice. Nurse Education Today, 29(6), 612–616.
doi:10.1016/j.nedt.2009.01.007
Lunden, I. (2012, July 30). Analyst: Twitter Passed 500M users In June 2012, 140M Of
Them In US; Jakarta “Biggest Tweeting” city. Retrieved from
http://techcrunch.com/2012/07/30/analyst-twitter-passed-500m-users-in-june2012-140m-of-them-in-us-jakarta-biggest-tweeting-city/
Madison Assessment. (2013a). Information literacy test. Retrieved from
http://www.madisonassessment.com/assessment-testing/information-literacy-test/
Madison Assessment. (2013b). Online ordering agreement. Retrieved from
https://www.madisonassessment.com/order-now/
McNeil, B. J., Elfrink, V., Beyea, S. C., Pierce, S. T., & Bickford, C. J. (2006). Computer
literacy study: Report of qualitative findings. Journal of Professional Nursing,
22(1), 52–59.
McNeil, B. J., Elfrink, V. L., Bickford, C. J., Pierce, S. T., Beyea, S. C., Averiill, C., &
Klappenbach, C. (2003). Nursing information technology knowledge, skills, and
preparation of student nurses, nursing faculty, and clinicians: A U.S. survey.
Journal of Nursing Education, 42(8), 341–349.
McNeil, B. J., Elfrink, V. L., & Pierce, S. T. (2004). Preparing student nurses, faculty and
clinicians for 21st century informatics practice: Findings from a national survey

144

of nursing education programs in the United States. Studies in Health Technology
and Informatics, 107, 903–907.
McNeil, B. J., Elfrink, V., Pierce, S., Beyea, S., Bickford, C. J., & Averiill, C. (2005).
Nursing informatics knowledge and competencies: A national survey of nursing
education programs in the United States. International Journal of Medical
Informatics, 74(11/12), 1021–1030. doi:10.1016/j.ijmedinf.2005.05.010
Mertler, C. A., & Vannatta, R. A. (2013). Advanced and multivariate statistical methods.
Glendale, CA: Pyrczak.
National League for Nursing. (2012). Percentage of students enrolled in basic RN
programs by sex and program type, 2012. Retrieved from
http://www.nln.org/researchgrants/slides/pdf/AS1112_F29.pdf
Nayda, R., & Rankin, E. (2008). Information literacy skill development and life long
learning: Exploring nursing students’ and academics’ understandings. Australian
Journal of Advanced Nursing, 26(2), 27–33.
Neumann, J. A., & Forsyth, D. (2008). Teaching in the affective domain for institutional
values. Journal of Continuing Education in Nursing, 39(6), 248–252.
O’Reilly, T. (2005, September 30). What is Web 2.0? Design patterns and business
models for the next generation of software. Retrieved from
http://oreilly.com/web2/archive/what-is-web-20.html
Özkul, H., & Kaya, H. (2009). The views of nursing students about their own information
literacy. New Educational Review, 19(3/4), 45–57.
Pallant, J. (2010). SPSS survival manual (4th ed.). New York, NY: McGraw-Hill.

145

Pennsylvania State Board of Nursing. (2013). NCLEX-RN performance of first time
candidates educated in Pennsylvania who completed NCLEX in the U.S.
Retrieved from
http://www.portal.state.pa.us/portal/server.pt/community/state_board_of_nursing/
12515/list_of_approved_nursing_programs/572050
PEW Research Center. (2010). Millennials: Conficent. Connected. Open to change.
Retrieved from http://www.pewsocialtrends.org/files/2010/10/millennialsconfident-connected-open-to-change.pdf
Pinto, M. (2010). Design of the IL-HUMASS survey on information literacy in higher
education: A self-assessment approach. Journal of Information Science, 36(1),
86–103. doi:10.1177/0165551509351198
Pinto, M. (2011). An approach to the internal facet of information literacy using the ILHUMASS survey. Journal of Academic Librarianship, 37(2), 145–154.
Pintrich, P. R., Smith, D. A., Garcia, T., & McKeachie, W. J. (1991). A manual for the
use of the Motivated Strategies for Learning. Michigan, WI: The University of
Michigan.
Polit, D. F., & Beck, C. T. (2012). Nursing research: Generating and assessing evidence
for nursing practice (9th ed.). Philadelphia, PA: Lippincott Williams & Williams.
Proficient. (2013). Dictionary.com. Retrieved from
http://dictionary.reference.com/browse/proficiency
Radcliff, C. J., Salem, J. A., O’Connor, L. G., & Gedeon, J. A. (2007). Project SAILS
skill sets for the 2012-2013 academic year. Retrieved from
https://www.projectsails.org/SkillSets

146

Rainie, L., Smith, A., & Duggan, M. (2013, February 5). Pew Internet: Coming and going
on Facebook. Retrieved from http://www.pewinternet.org/Reports/2013/Comingand-going-on-facebook/Key-Findings.aspx
Reed, K., Doty, D. H., & May, D. R. (2005). The impact of aging on self-efficacy and
computer skill acquisition. Journal of Managerial Issues, 17(2), 212–228.
Rice, L., Barth, J., Guadagno, R., Smith, G., & McCallum, D. (2013). The role of social
support in students’ perceived abilities and attitudes toward math and science.
Journal of Youth & Adolescence, 42(7), 1928–1949.
doi:10.1007/s10964-012-9801-8
Robb, M. (2012). Self-efficacy with application to nursing education: A concept analysis.
Nursing Forum, 47(3), 166–172. doi:10.1111/j.1744-6198.2012.00267.x
Rotter, J. B. (1966). Generalized expectancies for internal versus external control of
reinforcement. Psychological Monographs, 80(1), 1–28.
Rotter, J. B. (1990). Internal versus external control of reinforcement: A case history of a
variable. American Psychologist, 45(4), 489–493.
Salisbury, F., & Karasmanis, S. (2011). Are they ready? Exploring student information
literacy skills in the transition from secondary to tertiary education. Australian
Academic & Research Libraries, 42(1), 43–58.
Schoonover, H. (2009). Barriers to research utilization among registered nurses
practicing in a community hospital. Journal for Nurses in Staff Development,
25(4), 199–212. doi:10.1097/NND.0b013e3181ae145f
Shepard, C., & Mullane, A. M. (2010). Managing multimedia mania: Taming the
technology beast. Journal of College Teaching & Learning, 7(1), 59–70.

147

Shephard, K. (2008). Higher education for sustainability: Seeking affective learning
outcomes. International Journal of Sustainability in Higher Education, 9(1), 87–
98. doi:10.1108/14676370810842201
Society of College, National and University Libraries. (1999). Information skills in
higher education: A SCONUL position paper. Retrieved from
http://392274175.webhosting.wanadoo.nl/informationskillsUK_SCONUL.pdf
Soper, D. (2013). Statistics calculators. Retrieved from
http://www.danielsoper.com/statcalc3/calc.aspx?id=1
Stokes, P., & Urquhart, C. (2011). Profiling information behaviour of nursing students:
Part 1: Quantitative findings. Journal of Documentation, 67(6), 908–932.
doi:10.1108/00220411111183528
Tanner, A., Pierce, S., & Pravikoff, D. (2004). Readiness for evidence-based practice:
Information literacy needs of nurses in the United States. Studies In Health
Technology and Informatics, 107, 936–940.
Trail, M. A., Gutierrez, C., & Lechner, D. (2006). Reconsidering a traditional instruction
technique: Reassessing the print workbook. The Journal of Academic
Librarianship, 32(6), 632–640. doi:10.1016/j.acalib.2006.07.003
Trail, M. A., & Lechner, D. (2012). Prior knowledge of information literacy [PowerPoint
slides].
Tuncer, M. (2013). An analysis on the effect of computer self-efficacy over scientific
research self-efficacy and information literacy self-efficacy. Educational
Research and Reviews, 81(1), 33–40. doi:10.5897/ERR12.122

148

Wallace, M. C., Shorten, A., & Crookes, P. A. (2000). Teaching information literacy
skills: An evaluation. Nurse Education Today, 20(6), 485–489.
doi:10.1054/nedt.1999.0439
Weiner, B. (1976). An attributional approach for educational psychology. Review of
Research in Education, 4(1), 179–209. doi:10.3102/0091732X004001179
Weiner, B. (1985). An attributional theory of achievement motivation and emotion.
Psychological Review, 92(4), 548–573.
Weiner, B. (1986). An attributional theory of motivation and emotion. New York, NY:
Springer-Verlag.
Weiner, B. (2000). Intrapersonal and interpersonal theories of motivation from an
attributional perspective. Educational Psychology Review, 12(1), 1–14.
Weiner, B. (2006). Social motivation, justice, and the moral emotions: An attributional
approach. Mahwah, NJ: Lawrence Erlbaum.
Weiner, B. (2008). Reflections on the history of attribution theory and research: People,
personalities, publications, problems. Social Psychology, 39(3), 151–156.
doi:10.1027/1864-9335.39.3.151
Weiner, B. (2010). The development of an attribution-based theory of motivation: A
history of ideas. Educational Psychologist, 45(1), 28–36.
doi:10.1080/00461520903433596
Weiner, B. (2011). Ultimate and proximal determinants of motivation given an attribution
perspective and the metaphors guiding attribution theory. Group & Organization
Management, 36(4), 526–532. doi:10.1177/1059601111410564

149

Wise, S. L., Cameron, L., Yang, S., & Davis, S. L. (2009). The Information Literacy Test
(ILT) test manual. Retrieved from
http://www.jmu.edu/assessment/pdfDocs/ILT%20Test%20Manual%202010.pdf
Witek, D., & Grettano, T. (2012). Information literacy on Facebook: An analysis.
Reference Services Review, 40(2), 242–257. doi:10.1108/00907321211228309
Yilmaz, K. (2008). Constructivism: Its theoretical underpinnings, variations, and
implications for classroom instruction. Educational Horizons, 86(3), 161–172.

150

Appendix A
Information Literacy Self-Efficacy Scale (28-Item Survey)
This scale has been prepared to determine your level of efficacy on issues related to the
information (to ﬁnd, use, and communicate information). Here the notations shall be
referred to as 7 = almost always true, 6 = usually true, 5 = often true, 4 = occasionally
true, 3 = sometimes but infrequently true, 2 = usually not true, 1 = almost never true.
Please mark the most suitable choice for you. Thank you for your cooperation.
I feel confident and competent that I can:
*Deﬁne the information I need

1

2

3

4

5

6

7

Identify a variety of potential sources
of information

1

2

3

4

5

6

7

Limit search strategies by subject,
language and date

1

2

3

4

5

6

7

Initiate search strategies by using
keywords and Boolean logic

1

2

3

4

5

6

7

Decide where and how to ﬁnd the
information I need

1

2

3

4

5

6

7

*Use different kinds of print sources
(i.e., books, periodicals, encyclopedias,
chronologies)

1

2

3

4

5

6

7

*Use electronic information sources

1

2

3

4

5

6

7

*Locate information sources in the
library

1

2

3

4

5

6

7

*Use library catalogue

1

2

3

4

5

6

7

*Locate resources in the library using
the library catalogue

1

2

3

4

5

6

7

Use Internet search tools (such as
search engines, directories, and so on)

1

2

3

4

5

6

7

Use different kinds (types) of libraries

1

2

3

4

5

6

7

Use many resources at the same time to
make a research

1

2

3

4

5

6

7

Determine the authoritativeness,
currentness, and reliability of the
information sources

1

2

3

4

5

6

7

*Select information most appropriate
to the information need

1

2

3

4

5

6

7

Identify points of agreement and
disagreement among sources

1

2

3

4

5

6

7

This scale has been prepared to determine your level of efficacy on issues related with the
information (to ﬁnd, use, and communicate information). Here the notations shall be
referred to as 7 = almost always true, 6 = usually true, 5 = often true, 4 = occasionally
true, 3 = sometimes but infrequently true, 2 = usually not true, and 1 = almost never true.
Please mark the most suitable choice for you. Thanks for your cooperation.

Evaluate www sources

1

2

3

4

5

6

7

*Synthesize newly gathered information with
previous information

1

2

3

4

5

6

7

*Interpret the visual information (i.e., graphs,
tables, diagrams)

1

2

3

4

5

6

7

*Write a research paper

1

2

3

4

5

6

7

*Determine the content and form the parts
(introduction, conclusion) of a presentation
(written, oral)

1

2

3

4

5

6

7

*Prepare a bibliography

1

2

3

4

5

6

7

*Create bibliographic records and organize the
bibliography

1

2

3

4

5

6

7

*Create bibliographic records for different kinds
of materials (i.e., books, articles, Web pages)

1

2

3

4

5

6

7

*Make citations and use quotations within the text

1

2

3

4

5

6

7

Choose a format (i.e., written, oral, visual)
appropriate to communicate with the audience

1

2

3

4

5

6

7

*Learn from my information problem-solving
experience and improve my information literacy
skill

1

2

3

4

5

6

7

*Criticize the quality of my information-seeking
process and its products

1

2

3

4

5

6

7

* Statements on the 17-item scale

152

Appendix B
Letter of Permission to Use the Information Literacy Self-Efficacy Scale

153

154

Appendix C
Richard Stockton College of New Jersey Information Literacy Test: 2005
Circle the best answer for each question.
1. Suppose you want to extract from a periodical database all articles that contain
references both to ‘‘psychosis’’ as well as to ‘‘depression’’ (in the same article). Select
the expression below that uses the Boolean operator you should use to link the two parts
of the search statement.
1. Psychosis ALSO Depression
2. Psychosis OR Depression
3. Psychosis NOR Depression
4. Psychosis AND Depression
5. Psychosis NOT Depression
2. You are searching a periodical database, and the results list is huge. Which of the
following ways can you use to refine a search and to make it more specific?
Limit the search to:
1. Articles by a particular author
2. Articles in a specific periodical title
3. Articles printed on a certain date or year
4. All of the above
5. 1 and 3

3. Performing a subject search in the library catalog on global warming will likely give
you the same results as a keyword search.
1. True
2. False
4. If I am looking for journal articles for a term paper topic, which of these statements
reflects the BEST course of action?
1. I can use any good Web search engine such as Yahoo or Google
2. I need to use an index that searches for scholarly periodical articles
3. I should use the library’s catalog
4. I should use an index that broadly searches for periodical articles
5. Which of the following is a characteristic of scholarly journal articles?
1. Articles include descriptions of the research methods
2. Articles are heavily supported through advertising
3. Articles use non-technical language
4. Articles are considered secondary resources
6. The quickest way to begin to focus your topic is to put your topic in the form of a
question.
1. True
2. False

156

7. Which of the following is a characteristic of scholarly journals?
1. They are relatively inexpensive
2. They are available for sale in the university’s bookstore
3. They are multidisciplinary
4. They have a glossy format
5. They are found in academic libraries
8. When choosing a periodical database to use, what is the BEST way to tell what
subjects are covered by a database?
1. Do a search and check the results
2. Ask a librarian
3. It doesn’t matter, as all databases cover most journals anyway
4. Look for a help screen describing the database
5. Check a major journal
9. When trying a subject search using the Stockton Library’s catalog, you typed in the
words ‘‘police brutality.’’ The search did not produce any results. What do you do next?
1. Use a different terminal or computer
2. Identify a synonym for police brutality
3. Put quotes around the phrase ‘‘police brutality’’
4. Go to a different library
5. Surf the Internet

157

10. Which of the following are advantages of a controlled vocabulary?
1. Your can be sure that these terms appear in the database
2. You, the searcher, have ultimate control over search terms
3. You have to think of all the different possible terms your subject could be
called
4. Your search may be a very broad search
11. What is ‘‘peer review’’?
1. A system of revision first carried out by the English House of Lords. In
America, the Senate takes the place of the House of Lords under the vice
president.
2. A process for checking that other experts in the field before publication has
examined academic articles.
3. A process for guaranteeing that all articles are 100% true by having experts
read them before they are published.
4. A process for examining research material and checking results using a
microscope.
12. I can use something I find in my research in my paper without citing the source if I
rewrite it in my own words.
1. True
2. False

158

Use the information given below to answer questions 13–15.

13. What is the title of the journal?
1. SocialSci Abs
2. American Psychologist
3. Getting Academic Jobs
4. H. W. Wilson
5. Women College Teachers
14. What is the title of the article?
1. SocialSci Abs
2. American Psychologist
3. Getting Academic Jobs
4. H. W. Wilson
5. Women College Teachers
15. What is the date the article was published?
1. 1986
2. 1987
3. 1988
4. 1989
5. 1941

159

16. Why would I use a database that is not full text?
1. I wouldn’t, because all the library’s electronic periodicals are full text.
2. A very good article in a peer-reviewed journal on your topic may not be
available in a full text database.
3. Stockton may have the full text journal in the periodicals room.
4. If Stockton does not have the article either in print or electronically, I can order
it through Interlibrary Loan.
5. 2, 3, and 4

17. The above screen comes from the Library’s Catalog. What is the citation above for?

1. Book
2. Periodical
3. Thesis
4. Website
5. Dissertation
160

18. Stockton Library databases such as Academic Search Premier can only be used in the
library.
1. True
2. False
19. The advanced search mode on Google allows for limiting your search to a particular
domain.
1. True
2. False
20. Where can you find a model of how to cite a Web page?
1. Hacker’s A Writer’s Reference
2. Library’s Web Page
3. Ready Reference Shelves in the Library
4. All of the above

161

21. What is the citation above for?
1. Book
2. Journal
3. Thesis
4. Government Document
5. Dissertation
22. Is using a periodical database, such as Academic Search Premier (ASP), the same as
using the Internet?
1. Yes, the articles are duplicated from ASP to the Internet.
2. Yes, generally speaking, all databases are the same.
3. No, material on ASP first appeared in published magazines and journals.
4. Yes, like articles on ASP, the Internet also has consistent editorial overview.

23. What of the following forms of intellectual property are covered by copyright?

162

1. Architecture
2. Computer programs
3. Movies
4. Songs
5. All of the above
24. Why is it necessary to cite the sources you use?
1. To avoid committing plagiarism
2. To give credit to the work of the original authors or creators
3. Because my college requires it
4. 1, 2, and 3 are correct
25. Everything on the Web is in the public domain and can be used without permission.
1. True
2. False

163

Appendix D
Richard Stockton College of New Jersey Information Literacy Test: 2013
Prior Knowledge of Information Literacy
1. How do you know when you do not need peer-reviewed information? You are:
1) working on an assignment
2) placing a bar bet
3) making a purchase
4) voting
5) choosing your courses
2. Once you have an idea for a research paper, which of the following is the best next step
for conducting the research?
1) Try your idea out on your peers (classmates).
2) Put your idea into the form of a question.
3) Read a book on the topic.
4) Do a Web search.
5) Write down all that you know about the topic.
3. Of the following tools, select the three (3) best for current, reliable background
information on your topic.
1) Wikipedia
2) General encyclopedias
3) Faculty/Librarian
4) Textbooks
5) Scholarly journals

164

6) Specialized encyclopedias
4. Which of the following characteristics of a topic will LEAST help you develop a good
research question about it?
1) The experts do not agree.
2) A great deal of research has already been done on it.
3) It is broad, allowing for multiple lines of research.
4) You already wrote about it in high school.
5) There is no obvious answer.
6) You’re passionate about it.
The next slide uses Boolean operators to organize a search for the research topic listed
at the top. Choose the best search combination.
5. How is security provided for public transportation systems other than for airplanes?
1) “Transportation” AND “security” OR “airplanes”
2) “Security” AND “public transportation” NOT “airplanes”
3) “Security” AND “public transportation”
4) “Transportation security” NOT “airplanes”
6. In which of the following ways do journals differ from magazines?
1) Magazines cover specific time periods.
2) Journals are aimed at popular audiences.
3) Magazines are published for profit.
4) Journal articles are typically shorter.
7. Information can be found in print, electronic, and human sources. What
characteristics do these varied media types usually share?

165

1) Time period covered
2) Depth or quality of information
3) Peer review
4) Supported mostly by advertising
5) Always scholarly
8. Today, with Google and Google Scholar, virtually all information is available on the
Internet.
1. True
2. False
9. Which three (3) of the following are true and therefore make libraries more reliable
sources of information than the Internet is?
1) They offer scholarly materials not available on the Internet.
2) The librarians have not vetted the databases.
3) “Invisible Web” information is usually searched by search engines anyway.
4) The collections offer in-depth information from varied perspectives.
5) Trained, professional librarians can suggest a range of alternative sources.
10. Which of the following is characteristic of scholarly journals?
1) Their reference lists are optional.
2) They have high circulation.
3) The authors are journalists.
4) The articles include research methods.
5) They are available in larger bookstores.

166

11. Which two (2) of the following domain types would you consider reliable sources of
information?
1) .org
2) .biz
3) .mil
4) .edu
5) .gov
6) .com
7) .net
12. Which of the strategies listed below is one of the BEST ways to evaluate a website?
1) By how much advertising is on the site
2) By whether or not the website has been given awards
3) Because another person recommended it
4) Because the author or organization responsible is identified
13. Why is it necessary to cite the source you use?
1) To lend credibility to your work
2) To show evidence of research
3) To give credit to the original authors
4) To allow the reader to examine your sources
5) 1 and 2 are correct.
6) 1, 2, and 3 are all correct.
7) 1, 2, 3, and 4 are all correct.
14. Only books and journal articles need to be cited in a research paper.

167

1) True
2) False
15. I may only use short excerpts from the Internet in my paper because
1) … of copyright law restrictions.
2) … of the college’s paper use reduction requirement.
3) … it helps focus my intent.
4) … long excerpts are usually construed as plagiarism.
5) 1 and 3 are both correct.
6) 2 and 4 are both correct.
16. Which two (2) of the following are not “common knowledge” and need to be cited?
Familiar dates: July 4th is “Independence Day”
1) Familiar quotes such as “Four score and seven years ago …”
2) Numbers & statistics such as the population of Atlantic City
3) Simple chemical formulae like H2O
4) Familiar phrases such as “Look before you leap”
Please pass your clicker forward.
Open the library’s homepage on your computer.
Write your name and your faculty member’s name on the cover of your workbook.

168

Appendix E
Revised Version of Richard Stockton College of New Jersey Information Literacy Test
Used in Study
Circle the best answer for each question.
1. Suppose you want to extract from a periodical database all articles that contain
references both to ‘‘psychosis’’ as well as to ‘‘depression’’ (in the same article). Select
the expression below that uses the Boolean operator you should use to link the two parts
of the search statement.
1) Psychosis ALSO Depression
2) Psychosis OR Depression
3) Psychosis NOR Depression
4) Psychosis AND Depression
5) Psychosis NOT Depression
2. You are searching a periodical database, and the results list is huge. Which of the
following ways can you use to refine a search and to make it more specific?
Limit the search:
1) To articles by a particular author
2) To articles in a specific periodical title
3) To articles printed on a certain date or year
4) All of the above
5) 1 and 3

169

3. Performing a subject search in the library catalog on global warming will likely give
you the same results as a keyword search.
1) True
2) False
4. If I am looking for journal articles for a term paper topic, which of these statements
reflects the BEST course of action?
1) I can use any good Web search engine such as Yahoo or Google.
2) I need to use an index that searches for scholarly periodical articles.
3) I should use the library’s catalog.
4) I should use an index that broadly searches for periodical articles.
5. Which of the following is a characteristic of scholarly journal articles?
1) Articles include descriptions of the research methods.
2) Articles are heavily supported through advertising.
3) Articles use non-technical language.
4) Articles are considered secondary resources.
6. The quickest way to begin to focus your topic is to put your topic in the form of a
question.
1) True
2) False

170

7. Which of the following is characteristic of scholarly journals?
1) They are relatively cheap.
2) They are available for sale in the college’s bookstore.
3) They are multidisciplinary.
4) They have a glossy format.
5) They are found in academic libraries.
8. When choosing a periodical database to use, what is the BEST way to tell what
subjects are covered by a database?
1) Do a search and check the results.
2) Ask a librarian.
3) It doesn’t matter, as all databases cover most journals anyway.
4) Look for a help screen describing the database.
5) Check a major journal.
9. When trying a subject search using the Name of Local Library catalog, you typed in
the words ‘‘police brutality.’’ The search did not produce any results. What do you do
next?
1) Use a different terminal or computer.
2) Identify a synonym for police brutality.
3) Put quotes around the phrase ‘‘police brutality.’’
4) Go to a different library.
5) Surf the Internet.

171

10. Which of the following are advantages of a controlled vocabulary?
1) Your can be sure that these terms appear in the database.
2) You, the searcher, have ultimate control over search terms.
3) You have to think of all the different possible terms your subject might be called.
4) Your search may be a very broad search.
11. What is ‘‘peer review’’?
1) A system of revision first carried out by the English House of Lords. In America,
the Senate takes the place of the House of Lords under the vice president.
2) A process for checking that other experts in the field before publication have
examined academic articles.
3) A process for guaranteeing that all articles are 100 percent true by having experts
read them before they are published.
4) A process for examining research material and checking results using a
microscope.
12. I can use something I find in my research in my paper without citing the source if I
rewrite it in my own words.
1) True
2) False

172

Use the information given below to answer questions 13–15.

13. What is the title of the journal?
1) SocialSci Abs
2) American Psychologist
3) Getting Academic Jobs
4) H. W. Wilson
5) Women college teachers
14. What is the title of the article?
1) SocialSci Abs
2) American Psychologist
3) Getting Academic Jobs
4) H. W. Wilson
5) Women college teachers
15. What is the date the article was published?
1) 1986
2) 1987
3) 1988
4) 1989
5) 1941

173

16. Why would I use a database that is not full text?
1) I wouldn’t, because all the library’s electronic periodicals are full text.
2) A very good article in a peer-reviewed journal on your topic may not be available
in a full text database.
3) Stockton may have the full text journal in the periodicals room.
4) If Stockton does not have the article either in print or electronically, I can order it
through Interlibrary Loan.
5) 2, 3, and 4

174

17. The above screen comes from the Library’s catalog. What is the citation above for?
1) Book
2) Periodical
3) Thesis
4) Website
5) Dissertation
18. Name of Local Library databases such as Academic Search Premier can only be used
in the Library.
1) True
2) False

175

(If Academic Search Premier is not available through a local university library, the name
of an electronic database available through the library (i.e., CINAHL or OVID) will be
inserted in this sentence.)
19. The advanced search mode on Google allows for limiting your search to a particular
domain.
1) True
2) False
20. Where can you find a model of how to cite a Web page?
1) American Psychological Association Publication Manual
2) Library’s Web Page
3) Ready Reference Shelves in the Library
4) All of the above

176

21. What is the citation above for?
1) Book
2) Journal
3) Thesis
4) Government Document
5) Dissertation
22. Is using a periodical database, such as Academic Search Premier (ASP), the same as
using the Internet?
1) Yes, the articles are duplicated from ASP to the Internet.
2) Yes, generally speaking, all databases are the same.
3) No, material on ASP first appeared in published magazines and journals.
4) Yes, as with articles on ASP, the Internet also has consistent editorial overview.

177

23. What of the following forms of intellectual property are covered by copyright?
1) Architecture
2) Computer programs
3) Movies
4) Songs
5) All of the above
24. Why is it necessary to cite the sources you use?
1) To lend credibility to your work
2) To show evidence of research
3) To give credit to the original authors
4) To allow the reader to examine your sources
5) 1 and 2 are correct.
6) 1, 2, and 3 are all correct.
7) 1, 2, 3, and 4 are all correct.
25. Everything on the Web is in the public domain and can be used without permission.
1) True
2) False

178

26. Which two (2) of the following domain types would you consider reliable sources of
information?
1) .org
2) .biz
3) .mil
4) .edu
5) .gov
6) .com
7) .net

179

Appendix F
Letter of Permission to Use the Revised Version of Richard Stockton College of New
Jersey Information Literacy Test

180

Appendix G
Cover Letter to Institutions – Pilot Study Participant Recruitment

181

182

Appendix H
Cover Letter to Institutions –Participant Recruitment

183

184

185

186

187

188

189

190

191

192

Appendix I
Informed Consent for Pilot Study
(Consent was printed on IUP letterhead.)
You are invited to participate in this research study. The following information is provided in
order to help you to make an informed decision whether or not to participate. If you have any
questions please do not hesitate to ask. You are eligible to participate because you are a senior,
pre-licensure, nursing student at Wilkes University.
The purpose of this survey is to assess the reliability of a survey to measure the ability of senior
nursing students to gather and use information. Study participants will complete the survey two
different times. The researcher will analyze the answers from the two different submissions to
determine if the survey is consistent in measuring the ability of senior nursing students to collect
and use information. This is a minimal risk study. You may experience some frustration when
answering the survey questions. If you do experience any frustration, you can seek help from
your university’s health or counseling services.
After consenting to participate in this study, you will take a survey two times. You will complete
the first survey after signing this informed consent form. Next, you will retake the survey in
approximately two weeks. It will take approximately 10 to 15 minutes to complete the survey.
The more students that complete the survey both times, the more accurate the data analysis will
be. To compensate you for your time in completing the surveys, all students who complete both
surveys will be entered in a drawing to win a $50 Visa gift card.
When you complete the survey, you will print your name and email address on the cover sheet.
The researcher will use the coversheets to match the two surveys you complete. Once the
researcher matches both of your surveys, she will remove the cover sheets so that no one can link
your name with your survey answers. After the coversheets are removed, the researcher will use
letter and numbers to identify each survey.
The researcher will use the coversheets as an entry in the drawing for the $50 gift card. This
coversheets will be folded up and placed in a box. The researcher will randomly draw a name out
of the box. The winner will be contacted by email. The winner will respond to the email and list
a mailing address for the researcher. The researcher will then mail the gift card to the winner
using certified, priority, flat rate mail. The winner must reply to the researchers email within
three weeks. If the winner does not respond to the email in three weeks of the date the
notification email was sent, the researcher will draw another name from the box of coversheets.
The researcher will email the person listed on this coversheet to tell them that they won the gift
card. The researcher will mail the gift card to the winner as earlier describe. This process will
continue until a winner accepts the gift card. Once the gift card is mailed to the winner, the
researcher will shred all coversheets and dispose of the shreddings using the local waste
management company.
Your participation in this study is voluntary. You are free to decide not to participate in this study
or to withdraw at any time without adversely affecting your relationship with the research
investigator or your nursing instructors at Wilkes University. Your decision to participate or not

193

participate will not affect any of your grades or any loss of benefits to which you are otherwise
entitled. If you choose to participate, you may withdraw at any time by notifying the researcher
or informing the person administering the survey. If you request to withdraw from the study
before the researcher removes your coversheets, your all information pertaining to you will be
destroyed. Once the coversheets are removed from the surveys, the researcher will not know
which survey is yours and will not be able to remove your answers from the data analysis.
If you choose to participate, all information will be held in strict confidence and will have no
bearing on your academic standing or services you receive from the University. The survey is
confidential and your answers will not be shared with any of your teachers. Your survey answers
will be considered only in combination with those from other participants. The data analysis will
focus on all participant answers and will not report individual responses. The information
obtained in the study may be published in scientific journals or presented at scientific meetings
but your identity will be kept confidential.
If you are willing to participate in this study, please sign the statement below and return it to the
person administering the survey. If you wish to receive results of the study, please email the
researcher using the contact information below.
Researcher:
Pennsylvania

Camille Wendekier, PhD candidate, Indiana University of
P.O. Box 303
Carrolltown, PA 15722
814-312-5939
lndk@iup.edu

Faculty Advisor:

Dr. Theresa Gropelli
Department of Nursing and Allied Health Profession
1010 Oakland Avenue, 232 Johnson Hall
Indiana, PA 15705
724-357-3264
Theresa.Gropelli@iup.edu

This project has been approved by the Indiana University of Pennsylvania Institutional Review Board for
the Protection of Human Subjects (Phone: 724/357-7730).
VOLUNTARY CONSENT FORM:
I have read and understand the information on the form and I consent to volunteer to be a subject
in this study. I understand that my responses are completely confidential and that I have the right
to withdraw at any time. I have received an unsigned copy of this informed Consent Form to
keep in my possession.
Name (PLEASE PRINT)
Signature

Date

194

Appendix J
Email to Potential Study Participants
Hello,
My name is Camille Wendekier and I am a nursing PhD candidate at the Indiana University of
Pennsylvania. I am working on my dissertation titled, Information Literacy: Correlation of SelfEfficacy and Proficiency. To complete my research, I am collecting information from senior
nursing students through an electronic survey. Can you help me by completing this short online
survey? I am asking you to take the survey because you are a senior baccalaureate nursing
student. The purpose of this survey is to evaluate senior nursing students’ ability to find and use
information. You will not provide any identifying information on the survey. I will not be able
to track your answer back to you. This invitation to participate in my survey was sent to you by
people who already had access to your directory information. I do not have access to your email
addresses. Therefore, you will remain anonymous.
This survey will take approximately 10 to 15 minutes to complete. After you complete the
survey, you will be directed to a different Internet site where you can enter a drawing for a $50
Visa gift card. The information you use to enter the drawing is not connected to the survey
answers so that no one can track your name to your answers. If you are willing to take the
survey, please click on the link below. If you have any trouble with the link below, or any
questions regarding the study, please email me at C.M.Wendekier@iup.edu.
Thank you for helping me! I truly appreciate your time and support!
Follow this link to the Survey:
https://iup.co1.qualtrics.com/SE/?SID=SV_0DnRBcZwY8rGD0F
Sincerely,
Camille Wendekier, PhD candidate
Indiana University of Pennsylvania
Department of Nursing and Allied Health Professions, Johnson Hall
PhD in Nursing Program
1010 Oakland Avenue, Johnson Hall
Indiana, PA 15701
814-312-5939

Faculty
Advisor:

Dr. Theresa Gropelli
Department of Nursing and Allied Health Profession
1010 Oakland Avenue, 232 Johnson Hall
Indiana, PA 15705
724-357-3264
Theresa.Gropelli@iup.edu

195

Appendix K
Consent Statement on Qualtrix Survey

Dear senior nursing student,
Thank you very much for helping me by completing this short survey. I truly appreciate
you time and support! The purpose of this research is to learn the ability of nursing
students to gather and use information. This survey will evaluate your confidence and
knowledge in gathering and using information. The only foreseeable risk to participate in
this research is becoming frustrated when answering the survey questions. If you become
upset when answering any of the questions, you can go to your university or counseling
services to talk about your feelings.
Please remember that your participation in this study is voluntary. You are free to decide
not to participate in this study or to withdraw at any time without adverse consequences.
When you submit your answers for the electronic survey, there is no way I can link your
responses to your name. Qualtrics, the software that delivers the survey, removes all
identifiers from your responses. Once you complete the survey, I will not be able to
remove your responses because I will not know which responses are yours. Any
incomplete surveys will not be used in data analysis. Your survey answers will be
considered only in combination with those from other participants. The information obtained in
the study may be published in scientific journals or presented at scientific meetings but your
identity will be kept confidential. If you would like a copy of the results, please email at
C.M.Wendekier@iup.edu.

If you choose to, you can enter a drawing to win one of two $50 Visa gift cards. At the
end of the survey, you will be redirected to an independent website that will contain a
form for entering the drawing. There is no way to link any information from drawing
entries to the survey responses so that your survey answers will remain confidential.
If you are willing to participate in this study, please indicate your consent by clicking on
the first response.
o Yes
o No

196

Appendix L
IRB Approval: Indiana University of Pennsylvania

197

198

Appendix M
IRB Approval: Wilkes University, Carlow University, Drexel University, and Mansfield
University

Wilkes University Approval for Pilot Study:

199

Carlow University:

200

201

Drexel University:

202

Mansfield University:

203

Appendix N
Change of Protocol Approval for Recruiting Study Participants From Indiana University
of Pennsylvania

204

Appendix O
Change of Protocol Approval for Recruiting Study Participants From Pennsylvania State
University
IUP Letter of Approval:

205

206

Pennsylvania State University Letter of Approval:

207

208

209

Appendix P
Change of Protocol Approval for Recruiting Study Participants From Saint Francis
University
IUP Letter of Approval:

210

Saint Francis University Letter of Approval:

211

