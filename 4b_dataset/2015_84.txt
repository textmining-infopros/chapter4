The Applicability of ESQUAL for Assessing the Service Quality
of Social Media Services in Academic Libraries

A Thesis
Submitted to the Faculty
of
Drexel University
by
Hae Min Kim
in partial fulfillment of the
requirements for the degree
of
Doctor of Philosophy
May 2015

UMI Num b e r: 3705493

All rig hts re se rve d
INFO RMATIO N TO ALL USERS
The q ua lity o f this re p ro d uc tio n is d e p e nd e nt up o n the q ua lity o f the c o p y sub m itte d .
In the unlike ly e ve nt tha t the a utho r d id no t se nd a c o m p le te m a nusc rip t
a nd the re a re m issing p a g e s, the se will b e no te d . Also , if m a te ria l ha d to b e re m o ve d ,
a no te will ind ic a te the d e le tio n.

UMI 3705493
Pub lishe d b y Pro Q ue st LLC (2015). Co p yrig ht in the Disse rta tio n he ld b y the Autho r.
Mic ro fo rm Ed itio n © Pro Q ue st LLC.
All rig hts re se rve d . This wo rk is p ro te c te d a g a inst
una utho rize d c o p ying und e r Title 17, Unite d Sta te s Co d e

Pro Q ue st LLC.
789 Ea st Eise nho we r Pa rkwa y
P.O . Bo x 1346
Ann Arb o r, MI 48106 - 1346

ii

© Copyright 2015
Hae Min Kim. All Rights Reserved.

iii

ACKNOWLEDGMENTS
This dissertation is dedicated to my parents who have trusted and supported me in all my pursuits.
I extend my deepest gratitude to Jae, my husband, for his enduring love and constant
encouragement, to Ethan, my son for giving me comfort and rest, and to Jamin, my sister, for
standing by my side.
I would like to express my most sincere gratitude to my supervisor, Dr. Danuta A. Nitecki. Her
insights, critiques, and encouragement enabled me to develop a greater understanding of the
subject; she made substantial contributions throughout my research. I am deeply grateful to my
other dissertation committee members, Drs. Denise Agosto, Kristene Unsworth, Christopher
Yang, and Christian Resick for their detailed reviews, constructive criticism, and stimulating
suggestions. I also strongly acknowledge Dr. Eileen Abels for her advice through the proposal
phase of this study, and Drs. Dong-youl Jeong, Yeon-kyoung Chung, and Mi-kyeong Cha at
Ewha Womans University for guiding me in my admission to the Ph.D. program at Drexel
University.
I extend my thanks and recognition to my dear friends, Dr. Yoon-kyung Choi, Hye-lim Song, Dr.
Jihee Beak, J.A. Kajian, and Hyun H. Lee for their friendship and encouragement throughout my
doctoral studies, and my Drexel colleagues, Dr. Mi Zhang, Rachel Magee, Michelle Purcell,
Adam Townes, and Haodong Yang for their significant support in the focus group interview. I
give my appreciation to library staff members, Jenny Lee, Megan Mack, Katy Kelly, Martha
Chantiny, Dr. Lorie Kloda, Rebecca Kuglitsch, and Kelly Diamond, who helped in this study.
I owe a great debt to all these people in the completion of my Ph.D. degree. Thank you.

iv

TABLE OF CONTENTS
LIST OF TABLES ..................................................................................................................... VII
LIST OF FIGURES .....................................................................................................................IX
ABSTRACT ................................................................................................................................... X
CHAPTER 1.

INTRODUCTION............................................................................................. 1

1.1.

PROBLEM STATEMENT ...................................................................................................... 1

1.2.

THEORETICAL FRAMEWORK.............................................................................................. 2

1.3.

RESEARCH QUESTIONS AND HYPOTHESES ........................................................................ 5

1.4.

SIGNIFICANCE OF THE RESEARCH ..................................................................................... 7

1.5.

TERMINOLOGY................................................................................................................... 7

1.6.

ORGANIZATION OF THE DISSERTATION ........................................................................... 10

CHAPTER 2.
2.1.

LITERATURE REVIEW .............................................................................. 12

SOCIAL MEDIA SERVICES ................................................................................................ 12

2.1.1.

Social Media Services in Academic Libraries.......................................................... 12

2.1.2.

Evaluation of Library Social Media Services .......................................................... 17

2.1.3.

Evaluation of Social Media in Other Service Industries .......................................... 20

2.2.

SERVICE QUALITY EVALUATION..................................................................................... 21

2.2.1.

Service Quality Models ............................................................................................ 22

2.2.2.

Application of SERVQUAL to Library Services and LibQUAL ............................... 25

2.3.

E-SERVICE QUALITY ....................................................................................................... 28

2.3.1.

Evaluation Tools for E-Services............................................................................... 29

2.3.2.

E-Service Quality in Libraries ................................................................................. 35

2.4.

ONLINE SURVEY RESPONSE RATES ................................................................................. 37

2.5.

SUMMARY ........................................................................................................................ 39

v

CHAPTER 3.

RESEARCH METHODOLOGY .................................................................. 42

3.1.

RESEARCH DESIGN .......................................................................................................... 42

3.2.

THE INSTRUMENT AND MODIFICATIONS ......................................................................... 43

3.2.1.

Review of Previous Studies’ E-S-QUAL Modifications ........................................... 44

3.2.2.

Focus Group Interview ............................................................................................ 44

3.2.3.

Features of E-S-QUAL Modifications for This Study .............................................. 45

3.2.4.

Instrument Structure................................................................................................. 50

3.3.

POPULATION AND SAMPLING .......................................................................................... 51

3.4.

PILOT TEST ...................................................................................................................... 54

3.5.

STATISTICAL DATA ANALYSIS METHODS ....................................................................... 57

3.6.

ASSUMPTIONS AND LIMITATIONS.................................................................................... 59

CHAPTER 4.
4.1.

DATA ANALYSIS AND FINDINGS ............................................................ 61

DESCRIPTIVE ANALYSIS .................................................................................................. 61

4.1.1.

Response Rates ......................................................................................................... 61

4.1.2.

Respondent Characteristics ..................................................................................... 62

4.1.3.

Descriptive Analysis of Measurement Scales ........................................................... 64

4.2.

RELIABILITY .................................................................................................................... 65

4.3.

DIMENSIONALITY ............................................................................................................ 68

4.4.

VALIDITY ......................................................................................................................... 75

4.5.

RELATIVE IMPORTANCE OF DIMENSIONS ........................................................................ 81

4.6.

GAPS BETWEEN IMPORTANCE AND PERFORMANCE ........................................................ 83

CHAPTER 5.
5.1.

DISCUSSION, IMPLICATIONS, AND CONCLUSIONS ......................... 85

DISCUSSION ..................................................................................................................... 85

5.1.1.

Demographic Characteristics of Academic Library Twitter Services ..................... 85

vi

5.1.2.

Interpretations of Hypotheses Testing...................................................................... 86

5.1.3.

Discussion of the Four Dimensions ......................................................................... 93

5.1.4.

Guidelines for Application of the Modified E-S-QUAL Instrument ......................... 95

5.1.5.

Visualization of Gaps Between Importance and Performance ................................ 95

5.2.

IMPLICATIONS .................................................................................................................. 99

5.3.

CONCLUSIONS................................................................................................................ 102

BIBLIOGRAPHY ...................................................................................................................... 106
APPENDIX A: FOCUS GROUP INTERVIEW PROTOCOL ............................................. 116
APPENDIX B: THE MODIFIED E-S-QUAL INSTRUMENT............................................. 118

vii

LIST OF TABLES

TABLE 1.

DEFINITION OF THE FOUR CONSTRUCTS OF THE ORIGINAL E-S-QUAL .. 3

TABLE 2.

HYPOTHESES ........................................................................................................... 6

TABLE 3.

EVALUATION DIMENSIONS OF SERVQUAL ................................................... 24

TABLE 4.

E-SERVICE QUALITY EVALUATION TOOLS ................................................... 34

TABLE 5.

DIMENSIONS FOR EVALUATING LIBRARIES’ E-SERVICE QUALITY ....... 36

TABLE 6.

THE ORIGINAL AND MODIFIED E-S-QUAL STATEMENTS .......................... 48

TABLE 7.

THE ORIGINAL AND MODIFIED STATEMENTS OF THREE CRITERION

VARIABLES .......................................................................................................................... 50
TABLE 8.

DESCRIPTIONS OF PARTICIPATING RESEARCH SITES ................................ 52

TABLE 9.

THE NUMBER OF SURVEY RESPONSES AND RESPONSE RATES IN EACH

SITE ........................................................................................................................................ 62
TABLE 10.

DEMOGRAPHIC CHARACTERISTICS OF RESPONDENTS ........................... 63

TABLE 11.

DESCRIPTIVE ANALYSIS OF E-S-QUAL FOUR DIMENSIONS AND THREE

CRITERION VARIABLES *................................................................................................. 64
TABLE 12.

ITEM-TO-TOTAL STATISTICS ........................................................................... 66

TABLE 13.

INTER-CORRELATION AMONG ITEMS .......................................................... 67

TABLE 14.

CONFIRMATORY AND EXPLORATORY FACTOR ANALYSIS OF E-S-

QUAL 22 ITEMS ................................................................................................................... 69
TABLE 15.

COMPARISON OF E-SERVICE QUALITY FACTOR STRUCTURES OF 22

ITEMS .................................................................................................................................... 72
TABLE 16.

COMPARISON OF E-SERVICE QUALITY FACTOR STRUCTURES OF 32

ITEMS .................................................................................................................................... 73

viii

TABLE 17.

EXPLORATORY FACTOR ANALYSIS OF E-S-QUAL 22 ITEMS AND

CRITERION VARIABLES' 10 ITEMS ................................................................................. 74
TABLE 18.

AVE AND CORRELATIONS FOR FOUR DIMENSIONS ................................. 76

TABLE 19.

AVE AND CORRELATIONS FOR THREE CONSTRUCTS .............................. 76

TABLE 20.

INTER-CORRELATIONS AMONG THE FOUR E-S-QUAL DIMENSIONS

AND THREE CRITERION VARIABLES A ......................................................................... 77
TABLE 21.

SEM ANALYSIS TO EXAMINE E-S-QUAL’S NOMOLOGICAL VALIDITY 79

TABLE 22.

COMPARISON OF E-SERVICE QUALITY BETWEEN USERS AND SERVICE

PROVIDERS
TABLE 23.

(USERS N=239; SERVICE PROVIDERS N=15) ...................................... 80

REGRESSION ANALYSES OF CRITERION VARIABLES ON THE FOUR E-S-

QUAL DIMENSIONS' SUMMED OR FACTOR SCORES ................................................. 82
TABLE 24.

A PAIRED T-TEST BETWEEN IMPORTANCE AND PERFORMANCE

VALUES ................................................................................................................................ 84
TABLE 25.

DEMOGRAPHIC CHARACTERISTIC OF TWITTER STUDIES ...................... 86

TABLE 26.

SUMMARY OF HYPOTHESES TESTING .......................................................... 87

TABLE 27.

ITEMS IN EACH QUADRANT AND RECOMMENDATIONS ......................... 98

ix

LIST OF FIGURES
FIGURE 1. A MEANS-END FRAMEWORK * ............................................................................. 2
FIGURE 2. ELECTRONIC SERVICE QUALITY MODEL * ....................................................... 4
FIGURE 3. FIRST-ORDER FOUR-FACTOR MODEL .............................................................. 71
FIGURE 4. SECOND-ORDER FOUR-FACTOR MODEL ......................................................... 72
FIGURE 5. SEM MODEL ............................................................................................................. 78
FIGURE 6. A RADAR CHART OF 22 ITEMS' IMPORTANCE AND PERFORMANCE
SCORES ................................................................................................................................. 96
FIGURE 7. A QUADRANT CHART USING IMPORTANCE AND GAP SCORES................. 98

x

ABSTRACT
The Applicability of E-S-QUAL for Assessing the Service Quality of
Social Media Services in Academic Libraries
Hae Min Kim
Advisor: Danuta A. Nitecki, Ph.D.

Libraries of all types are using an increasing range of online applications for services to connect
and communicate with their users. Their emerging use of social media for service delivery
emphasizes the need for understanding user perceptions on service quality in order to meet user
needs. However, studies about social media in libraries have found several limitations in
identifying user perceptions, including outdated evaluation statements, fragmented quantitative
information from applications, and a lack of measurement instruments. This study addresses some
of these gaps by examining the applicability of the E-S-QUAL instrument, which was developed
by Parasuraman et al. (2005), for measuring the service quality of library social media services.
E-S-QUAL has never been applied in the library service field. Nine hypotheses address the
applicability in terms of 1) the scale’s reliability and validity, 2) the relationships between userperceived service quality and three related variables to service quality (overall quality, customers’
perceived value of information, and loyalty intentions), and 3) the scale’s potential to identify
differences between user-perceived importance for a library social media service and theirperceived performance of the service.
Online surveys were used to collect data in five academic university libraries in North America
offering Twitter services. A questionnaire based on a modified version of E-S-QUAL was

xi

distributed through library social media accounts, and a total of 266 responses were analyzed.
Multivariate statistical methods were used to analyze the data, including exploratory and
confirmatory factor analysis, correlation, regression analysis, and t-test in order to identify
reliability, dimensionality, and convergent, discriminant, predictive, nomological, and knowngroup validity using SPSS and Amos.
This study found that the modified E-S-QUAL has good reliability and relationships with
criterion variables as an instrument to measure the service quality of library Twitter accounts in
four dimensions. Although some psychometric properties of the scale were supported,
dimensionality and validity tests diagnosed the possibility of within-measure and across-measure
correlational systematic error. In order to reduce the possibility of such errors, rewording shared
phrases in different constructs and different items’ sequence on the questionnaire is suggested for
application of the E-S-QUAL instrument for assessment of service quality of Twitter used by
academic libraries. The results of this study help library managers apply the instrument to
measure service quality, determine directions and strategies for social media services, and
improve their performance to meet and exceed user needs.

xii

CHAPTER 1. INTRODUCTION
1.1. Problem Statement
Social media has become a primary method of interaction with people, resources, and institutions
in cyberspace. Information services have emerged on this new venue to build networks and
broaden ways of interacting with users (Cuddy et al., 2010). Libraries recommend, interpret,
evaluate, and use information flexibly on social media with more resources in order to serve
people’s information needs. About 80% of research university libraries have provided
information services using social media such as Facebook and Twitter, and their average numbers
of users are over 1,000 (Kim, 2014). Libraries’ emerging activities on social media have
highlighted the need for understanding users’ perceptions of those services. Service quality,
which is measured by differences between user expectations and perceptions of performances, is
an important assessment construct, useful to identify problems, and improve services. Evaluating
the service quality of library social media services is helpful to understand how relevant and
effective the libraries’ participation in people’s social networks is to help users access resources.
The measurement of service quality on social media platforms requires a different approach than
traditional library evaluation because the service engages with users online, service providers are
not face-to-face, and the service venue is managed through external applications. Existing
evaluation instruments used to assess the service quality of library services are limited to address
these features. Previous studies have quantified the use of social media services (Xie & Stevenson,
2014; Pinto & Manso, 2012; Xia, 2009), surveyed librarians’ perception of social media as part of
library services (Choi, 2012; Loudon & Hall, 2010; Hendrix et al., 2009; Charnigo & BarnettEllis, 2007), and identified patrons’ usage patterns (Gerolimos & Konsta, 2011; Connell, 2009;
Park, 2009). However, no study has systematically evaluated user perceptions of library service
applications of social media. While several authors recognize the need to evaluate libraries’ social

2

media services, there is no published research that applies service quality assessment to online
services to reveal efficiency, satisfaction, and quality from a user perspective. To fill this gap, this
study explores the applicability of an electronic service quality (e-service quality) instrument to
assess user perceptions of libraries’ information services offered via social media.
The results of this study will be of interest to library assessment managers and social media
service providers who want to understand how users perceive service quality by using the adapted
and statistically tested instrument. This study also will be of value to researchers to develop tools
for assessing the quality of library e-services and other industries’ social media services.
1.2. Theoretical Framework
A means-end theoretical framework underlies the development of instruments to measure eservice quality (Parasuraman et al., 2005). This framework includes four steps from concrete
cues, perceptual attributes, dimensions, to higher-order abstractions (see Figure 1). Parasuraman
et al. (2005) developed an e-service quality instrument, named E-S-QUAL, based on this
framework. Through the iterative process of scale development, E-S-QUAL evolved to include
22 items on four dimensions: efficiency, system availability, fulfillment, and privacy (Table 1).
The developers validated the instrument focusing on the relationships among e-service quality,
their respective dimensions, and endogenous constructs such as perceived value and loyalty
intentions.
Figure 1. A MeansEnd Framework *

*Parasuraman et al., 2005, p.6

3

Table 1.
Definition of the Four Constructs of the Original ESQUAL
Dimension
1. Efficiency
2. System
availability
3. Fulfillment
4. Privacy

Definition
The ease and speed of accessing and using the site.
The correct technical functioning of the site.
The extent to which the site’s promises about order delivery and item availability
are fulfilled.
The degree to which the site is safe and protects customer information.

This research adapted the E-S-QUAL instrument and assessed applicability to a library service
setting based on the e-service quality model, a causal relationship (attributes

dimensions

endogenous constructs) (see Figure 2). In addition, the instrument in this study applies the gap
measurement because service quality is traditionally measured by gaps between expectations for
an excellent service and performance perceived by users, and the gap data provide important
information for improving services.
The four dimensions of E-S-QUAL provide representative information about e-service quality (Kim et
al., 2006). It has been applied to various industry settings and the scale’s reliability and validity
have been confirmed. Also, it has been applied to not only for-profit commercial services, but
also non-profit e-services such as microbloggings (Hu et al., 2012), a university website (Zada et
al., 2012), and e-government services (Alanezi et al., 2012; Connolly et al., 2010; Jun et al.,
2009). The developers of E-S-QUAL encouraged examination of the scale in pure-service areas,
such as information services without delivering physical items, by modifying items and assessing
their psychometric properties (Parasuraman et al., 2005).
Studies of libraries’ e-service quality have identified similar dimensions to the E-S-QUAL’s four
dimensions. Efficiency is an important factor in several studies (Einasto, 2014; Kiran & Diljit,
2012; Hernon & Calvert, 2005) using such phrases as ‘easy to use’ and ‘convenient to access.’

4

System availability appears in studies (Einasto, 2014; Kiran & Diljit, 2012), in phrases such as
‘site is always available,’ ‘links are all working,’ and ‘correct technical functioning, no broken
links.’ Fulfillment is a crucial factor in most studies’ criteria to assess service quality (O’Neill et
al., 2001; Hernon & Calvert, 2005). Privacy is a factor revealed as a user’s concern in studies of
social media use in libraries (Park, 2009; Connell, 2009; Chu & Meulemans, 2008; Mack et al.,
2007).
The e-service quality model is considered to be relevant to a library social media service setting.
No one has utilized an instrument to measure the service quality of library social media services.
The researcher tests validity of E-S-QUAL for library social media services, an example of a nonprofit e-service.

Figure 2. Electronic Service Quality Model *

* Modified from Parasuraman et al. (2005)

5

1.3. Research Questions and Hypotheses
In this study, tests of reliability, dimensionality, and validity are applied to assess the E-S-QUAL
instrument applicability to library social media services in order to achieve the scale’s
consistency and accuracy. Different types of validity are considered: content validity for
representative items in a given context; convergent and discriminant validity for measuring a
construct; predictive validity for relationships with external criterion variables; nomological
validity for theoretical networks with related constructs (Viswanathan, 2005). This study also
assesses known-groups validity to identify differences of service quality perceptions between
service users and providers because these two groups have been distinguished for their
perceptions of library services in previous studies. In addition, this study assesses the instrument
applying the gap measurement, which identifies the differences between user-perceived
importance for service excellence and their-perceived performance of service delivered by the
service provider (Hernon & Whitman, 2001).
The research questions are as follows:
1) To identify psychometric properties of E-S-QUAL when used to assess the service
quality of a library social media service.
2) To identify the relationships between user-perceived service quality and three criterion
constructs: a) overall quality, b) customers’ perceived value of information, and c) their
intended loyalty.
3) To identify whether ESQUAL measures the gaps between user-perceived importance
for a library social media service and their-perceived performance of the service.
This study is undertaken through an exploration of nine research hypotheses (Table 2).

6

Table 2.
Hypotheses
Validation

Code

Hypothesis

Reliability

H1

The total scale reliability as measured by the Cronbach Alpha for
the dimensions of the instrument falls within the range (0.6 0.97)
of the scale's reliabilities as reported in non library settings.

Dimensionality

H2

The dimensions of the modified E S QUAL scale measured by
factor analysis are equivalent to the four underlying dimensionality
found in the original E S QUAL by Parasuraman et al. (2005).

H3a

The AVE (Average Variance Extracted) value of each dimension is
over 0.5 to demonstrate each dimension’s convergent validity.

H3b

The AVE value of e service quality is over 0.5 to demonstrate
convergent validity with two criterion constructs, perceived value
and loyalty intentions.

H4a

The AVE value of each dimension is greater than the pairwise r2
(squared inter factor correlation) across the four dimensions of
the modified E S QUAL to demonstrate the discrimination of the
four dimensions.

H4b

The AVE value of e service quality is greater than the pairwise r2
across two criterion constructs, perceived value and loyalty
intentions.

H5

The four dimensions of E S QUAL have a significantly positive
correlation (r2 > 0.4, p < 0.05) with overall quality, perceived value,
and loyalty intentions.

H6a

E service quality has a significantly positive relationship on
perceived value.

H6b

E service quality has a significantly positive relationship on loyalty
Intentions.

H6c

Perceived value has a significantly positive relationship on loyalty
intentions.

Knowngroup validity

H7

The average means of summed E S QUAL and four dimensions are
significantly different (p < 0.05) between in users and service
providers.

Relative importance of
the four dimensions

H8

The magnitude of the relationship of overall quality, perceived
value, and loyalty intentions is different for each dimension.

Gap measurement

H9

E S QUAL measures significant differences (p < 0.05) in the value
of importance and performance of each item.

Convergent validity

Discriminant validity

Predictive validity

Nomological validity

7

1.4. Significance of the Research
The significance of the research is to validate the E-S-QUAL instrument’s applicability in a
setting of an information service using social media, and to introduce it for evaluation of a
library’s social media service by actual users. Accurate measurement minimizing errors is
important in empirical studies (Viswanathan, 2005). Service quality is an abstract and elusive
construct that is difficult to delimit and measure (Yaya et al., 2012). This study provides
knowledge of the adoption of an instrument for measuring service quality by assessing its
reliability and validity, and provides insight into the use of the instrument in information services
using social media.
User-perceived service quality is an important factor in determining the success or failure of
services (Santos, 2003). There has been an increasing demand for service providers to measure
performance of services from user perspectives as a method to account for the rationale and
direction for using social media. Understanding gaps between users’ perceptions of importance
and performance assists service providers in determining strategic plans to improve the services.
This research will help service providers manage social media services by providing an
instrument to measure service quality. Ultimately, the effective measurement of service quality
will lead to improved services with efficient operations, good service quality, and satisfied users.
1.5. Terminology
Social media
Social media has become a popular term primarily referring to web services such as Facebook
and Twitter. Many researchers have studied social media, but there is no universally accepted
definition of the term. Even other relevant terms such as Web 2.0 and Library 2.0 are used
without clear boundaries. Some studies about social media only encompass social networking

8

services, and other studies about Web 2.0 and Library 2.0 include web technologies such as email
and chat as well as social networking services. Social media are originally based on the Web 2.0
concept including user-generated content, online collaboration, information sharing, and
collective intelligence (O’Reilly, 2005). A combination of an increase in Internet users,
broadband Internet, easy mobile interfaces, smart devices, and cultural transitions has brought the
term social media into the popular culture. Library 2.0 is the integration of Web 2.0 features into
library online services (Harinarayana & Raju, 2010). Email and chat services have been improved
by integrating them with Web 2.0 technologies and used as library service tools; however, they
are limited within the social media boundary because they focus on personal rather than many-tomany communications, and they do not generate user communities by open discussion and
content sharing.
Therefore, in this study, social media is defined as web applications which allow people to
participate in content generation and discussions, to discover and disseminate information to a
large number of people, and to have relationships among users in the community (Van Niekerk &
Maharaj, 2013; Harinarayana & Raju, 2010; Holmberg et al., 2009; Agichtein et al., 2008;
Maness, 2006).
The most popular services are Facebook, LinkedIn, Pinterest, Instagram and Twitter as an
investigation in September 2014 (Duggan et al., 2015). Among them, Facebook and Twitter have
been identified as the most popular social media services used in libraries (Xie & Stevenson,
2014; Chu & Du, 2012; Dowd, 2013; Mundt, 2013; Walia & Gupta, 2012). Facebook was
initiated in 2004 and has 890 million daily active users on average as of December 20141, and
Twitter began its service in 2006 and has 100 million daily active users as of October 20132.

1
2

Facebook Newsroom http://newsroom.fb.com/companyinfo/
US SEC http://www.sec.gov/Archives/edgar/data/1418091/000119312513390321/d564001ds1.htm

9

EService quality
E-service is defined as “an interactive, content-centered, and Internet-based customer service that
is driven by the customers and integrated with the support of technologies and systems offered by
service providers” (Liu, 2012), and more broadly “all phases of a customer’s interactions with a
website” (Parasuraman et al., 2005). Quality is defined as “a dynamic state associated with
products, services, people, processes, and environments that meet or exceed customers’
expectations” (Goetsch, 2006). Based on these definitions, e-service quality can be
understandable as excellence of the efficient and effective service delivery on internet-based
websites. An operational definition for measuring e-service quality was developed to assess four
dimensions including efficiency, fulfillment, system availability, and privacy by customers
(Parasuraman et al., 2005). It is a higher-order construct conceptualized with four dimensions.
Service quality versus Satisfaction
Service quality is used interchangeably with satisfaction in some studies, but other studies argue
that those terms are distinct. Researchers have different perspectives about which concept is the
antecedent of the other. Parasuraman et al. (1991) see service quality as the precursor of
satisfaction whereas Oliver (1981) considers satisfaction as the precursor of service quality.
Parasuraman et al. (1988) distinguished two terms: service quality indicates an overall impression
based on customers’ judgment about a service’s overall excellence or superiority resulting from a
comparison of expectations of excellence with perceptions of performance, while satisfaction is a
reaction to a specific service transaction. Oliver (1981) defined satisfaction as “a summary
psychological state resulting when the emotion surrounding disconfirmed expectations is coupled
with the consumer’s prior feelings about the consumption experience” (p.27).

10

This study uses the two terms with the following understanding of their differences: service
quality focuses on specific attributes whereas satisfaction focuses on a specific transaction.
Judgment of service quality is cognitive and diagnostic whereas that of satisfaction is more
affective and emotional regarding actual experiences (Hernon & Nitecki, 2001).
Libraries’ social media services
In this study, libraries’ social media services indicate a new format of information delivery using
social media such as Facebook, Twitter, and others on which library staff members create
accounts representative of their libraries, in order to interact with users. Those accounts are
usually open to the public (used aged 14 and above, in the U.S.). If people subscribe to the
accounts, they receive information posted by the libraries on their customized personal pages.
Libraries have different purposes in using social media. In this study, ‘library information’
indicates any text, image, and video formatted information that libraries have posted on their
social media accounts.
1.6. Organization of the Dissertation
To address the research questions and validate research hypotheses, this study is organized into
five chapters. In chapter one, the problem statement, theoretical framework, study’s significance,
research questions and hypotheses, and terminology are discussed. In chapter two, social media
use in libraries, concepts and evaluation of service quality, e-service quality, and online survey
response rates are discussed through a review of literature in library and information science,
business, and social sciences. In chapter three, the research methodology is described including
the research design, instrument and modifications, population and sampling, a pilot test, statistical
data analysis plans, and assumptions. In chapter four, the results of the data analysis are presented
including response rates, respondents’ profiles, tests of reliability, dimensionality, validity,

11

relative importance of dimensions, and gap analysis. In chapter five, discussion, implications, and
conclusions are presented. After these chapters, a bibliography and appendices conclude this
dissertation.

12

CHAPTER 2. LITERATURE REVIEW
The literature review includes four major topics as relevant for this research: 1) library social
media services, 2) service quality evaluation, 3) e-service quality, and 4) online survey response
rates. The first section focuses on adoption and evaluations of social media in libraries as well as
in other industries. The second section covers scales and instruments for evaluating service
quality and how libraries evaluate services. The third section on e-service quality includes scales
and instruments for evaluating e-service quality including in library contexts. The fourth section
covers response rates of online surveys and ways to improve participation.
2.1. Social Media Services
The adoption of social media in libraries has increased in the last several years, which has been
identified in different works such as Kim and Abbas (2010), Agosto and Abbas (2009), Bejune
and Ronan (2008), Kroski (2008), Farkas (2007), and Bradley (2007). This section examines how
social media have been applied and used in academic libraries, perceptions of service providers
and users of the services, and evaluations in libraries as well as other industries.
2.1.1. Social Media Services in Academic Libraries
Studies of this topic are divided into two parts. First, numerous studies have attempted to analyze
how social media services have been used in libraries (e.g. Abdullah et al., 2015; Cavanagh,
2015; Stone, 2014; Mahmood & Richardson, 2011; Kim & Abbas, 2010; Harinarayana & Raju,
2010; Linh, 2008; Shoniwa & Hall, 2007). These researchers visited library web sites and
investigated publicly available applications and their usage. Second, researchers conducted
surveys and interviews with librarians to identify the purposes of those services (Cavanagh, 2015;
Abdullah et al., 2015; Chu & Du, 2012; Kim & Abbas, 2010; Loudon & Hall, 2010; Linh, 2008;

13

Charnigo & Barnett-Ellis, 2007; Shoniwa & Hall, 2007), and with users to identify their
perceptions about the services (Chu & Meulemans, 2008; Connell, 2009; Kim & Abbas, 2010).
Studies about social media services in libraries began to appear in 2006. Early works described
Facebook as a tool that could accomplish a library’s various tasks such as reference, outreach to
patrons, instruction, and research in a more effective and efficient way (Mack et al., 2007; Landis,
2010). Twitter was also considered a positive platform that allowed library resources and services
to connect with the places where patrons were (Devoe, 2009). Similar to the features of Facebook
service, the background of using Twitter was outreach to patrons by providing library events and
reference services and sharing information related to patrons from various sources (Forrestal,
2010; Cuddy & Morton-Owens, 2010).
More recent studies have analyzed how libraries use social media. Content analysis was used to
investigate purposes of Facebook use in academic libraries, such as information delivery to their
patrons and marketing library services to them (Aharony, 2012; Chiu & Lin, 2012; Ayu &
Abrizah, 2011). In a more comprehensive study, Chen et al. (2012) analyzed posts for five
months on Facebook and Twitter from forty libraries including both public and academic libraries.
They identified four different types of interaction on libraries’ social media – knowledge sharing,
information dissemination, communication, and knowledge gathering. They found differences
between Facebook and Twitter; Facebook is effective in knowledge sharing, while Twitter is
efficient in facilitating communication. The study also identified that academic libraries’ patrons
participated in social media to communicate with libraries, and public libraries’ patrons used
social media for knowledge sharing.
In particular, Mack et al. (2007) investigated how social media can be used as reference tools.
They examined the number of reference transactions through various communication methods as
a case study in an academic library for one semester. The results showed that Facebook received

14

more reference questions than other media such as E-mail, instant messaging, the telephone, and
in-person interaction. Stone (2014) identified significant relationships between reference
interactions with librarians and friendship on Facebook. These studies indicated that Facebook
has been used as a reference tool for library users.
Several studies investigated categories of messages that libraries have posted and shared with
users. Using content analysis, messages posted on several libraries’ social media services were
gathered, analyzed manually, and categorized. The identified content categories include
announcements including library events, operation hours, policies, library resources such as
collection and databases, services such as reference and instructional classes, and the library’s
values such as encouraging reading (Dann, 2010; Stuart, 2010; Aharony, 2011; Phillips, 2011;
Wan, 2011). Subcategories differed in categorizing standards and library types. Aharony (2011)
divided Facebook messages based on contents, and Phillips (2011) categorized them based on
motivation and contents. Dann’s categories of Twitter were based on message characteristics such
as conversations with other users, status answering to current activities, and connections through
a retweet function or links to other websites. Kim et al. (2012b) classified Twitter messages based
on four domains (motivation, content, audience, and source) to include different aspects and
avoid mixed categories.
Lilburn (2012) and Milberry and Anderson (2009) raised questions about the social media
services in libraries. Libraries’ values are shared resources that are openly available to the public,
but social media are commercial places to limit networking establishment and private commodity.
That is, social media in libraries are not examined as to whether they are consistent with library
values (Lilburn, 2012). Although social media have been adopted in various fields not only in
libraries, they are not developed specifically for each of these types of institutions. Voida et al.

15

(2012) showed that when organizations’ missions and values are not connected to technology
usages, social media are underutilized.
Studies have been conducted to investigate the perception of librarians who manage the services
and users who are actually offered these services, using surveys and interviews, to collect both
librarians and users’ opinion data on the social media services. Studies under those topics
illustrated how librarians deal with social media as library services and potential effects of social
media on user perceptions of success and reasons they do or do not use the services.
Cavanagh (2015) conducted 71 surveys from public libraries offering Twitter services in Canada,
and identified librarians’ perceived benefits and challenges of using Twitter. Benefits were
connections and communication with users and other organizations including libraries, and
expanding services and audiences. Challenges were organization, management, and staff time
constraints. Abdullah et al. (2015) also found similar opinions of benefits and challenges from
librarians for using social media as library services, for instance, reaching out to users and
improving communication, and staff limitation on time and skills for management. Choi (2012)
surveyed 275 librarians from various types of libraries and found that they perceived social media
as part of a library’s strategic plan and as important for communication; furthermore, they agreed
on new roles for social media such as communicating with users, posting messages for providing
library events and resources, monitoring feeds, and networking with staff of other organizations.
Loudon and Hall (2010) conducted a survey of 299 academic librarians and interviewed them
about Twitter use; the results showed that Twitter is a useful tool for extending library services
and collaborative work, developing professional capacity by receiving and communicating with
other professionals and organizations, and presenting an up-to-date image to patrons. As the
community of Twitter users is expected to grow, that growth could improve service delivery,
information dissemination, and customer service (Loudon & Hall, 2010). Some librarians agree

16

that social media can be used in a positive way; however, there are negative views of social media
as well. Librarians interviewed by Hendrix et al. (2009) indicated that the platform’s usefulness
and effectiveness cannot be determined. Charnigo and Barnett-Ellis (2007) surveyed 126
academic librarians and found that they consider Facebook does not serve an academic purpose
and is outside the realm of professional librarianship.
Some user studies investigated how users perceive libraries’ social media and why they use the
services. Mack et al. (2007), Chu and Meulemans (2008), and Connell (2009) conducted surveys
and focus group interviews with users and found that privacy was an issue affecting participation
because students might not be willing to share personal information with libraries. Park (2009)
identified six factors affecting different usage patterns by user groups at a university: desire for
expression, peer influences, familiarity with IT, sensitivity to privacy, nature of using the Internet,
and perception of social media. Based on these features, he suggested that strategies for different
user groups are needed for libraries’ social media services and emphasized the balance between
information exposure and privacy.
In summary, many researchers have conducted exploratory studies about social media services in
academic libraries examining types of social media, purposes from a librarian’s perspective, and
categories of offered information. These studies have used content analysis, surveys, and/or
interviews of librarians. Some critical studies show that there are some discrepancies between
librarians’ expectations and patrons’ usage. Librarians considered social media as services for
announcing news, providing information, and communicating with users for reference purposes.
However, user surveys showed that patrons worried about privacy issues and their participation
was low. Such differences might cause a substantial difference between the adoption rates of
social media by libraries and the usage rates by users (Kim & Abbas, 2010). In general, Kilian et
al. (2012) investigated motives for social media usage among millennials based on the four

17

motives for using media developed by McQuail (1983): information, integration and social
interaction, personal identity, and entertainment. The results showed that millennials use
Wikipedia and blogs for information and social network sites for entertainment and self-identity,
which are different from the libraries’ purposes of using social media. Therefore, users’
expectations for libraries’ social media services might be different from libraries’ plans, and their
perceptions of the service performance might not meet their expectations.
2.1.2. Evaluation of Library Social Media Services
Although a few studies discussed evaluation of library social media services, none provided a tool
to measure user perceptions of service quality. Emery and Schifeling (2015), Le Gac (2010), and
Doshi (2012) analyzed content for the assessment of the effectiveness and success of social media
use, and quantified the amount of user feedback, the number of interactions with users, and the
number of messages about the library. Based on these measures, several studies represented the
usages of library social media and judged the service’s status. However, quantitative measures are
limited in revealing other qualitative factors such as impact, efficiency, satisfaction, and quality.
There are many descriptive works mentioning the necessity of evaluation of social media services,
but just a few researchers have conducted studies on that in practice. Several authors called for
the need to evaluate library services using Facebook and Twitter (Glazer, 2009; Le Gac, 2010;
Bodnar & Doshi, 2011; Doshi, 2012); however, very few authors actually conducted research
with systematic protocols in this area. Some studies assessed libraries’ Facebook pages with
quantitative criteria. Xia (2009) analyzed Facebook groups of two academic libraries to evaluate
the effectiveness of Facebook in promoting library visibility. This study used quantitative criteria
such as the number of members, wall posts, discussions, and the earliest and latest posts to
measure the groups’ activity. Wan (2011) examined how successful Facebook has been to reach
out to their patrons using the number of ‘Fans’. Over 60% of 115 ARL member libraries’

18

Facebook pages have fewer than 200 Fans, while only four libraries’ pages have more than 1000
Fans. The author concluded that Facebook pages are not successful in attracting users. GarciaMilian et al. (2012) investigated 72 academic health science libraries’ Facebook pages, and found
positive relationships between the content on Facebook pages and their popularity, the number of
Fans; in particular, the more video content on library Facebook pages the more Fans they have. In
the case of Twitter, Del Bosque et al. (2012) used quantifiable measures such as the number of
followers, interactions with them, and updated tweets to reflect how library Twitters are used by
end-users by indicating the objective status of each account. They conducted online surveys in
296 academic libraries. Emery and Schifeling (2015) analyzed connectivity among users who
were following and mentioning on academic libraries’ Twitter accounts and visualized the data to
identify communication among accounts. This study investigated characteristics of tweets in three
ways, activity, community, and content. Activity included number of users and frequency of
tweets. Community was examined by mentions, replies, and retweets. Content was analyzed
using hashtags, URLs, and images per tweet.
Landis (2010) suggested three different techniques in his book that enable libraries to collect
quantitative and qualitative statistical data about library social media use. First, libraries can
monitor usage statistics that are available from social media services for each account and third
party applications. Usage statistics include the account’s number of friends/followers, unique
daily visitors, demographics of visitors such as age and gender, new and total fans, photo views,
wall posts, the time of stay on a library account, and traffic patterns. Second, user surveys allow
libraries to find users’ purposes, information needs, and preferences for libraries’ social media
services. Based on the survey results, libraries can provide content that is more helpful to their
patrons. Third, libraries can conduct focus groups to get detailed qualitative data from patrons.
Open-ended questions lead patrons to provide their preferences as well as critical opinions. Based
on these evaluation methods, Landis (2010) emphasizes that libraries need to establish

19

measurable goals for using social media, which enables libraries to evaluate their success and
provide services meeting their patrons’ needs. Articles such as Powers et al. (2008), Cuddy et al.
(2010), and Le Gac (2010) also suggested qualitative data from user surveys solicit feedback and
types of friends or followers, and quantifiable data, for instance, can measure the numbers of
friends or followers, and interactions with the library. However, none of these studies actually
evaluated their services qualitatively.
Some studies have approached library digital reference services as social media. Ramos and
Abrigo (2012) examined communication processes and answer quality of libraries’ reference
service tools such as email, chat, Web form, FAQ, and Facebook. They investigated 22 academic
libraries’ services in the Philippines and users’ awareness of those services: Facebook and Twitter
were the most offered services by libraries, but users were aware of their existence in order of
web form, email, and Facebook; the number of reference questions via Facebook was low. This
study indicates that social media such as Facebook might not be suitable for a question and
answer service and the service evaluation should be done by qualitative measures. Pinto and
Manso (2012) developed a tool to evaluate virtual reference services with 24 quantitative
measures under three categories; communication interface, service policies, and incorporation of
Web 2.0 elements, based on guidelines from International Federation of Library Associations
(IFLA) and Reference & User Services Association (RUSA), and Web 2.0 elements.
Studies considering reference service tools as social media in libraries showed that users are
aware of those service platforms; however, the number of transactions for question and answer is
low. Therefore, it might not be suitable to use guidelines and evaluation measures developed for
reference services. Social media services in academic libraries have different purposes such as
communication, announcement, and marketing rather than Q&A. Also, as the uses of social

20

media are still evolving, users’ perceptions for the services need to be analyzed to understand
their needs through social media and to improve the services.
2.1.3. Evaluation of Social Media in Other Service Industries
With an increase in the popularity of social media, many industries have used social media for
their own purposes including marketing and communication. Not only in the library and
information science field, but also in other industries such as business and management,
researchers are challenged to evaluate their services using social media. Traditional metrics for
linear communication in marketing are not applicable to evaluate social media’s interactive
communication (Michaelidou et al., 2011). Evaluations for social media services are investigated
to find helpful methods. However, there are a few studies focusing on the evaluation of social
media service quality in other industries.
Service quality studies for services using social media have been conducted in marketing
(Mohammadian & Mohammadreza, 2012), social commerce (Lee et al., 2012) as well as in
evaluation for social media websites themselves (Hu et al., 2012; Ellahi & Bokhari, 2013).
Mohammadian and Mohammadreza (2012) identified the following four factors that influence the
success of social media use in marketing areas: security, attractive content, reputation, interaction
and communication. They surveyed 385 students in a university using a questionnaire the authors
designed, and analyzed responses with factor analysis and structural models. Others (Lee et al.,
2012; Hu et al., 2012) modified and used an existing instrument, E-S-QUAL, developed by
Parasuraman, Zeithaml, and Malhotra (2005), to examine customers’ perception of service quality.
Lee et al. (2012) applied the modified E-S-QUAL to social commerce websites. The authors
mentioned differences between e-commerce and social commerce such as group shopping,
mobile applications, and word-of-mouth marketing. The data were collected using social
commerce user surveys, and the authors found ‘responsiveness’ to be the most affective factor for

21

perceived value and customer loyalty. Hu et al. (2012) evaluated the service quality of 11
microblogging sites with the purpose of increasing revisits. They conducted three surveys: 1) the
Delphi technique with experts to determine factors among a preliminary framework, E-S-QUAL,
2) a questionnaire of experts which determined relationships among criteria, and 3) a
questionnaire used among microbloggers to find important factors for measuring the service
quality. Their framework consisted of eight dimensions: efficiency, system availability,
security/privacy, responsiveness, tangibles, entertainment, convenience, and empathy. Among
them, the key factors to measure service quality were security/privacy, empathy, and efficiency.
Using surveys of 300 university students in Pakistan who had used social media such as
Facebook, Twitter, LinkedIn, and Orkut, Ellahi and Bokhari (2013) identified factors related to
service quality of social media, and identified six factors as most important, user-friendliness,
community drivenness, efficiency, privacy, entertainment, and navigability.
In summary, the number of social media users has increased and many industries including
libraries have adopted those media for service delivery and customer communication. Many
studies emphasized evaluation of social media to improve services. Quantitative measurements
such as the number of members and interaction with users have been used to identify usage status,
and content analyses have been applied to assess user feedback, comments, and postings (Xia,
2009; Wan, 2011; Garcia-Milian et al., 2012; Del Bosque et al., 2012; Doshi, 2012). A systematic
instrument, E-S-QUAL has been applied to evaluating service quality of e-commerce using social
media (Lee et al., 2012).
2.2.

Service Quality Evaluation

The overall purpose of a library evaluation is to improve the performance of its services and the
effectiveness of its management through measuring the details of the services’ human resources,
physical materials, and contents (Saracevic, 2000; Matthews, 2007). After a new service has been

22

operating for a certain period, evaluation is required to assess the effectiveness of the service and
to determine whether to develop, change, or discard it. Evaluations have been conducted by
gathering data using qualitative and quantitative methods such as surveys and interviews of
patrons and library staff members and/or counting the number of service transactions. The
business evaluation instrument, SERVQUAL has been applied within the library context (Hébert,
1993; Nitecki, 1995; Coleman et al., 1997; Ho & Crowley, 2003; Nagata et al., 2004; Landrum et
al., 2008; Yu et al., 2008). However, recent trends in library services using social media
applications have made it hard to evaluate services by only applying criteria used for face-to-face
services. This section addresses studies about evaluating the quality of library services using
evaluation tools developed for measuring service quality such as SERVQUAL and LibQUAL+.
2.2.1.

Service Quality Models

Many researchers have developed service quality models for different characteristics about
services. Seth et al. (2005) reviewed 19 models of service quality and categorized them by using a
gap analysis and research issues. From among them, this study reviewed the three following
models that have been applied to studies in library and information science. The models offer
different dimensions to measure service quality based on its conceptualization as a gap between
customers’ expectations and perceptions.
Gr nroos (1984) defined service quality as perceived by customers in a subjective manner, and
conceptualized it with three dimensions: technical quality, functional quality, and image.
According to this model, perceived service quality is affected by image, which is built upon
technical and functional quality of service. Technical quality is what users actually receive from
the service and functional quality is how the service is delivered to them. In the author’s study
(Gr nroos, 1988), six criteria for good perceived service were identified: ‘reputation and
credibility’ is for image, ‘professionalism and skills’ is for technical quality, and ‘behavior and

23

attitudes’, ‘accessibility and flexibility’, ‘reliability and trustworthiness’, and ‘recovery’ are for
functional quality. His concept for service quality as the difference between perceived and
expected quality by customers has been a basis for the following service quality models.
Parasuraman, Zeithaml, and Berry’s (1985) Gaps Model of Service Quality is the most cited
framework used for service quality studies (e.g. Ali, 2012; Lin et al., 2009; Landrum et al., 2008;
Yu et al., 2008; Cook & Heath, 2001; Nitecki, 1995). They developed the model to understand
factors contributing to customer perceived service quality in order to help managers prioritize
those factors most likely to affect service improvement. Five different gaps among customers,
marketers, and services were identified. Gap 1 is the discrepancy between what customers expect
of excellent service and managers’ perceptions of customers’ expectations. Gap 2 is the
discrepancy between managers’ perceptions of customers’ expectations and service quality
specifications. Gap 3 is the discrepancy between the service specifications and actual service
delivery. Gap 4 is the discrepancy between service delivery and external communications to
customers. These four gaps emerge from a marketer perspective and have an impact on Gap 5,
which is viewed from a customer perspective. Gap 5 is the discrepancy between customers’
expectations for service excellence and their perceptions of the performance of service delivered
by the service provider. Their model is similar to Gr nroos model in conceptualizing service
quality by the difference between customers’ perceptions and expectations; however, they
consider both customers and marketers.
While Gr nroos (1984) did not provide an instrument to measure functional and technical
qualities, Parasuraman et al. (1988; 1991) designed the SERVQUAL tool for measuring Gap 5.
The instrument focuses on five dimensions: tangibles, reliability, responsiveness, assurance, and
empathy (Table 3). Service quality is diagnosed as high when the gap measure is narrow.

24

Table 3.
Evaluation Dimensions of SERVQUAL
Dimensions

Definition

1. Tangibility

Appearance of physical facilities, equipment and communication material

2. Reliability

Ability to perform the promised service dependably and accurately

3. Responsiveness

Willingness to help customers and provide prompt service

4. Assurance

Knowledge and courtesy of the employees and their ability to convey trust and
confidence

5. Empathy

The caring and individualized attention, organization provides to its customers

Cronin and Taylor (1992) argued that customers’ expectations are unclear to identify, and only
the performance which customers perceived after experiencing services shows the quality of
delivered services. Based on this position, they developed a SERVPERF instrument that measures
customers’ perception of performance, instead of considering both expectations and performance
perceptions. The dimensions of SERVPERF are the same as those used in SERVQUAL, but this
model measures only perceptions after using a service.
The above three models have been applied to many studies evaluating service quality. The two
models that provided instruments, SERVQUAL and SERVPERF, have been examined for
reliability and validity in various service industries. About the debate of measuring customer’s
expectations, Zeithaml et al. (1996) suggested that:
“The perceptions-only operationalization is appropriate if the primary purpose of
measuring service quality is to attempt to explain the variance in some dependent
construct; the perceptions-minus-expectations difference-score measure is appropriate if
the primary purpose is to diagnose accurately service shortfalls.”

25

The next section covers how SERVQUAL has been applied to libraries’ service quality
evaluation.
2.2.2.

Application of SERVQUAL to Library Services and LibQUAL

Parasuraman et al. (1988) developed a service quality assessment tool, SERVQUAL, which has
been widely used in service industries including libraries. Earlier studies such as Hébert (1993),
Nitecki (1995), White and Abels (1995), and Coleman et al. (1997) examined the application of
SERVQUAL to measure library service quality. They modified SERVQUAL slightly to survey
library users, identified affective factors, and supported the scale’s reliability and validity.
SERVQUAL continues to be used for evaluating library service quality. Ho and Crowley (2003)
focused on reliability as the most important among the five SERVQUAL dimensions, which has
been revealed in several library studies (Hébert, 1993; Nitecki, 1995; Nitecki & Hernon, 2000;
Coleman et al., 1997), to investigate service quality of access, reference, circulation, and online
catalogs. Coleman et al. (1997) conducted focus group interviews with university students
applying a survey with five questions under the SERVQUAL’s reliability dimension, and found
this method was useful to identify areas for improvement.
Some researchers developed their instruments based on SERVQUAL and other factors. Nagata et
al. (2004) conducted a questionnaire survey based on SERVQUAL and items of technical quality
from Gr nroos’ model, and identified four dimensions: effect of service (personal), library as a
place, reliability, collection and access, and effect of service (organizational). Landrum et al.
(2008) developed an instrument, SERVCESS, based on items from SERVQUAL and others
measuring information system success. They conducted a survey and identified five dimensions
with 30 items such as service quality, information quality, system quality, usefulness, and
involvement.

26

Yu et al. (2008) investigated SERVQUAL based on an epistemological perspective to enhance its
utility as a library evaluation tool. The authors conducted comprehensive literature reviews,
surveys and interviews with university students and librarians, and provided four suggestions to
improve the utility of SERVQUAL in libraries: separate surveys of different user groups,
purposefully selected samples, qualitative methods (interviews, focus groups) with SERVQUAL
to collect data about users’ library experiences, and a modified survey without the expectation
construct.
Although SERVQUAL has been used to evaluate library service quality and to help find areas for
improvement, Cook and Thompson (2000) testing reliability and validity of SERVQUAL found
that its data were highly reliable across different years and user groups, but validity was
questionable. Other studies such as Nitecki and Hernon (2000) and Calvert (2001) found that they
identified three rather than five dimensions of SERVQUAL. Cook and Thompson (2000) argued
that new measurements were necessary for evaluating academic libraries’ service quality.
LibQUAL+
LibQUAL+ is an evaluation tool to measure patrons’ minimum, perceived, and desired levels of
library service quality. Researchers from Texas A&M University and the Association of Research
Libraries (ARL) developed the tool with 22 questions in three dimensions (service effect,
information control, and library as place) and an open-ended comments box (Cook & Heath,
2001). They challenged the applicability of SERVQUAL to the evaluation of library services and
then developed LibQUAL+ from a grounded theory approach. More than 1,200 libraries have
used this tool since 2000 for improvement of library services3.
Many studies have examined the validity of LibQUAL+ using statistical methods. Thompson et
al. (2005) conducted a concurrent validity test with LibQUAL+ scores and satisfaction and
3

LibQUAL+ http://www.libqual.org

27

outcome scores using surveys with university users in the US and UK. This study found that
LibQUAL+ measures satisfaction rather than outcome (perceived value for academic purposes).
Lane et al. (2012) conducted an analysis of factorial validity using three independent data sets
which surveyed university students and faculty, and found LibQUAL+ scores are relatively
consistent over time, which indicates the structure of the tool is stable. However, they found that
service quality may be evaluated with two rather than three dimensions. Kieftenbeld and Natesan
(2013) measured structural invariance of LibQUAL+ scores among three user groups:
undergraduate students, graduate students, and faculty members. They found that scores of
undergraduate students showed high perceptions on the ‘Library as Place’ factor and faculty
scores showed high perceptions on ‘Affect of Service’. Helgesen and Nesset (2011) conducted
surveys with undergraduate students and analyzed the data based on the structural equation model
to find that three dimensions of LibQUAL+ explain student loyalty to the library. This study
showed that the data from LibQUAL+ can be used to identify other factors related to libraries.
LibQUAL+ survey data have been analyzed to identify dimensions required to improve library
services. Dissertations such as those by Miller (2008), Posey (2009), and Martin (2011) applied
LibQUAL+ and compared characteristics of institutions such as budgets, FTE, type, gender and
generations to provide information about the meaning of scores to library decision makers.
Kayongo and Jones (2008) examined the result of LibQUAL+ surveys for the Notre Dame
libraries in 2006 and identified that a faculty group was not satisfied with the ‘Information
Control’ area, which means technological support, while the overall results showed satisfaction
with library services. This study emphasized that libraries need to identify services that are
important to a faculty group. Roy et al. (2012) analyzed LibQUAL+ data in 2008 and found that
‘Affect of Service’ is the most important dimension effecting overall satisfaction. However,
LibQUAL+ didn’t measure it adequately; the answer rate for ‘Affect of Service’ was lower than

28

the other two dimensions, which depended on user characteristics such as library experience and
positions (faculty and students).
There are studies raising issues of LibQUAL+ and suggesting modifications and/or verification of
the results for improving this assessment tool. Guidry (2002) analyzed LibQUAL+ comments in
2001 and found that the length of the survey was a problem, so the number of items was reduced.
The concerns were primarily caused by the gap concept, which measures expectations and
perceptions. Roszkowski et al. (2005) conducted a multiple regression analysis with perceived
and gap score, which is the difference between perceived and desired levels of performance,
based on the LibQUAL+ data from 308 colleges and universities. The results showed that the
perceived score is a better measure than the gap score on the LibQUAL+.
2.3. EService Quality
As electronic services (e-services) have emerged, many studies have been conducted evaluating
e-service quality to include characteristics of e-services and users. An earlier study by Zeithaml et
al. (2000) defined e-service quality as “the extent to which a web site facilitates efficient and
effective shopping, purchasing, and delivery”, which focused on the processes of retail services.
The authors mentioned the definition of e-service quality again in their 2005 study (Parasuraman
et al., 2005) as that e-service quality is defined “broadly to encompass all phases of a customer’s
interactions with a web site.” A more recent study by Liu (2012) analyzing the effect of e-service
quality, defined e-service as “an interactive, content-centered, and Internet-based customer
service that is driven by the customers and integrated with the support of technologies and
systems offered by service providers who aim at strengthening the customer-provider
relationship”, which included comprehensive features related to e-services.
The criteria for e-service quality have been developed by modifying established measurements
for offline services as well as introducing ones from other fields. Most studies established scales

29

for their e-services based on factors extracted from literature reviews and refined them by focus
group interviews of experts in their fields. This section covers ten different instruments for
evaluating e-services and measurements of libraries’ e-services.
2.3.1. Evaluation Tools for EServices
Since the early 2000s, more than ten measurements have been developed for evaluating e-services.
Most of them are for e-commerce sites; some dimensions of each scale overlap, but they are
slightly different and the testing respondents are varied (Table 4). The authors argued that online
services have different characteristics compared to traditional services and thus justifying
development of their own scales.
Loiacono et al. (2002) developed ‘WebQUAL’ which consists of 12 dimensions with 36 items for
websites quality to measure customers’ intentions to purchase and revisit. They conducted
interviews with web designers and users. However, the survey respondents were not customers
who had purchasing experience through the websites, but web designers who might focus on the
technical side rather than service delivery. Barnes and Vidgen (2002) developed a scale with five
dimensions that also is named ‘WebQUAL’. They surveyed university students and staff who
used online bookstores; however, their scale was criticized as the respondents had no experience
of the whole purchase transaction, thus the survey does not evaluate comprehensive service
quality (Parasuraman et al., 2005). Yoo and Donthu (2001) developed ‘SITEQUAL’ which
consists of four dimensions with nine items to measure the perceived quality of Internet shopping
sites. They collected items using surveys of college students, and conducted factor analyses to
narrow down and generate the final items. This scale focuses on measuring the interface of
websites rather than service delivery.
The following scales were developed to measure more detailed parts of e-services than the three
studies mentioned above which do not constitute comprehensive evaluation. Santos (2003)

30

developed an e-service quality model to measure customers’ attitudes toward websites, their
intention to purchase, and loyalty, which consisted of two dimensions: incubative and active.
Wolfinbarger and Gilly (2003) developed ‘eTailQ’ to measure customers’ experience with
shopping websites using online and offline focus groups, hierarchical cluster analysis, and online
customers who had the entire purchase experience, which consists of four dimensions and 14
items: website design, fulfillment/reliability, privacy/security and customer service. Their study
found privacy/security is connected to website design and affects the customers’ website
experience. Bauer et al. (2006) developed the ‘eTransQual’ instrument including hedonic factors
such as enjoyment and aesthetic design. The authors indicated that the previous scales such as
eTailQ and E-S-QUAL don’t include hedonic items. They emphasized those intrinsic factors
because they found those factors are connected to utilitarian quality factors such as availability,
responsiveness, reliability, and privacy. Ding et al. (2011) developed ‘e-SELFQUAL’ to assess
the relationship between online service quality and customers’ satisfaction and loyalty from an
online self-service view. The scale consists of four dimensions (perceived control, service
convenience, service fulfillment, and customer service) and 12 items based on a literature review
to collect possible items and survey business faculty and students to narrow down and test their
validity. Huang et al. (2015) developed ‘M-S-QUAL’ to measure service quality in a mobile
context for both physical and virtual products. The scale consists of efficiency, fulfillment,
responsiveness, contact for both physical and virtual services, but privacy is added for virtual
services. This scale was based on SERVQUAL and E-S-QUAL, and has value for reflecting
mobile features because hand-held device users are increasing.
Tate and Evermann (2010) argued that SERVQUAL is not applicable for online services because
it was developed for face-to-face marketing that differs from online services in interaction
patterns of use. They suggested some dimensions that are required for evaluating online service
quality: characteristics of technology, usage patterns, and the way of software adaptation.

31

Zeithaml et al. (2000) explored customer interaction with e-service providers based on focus
group research with customers. They proposed a Means-End model of perceptions of e-service
quality to understand the cognitive structure of customers, which consists of concrete cues,
perceptual attributes, dimensions, and higher-level abstractions. The researchers found 11
dimensions for the evaluation of e-service quality: access, ease of navigation, efficiency,
flexibility, reliability, personalization, security/privacy, responsiveness, assurance/trust, site
aesthetics, and price knowledge. Their study also developed a conceptual model for
understanding and improving e-service quality that presents four organizational gaps: information,
design, communication, and fulfillment. Three gaps: information, design, and communication,
occur in the process of marketing, designing, and operating web sites on the service provider side.
These three gaps contribute to the fulfillment gap on the customer side, which represents a
discrepancy between customers’ requirements and experiences. The fulfillment gap has an effect
on perceived e-service quality, perceived value, and purchase/repurchase behavior (Zeithaml et
al., 2000). The authors investigated trends of evaluating e-service quality on the basis of literature
reviews and synthesis, and identified criteria related to e-service quality perceptions. They
suggested an e-SERVQUAL scale consisting of seven dimensions: efficiency, reliability,
fulfillment, privacy, responsiveness, compensation, and contact (Zeithaml et al., 2002). After that,
they established an instrument based on the means-end framework, ‘E-S-QUAL’ which consists
of four dimensions: efficiency, system availability, fulfillment, and privacy (Parasuraman et al.,
2005). This instrument contains 22 items, which was reduced from 113 items collected from
online user surveys and iterative analysis. Parasuraman et al. (2005) didn’t investigate e-service
quality as gaps between user-perceived expectation and performance, but the authors suggested
that companies can measure the perceptions by comparing desired and delivered service levels.
Some studies measured the gaps using the E-S-QUAL model to assess the quality of services in
Internet banking (Ali, 2012) and an online job-seeking site (Lin et al., 2009).

32

E-S-QUAL measures the customers’ perceptions of service quality delivered via online and has
been applied in a variety of e-service industries such as online shopping (Kandulapati &
Bellamkonda, 2014; Wu, 2006), online book stores (Boshoff, 2007), online grocery sites (Rafiq et
al., 2012), social commerce (Lee et al., 2012), microblogging sites (Hu et al., 2012), and different
geographical and cultural environments including online shopping experiences of African
American and Chinese customers (Meng & Mummalaneni, 2010), online banking in Turkey
(Akinci et al., 2010), and an online Spanish supermarket (Marimon et al., 2010). Yaya et al.
(2012) conducted comprehensive literature reviews about E-S-QUAL and found that E-S-QUAL
is applicable to various e-service industries in 11 countries; however, the dimension of fulfillment
appear to be specific to web sites selling physical products whereas the other three dimensions are
consistent in the various service settings. Boshoff (2007) found a different dimensionality of E-SQUAL: specifically, ‘reliability’ which has two sub-dimensions: trust (correct items) and access
(website connections). The author suggested that researchers need to reassess the dimensionality
of their studies’ E-S-QUAL data.
In summary, e-service quality studies applying SERVQUAL and developing new instruments
indicate that e-services need different dimensions to measure their quality than do services
delivered offline. As to research methods, researchers primarily conducted focus group interviews
with experts, user surveys, and/or the Delphi technique to identify relevant items for their specific
services; applied factor analysis to narrow the range of items to find essential dimensions and to
support validity; and analyzed relations among factors using the structural equation model.
However, validation issues remain with some small sample sizes, and biased composition for
surveys and interviews.
The studies reveal a general consensus that the online environment is different from the
traditional retail context in terms of convenience, efficiency, confidentiality, privacy, and absence

33

of face-to-face contact (Ladhari, 2010). Researchers have developed scales in e-commerce
(Loiacono et al., 2002; Barnes & Vidgen, 2002; Wolfinbarger & Gilly, 2003; Parasuraman et al.,
2005) and banking (Yang et al., 2004) indicating that different criteria are needed. However, there
are common dimensions such as reliability/fulfillment, responsiveness, web design, ease of
use/usability, privacy/security, information quality/benefit (Ladhari, 2010).

34
Table 4.
EService Quality Evaluation Tools
SiteQual

WebQual

WebQual

e SERVQUAL

E service quality

Authors

Yoo & Donthu
(2001)

Loiacono et al.
(2002)

Barnes & Vidgen
(2002)

Zeithaml et al.
(2002)

Santos
(2003)

Dimensions

Tools

Tools

Dimensions

Authors

 Ease

 Usefulness

 Usability

 Efficiency

 Incubative



of use
Convenient to use; Easy to
search
 Aesthetic design
 Colorful; Creative; Good
pictures of products
 Processing speed
 Easy to access the results;
Quick process
 Security
 Ensure me of security;
Confident of security with
this site

Information quality; Functional Fit
toTask; Interactivity; Trust;
Response Time
 Ease of Use:
Ease of understanding; Intuitive
operations
 Entertainment
 Visual appeal; Innovativeness; Flow
 Complimentary relationship
 Consistent image; Online
completeness; Better than
alternative channels
 Customer service

 Information

 Reliability



 Design

 Fulfillment

 Trust

 Privacy

 Empathy

 Responsiveness

eTailQ
Wolfinbarger & Gilly
(2003)
 Website Design
 Reliability/fulfillment
 Privacy/Security
 Customer service



ESQUAL
Parasuraman et al.
(2005)
 Efficiency
 Fulfillment
 System availability
 Privacy
 Responsive
 Compensation
 Contact

 Compensation
 Contact

eTransQual
Bauer et al.
(2006)
 Functionality/design
 Enjoyment
 Process
 Reliability
 Responsiveness

eSelfQual
Ding et al.
(2011)
 Perceived control
 Service convenience
 Customer service
 Service fulfillment

dimension
Ease of use; Appearance;
Linkage; Structure and
layout; Content
 Active dimension
 Reliability; Efficiency;
Support; Communication;
Security; Incentive

MSQUAL
Huang et al.
(2015)
Physical Product
 Efficiency
 Fulfillment
 Contact
 Responsiveness
Virtual Product
 Contact
 Responsiveness
 Fulfillment
 Privacy
 Efficiency

35

2.3.2. EService Quality in Libraries
Studies developing evaluation tools for libraries’ e-services investigated factors applicable to the
library context on a basis of existing scales of service quality and focus group interviews with
experts and/or users to modify dimensions and items. In those studies, e-services in libraries
primarily entail information provision on library websites and communication via online. This
section covers studies about evaluating service quality of online library services.
O’Neill et al. (2001) and Hernon and Calvert (2005) modified the original SERVQUAL to fit in
the online context, specifically, for online library service evaluation. Both studies conducted
surveys and interviews with university students and library staff members to customize item
wording applicable to the academic library context. O’Neill et al. (2001) took an 18 items
questionnaire which asked participants to rate their expectations, perceptions, and the importance
of each item. Factor analysis revealed four dimensions: contact, response, reliability, and
tangibles. Among them, reliability is highly important but a low performance attribute, which
identifies opportunity for the library to improve. Hernon and Calvert (2005) developed a
questionnaire using reviews of existing instruments including SERVQUAL and e-SERVQUAL.
The survey results identified 11 dimensions from 104 statements and found ‘ease of use’ is the
most important dimension for online environment of library services.
The studies of O’Neill et al. (2001) and Hernon and Calvert (2005) utilized SERVQUAL;
however, Kiran and Diljit (2012) argued that SERVQUAL is not applicable to online library
services because it is based on offline services. They developed a conceptual model for online
library service quality based on a comprehensive literature review and surveys with post-graduate
and library staff members to identify factors related to online services. They found three
dimensions (environment, delivery, and outcome) and eight items of e-service quality; the model
has a two level hierarchical construct. They emphasized how customers perceive the outcome of

36

service uses; the survey investigated only performance without perceptions for expectations.
Table 5 shows dimensions and items of the above three studies. Among them, the dimension of
reliability consistently appears.
The LibQUAL+ instrument measures library service quality of traditional services in physical
places and face-to-face communication settings. DigiQUAL and MINES have been developed for
measuring electronic services in libraries. DigiQUAL is an instrument developed by ARL, Texas
A&M University Libraries, and the University of Texas, for evaluating digital library websites
(Kyrillidou & Giersch, 2005). The questionnaire includes items of modified LibQUAL+ items;
three dimensions are identified: information control, content comprehensiveness, and ease of use
(Kyrillidou et al., 2011). MINES (Measuring the Impact of Networked Electronic Services)
focuses on usage of electronic resources through library systems (Franklin & Plum, 2006).

Table 5.
Dimensions for Evaluating Libraries’ EService Quality

Tools

Online library services

E service quality in libraries

Web based library service
quality

Authors

O’Neill et al.
(2001)

Hernon & Calvert
(2005)

Kiran & Diljit
(2012)

Dimensions

Contact
Responsiveness
 Reliability
 Tangibles

Ease of use
Collections
 Reliability
 Customization/personalization
 Security/privacy/trust
 Support
 Easy of access
 Linkage
 Flexibility
 Web site aesthetics









Web service
Access & collection
 Equipment
 Delivery
 Personalization
 Customer support
 Customer relationship
 Outcome
 Reliability
 Functional benefits
 Emotional benefits




37

2.4. Online Survey Response Rates
The survey response rate supports the reliability and validity of study results because it relates to
the representativeness of the sample respondents (Babbie, 2009, p.272). A low response rate
increases the chance of higher error in generalizability to the target population. The minimum
response rate accepted in offline survey research has been around 70% (Babbie, 2009, p.273).
However, many studies using online surveys have shown lower response rates (3% – 50%) (e.g.
Grevet et al., 2014; Balfe et al., 2012; Baruch & Holtom, 2008; Deutskens et al., 2004).
Low response rates of online surveys could increase bias in the representativeness of the
population. However, online survey and recruitment can be objective to identify relevant
audiences when users who are engaged in online activities are the target of the investigation
(Panagiotopoulos, 2012). In addition, participants who have personal interests are likely to
complete the survey with higher data quality (Barrios et al., 2011).
Studies inviting survey participants using social media could not identify the total number of
samples because distribution through social media is not usually confined to a specific population.
If survey postings are shared or retweeted by other users, it is hard to calculate the number of
people who are exposed to the survey. Hence, the response rate can be calculated based on both
the number of click-throughs and the number of impressions. The American Association for
Public Opinion Research (AAPOR, 2011) defined these calculation methods as “participation
rate.”
Some studies did not indicate the total number of impressions and click-throughs when the survey
target was broad and snowball sampling was conducted using various venues such as email,
instant messages, and direct messages on social media. For non-probability samples, response
rate calculation is impossible because the denominator is unknown (Callegaro & DiSogra, 2008).

38

The numbers of valid responses in those studies, for example, were 402 (Lin & Lu, 2011) and 182
(Cheung et al., 2011) to explore motivations of using social media, and 343 (Wu et al., 2014), 162
(Choi et al., 2013) and 319 (Hsieh et al., 2012) to investigate switching behavior in social media.
To avoid a low response rate, different approaches have been used in studies. Grevet et al. (2014)
investigated political differences on Facebook but sent their survey to selected people using
Twitter messages. Because sending messages to non-friends on Facebook includes a fee, they
searched Twitter users who have mentioned relevant tweets. The response rate was 5.4% (103 out
of 1,900). Balfe et al. (2012) put a recruitment posting on two Facebook pages (1,500 and 220
members) related to the study purpose, young adults with diabetes, and received respectively 26
responses from the larger group, which reflected a 1.7% response rate, and no responses from the
small group even sending one reminder. Batterham (2014) examined the effectiveness of
advertising statements that invited more responses. Facebook was used to recruit participants and
the authors concluded that the statement including terminology of problem frames with self-gain
is more effective rather than positive and altruistic terminology. Personalized invitation messages
mainly affected the response rates positively rather than anonymous emails (Sánchez-Fernández
et al., 2012).
Response rates and recruitment methods have been important components in conducting survey
research. This study will analyze survey response rates to identify whether social media have
enough valid completed responses for a library survey, which reflects populations and helps to
determine reliability and validity.
In this study, response rates will be calculated in two ways. The first metric uses the number of
impressions that indicates the number of people who are exposed to the survey announcements.
The second metric uses click-throughs, which indicates the number of URL links clicked on the
survey announcement and displays at least the first webpage of the survey.

39



 

       



   



       
    

2.5. Summary
This literature review covers libraries’ social media services; the evaluation of library services,
service quality, and e-service quality; and online survey response rates. It highlights the current
lack of research on the evaluation of service quality for libraries’ social media services,
specifically, the evaluation of libraries’ social media services from a user perspective and
evaluation instruments for social media service quality. Outdated evaluation statements,
fragmented quantitative information from external applications, and a lack of measurement
instruments are limitations in identifying user perceptions.
Many libraries have used social media for marketing, service delivery, and communications.
Studies about libraries’ social media usage showed that there might be differences between
libraries’ uses and their patrons’ expectations of social media. Previous studies have approached
the evaluation of libraries’ social media services with quantitative measures and qualitative
surveys about librarians and users’ perceptions, but there are no studies about the evaluation of
perceived service quality of library social media applying a validated instrument.
Instruments for assessing service quality and e-service quality have been developed mainly in
business since the 2000s, and applied to a variety of service areas including library services.
Based on the Parasuraman et al.’s Gaps Model of Service Quality, LibQUAL+ has been
developed for evaluating libraries’ service quality. However, that instrument assesses services
related to physical places and face-to-face communications, which are different from the online

40

services’ communication processes. DigiQUAL and MINES have been developed for evaluating
digital library websites and used of electronic resources, but DigiQUAL has not been tested for
social media services and MINES focuses on the usage statistics of digital content. Criteria for
assessing service quality of libraries’ social media services have not yet been developed. An
instrument for assessing libraries’ e-service quality will help service providers to improve users’
perceived service quality of library social media.
Lee et al. (2012) and Hu et al. (2012) modified Parasuraman, Zeithaml, and Malhotra’s E-SQUAL for assessing social commerce and microblogging. Studies such as Meng and
Mummalaneni (2010), Akinci et al. (2010), and Ingle and Connolly (2006) showed that E-SQUAL is valid and reliable in diverse e-commerce and geographical settings. The service quality
depends on who provides the services as well as when, where, and how they are provided (Kotler
& Armstrong, 2013, p.260). However, no evidence is found that E-S-QUAL has been used in any
library settings. For these reasons, this study selected the E-S-QUAL instrument to evaluate the
service quality of library social media.
Online surveys, specifically, inviting participants online, have two issues: low response rates and
the calculation of the number of people in a sample. First, to increase response rates, previous
studies have used reminders, personalized messages, incentives, and social media’s advertisement
products. This study applied some of these methods to invite participants and address how those
methods were used in a library social media context. Second, when a survey is distributed
through social media, the number of people who are exposed to the survey could be imprecise.
Hence, this study used two methods for calculating response rates using the numbers of
impression and click-through.
This study focused on academic libraries to assess the applicability of E-S-QUAL. About 90% of
U.S. young adults (18-29) use social media, which is the most of any generation, and they spend

41

more time on social media than with any other single online activity (Hampton et al., 2011). To
address their concentrated behavior using social media, this study focuses on academic libraries’
social media services because the majority of library users are young adults (Becker, 2009).
This research evaluating the applicability of an instrument to the measurement of service quality
of library social media services is important for information professionals to assess service
quality and to describe the impact of services, avoid errors, increase efficiency, and support
planning strategies. Furthermore, results will help library managers give feedback to staff and
make decisions to continue or discontinue their libraries’ services (Powell, 2006; Wallace & Van
Fleet, 2001; Weiss, 1998).

42

CHAPTER 3. RESEARCH METHODOLOGY
The assessment of the E-S-QUAL’s applicability to the academic library context was undertaken
through nine hypotheses. The data gathering methodology followed standard online survey
protocols. The study extended the methodology to utilizing social media to gather data, which
raised issues of identifying the population sample and determining response rates. This study
included research questions related to methodological issues and explored different approaches to
address them. The E-S-QUAL instrument was modified for application to library services. A
focus group interview was used to test content validity and the researcher used the insights from
the interview to modify the instrument. A pilot test, conducted at one academic library, identified
problems in the modified statements and checked the effectiveness of the survey procedures
including finding participating sites, checking the online survey structure, and gathering survey
participants through social media. Based on the results of the pilot test, errors in the modified
statements were identified and corrected, and then a final instrument was designed.
3.1. Research Design
This study was conducted during the 2014 fall semester at five research university libraries in
North America, selected by the following criteria: providing Twitter service, having more than
1,000 followers, and currently operating the service. To recruit participants, the researcher asked
library managers to broadcast several postings including a link to the online survey. To recruit
service provider participants, the researcher asked the managers of the participating libraries to
send the questionnaire to library staff members who have managed social media services. Data
were gathered during two months, between October 13th, 2014 and December 22th, 2014. The
collected data were analyzed primarily with statistical methods to examine the research questions
and hypotheses.

43

In this chapter, details of the research design will be discussed within the following sections: the
instrument and modifications, population and sampling, pilot test, and statistical data analysis
methods. The research design’s assumptions and limitations will conclude this chapter.
The instruments and research protocol were approved by the Institutional Review Board at Drexel
University, and permission letters were received from the five participating libraries.
3.2. The Instrument and Modifications
The original E-S-QUAL instrument is composed of four sections. The first section includes 22
items for measuring service quality. The second section contains 11 items that are for recovery
services such as product returns. Respondents were asked to indicate their answers to each item of
E-S-QUAL measured by a five-point scale ranging from 1 (strongly disagree) to 5 (strongly
agree). The third section consists of two criterion constructs, four items in perceived value and
five items in loyalty intentions. Perceived value was measured by a ten-point scale from 1 (poor)
to 10 (excellent). Loyalty intentions were measured by a five-point scale from 1 (strongly
disagree) to 5 (strongly agree). The fourth section contains demographic questions including age,
gender, education, income level, length of web site use, and frequency of web site visits. As
mentioned in the previous chapter, E-S-QUAL was developed in an e-commerce context. For
application with a library social media service, the researcher modified items’ statements in three
steps. First, the researcher slightly revised wording based on the review of previous studies.
Second, a focus group interview was conducted to test content validity. Third, the researcher
modified the statements based on the results of the interview and confirmed the modified
statements using follow-up email correspondence. Details will be described in the following
subsections.

44

3.2.1. Review of Previous Studies’ ESQUAL Modifications
The researcher modified the wording in the original E-S-QUAL statements to reflect the service
context of online interactions with users about library information delivered through platforms
hosted by external applications. Previous studies that assessed non-profit services using E-SQUAL were consulted to guide the modifications. Jun et al. (2009) modified items in an egovernment services setting and omitted no items from the original version. The authors changed
fulfillment and privacy items significantly and some statements such as EFF3, SYS3, and SYS4
to reflect e-government services. Hu et al. (2012) deleted 11 items that were related to purchase
transactions and added some items from other studies to apply E-S-QUAL for assessing
microblogging sites. Zada et al. (2012) deleted two items that had low coefficient values within
the dimensions when they used the instrument to assess a university website. Table 6 on page 48
contains above three papers’ statement modifications. As the first step of modifications, this
present study slightly revised some wording related to product orders and physical delivery and
did not remove any items.
3.2.2. Focus Group Interview
A focus group interview was conducted to test that the modified statements were explicit in the
context of libraries’ social media services and to maximize content validity of the instrument
wording. A focus group interview was used to encourage participants to discuss their opinions in
order to explore unanticipated issues (Marshall & Rossman, 2011). Four doctoral students in an
information science program who have an interest in this study topic and one library staff
member who manages social media services in a research university library participated in the
focus group interview (Appendix A). The doctoral students, having experience in survey research
studies and the use of social media, helped examine the statements and the library staff member
helped ensure that the questions reflected library services.

45

The focus group interview was conducted as follows: the researcher recruited doctoral students
and librarians via email requests. Four students and one library staff member voluntarily
participated in the interview. The researcher as a moderator guided the interview with the five
participants. The researcher presented the study setting to the participants to ensure they
understood the purposes of the focus group interview. Each participant completed the
questionnaire to identify vague and misleading statements. After that, the interviewer encouraged
them to express their opinions about statements that were misleading to apply to a library social
media service setting. The participants were free to discuss their understandings with each other.
The interview was conducted for 80 minutes on May 29th, 2014, and recorded by a digital device.
The participants’ privacy was ensured and their opinions were used only for this study purpose.
Based on the opinions expressed through the focus group interview, the researcher identified
items conceptually inconsistent to this study setting. The statements were further revised to
reduce some confusing wording. Group consensus was achieved on the modification of
statements for ensuring content validity. From the results of the interview and follow-up emails,
the researcher identified three features about the E-S-QUAL modifications for this study, which
are discussed in the following section.
3.2.3. Features of ESQUAL Modifications for This Study
The modifications made to the E-S-QUAL items considered three features of libraries’ social
media services where participants felt the original instrument wording was vague and not
applicable. First, using social media to communicate with users and to provide information is an
online process. Offline activities are rarely combined with the services. The E-S-QUAL items
were developed to assess the e-service quality of website users’ purchase and delivery of material
goods which combines features of online information use as well as physical delivery. Therefore,
phrases related to offline delivery such as “delivers orders” and “sends out the items ordered”

46

were modified to reflect the process of online information delivery. Second, the service provides
information that is generated and described by libraries. Information can be posted on the
libraries’ social media accounts without specific requests from users. “Item” in the original E-SQUAL statements was changed to “library information” to indicate any content posted and shared
by a library on its social media accounts. Third, the service uses social media as a platform that is
neither owned nor configured by a library. The originally stated items of system availability and
privacy dimensions were developed with the intention that service providers operate the sites.
However, libraries create services for users on the selected social media platforms, which have
been developed by IT companies. It is different from other non-profit services such as egovernment ones which have developed their own websites. Social media are limited to modify
the sites’ structure and layouts. Therefore, the modifications were made based on the requirement
that a platform be both a functioning and protected system to ensure stable services to users.
In the case of e-service quality, it is hard to discriminate between service and websites because
providers use websites to operate their services. E-services cannot be designed without
considering websites. E-service quality criteria developed by others including Loiacono et al.
(2002), Barnes and Vidgen (2002), Santos (2003), Wolfinbarger and Gilly (2003), and Ding et al.
(2011) also include dimensions for assessing performance of services and websites. For instance,
ease of use and security are issues for website structures; criteria related to reliability and
fulfillment include service issues. Henencece, the statements of the adapted E-S-QUAL for this
study were changed to include both services and sites to fit into the library social media service
setting.
From the original statements of E-S-QUAL items, the words related to online shopping were
changed in response to the characteristics of academic libraries’ social media services: “items”
which refer to selling products were changed to “information” or “contents.” “Order items” were

47

modified to “information that a user expects to receive” from a library’s social media site.
“Delivery” and “transaction” were modified to “receiving/getting library information.”
Among the four dimensions, first, items in efficiency dimension were modified to reflect the
extent of providing and receiving information through a platform that is easy to use. The word
“site” was modified to “a social media site” if it was used as a platform, and some words
indicating features that reflect communication with users were modified to “library information.”
Second, system availability evaluates the platform’s functioning as a library’s service tool. Most
of its items are applicable in the context of libraries’ social media services. A phrase “order
information” was changed to “my comments” which reflect a similar function. Third, fulfillment
dimension involves accurate orders and product representation, and on-time delivery
(Parasuraman et al., 2005). This dimension is important to include users’ experiences after their
interactions with services (Parasuraman et al., 2005). However, those attributes do not include the
purpose of the use of social media in libraries. To reflect features of libraries’ social media
services, the definition was slightly revised to the extent to which the service’s promise about
dependable and accurate information delivery is fulfilled. Items were modified based on this
definition while retaining the key concepts of the original statements. Fourth, privacy items were
modified based on two perspectives: a library as a service provider, and social media as
platforms. An account owner might have information about user lists or data about who clicks
links. Items address the social media sites maintenance of their own privacy regulations.
Parasuraman et al. (2005) verified the scale’s validity by examining the effect of the four
dimensions on three criterion constructs: overall quality, perceived value, and loyalty intentions.
The overall quality statement does not need to be modified. Multiple items of the two constructs
were modified to measure validity. Phrases including perceptions of economical benefits in the

48

perceived value items were deleted. Items of loyalty intentions are about behavioral views: most
of them are applicable in the libraries’ social media setting by modifying a few phrases.
To summarize the modifications, among the original 22 E-S-QUAL items, seven items reflecting
the fulfillment dimension were significantly changed while retaining their main attributes. Even
though there was a need to adjust specific wording, no items were eliminated. Tables 6 and 7
describe the modified statements of the 22 items and of the three criterion variables, respectively.
Table 6.
The Original and Modified ESQUAL Statements
E S QUAL (Parasuraman et al., 2005)
Modified for e government (Jun et
al., 2009)
– Deleted


Dimensions

Item

Modified statement for this study

Efficiency

EFF1

This service makes it easy to find
library information that I need.

EFF2

This service makes it easy to get
library information.

EFF3

It enables me to get to library
information quickly.

EFF4

Library postings on Twitter are well
organized.

EFF5

The site loads its pages fast.

EFF6

Library information at the Twitter
site is simple to use.



EFF7

The Twitter site enables me to get to
library information quickly.



EFF8

The organization of posts on Twitter
site works well for using library
information.

SYS1

The Twitter site is always available
for this service.



SYS2

This Twitter site launches and runs
right away.



System
Availability

This site makes it easy to find what I need.
site makes it easy to find which
service I need.
 It makes it easy to get anywhere on the
site.
 It makes it easy to get anywhere on the
site.
 It enables me to complete a transaction
quickly.
 The service process is concise.
– Deleted: Hu et al. (2012)


 This



Informaon at this site is well organized.
at this site is well organized.

 Informaon


It loads its pages fast.
loads its pages fast.

 It

This site is simple to use.
site is simple to use.

 This

This site enables me to get on to it quickly.
site enables me to get on to it quickly.

 This


This site is well organized.
site is well organized.

 This

This site is always available for business.
site is always available for service.

 This

This site launches and runs right away.
site launches and runs right away.

 This

49

SYS3

This site does not crash.

This Twitter site does not crash.

 The pages of the website display normally.

SYS4

Pages at this site do not freeze after I
enter my comments.

Pages at this site do not freeze after I
enter my order information.
 There is no error occurred during using the
website.
– Deleted: Hu et al. (2012), Zada et al. (2012)

FUL1

This service delivers timely
information.

FUL2

It gives responses for my questions
within a suitable time frame.

FUL3

It quickly provides information that I
seek.
It provides information that I
expect in a timely manner.

FUL4

It provides information that I’d like
to receive.

It delivers orders when promised.

Fulfillment

FUL5

It has information about what is
going on in the library.

FUL6

It is truthful about the information it
provides.

 It oers service when necessary

information and materials are submitted.
– Deleted: Hu et al. (2012), Zada et al. (2012)
This site makes items available for delivery
within a suitable time frame.
 This site gives feedback quickly.
– Deleted: Hu et al. (2012)
It quickly delivers what I order.

 The service was delivered before promised
deadline.
– Deleted: Hu et al. (2012)
It sends out the items ordered.

 It fulfills promised service quickly.
– Deleted: Hu et al. (2012)
It has in stock the items the company
claims to have.
 The service is available when it was
showed on the page.
– Deleted: Hu et al. (2012)
It is truthful about its offerings.

 It is truthful about its promised.
– Deleted: Hu et al. (2012)
It makes accurate promises about delivery
of products.
 It makes accurate promises about its
service.
– Deleted: Hu et al. (2012)

FUL7

It delivers accurate information.

PRI1

The library does not share
information about my behavior
(browsing pages, clicking links, etc.)
on its Twitter account with others.

It protects informaon about my Web
shopping behavior.
 It protects my personal informaon.

PRI2

The library does not share my
personal information on Twitter with
other sites.

PRI3

The Twitter site protects information
about my personal data.

It does not share my personal information
with other sites.
 It does not leak my personal informaon
to public.
This site protects informaon about my
credit card.
 It protects my submied materials’
information.
– Deleted: Hu et al. (2012)

Privacy

50

Table 7.
The Original and Modified Statements of Three Criterion Variables
Variable
Perceived
Value

Item
VALUE1
VALUE2

VALUE3

VALUE4
Loyalty
Intentions

LOYALTY1
LOYALTY2
LOYALTY3
LOYALTY4
LOYALTY5

Modified statement for this study

Parasuraman et al. (2005)

The information and services
available at this library’s social media.

The prices of the products and services
available at this site (how economical
the site is).
The overall convenience of using this
site.

The overall convenience of using this
service.
The extent to which the library’s
social media service gives you a
feeling of being in control of what
you intend to do.
The overall value you get from this
service for your efforts.
Say positive things about this service
to other people.
Recommend this service to someone
who seeks your advice.
Encourage friends and others to
follow this service.
Consider this service to be your first
choice for future library information.
Keep following this service in the
coming months.

The extent to which the site gives you a
feeling of being in control.
The overall value you get from this site
for your money and effort.
Say positive things about this site to
other people?
Recommend this site to someone who
seeks your advice?
Encourage friends and others to do
business with this site?
Consider this site to be your first choice
for future transactions?
Do more business with this site in the
coming months?

3.2.4. Instrument Structure
The survey instrument to assess applicability of E-S-QUAL in this study was the modified
version of the original questionnaire. This study adopted the E-S-QUAL items, criterion
constructs, demographic, and library social media usage questions. The scales for measuring
items were not changed. The researcher put a service usage section before the E-S-QUAL
questions to invoke respondents’ experiences with the library Twitter service, and located
questions about demographic information in the last part. For each of the E-S-QUAL 22 items,
survey participants were asked to rate both perceived importance for libraries’ social media
services and the performance they experienced. Respondents who completed the questionnaire
were invited to submit their email address for a random prize drawing as an incentive. The
participants’ privacy was ensured and their emails were used only for this study purpose. The

51

instrument used in this study had a total of 41 questions. The structured questionnaire (Appendix
B) that was used for this study is organized into the following four sections:
Section A. Social media service usage: this section includes the participant’s initial access
route to library social media (question A1), access frequency to social media (A2),
awareness of library contents (A3), and interest for the service (A4 – A5).
Section B. E-service quality measurement: this section includes the modified E-S-QUAL
items comprising the four dimensions; efficiency (B1 – B8), fulfillment (B9 –
B15), system availability (B16 – B19), and privacy (B20 – B22). In addition, one
question (B23) is included to ask whether the 22 items omitted important features
about libraries’ social media services in order to test content validity.
Section C. Relevant variables: this section includes measures adopted from the scale
designed by Parasuraman et al. (2005) for overall quality (C1), perceived value
(C2 – C5), loyalty intentions (C6 – C10).
Section D. Participants’ demographics: this section includes questions about gender (D1),
age (D2), and status on the campus (D3 – D4) of respondents.
3.3. Population and Sampling
The following criteria were considered to select university libraries for participation in the study:
1) Libraries within North American research universities.
2) University libraries with links on library main websites to their Twitter service accounts.
3) Libraries with at least 1,000 ‘Followers.’

52

4) Libraries’ Twitter accounts currently providing services, defined as having updated
content for three consecutive months before they participated in the survey.
From the lists of research university, including the Carnegie classification listed in the National
Center for Education Statistics4 and U15 Group of Canadian Research Universities5, whose
libraries have Twitter services, the researcher selected the libraries in descending order by the
number of followers each had, and invited the top 30 to participate.
In addition, some librarians from university libraries contacted the researcher to participate in the
study at a conference venue (the 2014 Library Assessment Conference) as well as through a
listserv (arl-assess@arl.org) on which the researcher posted a message inviting interest in the
study. Among them, libraries that met the selection criteria were considered as a priority because
librarians could be more motivated and cooperative to conduct the survey.
Table 8.
Descriptions of Participating Research Sites

Site

Survey
Duration

Incentive

Enrollment
(’13)

Twitter
Service
Since

Average
Posting
Frequency*

Total
Tweets

Followers
*

A

Oct 13 – Nov 17
(5 weeks)

Apple
iPad

11,000

Jun 2009

1.48

1,732

1,900

B

Nov 3 – Nov 22
(3 weeks)

Apple
iPad

32,000

Feb 2009

1.84

2,645

3,604

C

Nov 20 – Dec
19 (4 weeks)

Apple
iPad

59,000

Apr 2009

0.72

3,327

1,063

D

Dec 8 – Dec 22
(2 weeks)

$100 gift
card

29,000

Jul 2009

1.27

1,623

1,240

E

Nov 3 – Nov 30
(4 weeks)

$100 gift
card

32,000

Mar 2008

1.34

3,296

1,765

* The total number of postings from 8/2014 through 11/2014 was divided by 122 days (for those three
months).
** The numbers were collected when the survey started at each site.
4

IPEDS (Integrated Postsecondary Education Data System) Data Center
http://nces.ed.gov/ipeds/datacenter/
5
U15 http://u15.ca/

53

Five research university libraries participated in the modified E-S-QUAL survey. Table 8
presents the details of these participating libraries; they were assured that their identity would
remain anonymous in reports of the study findings. The size of schools and the number of
followers are different among the five participating libraries. However, the purposes of their
library’s Twitter services are similar, such as sharing information about their library’s news,
events, and seminars, and suggesting useful information from other sources.
Data collection from the five different university libraries was conducted from October 2014
through December 2014. Each survey was conducted for two weeks at each site, but it was
expanded up to three more weeks when the response rates were low and the library agreed on the
expansion.
The target population for this study is two groups: users and service providers. First, research
university library’s Twitter service users who have followed its account to receive the library’s
contents on the application were the primary study population. For this study, “users” are limited
to people who access Twitter services more than once a week. Because postings on Twitter are
displayed in order of time of update, it could be assumed that if a user does not visit the
applications frequently, postings might be overlooked. This study assumed that survey
participants have sufficient experience in the use of library social media services. Service users
may include non-members of university communities because any users of Twitter can connect
with library accounts if service accounts are open to the public (Kim et al., 2012a; Yep &
Shulman, 2014). To recruit user participants, the researcher asked library social media managers
to broadcast postings including a link to the online survey on the libraries’ Twitter accounts and
the universities’ other social media pages such as library Facebook and student unions to ensure
that the survey postings reached as many users as possible. Those postings were activated or reposted to appear on the top of each user’s timeline in order to expose the survey to users and

54

invite more participants. Data were collected between two and five weeks, depending on each site,
during the fall semester (from October through December) in 2014. The survey was conducted
using the Survey Gizmo (http://www.surveygizmo.com), a web-based survey software product.
The respondents who completed the survey were given an opportunity to submit their email
address for a prize drawing.
The second target population was service providers who manage the social media services
including Twitter and Facebook in each participating university library. To recruit them, the
researcher asked library managers to send an email to their library staff members to request
participation in the survey. The survey for librarians included a question to identify their library
department to confirm their involvement in social media services.
Sample size is important for using factor analysis, one of the statistical methods used in this study.
Comrey and Lee (1992) advised that a sample size for factor analysis of 100 is poor, 200 is fair,
and 300 is good. Bruin (2006) suggested that a minimum of 10 samples per variable is required to
reduce computational difficulties, which indicates 320 for this study. However, MacCallum et al.
(1999) emphasized that the level of communalities, the amount of variance in a variable that is
explained by factors, is a more critical aspect to determine good discovery of factors rather than
the exact sample size. The authors recommended that communalities be over 0.5 in the variables.
If the values are less than 0.5, the sample size must be over 100. Following Bruin (2006), the
sample size for this present study should be at least 220, and preferably over 320.
3.4. Pilot Test
A pilot test was conducted to check the effectiveness of the survey procedures including finding
participating sites, checking an online survey structure, gathering survey participants through
social media, and the duration of data collection, as well as to identify any additional wording. A

55

survey was conducted at one research university library providing a Facebook service. The
participating library has been operating its Facebook service since June 2009, and had 1,231 users
who connected with the library Facebook account as of June 23th, 2014. The survey recruited
participants for three weeks from June 25th, 2014 through July 18th, 2014.
To recruit user participants, the researcher asked the library manager to broadcast the survey post
on the library’s Facebook page and to send an email to library staff members. Because of low
response rates in the first two weeks, the survey duration was expanded from two weeks to three
weeks. In addition, librarians on sites posted survey announcements on the university Facebook
pages for student services. Respondents who completed the questionnaire were invited to submit
their email address for a prize drawing for a chance to win a $50 Amazon.com gift card. The total
number of completed responses was 88. The data were analyzed using statistical analyses and
some helpful comments from respondents were considered to identify and edit vague wording.
The themes identified in the analysis of responses are as follows. First, one item (EFF5) in the
efficiency dimension and three items (FUL2, FUL3, FUL4) in fulfillment were not grouped in
each dimension in the results of exploratory factor analysis. The EFF5 item had been identified as
not grouped with efficiency items but with system availability in previous studies. Among the
three fulfillment items, the researcher decided to revise FUL3 statements from “It quickly
provides information that I seek” to “It provides information that I expect in a timely manner.”
Second, some survey respondents indicated that they were confused about the wording “library
information.” In order to help participants understand it clearly, a statement, “ ‘Library
information’ indicates any content posted and shared by a library on its social media accounts”
was added before the E-S-QUAL questions.

56

Third, in the pilot test, the primary obstacle to data collection was the response rate. Based on the
formula mentioned in Chapter 2.4 Online Survey Response Rate, the impression rate was 0.8%
(88/10,955) and the click-through rate was 15.3% (88/575). The response size [N=88] could be
small to conduct factor analysis. However, the level of communality in the pilot test is from the
lowest, 0.66 (EFF8) to the highest, 0.93 (SYS4), which is high enough based on MacCallum et
al.’s study (1999). To increase and achieve an acceptable response rate in this study, the
researcher conducted surveys at sites for the duration of a semester, asked site librarians to send
frequent reminders, and offered intriguing incentives.
The librarians’ survey participation was low. In the pilot test, the library manager sent an email to
the library’s 150 staff members, and four responses were collected (3%). To gain more responses
from them, emails including personalized messages and a prize drawing were sent.
In summary, from the pilot test, some changes were made in the instrument. One item statement
was revised but no item was deleted. Information details about a critical phrase were provided. A
resulting modified E-S-QUAL instrument was used in the study. Methods for increasing the
response rate were identified and incorporated in the final research design.
After the pilot test, Facebook changed its timeline algorithm from a chronological listing to
postings in order of their activeness such as the number of comments and likes. Correspondingly,
library postings are not exposed to users if they do not have relatively high amounts of feedback.
Therefore, Facebook may not have been a productive source for this study when this research was
conducted. The researcher decided to validate the instrument using a Twitter service with the
agreement of participating libraries’ social media service managers.

57

3.5. Statistical Data Analysis Methods
The quantitative data collected from the online survey were analyzed statistically using SPSS
22.0 and Amos 22.0. The qualitative comments from respondents in the survey were gathered and
categorized in order to identify items that were not applicable and to identify user-suggested
statements that were not included in the E-S-QUAL 22 items.
The internal consistency reliability of the modified E-S-QUAL scale was evaluated to identify
whether different items for constructs produce consistent scores. The Cronbach Alpha value for
each construct was used. Its conventional minimum is 0.7 (Nunnally & Bernstein, 1994).
According to previous studies of service quality applying E-S-QUAL, the range of Cronbach
Alpha was from a low of 0.6 (Malhotra, 2004) to a high of 0.97 (Chiou et al., 2009; Wu & Ding,
2007). The Cronbach Alpha values were compared with other data from different service industry
settings to determine whether the adapted E-S-QUAL scale is applicable to the library social
media setting.
The relationships between measured variables and latent constructs of E-S-QUAL have not been
verified in a library’s social media context; hence, an exploratory factor analysis (EFA) was
conducted to identify the underlying structure of measured variables and to detect low-fit
variables. EFA is used for a preliminary analysis for scale construction. However, Gerbing and
Anderson (1988) argued that confirmatory factor analysis (CFA) is needed to assess the resulting
scales because EFA does not represent underlying theoretical constructs. After conducting EFA,
CFA was conducted to test that measures of four factors in this study setting were consistent with
the original E-S-QUAL’s structure.
Correlations within and between the four dimensions (efficiency, system availability, fulfillment,
and privacy) and three constructs (e-service quality, perceived value, and loyalty intentions) were

58

analyzed to test convergent and discriminate validity. This study adopted the Fornell and Larcker
(1981) method: average variance extracted (AVE) is calculated based on the following equation
below. They suggest that if the AVE of each dimension and each construct is over 0.5, the
dimension and construct’s convergent validity is adequate because a value less than 0.5 indicates
that the variance measured by measurement error is larger than the variance by the dimensions
and construct (Fornell & Larcker, 1981). For discriminant validity, if the AVE of each dimension
and each construct is larger than the squared correlation between the two dimensions and the two
constructs (r2), the discrimination of dimensions/constructs is fully satisfied.

 

 
     

Correlation analysis was conducted to assess predictive validity between each summed criterion
variable (overall quality, perceived value, and loyalty intentions) and each summed dimensional
scores of the four E-S-QUAL dimensions. The Pearson correlation coefficient from this analysis
indicates whether instances are positively correlated. Many previous studies including
Parasuraman et al. (2005) confirmed positive correlation with the three criterion variables. This
study supposes that E-S-QUAL scores predict these three variables.
Structural equation modeling (SEM) analysis was conducted to test nomological validity. Based
on Parasuraman et al. (2005), the model is composed of three latent constructs: e-service quality,
perceived value, loyalty intentions (see Figure 1). Nomological validity examines relationships
among different constructs in network (Cronbach & Meehl, 1955). It tests the extent of impact eservice quality as an exogenous construct has on the two higher order constructs, perceived value
and loyalty intentions. Perceived value is set as an antecedent of loyalty intentions. The results
from the SEM analysis support the psychometric soundness of the E-S-QUAL instrument.

59

Multiple regression analysis was conducted to identify differences among the four dimensions’
impact on the higher order measures, overall quality, perceived value, and loyalty intentions,
respectively. The r2 (squared correlation coefficient) value indicates to what extent each
dimension explains impact on the dependent variables.
A t-test was conducted to assess known-group validity, which identified significant differences in
summed E-S-QUAL scores and each summed dimensions between service users and providers. A
paired t-test was conducted to identify significant differences between the importance and
performance of each item.
3.6. Assumptions and Limitations
In this research design, it was assumed that the self-selected survey participants identified a
representative sample of users of academic library social media services. The timeframe for data
collection was optimal for academic students who would be the study’s participants. It was
assumed that the survey announcements through social media were exposed equally to all users of
the participating library’s social media services. In the social media setting, people might not
receive the survey announcements because their access times to the services and timeline
browsing behaviors could be different from the time points of announcement postings. To avoid
this limitation, the survey announcements were posted different times during a day.
Online survey recruitment is assumed to be objective to identify relevant audiences because the
target of the investigation is users who are engaged in online activities (Panagiotopoulos, 2012).
It was assumed that the respondents who voluntarily participated in the survey were indeed the
recipients of the library social media services, and they had experience with the services.
The Likert scales used in this study are assumed and treated as an interval level measurement.
The study results are limited to academic libraries’ Twitter services because this study tested E-S-

60

QUAL’s applicability to the Twitter services at the five academic university libraries. The results
of this study and statement revision using focus group interviews should be considered for the
application of the modified E-S-QUAL in other contexts.

61

CHAPTER 4. DATA ANALYSIS AND FINDINGS
This chapter first describes the study’s data profiles including response rates, respondents’
characteristics, and descriptive statistics. Next, the reliability, dimensionality, and validity of the
measurement scales are analyzed using multivariate statistics and structural equation modeling.
Finally, relative importance of dimensions and gap analysis are examined and reported. Detailed
theoretical and practical implications from the data analysis results will be discussed in the next
chapter.
4.1. Descriptive Analysis
From the five research sites, 435 people participated in the survey. Among the submitted
questionnaires, 153 were incomplete, having all empty answers, and 16 were invalid having no
deviation among all responses to the 22 items of E-S-QUAL and the 10 items of three criterion
variables. These 169 responses were excluded. Missing values were random in variables and had
no pattern. They were replaced by the maximum likelihood estimation method using the
expectation-maximization (EM) algorithm in SPSS. After the data screening, the final sample
used for data analysis was 266 responses.
4.1.1. Response Rates
Response rates were calculated in two ways: impression rate6 and click-through rate7. Impression
indicates the number of people who were exposed to the survey announcements. It was calculated
by adding the numbers of Twitter and/or Facebook followers, assuming they all received the
announcements. Click-through rate indicates the number of survey links clicked, which was
calculated by Bitly.com (a URL shortening service).

6
7

Impression Rate=(The number of valid completed responses)/(The number of impressions)
Clickthrough Rate=(The number of valid completed responses)/(The number of click throughs)

62

Table 9.
The Number of Survey Responses and Response Rates in Each Site
Number
of
Postings

Total
Responses

Valid
Responses

Impression
Rate

Clickthrough
Rate

23

217

133
(61.3%)a

4.2%
(3,133)b

41.2%
(323)c

15

75

library Twitter
and Facebook

11

53

2

library Twitter
and Facebook

8

43

4

library Twitter
and Facebook

15

47

42
(56.0%)
33
(62.3%)
30
(69.8%)
28
(59.6%)

0.4%
(10,255)
1.5%
(2,235)
0.8%
(3,771)
0.2%
(12,682)

25.9%
(162)
31.7%
(104)
44.1%
(68)
33.7%
(83)

266
(61.1%)

Average 1.4%
Median 0.8%

Average 35.3%
Median 33.7%

Site

Duration
(Weeks)

A

5

B

3

C

4

D
E

Announcement
Channels
library Twitter,
Facebook, blog,
and email
library Twitter
and Facebook

Total

435

a. [(Valid responses)/(Total responses)] x100
b. The number of impressions; c. The number of click throughs \

Table 9 presents survey announcements’ duration, channels, and the number of postings
(reminders), the number of valid responses, and two types of response rates in each site. For
instance, in site A, the survey was open for five weeks, and announcements were posted 23 times
through the library Twitter, Facebook, blog, and email. The number of valid responses was 133.
The total number of impressions was 3,133 (impressions rate 4.2%) and the number of clickthroughs was 323 (click-through rate 41.2%). The average of impressions rates and click-through
rates of participants from the five sites were 1.4% and 35.3%, respectively. In online survey
environments, these rates are considered to be acceptable based on previous studies.
4.1.2. Respondent Characteristics
The demographic information of the respondents is presented in Table 10. The majority of
respondents were female (66.3%), aged 18-29 (80.9%), university members (94.1%), and
undergraduate students (72.5%). Among all age groups, specifically respondents aged 21 (born in

63

1993) were the largest (23.1%). A small number (15) of library staff members responded to the
surveys.
Table 10.
Demographic Characteristics of Respondents
Measure
Gender

Age

University
Member

Affiliation

Item

Frequency

Percent

Valid Percent

Male

86

32.3

33.7

Female

169

63.5

66.3

Missing

11

4.1

Total

266

100.0

100.0

18 29

203

76.3

80.9

30 39

29

10.9

11.6

40 49

10

3.8

4.0

50 59

7

2.6

2.8

60 64

2

0.8

0.8

Missing

15

5.6

Total

266

100.0

100.0

Yes

240

90.2

94.1

No

15

5.6

5.9

Missing

11

4.1

Total

266

100.0

100.0

174 (1)*

65.4

72.5

Master’s student

12 (1)

4.5

5.0

Doctoral student

11 (2)

4.1

4.6

8

3.0

3.3

Library staff

12 (3)

4.5

5.0

Non library staff

11(1)

4.1

4.6

Other

12 (7)

4.5

5.0

26

9.8

266 (15)

100.0

Undergraduate
student

Faculty

Missing
Total

100.0

* The numbers in parentheses indicate the number of respondents who were not members of
university

64

4.1.3. Descriptive Analysis of Measurement Scales
The results of the analysis of descriptive statistics for the four dimensions of E-S-QUAL and
three criterion variables are presented in Table 11. Detailed statistics for each item of dimensions
will be discussed in Chapter section 4.6, Gaps between Importance and Performance.
The modified E-S-QUAL is composed of 22 items arranged in four dimensions, for which
respondents are asked to rate on a five-point scale ranging from strongly disagree (1) to strongly
agree (5). The means of responses to the ratings of importance and performance were 4.27 and
4.03, respectively, with a possible range of 1 to 5. The mean of the summed 22 item ratings of
importance and performance were 93.83 and 88.56, respectively, with a possible range of 22 to
110. The dimension with the highest mean scores for importance and performance was privacy
(4.55 and 4.34), and the lowest mean score was efficiency (3.99 and 3.72). The scores of summed
items in each dimension have different ranges, the efficiency dimension with a possible range of
8 to 40, system availability with 4 to 20, fulfillment with 7 to 35, and privacy with 3 to 15.
Table 11.
Descriptive Analysis of ESQUAL Four Dimensions and Three Criterion Variables *

Factors

E S QUAL
Dimensions

Criterion
Variables

*N=266

Number
of items

Mean of Summed
Scores

Mean

Std. Deviation
(mean)

Impo.

Perf.

Impo.

Perf.

Impo.

Perf.

Efficiency

8

3.99

3.72

31.90

29.73

1.060

1.067

System availability

4

4.36

4.29

17.43

17.14

0.908

0.978

Fulfillment

7

4.41

4.10

30.87

28.67

0.830

0.968

Privacy

3

4.55

4.34

13.64

13.02

0.869

0.967

Overall quality

1

7.54

7.54

1.756

Perceived value

4

7.50

29.99

1.861

Loyalty intentions

5

3.89

19.44

1.117

65

For the three criterion variables, respondents were asked to rate on a ten-point scale ranging from
poor (1) to excellent (10) for overall quality and perceived value, and a five-point scale ranging
from strongly disagree (1) to strongly agree (5) for loyalty intentions. The score of summed items
in perceived value is in a possible range of 4 to 40, in loyalty intentions in a range of 5 to 25.
Table 11 summarizes the mean scores of the summed items in each construct.
4.2. Reliability
Internal consistency reliability assesses the extent to which items within a scale are consistent
with each other. Inter-correlations among items and item-to-total correlations are examined to
assess internal consistency (Viswanathan, 2005). Relatively low correlations indicate that
common cores among items might not exist, whereas relatively high correlations might represent
redundant items of the overall constructs (Viswanathan, 2005). The average of inter-item
correlation of the sample data was 0.48, which was greater than an ideal range of inter-item
correlations, between 0.2 and 0.4 (Viswanathan, 2005). Some items can presumably be redundant.
Table 13 on page 67 presents inter-correlations among the 22 items. Item-to-total statistics (Table
12) indicated high correlations between all items and the total score. There is no item having low
correlations with the total score, which is assumed to be lacking internal consistency
(Viswanathan, 2005).
An overall indicator of internal consistency, the Cronbach alpha of the scale was 0.95. At a
dimension level, acceptable internal consistency reliabilities were found including efficiency ( =
0.91), system availability ( = 0.92), fulfillment ( = 0.89), and privacy ( = 0.87), exceeding the
conventional minimum of 0.7 (Nunnally & Bernstein, 1994) and within the range of previous
studies’ results including the original E-S-QUAL’s Cronbach alpha (EFF  = 0.94, SYS  = 0.83,
FUL  = 0.89, and PRI  = 0.83), which demonstrates high internal consistency of each
dimension. The data in this study support H1.

66

Table 12.
ItemtoTotal Statistics

Item*

Scale Mean if
Item Deleted

Scale Variance
if Item Deleted

Corrected
Item Total
Correlation

Squared
Multiple
Correlation

Cronbach's
Alpha if Item
Deleted

EFF1

85.09

224.937

.612

.631

.951

EFF2

84.94

222.296

.692

.677

.949

EFF3

85.00

221.265

.682

.684

.950

EFF4

84.90

219.805

.718

.643

.949

EFF5

84.50

226.763

.610

.469

.950

EFF6

84.46

224.823

.667

.559

.950

EFF7

84.86

222.725

.637

.626

.950

EFF8

84.97

221.764

.683

.656

.950

SYS1

84.26

224.449

.689

.726

.950

SYS2

84.28

222.908

.729

.841

.949

SYS3

84.26

225.442

.660

.729

.950

SYS4

84.28

223.833

.684

.725

.950

FUL1

84.55

223.006

.725

.626

.949

FUL2

84.74

223.317

.666

.604

.950

FUL3

84.77

220.386

.748

.697

.949

FUL4

84.78

221.840

.675

.610

.950

FUL5

84.33

225.393

.671

.571

.950

FUL6

84.03

229.764

.620

.797

.950

FUL7

84.03

229.461

.612

.788

.950

PRI1

84.21

224.991

.664

.748

.950

PRI2

84.16

225.995

.663

.733

.950

PRI3

84.27

223.833

.683

.678

.950

* See Table 24 to refer the questions of items

67

Table 13.
InterCorrelation among Items
Item

EFF1

EFF2

EFF3

EFF4

EFF5

EFF6

EFF7

EFF8

SYS1

SYS2

SYS3

SYS4

FUL1

FUL2

FUL3

FUL4

FUL5

FUL6

FUL7

PRI1

PRI2

EFF1

1.00

EFF2

.742

1.00

EFF3

.646

.703

1.00

EFF4

.587

.611

.562

1.00

EFF5

.359

.392

.389

.411

1.00

EFF6

.402

.443

.504

.508

.571

1.00

EFF7

.455

.524

.670

.567

.492

.598

1.00

EFF8

.553

.594

.585

.714

.457

.524

.646

1.00

SYS1

.364

.437

.368

.477

.485

.466

.383

.418

1.00

SYS2

.375

.445

.405

.477

.513

.459

.372

.386

.810

1.00

SYS3

.301

.373

.350

.437

.424

.425

.295

.330

.671

.799

1.00

SYS4

.356

.411

.386

.442

.502

.505

.390

.338

.671

.788

.754

1.00

FUL1

.494

.524

.531

.591

.438

.486

.484

.584

.474

.498

.428

.394

1.00

FUL2

.410

.462

.520

.488

.452

.483

.518

.517

.441

.439

.360

.443

.605

1.00

FUL3

.525

.585

.654

.561

.465

.538

.565

.582

.458

.482

.380

.389

.610

.687

1.00

FUL4

.476

.541

.554

.585

.389

.542

.528

.585

.457

.407

.364

.393

.543

.593

.670

1.00

FUL5

.393

.419

.403

.423

.398

.483

.333

.416

.508

.489

.531

.476

.556

.461

.503

.525

1.00

FUL6

.227

.320

.313

.343

.355

.419

.270

.284

.509

.480

.565

.510

.494

.465

.432

.358

.611

1.00

FUL7

.208

.336

.285

.344

.387

.382

.230

.270

.501

.520

.568

.524

.436

.403

.427

.390

.614

.859

1.00

PRI1

.306

.393

.343

.461

.409

.367

.318

.374

.420

.581

.553

.522

.569

.375

.509

.364

.512

.557

.584

1.00

PRI2

.344

.397

.382

.405

.419

.385

.312

.339

.495

.618

.537

.549

.486

.360

.478

.314

.525

.554

.576

.792

1.00

PRI3

.423

.462

.411

.517

.395

.375

.368

.464

.506

.572

.531

.552

.485

.361

.465

.346

.515

.525

.509

.720

.747

PRI3

1.00

68

4.3. Dimensionality
Dimensionality was analyzed using two sets: first, the 22 items of the modified E-S-QUAL and,
second, the 32 items including the modified E-S-QUAL’s 22 items and three criterion variables’
10 items. Exploratory factor analysis (EFA) was used to assess dimensionality, which indicates
common core factors among variables. Because E-S-QUAL has four dimensions that have never
been tested in library and information fields, this study examined the scale’s dimensionality to
detect whether the same variables are reduced to these dimensions. After EFA was conducted for
initial evidence, confirmatory factor analysis (CFA) was used to provide conclusive evidence of
the dimensionality (Viswanathan, 2005).
First, Table 14 presents the results of EFA and CFA for the modified E-S-QUAL’s 22 items, as
well as Cronbach alpha values for the four dimensions and loadings for each item. For the
analysis of the modified E-S-QUAL 22 items, the KMO and Bartlett’s statistics showed that the
KMO was greater than 0.7 at 0.93 and the Bartlett was significant (2 (df = 231) = 4637.93, p <
0.001), indicating that this data set was suitable for factor analysis. The greater KMO value
indicated that observed variables might have underlying factors. These two test results indicated
that the sample data were suitable for structure detection. Communality values of 22 items were
from a low of 0.52 (EFF5) to a high of 0.87 (SYS2). No item was excluded from analysis.
EFA was conducted, using SPSS, on the 22 items of the modified E-S-QUAL using principle
component analysis with a varimax rotation. The results showed that four factors that had an
Eigen Value greater than one were extracted. According to factor loading values suggested as the
minimum ±0.35 (Overall & Klett, 1972), items of efficiency, system availability, fulfillment, and
privacy dimensions had over 0.4 loadings. All the four factors explained 71.17% variance of eservice quality.

69

Table 14.
Confirmatory and Exploratory Factor Analysis of ESQUAL 22 Items

Item

Mean

SD

EFA loadings c

CFA
Loadings

a

C.R

b

1

2

3

4

Efficiency (Cronbach alpha=.909)
EFF1

3.46

1.051

0.731

EFF2

3.61

1.062

0.79

12.751

.750

EFF3

3.55

1.123

0.798

12.899

.793

EFF4

3.66

1.138

0.783

12.637

.710

EFF5

4.06

.960

0.584

9.296

.419

.526

EFF6

4.09

.977

0.679

10.876

.553

.431

EFF7

3.70

1.123

0.752

12.11

.750

EFF8

3.59

1.099

0.793

12.809

.784

SYS1

4.29

.966

0.834

SYS2

4.28

.985

0.949

20.589

.814

SYS3

4.30

.958

0.846

17.14

.762

SYS4

4.27

1.001

0.839

16.922

.805

.985

0.773

FUL2

3.82

1.051

0.738

FUL3

3.78

1.072

FUL4

3.78

FUL5

6.027

27.396

3.827

17.397

2.982

13.555

2.822

12.825

.359

.759

Fulfillment (Cronbach alpha=.893)
4.01

%of
Variance

.746

System Availability (Cronbach alpha=.915)

FUL1

Eigen
values

.582

.423

12.562

.586

.519

0.802

13.866

.692

.419

1.107

0.727

12.331

.676

.413

4.23

.945

0.721

12.204

.601

FUL6

4.52

.794

0.674

11.3

.763

.358

FUL7

4.53

.820

0.66

11.029

.737

.385

Privacy (Cronbach alpha=.872)
PRI1

4.34

.973

0.878

.367

.728

PRI2

4.39

.926

0.897

19.618

.737

PRI3

4.28

1.002

0.832

17.387

.738

KMO and Bartlett’s Test: KMO = 0.930; Sig < 0.001
Communalities range: 0.516 (EFF5) – 0.869 (SYS2)
Goodnessoffit statistics: X2 = 544.35 (p < .001); df = 203; CFI = .908; NFI = .871; TLI = .893; RMSEA = .089
NOTE: CFI = Comparative Fit Index; NFI = Normed Fit Index; RFI = Relative Fit Index; TLI = TuckerLewis Index;
RMSEA = Root mean square error of approximation
a. Standardized loading estimated from CFA using the Amos 22. Method of estimating the parameters: Maximum
likelihood method.
b. C.R. = Critical Ratio (> 1.965); Significant at p < .001
c. Extraction Method: Principal Component Analysis; Rotation method: Varimax rotation using SPSS 22; Loadings < .35
not shown.

70

Cross loadings greater than 0.35 were detected in the efficiency and fulfillment dimensions. The
loading value of EFF5, which is “The site loads its pages fast,” was higher in the system
availability dimension (0.53) than in efficiency (0.42). Four items (FUL1, 2, 3, and 4) in the
fulfillment dimension had cross loadings with the efficiency dimension. High loadings (over 0.5)
are in both dimensions, which might indicate a possible issue of within-measure correlational
systematic error caused by answers reflecting respondents’ differences and/or items connected to
different constructs (Viswanathan, 2005). This result can indicate the possibility of the
discriminant validity problem of the scale between efficiency and fulfillment. Dimensionality was
assessed through confirmatory factor analysis.
Confirmatory factor analysis was conducted to test first-order four-factor, second-order fourfactor, and second-order one-factor models. The results of the first-order four-factor model
showed significant item-construct loadings in this study setting (Table 14). The loading values in
the four factors were in the range of 0.58 – 0.95. The four latent constructs were well reflected by
their corresponding measured variables (see Figure 3 on page 71). The goodness-of-fit indexes
imply that the data fit the proposed model reasonably well. According to the guidelines for model
fit (Hooper et al., 2008), the values of CFI, NFI, and TLI above 0.90, and RMSEA in the range of
0.05 to 0.10 indicate a fair fit. Among them, CFI is the most recommended index (Viswanathan,
2005). The indexes of this present study’s 22 item model were well above the conventional CFI
(0.91) cutoff value. The results of the second-order four-factor model showed a moderate fit with
the data (X2 = 978.121/df = 205, CFI = 0.902, RMSEA = 0.092). The loading values for the four
factors were in the range of 0.76 – 0.96. The e-service quality construct was well reflected by the
four factors (see Figure 4 on page 72). The fit of the second-order one-factor model was not
acceptable (Table 15). These findings support the soundness of the modified E-S-QUAL scale’s
four factor structures in the library’s Twitter service context; however, the slightly better fit of

71

model 1 rather than model 2 indicates that e-service quality conceptualized as a second-order
construct could be problematic.

Figure 3. FirstOrder FourFactor Model

72

Table 15.
Comparison of EService Quality Factor Structures of 22 Items
X2

df

CFI

RMSEA

Model 1: First order 4 factor solution

950.85

203

.908

.089

Model 2: Second order 4 factor indicators of
e service quality (E SQ)

978.121

205

.902

.092

Model 3: Second order 1 factor (All 22 items) indicators
of E SQ

1785.605

209

.743

.147

Model and Description

Figure 4. SecondOrder FourFactor Model

73

Second, Table 17 presents the results of EFA for the modified E-S-QUAL’s 22 items and three
criterion variables’ 10 items. For the analysis of the 32 items, KMO was greater than 0.7 at 0.94
and the Bartlett test was significant (2 (df = 496) = 7193.1, p < 0.001), indicating that this data
set was suitable for factor analysis. Communality values of 32 items were from a low of 0.54
(FUL2) to a high of 0.85 (SYS2). No item was excluded from analysis.
The results of EFA using 32 items showed five factors over an eigenvalue of 1 with 70.17% of
cumulative variance. Similar cross loadings were identified in efficiency and fulfillment
dimensions. Specifically, fulfillment items were not grouped as one factor, but FUL1, 2, 3, and 4
were grouped with efficiency and FUL5, 6, and 7 with privacy.
CFA tested two models (see Table 16): first, a three-factor solution (model 4) with e-service
quality (one factor - all 22 items), perceived value, and loyalty intentions, and second, a higherorder three-factor solution (model 5) with e-service quality (a higher order construct with 4
dimensions), perceived value, and loyalty intentions. The fit of the two models showed that
model 5 had a better fit than model 4.
Table 16.
Comparison of EService Quality Factor Structures of 32 Items
X2

df

CFI

RMSEA

Model 4: 3 factor solution (E service quality, PV, LI)

2175.679

431

.847

.095

Model 5: 3 factor solution (E service quality as a
second order construct with 4 dimensions, PV, LI)

1362.800

427

.910

.073

Model and Description

74

Table 17.
Exploratory Factor Analysis of ESQUAL 22 Items and Criterion Variables' 10 Items
EFA loadingsa

Item

Mean

SD

EFF1

3.46

1.051

.705

EFF2

3.61

1.062

.698

EFF3

3.55

1.123

.747

EFF4

3.66

1.138

.667

EFF5

4.06

.960

.430

.520

EFF6

4.09

.977

.489

.441

EFF7

3.70

1.123

.710

EFF8

3.59

1.099

.772

SYS1

4.29

.966

SYS2

4.28

.985

.411

.769

SYS3

4.30

.958

.462

.727

SYS4

4.27

1.001

.359

.770

FUL1

4.01

.985

.585

FUL2

3.82

1.051

.548

FUL3

3.78

1.072

.631

FUL4

3.78

1.107

.572

FUL5

4.23

.945

.575

FUL6

4.52

.794

.736

FUL7

4.53

.820

.742

PRI1

4.34

.973

.789

PRI2

4.39

.926

.778

PRI3

4.28

1.002

.699

OQ

7.54

1.756

.794

PV1

7.51

1.751

.736

PV2

7.97

1.814

.741

PV3

7.06

1.972

.794

PV4

7.45

1.908

.777

LI1

3.94

1.114

.796

LI2

3.94

1.091

.794

LI3

3.87

1.126

.777

LI4

3.38

1.288

1

2

3

4

5

.735

.406

. 401

.620

LI5
4.31
.964
.620
KMO and Bartlett’s Test: KMO = 0.94; Sig < 0.001
Communalities Range: 0.54 (FUL2) – 0.85 (SYS2)
a. Extraction Method: Principal Component Analysis; Rotation method: Varimax rotation using SPSS
22; Loadings < .35 not shown.

75

4.4. Validity
This chapter presents the results of five types of validity tests: convergent, discriminant,
predictive, nomological, and known-group validity. Interpretation and comprehensive
explanations will be discussed in Chapter 5.
Convergent validity demonstrated the degree to which items converge with other items for a same
construct. If the average variance extracted (AVE) of each dimension is over 0.5, the construct’s
convergent validity is adequate. Discriminant validity demonstrates a construct had no
relationship with other constructs that are related weakly or not at all (Viswanathan, 2005). If the
AVE of each construct is greater than the squared correlation between the two constructs (r2), the
discrimination of constructs is fully satisfied (Fornell & Larcker, 1981). Convergent and
discriminant validity were tested at two levels: dimension and construct.
First, at the dimension level, four dimensions (efficiency, system availability, fulfillment, and
privacy) were considered as distinct factors explaining e-service quality. Table 18 shows that the
AVE value of each dimension was above the cutoff value, 0.5, which supports convergent
validity in this study setting (H3a). Although the AVE values of efficiency (0.52) and fulfillment
(0.55) were slightly over the cutoff, their factor loadings exceeded a conventional cutoff value of
0.6, except the EFF5 item, and the internal consistencies were very high (efficiency = 0.91,
fulfillment = 0.89). Some items such as EFF5 might be considered for deletion based on the
results of correlation and other validity tests. For the discriminant validity, this study’s AVE
values of the three dimensions (system availability, fulfillment, and privacy) were greater than r2.
The AVE value of efficiency (0.52) was less than the r2 [0.702 = (0.838)2] between efficiency and
fulfillment. This result indicates two dimensions’ discriminant validity is not supported (H4a),
which demonstrates a possible issue of across-measure systematic error caused by a halo effect
that is previous answers influencing the following answers (Viswanathan, 2005).

76

Table 18.
AVE and Correlations for Four Dimensions
Dimensions

1

1. Efficiency

Correlation a
2
3

4

Range of
loadings

AVE

Internal
consistency









(0.584 – 0.798)

0.524

0.909

2. System availability

0.604







(0.834 – 0.949)

0.763

0.915

3. Fulfillment

0.838

0.699





(0.660 – 0.802)

0.552

0.893

4. Privacy

0.584

0.711

0.732



(0.832 – 0.897)

0.766

0.872

a. The intercorrelations among four dimensions are from CFA using Amos22. All values are significant p
< 0.05.

Second, at the construct level, e-service quality was considered as a higher-order construct and
compared with theoretically relevant constructs, perceived value and loyalty intentions. As
reported in Table 19, the AVE score of e-service quality was 0.77 that exceeded the criterion of
0.5. In addition, the loadings for the construct exceeded a conventional cutoff value (0.6) and the
internal consistency of e-service quality was very high. Therefore, the e-service quality measure
exhibited good convergent validity (H3b). For discriminant validity, the AVE value of e-service
quality (0.77) was greater than r2, 0.47 between e-service quality and perceived value, and 0.43
between e-service quality and loyalty intentions. These results support that e-service quality
exhibits discriminant validity in reference to the two other constructs examined in this study
(H4b).
Table 19.
AVE and Correlations for Three Constructs

1

Correlation a
2

3

1. E service quality





2. Perceived value

0.688

3. Loyalty intentions

0.652

Constructs

a. All values are significant p < 0.05.

Range of loading

AVE

Internal
consistency



(0.727 – 0.974)

0.774

0.952





(0.804 – 0.907)

0.442

0.913

0.677



(0.663 – 0.917)

0.610

0.898

77

Third, the predictive validity demonstrated relationships between four dimensions of the modified
E-S-QUAL and three criterion variables. Overall quality, perceived value, and loyalty intentions
have been tested and the researcher confirmed their relationships with e-service quality in
previous studies (Parasuraman et al., 2005; Lee et al., 2012; Santouridis et al., 2012). Table 20
presents inter-correlations among the four E-S-QUAL dimensions and the measures of overall
quality, perceived value, and loyalty intentions. Each variable was the summed score of items in
each dimension. The two dimensions of E-S-QUAL, efficiency and fulfillment, have consistently
positive correlations with overall quality (0.56, 0.59), perceived value (0.60, 0.63), and loyalty
intentions (0.62, 0.56). However, system availability and privacy have positive correlations only
with perceived value (0.41, 0.42). Their correlations with overall quality (0.38, 0.39) and loyalty
intentions (0.38, 0.37) are positive but not over the cutoff value, 0.4. The predictive validity is not
fully supported (H5). The three criterion variables’ correlations with system availability and
privacy are relatively lower than the values with efficiency and fulfillment, which was also
observed in Parasuraman et al. (2005).

Table 20.
InterCorrelations among the Four ESQUAL Dimensions and Three Criterion Variables a
Dimensions

EFF

SYS

FUL

PRI

OQ

PV

Overall Quality (OQ)

.555

.382

.585

.386

1

Perceived Value (PV)

.599

.406

.627

.423

.856

1

Loyalty Intentions (LI)

.624

.376

.563

.371

.577

.649

a. Inter correlation is significant at the 0.01 level (2 tailed). All values are significant p < 0.001.

LI

1

78

Fourth, nomological validity demonstrated that the modified E-S-QUAL measure is related to
two high order constructs that are expected to be theoretically related: perceived value and loyalty
intentions. Figure 5 shows a structural model that has an exogenous construct, e-service quality,
and two endogenous constructs, perceived value (antecedent) and loyalty intentions (consequent).
The summed scores of the four dimensions computed the latent e-service quality. Table 21
presents the results of the structural equation modeling by Amos 22. The overall goodness-of-fit
statistics shows this study data fit the model reasonably well. CFI (0.96) is over the cutoff value
(0.9) as well as NFI, TLI, and RMSEA. The nomological network among the three constructs is
strongly supported. Statistically significant correlations were found among direct and indirect
measures of three constructs. The e-service quality has a significant positive direct relationship (r
= 0.69) on perceived value (H6a). The perceived value has a significant positive direct
relationship (0.44) on loyalty intentions (H6b). The e-service quality has a significant positive
direct relationship (0.34) on loyalty intentions (H6c).
Figure 5. SEM Model

79

Table 21.
SEM Analysis to Examine ESQUAL’s Nomological Validity
Structural Coefficients and R2 Values
Dependent Variable
Perceived Value

Loyalty Intentions

Coefficient

C.R.a

E Service Quality

.687

10.272

R2

.472

E Service Quality

.342

4.591

Perceived Value

.442

5.833

R2

.520

Independent Variable

Latent Variable

Measurement variable

EService Quality

Efficiency

.828

System availability

.723

12.921

Fulfillment

.913

17.518

Privacy

.717

12.697

Price

.804

Overall value

.814

15.117

Perceived control

.884

16.727

Perceived convenience

.907

17.289

Positive word of mouth

.917

Recommend to others

.898

23.002

Encourage others to use

.871

21.444

First choice for future

.687

13.556

Do more business in future

.663

12.871

Perceived Value

Loyalty Intentions

Construct Loading

C.R.

Goodnessoffit statistics X2 = 171.827; df = 62; CFI = .957; NFI = .935; TLI = .947; RMSEA = .082
a. C.R. = Critical Ratio (> 1.965); Significant at p < .001

80

Fifth, known-group validity demonstrated whether users and service providers assessed the
modified E-S-QUAL measured service quality differently. T-tests were conducted to compare the
summed scores of 22 items, four dimensions, and three criterion variables between two groups.
Table 22 summarizes the results of independent samples t-tests. Mean scores of the summed E-SQUAL, four dimensions, and loyalty intentions were greater in the user group. However, the ttests failed to reveal a statistically reliable difference between the mean scores of E-S-QUAL for
users (M = 89.34, s = 15.32) and service providers (M = 83.77, s = 18.12), t(252) = 1.35, p =
0.18,  = . 05, as well as for other tested variables. This result might have been caused by there
being no difference really existing, the small sample size of the provider group, and/or the
modified E-S-QUAL not being capable of measuring the differences.
Table 22.
Comparison of EService Quality between Users and Service Providers
(Users N=239; Service Providers N=15)

Variables

User

Mean
Provider

Std. Deviation
User
Provider

E S QUAL

89.336

83.768

15.323

18.119

Efficiency

30.005

27.873

6.558

System availability

17.293

16.046

Fulfillment

28.786

Privacy

T test
df

p

1.350

252

.178

6.928

1.217

252

.225

3.317

5.804

.824*

14.579

.423

28.508

5.283

5.604

.197

252

.844

13.252

11.341

2.411

4.106

1.783*

14.612

.095

Overall Quality

7.540

7.800

1.793

1.656

.548

252

.584

Perceived Value

29.972

30.800

6.841

5.669

.459

252

.647

Loyalty Intentions

19.545

18.400

4.794

5.082

.894

252

.372

*Equal variances not assumed

t

81

4.5. Relative Importance of Dimensions
In this chapter, the relative importance of the modified E-S-QUAL’s four dimensions was
determined. The validity tests in the previous chapter confirmed that the dimensions had
significant relationships with three criterion variables: overall quality, perceived value, and
loyalty intentions. To determine the extent to which four dimensions contribute to three criterion
variables, multiple regression analysis was conducted. Table 23 summarizes the results. The
regression was conducted with four dimensions as independent variables that were calculated by
two methods, and three criterion variables as dependent variables.
First, each independent variable was calculated by the summed scores of responses for each
dimension’s items. Efficiency and fulfillment had significant positive effects on three dependent
variables (p < 0.001), whereas system availability and privacy had no significant effects.
Fulfillment had greater effects on overall quality ( = 0.41) and perceived value ( = 0.43), and
efficiency had a greater effect on loyalty intentions ( = 0.47).
From the regression result, the researcher determined that multicollinearity might occur because
inter-correlations (Table 20) showed that system availability and privacy had significant
relationships with perceived value but no significance in regression. There are several ways to
detect multicollinearity. In this study, no significance was consistently found in the two predictors,
system availability and privacy. High inter-correlation was found between efficiency and
fulfillment (0.75). The three entire sets were significant (p < 0.001), but individual variables
(system availability and privacy, p > 0.05) were not significant. The eigenvalue of privacy (0.008)
was close to 0. The tolerance, calculated by 1/VIF, for system availability (0.33) was lower than
the cutoff, 0.4 determined by Allison (1999). These values imply a moderate degree of
multicollinearity.

82

In order to minimize the correlation among independent variables, as the second method for
regression, four orthogonal factor scores were extracted by factor analysis with varimax rotation.
The analysis results showed that all four factor scores had significant positive effects on the three
dependent variables (p < 0.01). The factors representing efficiency and fulfillment had stronger
effects on the dependent variables. Adjusted R2 indicated that 36.7% of the variance in overall
quality, 42.5% in perceived value, and 42.2% in loyalty intentions can be predicted from the
modified E-S-QUAL’s four dimensions.
From the two results of multiple regression analysis, four dimensions had different effects on the
three criterion variables (H8 is supported). Efficiency and fulfillment dimensions were relatively
important compared to system availability and privacy.
Table 23.
Regression Analyses of Criterion Variables on the Four ESQUAL Dimensions' Summed or
Factor Scores
Dependent

Overall SQ
Std. beta

Independent

Sig.

Perceived Value

Loyalty Intentions

Collinearity

Std. beta

Sig.

Std. beta

Sig.

VIF

Eigen

Independent variables – Summed scores
Efficiency

.273

.000

.303

.000

.474

.000

2.399

.025

System Availability

.040

.576

.060

.374

.051

.464

2.106

.014

Fulfillment

.411

.000

.429

.000

.255

.000

3.061

.021

2.079

.008

Privacy

.009

.898

.014

.841

.024

.722

2

.364

.000

.423

.000

.402

.000

F

38.904

.000

49.636

.000

45.580

.000

Adjusted R

Independent variables – Factor scores*
Factor 1

.481

.000

.515

.000

.598

.000

1

1

Factor 2

.191

.000

.189

.000

.157

.001

1

1

Factor 3

.312

.000

.339

.000

.179

.000

1

1

.134

.004

.126

.007

1

1

Factor 4

.102

.038

2

.367

.000

.425

.000

.422

.000

F

39.366

.000

49.934

.000

49.337

.000

Adjusted R

* Factor scores were generated by SPSS 22 when the factor analysis (varimax rotation) was conducted.

83

4.6. Gaps between Importance and Performance
A paired t-test was used to determine differences between user-perceived importance for library
Twitter services and perceptions of performance of the services measured by the modified E-SQUAL. Table 24 presents the results of the means of each item’s importance and performance
scores, differences between them, and a paired t-test result to identify whether the differences are
significant.
The mean scores for importance were in the range of 3.83 (EFF8) – 4.7 (FUL7), and 4.27 for all
22 items. The mean scores for performance were in the range of 3.46 (EFF1) – 4.53 (FUL7), and
4.03 for the total. In the dimension level’s mean scores, privacy (4.55) was measured as the most
important dimension, followed by fulfillment (4.41), system availability (4.36), and efficiency
(3.99). However, how the services were performed was measured in order of privacy (4.34),
system availability (4.29), fulfillment (4.10), and efficiency (3.72).
The gap scores between performance and importance were all negative; the fulfillment dimension
had the largest difference (-0.31), followed by efficiency (-0.27), privacy (-0.21), and system
availability (-0.07). These results were only for this study data set including all five participating
libraries’ responses. Other studies using this instrument could have positive numbers that indicate
library performance exceeds importance of the service.
A paired t-test revealed statistically reliable differences (p < 0.05) between the mean numbers of
importance and performance of each item, except EFF5, SYS1, and SYS2 (H9). This result
indicates that the modified E-S-QUAL is able to measure differences between user-perceived
importance and performance of the library Twitter services.

84

Table 24.
A Paired TTest between Importance and Performance Values

Code
EFF1
EFF2
EFF3
EFF4
EFF5
EFF6
EFF7
EFF8
SYS1
SYS2
SYS3
SYS4
FUL1
FUL2
FUL3
FUL4
FUL5
FUL6
FUL7
PRI1
PRI2
PRI3

Item
This service makes it easy to find library
information that I need.
This service makes it easy to get library
information.
It enables me to get to library information
quickly.
Library postings on Twitter are well organized.
The site loads its pages fast.
Library information at the Twitter site is
simple to use.
The Twitter site enables me to get to library
information quickly.
The organization of posts on Twitter works
well for using library information.
The Twitter site is always available for this
service.
This Twitter site launches and runs right away.
This Twitter site does not crash.
Pages at this site do not freeze after I enter
my comments.
This service delivers timely information.
It gives responses for my questions within a
suitable time frame.
It provides information that I expect in a
timely manner.
It provides information that I’d like to receive.
It has information about what is going on in
the library.
It is truthful about the information it provides.
It delivers accurate information.
The library does not share information about
my behavior (browsing pages, clicking links,
etc.) on its Twitter account with others.
The library does not share my personal
information on Twitter with other sites.
The Twitter site protects information about
my personal data.

Total Mean
Efficiency (8 Items)
System availability (4 items)
Fulfillment (7 items)
Privacy (3 items)
* 2tailed test

Impo
Mean

Perf
Mean

Perf –
Impo
mean

Std.
Dev.

t
(265)

Sig. *

3.89

3.46

0.429

1.147

6.099

.000

4.03

3.61

0.415

1.089

6.215

.000

3.88

3.55

0.331

1.042

5.185

.000

3.84
4.11

3.66
4.06

0.183
0.051

1.230
.950

2.424
.869

.000
.386

4.31

4.09

0.211

.946

3.644

.000

4.00

3.70

0.306

1.123

4.447

.000

3.83

3.59

0.245

1.175

3.406

.000

4.30

4.29

0.003

1.017

.054

.957

4.33
4.42

4.28
4.30

0.049
0.126

1.017
1.048

.967
2.344

.334
.000

4.39

4.27

0.113

1.218

2.020

.000

4.36

4.01

0.351

.989

5.624

.000

4.19

3.82

0.374

.726

5.991

.000

4.19

3.78

0.411

.739

6.396

.000

4.32

3.78

0.541

.981

7.243

.000

4.43

4.23

0.200

.830

3.305

.000

4.67
4.70

4.52
4.53

0.150
0.170

.878
.909

3.373
3.753

.000
.000

4.53

4.34

0.188

.884

3.476

.000

4.54

4.39

0.142

.921

2.517

.000

4.57

4.28

0.287

.880

5.322

.000

4.27
3.99
4.36
4.41
4.55

4.03
3.72
4.29
4.10
4.34

0.24
0.27
0.07
0.31
0.21

85

CHAPTER 5. DISCUSSION, IMPLICATIONS, AND CONCLUSIONS
This study set out with the aim of assessing the applicability of the E-S-QUAL instrument to
measure the service quality delivered by library social media. It is the first study to examine and
explore an instrument for measuring social media service quality in a library service setting. The
specific purpose of this study was, first, to identify psychometric properties of the modified E-SQUAL, second, to examine relationships between user-perceived service quality and criterion
constructs including overall quality, perceived value, and loyalty intentions, and third, to identify
any differences between user-perceived importance and performance in the service quality
measured by E-S-QUAL. Service quality was measured by library Twitter service users through
four dimensions of 22 items, the modified E-S-QUAL. A total of nine hypotheses were tested.
In this chapter, the study results are discussed in three sections. First, interpretations of the results
address nine hypotheses with caution to measurement errors and comparison to prior research
applications of E-S-QUAL in different fields, and visualization methods using the results of the
modified E-S-QUAL are presented. Second, theoretical, methodological, and practical
implications of the findings are suggested to help researchers and practitioners understand and
use this study. Third, the conclusions address the contributions of this study and suggest
improvements, limitations, and directions for future research.
5.1. Discussion
5.1.1. Demographic Characteristics of Academic Library Twitter Services
The demographic characteristics of most respondents to this study’s survey are consistent with
studies about general Twitter users and previous surveys of social media. Specifically, Table 25
shows that gender, age, and academic affiliation align with the characteristics of Twitter users
investigated in 2014 by Duggan et al. (2015). In studies collecting respondents through social

86

media, Cheung et al. (2011) and Wu et al. (2014) identified similar characteristics in their
samples. In general, academic libraries’ main users are undergraduate students. Demographic
findings in the present study are consistent with those studies. These findings validated the
sample as representative of the population for this study.
Table 25.
Demographic Characteristic of Twitter Studies

Characteristics

Sample in This Study

General Twitter User Data
(Duggan et al., 2015)

Data in Social Media Studies
Cheung et al. (2011) Wu et al. (2014)

Gender

66.3% Female

47% Female

68% Female

53.6% Female

1829

75% 1923

66% 2130

College educated

86% College
students

42.5% College
students

Ages
Educations

25 (Average)
21 (Median and Mode)
72.5% Undergraduate
students

5.1.2. Interpretations of Hypotheses Testing
Out of nine hypotheses examined, six were supported, two were partially supported, and one was
not supported by the study results. Table 26 summarizes the results of the hypotheses tests based
on the data analysis in Chapter 4.
H1: The total scale reliability as measured by the Cronbach Alpha for the
dimensions of the instrument falls within the range (0.6 - 0.97).
Reliability of the modified E-S-QUAL using Cronbach alpha (22 items  = 0.95; EFF  = 0.91,
SYS  = 0.91, FUL  = 0.89, PRI  = 0.87) is supported (H1), exceeding the conventional
minimum of 0.7 and within the range of previous studies. Specifically, in studies applying E-SQUAL in non-profit services, Zada et al. (2012) found Cronbach alpha to be 0.88 for the total
scale for a university website, Connoll et al. (2010) found it for each construct to be EFF  =0.90,
SYS  =0.85, PRI  = 0.85, for e-government services (fulfillment was deleted in this study).

87

Table 26.
Summary of Hypotheses Testing
Tests

Hypothesis Tested

Outcome

H1

The total scale reliability as measured by the
Cronbach Alpha for the dimensions of the
instrument falls within the range (0.6 0.97).

Supported

H2

The dimensions of the modified E S QUAL scale
measured by factor analysis are equivalent to the
four underlying dimensionality found in the
original E S QUAL by Parasuraman et al. (2005).

Supported

H3a

The AVE value of each dimension is over 0.5.

Supported

H3b

The AVE value of e service quality is over 0.5.

Supported

H4a

The AVE value of each dimension is greater than
the pairwise r2 across the four dimensions of the
modified E S QUAL.

Partially
Supported
(Not supported
between EFF and
FUL dimensions)

H4b

The AVE value of e service quality is greater than
the pairwise r2 across two criterion constructs,
perceived value and loyalty intentions.

Supported

H5

The four dimensions of E S QUAL have a
significantly positive correlation (r2 > 0.4, p <
0.05) with overall quality, perceived value, and
loyalty intentions.

Partially
Supported
(Not supported
between SYS, PRI
and OQ, LI)

H6a

E service quality has a significantly positive
influence on perceived value.

H6b

E service quality has a significantly positive
influence on loyalty Intentions.

H6c

Perceived value has a significantly positive
influence on loyalty intentions.

Knowngroup validity

H7

The average means of E S QUAL items’ summed
scores are significantly different (p < 0.05)
between in users and service providers.

Not Supported

Relative importance of
the four dimensions

H8

The magnitude of the relationship of overall
quality, perceived value, and loyalty intentions
are different for each dimension.

Supported

Gap measurement

H9

E S QUAL measures significant differences (p <
0.05) in the value of importance and
performance of each item.

Supported

Reliability

Dimensionality

Code

Convergent validity

Discriminant validity

Predictive validity

Nomological validity

Supported

88

Zada et al. (2012) analyzed item-to-total correlations to identify items that decrease reliability,
and deleted FUL1 and SYS4 in which correlations were lower than 0.3. This present study’s
item-to-total correlations (see Table 12) were between 0.61 (EFF5) and 0.75 (FUL3). No item
was considered for removal.
The inter-item correlations identified some low values and high values, which could cause withinmeasure correlational systematic error (Viswanathan, 2005). A correlation between EFF1 and
FUL7 had the lowest value at 0.21. Relatively low correlation items may lack specific context
because of the general wording that caused different interpretations by respondents (Viswanathan,
2005). FUL7 (It delivers accurate information) has relatively low correlations with some of the
efficiency items. The data suggest that this statement needs to be changed. On the contrary, FUL7
and FUL6 (0.86) and SYS1 and SYS2 (0.81) have high correlations, which indicates redundant
items. In the FUL7 and FUL6 (It is truthful about the information it provides) statements, using
the word ‘accurate’ and ‘truthful’ could be redundant. SYS1 (The Twitter site is always available
for this service) and SYS2 (This Twitter site launches and runs right away) may not be distinctive
statements but could be a repetition of the site’s availability for users.
H2: The dimensions of the modified E-S-QUAL scale measured by factor analysis
are equivalent to the four underlying dimensionality found in the original E-SQUAL by Parasuraman et al. (2005).
The dimensionality of the E-S-QUAL’s 22 items was constrained to the four dimensions by factor
analyses and confirmed the structure in the e-commerce context (Parasuraman et al., 2005). This
study also identified four dimensions through exploratory factor analysis, and the structure of four
dimensions and corresponding items were confirmed through confirmatory factor analyses. H2 is
supported.

89

However, exploratory factor analysis identified some major cross-loadings in efficiency and
fulfillment. EFF5 (The site loads its pages fast) had loadings of 0.42 in factor one (efficiency)
and 0.53 in factor two (system availability). The confirmatory factor analysis result also showed a
relatively low loading, 0.58, on EFF5. This occurred in other studies such as in Petnji et al. (2011),
Marimon et al. (2010), and Fuentes-Blasco et al. (2010). EFF5 could be deleted or should be
reworded because it had higher loadings on the secondary dimension through EFA (Viswanathan,
2005).
Four items in the fulfillment dimension had cross loadings with efficiency. High loadings are in
both dimensions, which might indicate a possible issue of within-measure correlational
systematic error (Viswanathan, 2005). At the item level, those items should be examined in
different constructs or reworded, and at the measure level, items are ordered differently
(Viswanathan, 2005).
Previous studies applied E-S-QUAL and identified four dimensions with corresponding items
through EFA (Rafiq et al., 2012; Yang & Tsai, 2007; Wu & Ding, 2007). Other studies found
four dimensions but with some corresponding items were deleted (Lee et al., 2012; Akinci et al.,
2010; Marimon et al., 2010; Sahadev & Purani, 2008), and Boshoff (2007) identified the
fulfillment dimension split into two.
H3a: The AVE value of each dimension is over 0.5 to validate each dimension’s
convergent validity.
H3b: The AVE value of e-service quality is over 0.5 to demonstrate convergent
validity with two criterion constructs, perceived value and loyalty intentions.
Convergent validity is confirmed by the AVE values for four dimensions (Table 18) and e-service
quality construct (Table 19), greater than 0.5 (H3a and H3b). However, the AVE in efficiency

90

(0.52) and fulfillment (0.55) is slightly over the cutoff value. In order to increase the convergent
validity, deletion of EFF5 is considered because it has the lowest loading (0.58) among the
standardized factor loadings in efficiency, and low correlations with other efficiency items, for
instance, r = 0.36 between EFF5 and EFF1. When EFF5 is deleted, the AVE for efficiency
increases from 0.52 to 0.55, which was the largest increase without deleting other items. In the
fulfillment dimension, the AVE value increases from 0.55 to 0.57 when FUL4 (It provides
information that I’d like to receive) is deleted. FUL4 has low correlations with other fulfillment
items, for instance, r = 0.36 between FUL4 and FUL6, r = 0.39 with FUL7. This might be caused
by “individual differences in social desirability” (Viswanathan, 2005) for the FUL4 statement.
Item removal could improve the validity of the test, or rewording is necessary.
H4a: The AVE value of each dimension is greater than the pairwise r2 across the
four dimensions of the modified E-S-QUAL to validate the discrimination of the
four dimensions.
H4b: The AVE value of e-service quality is greater than the pairwise r2 across two
criterion constructs, perceived value and loyalty intentions.
Discriminant validity among dimensions is partially supported (H4a). E-service quality as a
higher-order construct is discriminated with the two relevant constructs (H4b). Among the four
dimensions, efficiency and fulfillment dimensions are not discriminated. This result indicates a
possible issue of across-measure systematic error (Viswanathan, 2005). A high correlation of
items between the two dimensions are found (r = 0.65) in EFF3 (It enables me to get to library
information quickly) and FUL3 (It provides information that I expect in a timely manner). After
deleting FUL3, the AVE value of efficiency (0.52) is still less than the r2 [0.54 = (0.74)2] between
efficiency and fulfillment, and it causes another discriminant issue between fulfillment and
privacy dimensions [(AVE (0.55) < r2 (0.58)]. Deleting items does not solve the discriminant

91

problem between efficiency and fulfillment. FUL3 as well as FUL1 and FUL4, have high
correlations with efficiency items. In order to enhance discriminant validity, those statements
could be reworded and/or items of efficiency and fulfillment could be separated from each other
on the questionnaire.
H5: The four dimensions of E-S-QUAL have a significantly positive correlation
with overall quality, perceived value, and loyalty intentions.
Predictive validity is partially supported (H5). Two dimensions, system availability and privacy,
have low correlations (r < 0.4) with overall quality and loyalty intentions. Especially, correlations
with loyalty intentions are relatively low, and r values with LOYALTY4 (Consider this service to
be your first choice for future library information) are very low such as 0.12 with SYS3 and 0.14
with PRI2. This result indicates that the Twitter site’s functioning and privacy do not have
significant relationships with further use of the service. This phenomenon can be identified in
other studies. Zehir et al. (2014) found low correlations (r < 0.4) between system availability and
perceived value and loyalty intentions. Marimon et al. (2010) and Akinci et al. (2010) found no
significant relationship between privacy and perceived value. Parasuraman et al. (2005) identified
lower-level significant relationships for privacy. For online users, privacy is a critical issue to
protect their personal information. However, users might consider it prior to actual use of online
services. If users determine a service is not safe, they might not consult the service to gain
benefits and values.
H6a: E-service quality has a significantly positive influence on perceived value.
H6b: E-service quality has a significantly positive influence on loyalty Intentions.
H6c: Perceived value has a significantly positive influence on loyalty intentions.

92

Nomological validity is confirmed among e-service quality, perceived value, and loyalty
intentions (H6a, H6b, and H6c). Perceived value mediates the relationships (R2 = 0.52, p < 0.001)
between e-service quality and loyalty intentions. In other words, e-service quality has a
significant positive relationship with loyalty intentions via perceived value. The nomological
network in this study setting is supported, which indicates theoretical coherence. These results
support the empirical findings in Parasuraman et al. (2005).
H7: The average means of E-S-QUAL items’ summed scores are significantly
different between in users and service providers.
Known-group validity is not supported (H7). Based on the previous studies investigating
perceptions of library service providers (Loudon & Hall, 2010; Hendrix et al., 2009) and users
(Mack et al., 2007; Chu & Meulemans, 2008; Connell, 2009) of social media services, their
difference in scores on e-service quality was assumed. However, the t-test result showed no
significant differences between the two groups in the modified E-S-QUAL measures. This
finding might have been affected by the measurement and a small sample of service providers
(N=15). The current study cannot identify reasons because e-service quality for Twitter services
had never been measured by library service providers and users. Further research with more
samples will be necessary to draw reliable conclusions.
H8: The magnitude of the relationship of overall quality, perceived value, and
loyalty intentions is different for each dimension.
The magnitude of the relationship of overall quality, perceived value, and loyalty intentions is
different for the four E-S-QUAL dimensions. H8 is supported. The order of magnitude is the
same as efficiency, fulfillment, system availability, and privacy, for three dependent variables.
Similar patterns were also found in the findings of Lee et al. (2012), Marimon et al. (2010), and

93

Parasuraman et al. (2005); however, Santouridis et al. (2012) found system availability ( = 0.5)
was a more important factor for perceived value than efficiency ( = 0.41) in the e-commerce
context.
H9: E-S-QUAL measures significant differences in the value of importance and
performance of each item.
The modified E-S-QUAL successfully measured the differences between perceptions of
importance and performance of the library Twitter services by users. H9 is supported. The
original E-S-QUAL developed by Parasuraman et al. (2005) did not use these two measures. This
study found that user-perceived gaps for service quality are identifiable by the modified E-SQUAL. The gap analysis between two scores, importance and performance, offers a useful
diagnostic measure to prioritize where service improvements will most likely affect user
perceived service quality.
5.1.3. Discussion of the Four Dimensions
Results of analyses suggest modifications to the E-S-QUAL instrument for application with social
media library services. This section discusses different test results for each dimension.
In the efficiency dimension, EFF5 (The site loads its pages fast) can be deleted from the scale
dimension because it has a relatively low loading value (0.42) in efficiency and a higher loading
value (0.53) in system availability as seen in the results of factor analyses. The removal improves
the convergent validity of the efficiency dimension. From the multiple regression analysis, this
construct was the most critical facet of library Twitter service quality on overall quality,
perceived value, and loyalty intentions.
In the system availability dimension, validity tests were highly supported. However, the
correlation (0.81) between SYS1 (The Twitter site is always available for this service) and SYS2

94

(This Twitter site launches and runs right away) is very high. One of the items could be deleted or
reworded to reduce redundancy.
In the fulfillment dimension, convergent validity is supported. However, the result of intercorrelation among items identified that FUL6 (It is truthful about the information it provides)
and FUL7 (It delivers accurate information) have relatively low correlation values with
efficiency items. Specifically, FUL7 has the lowest correlation value (0.21) with EFF1, and high
correlation (0.86) with FUL6. Removal or rewording of FUL7 could be considered. Also,
fulfillment items might need to be ordered differently. The results of factor analysis showed that
CFA confirmed high loadings of each item, but EFA showed high loadings of FUL3 (0.69) and
FUL4 (0.68) as well as FUL1 (0.58) and FUL2 (0.59) in efficiency. They have relatively higher
correlations with efficiency items than FUL5, 6, and 7. FUL1, 2, 3, and 4 should be reworded to
enhance discriminant validity.
The privacy dimension does not have statistical issues, but some respondents commented that
statements were confusing because they read them as rating the platform’s functioning as an
application itself, which libraries cannot manage. To reduce this confusion, adding phrases such
as “the site as an application for the library service” within statements might be clearer.
In addition, an improvement to the instrument was suggested from the survey respondents’
comments. Respondents identified “frequent updates” among the features for excellent library
Twitter services that were not mentioned in the modified E-S-QUAL 22 statements. A statement
could be added to the fulfillment dimension such as “the service updates information constantly”
or “the service provides up-to-date information.”

95

5.1.4. Guidelines for Application of the Modified ESQUAL Instrument
In order to provide excellent services to users, goals should be set up for the services which are in
line with libraries’ missions. Many libraries have not established purposes and policies for social
media services. It is very easy to begin using Facebook and Twitter by creating accounts and
posting contents. However, library managers should consider why they use social media, for what
purposes, and to whom. This step is important and necessary before service assessment.
If a library has offered social media services for a while to a substantial number of users and
would like to improve service quality, library managers can consider conducting service
assessment using this modified E-S-QUAL instrument to identify user perceptions of service
quality. It is a diagnostic tool for a site using four different factors. Slight statement modifications
will be necessary to apply this instrument in a particular library. Focus group interviews with
users and library staff members are recommended. The 22 core questions are recommended to
administrate random order. The survey result data can be used for understanding only service
performance by mean values of 22 items, and for calculating gaps between importance and
performance data to identify weakness and strength of items. In the following section, two
visualization methods using gap data are recommended to find a way to improve the service.
5.1.5. Visualization of Gaps Between Importance and Performance
The modified E-S-QUAL instrument can measure user-perceived importance and performance of
the service quality of Twitter in academic libraries. The two factors are helpful for practitioners to
identify which items are ideally important for the service and how users perceive their
performance. This study suggests two visualization methods for presenting the gap data between
two factors: radar and quadrant charts. MS Excel supports creating these charts.

96

First, a radar chart (a radial graph) displays multivariate data of several quantitative variables.
Figure 6 shows the chart with 22 items’ importance and performance data. This chart helps
practitioners identify two scores and differences between them. In Figure 6, the 266 data set was
used to create the chart, not one library’s data. It is easily observed that no item’s performance
score exceed users’ desired level of service. Items, EFF1, EFF2, and FUL4, have more gaps than
other items, which indicate the service performance does not meet users’ expectations for service
excellence. Items of system availability dimension have small gaps. Privacy items were perceived
as more important than others.
Figure 6. A Radar Chart of 22 Items' Importance and Performance Scores
EFF1
PRI3 5
PRI2

EFF2
EFF3

4

PRI1

EFF4

3

FUL7

EFF5

2
1

FUL6

EFF6

Importance

EFF7

Performance

0
FUL5
FUL4

EFF8

FUL3

SYS1

FUL2

SYS2
FUL1

SYS3
SYS4

Second, a quadrant chart is a graphic correlation technique that presents comparative information
among items, basically based on the average values of importance and performance (Lynch et al.,
1996; Hernon & Altman, 2010). In this study, gap analysis was incorporated into a quadrant chart
to produce strategically oriented information that helps to identify features where changes have
the potential to produce increases in service quality (Lynch et al., 1996). This chart helps

97

practitioners develop strategic planning for service improvement beyond simple frequency
distribution (Lynch et al., 1996; Hernon & Altman, 2010).
Figure 7 presents the quadrant chart using this study data. Each item’s xvalue is the mean of
importance and the yvalue is the mean of importance minus the mean of performance in order to
present the gap values. Both mean values of importance (4.27) and gap (0.24) scores are used for
coordinates, which make four quadrants.
Table 27 identifies items in each quadrant. Items falling into quadrant 1 indicate that users
perceive those items as very important and they rate the library service as trying to meet those
expectations (Hernon & Altman, 2010). Libraries retain these items, and resources could be saved
and reallocated. Items in quadrant 2 are important but do not meet the users’ expectations.
Libraries may need to change the service in order to improve performance or to be exposed to
users. Items in quadrant 3 reflect that users perceived those items as relatively unimportant, but
they identified those expectations in the service (Hernon & Altman, 2010). Libraries refocus the
service to enhance the importance of these items or to put their efforts on more important features.
Items in quadrant 4 may not be seen by users or are not important and the service does not have
those items’ attributes. Libraries may need to promote those attributes to improve importance or
ignore them.
For example, FUL1 (This service delivers timely information) is located in the quadrant 2. It is an
important feature but its performance doesn’t meet the users’ expectation for excellence. To
improve performance, library managers can post information at appropriate time and current
issues, and expose to users by posting information more frequently.

98

Table 27.
Items in Each Quadrant and Recommendations
Quadrant

Recommendation

Items

1

Retain

EFF6, FUL5, FUL6, FUL7, PRI1, PRI2, SYS1, SYS2, SYS3, SYS4

2

Improve performance

FUL1, FUL4, PRI3

3

Reposition

EFF4, EFF5, EFF8

4

Improve importance or Ignore

EFF1, EFF2, EFF3, EFF7, FUL2, FUL3

Figure 7. A Quadrant Chart Using Importance and Gap Scores

Very Important

5

Q1

Q2

4.5
4
3.5

Q4

Q3

Importance

3
2.5
2

Very Unimportant

1.5
1
0.5
0
0

0.1

0.2

Low potential
for improvement

0.3

0.4

0.5
Gap Score

0.6

0.7

0.8

0.9

1

High potential
for improvement

99

5.2. Implications
This study’s primary implications relate to 1) the validation of the E-S-QUAL instrument in
another non-profit service setting, 2) an application for the management of social media services
in academic libraries, 3) an understanding of online survey methodology to recruit participants
through social media, and 4) the rationale and directions of library online service operations.
First, this study’s results contribute to modifying the E-S-QUAL questionnaire to examine service
quality in the context of academic library Twitter services and to assess the instrument’s
psychometric properties. Parasuraman et al. (2005) developed E-S-QUAL for e-commerce
services selling and delivering physical products and hoped researchers would apply the
instrument in pure-service settings, which exclude physical material delivery. The present study is
unique to test E-S-QUAL in the library field, following studies in areas of e-government (Alanezi
et al., 2012; Connolly et al., 2010), university websites (Zada et al., 2012), and microbloggings
(Hu et al., 2012). The present study confirms the E-S-QUAL dimensionality composed of four
constructs, efficiency, system availability, fulfillment, and privacy, although suggests that some
items could be deleted and reworded to improve validity. This study fills a gap in both library
services and social media by empirically validating an instrument to measure their client
perceptions of service quality.
Second, the findings of this study provide insights for the management of social media services in
academic libraries. There have been no tools for measuring service quality of library social media
services. This study filled the gap by offering a possible tool. In general, this study encourages
assessing the quality of library services using online applications. The empirical findings in this
study provide a statistically tested structured instrument that goes beyond fragmented quantitative
information about applications. Applying the instrument to measure service quality will help
service providers determine directions and strategies for information services using social media,

100

a domain of an emerging social network infrastructure. This study offers guidance for the
modification of E-S-QUAL statements to fit into an individual service context and for the online
survey procedures. Service providers can implement the procedure employed in this study to
identify user-perceived service quality.
Specifically, this study identified dimensions important for the quality of library Twitter services,
which helps service managers prioritize those dimensions to improve service quality. Among the
four E-S-QUAL dimensions, users’ assessment of library Twitter services on efficiency has the
strongest influence on overall quality, perceived value, and loyalty intentions. The order of
magnitude is followed by fulfillment, system availability, and privacy. The results of gap
measurement could provide more definitive evidence for service providers to identify strong and
weak factors for their services. In this study, fulfillment items had greater differences between
user-perceived importance and performance of the Twitter services. Service providers could
emphasize those attributes to meet or exceed users’ expectations. The gap data can be
incorporated into a quadrant chart to visualize relative values of items and to prioritize service
areas for improvement. An understanding of those factors could assist service providers to
develop a strategic plan for systematically improving services and allocating resources to do so.
For instance, efficiency is consistently important, which emphasizes the need for service
providers to offer easy access to the service, deliver information frequently and up-to-date, and
organize the content simply.
Third, the methodology of this study implies that an online survey using the modified E-S-QUAL
through social media can be effective in data collection. Previous survey studies about library
social media services distributed the questionnaires mainly through papers in classrooms and
through emails (Kim & Abbas, 2010; Connell, 2009). However, inviting participants through
social media has the key advantage to target the population of social media users. Recruitment

101

through the service venues themselves relates to the representativeness of the sample respondents
and supports the reliability and validity of study results (Babbie, 2009). This study identified
opportunities and challenges of conducting online surveys on social media, which affect response
rates. Based on the response rates from the five different libraries, the researcher proposes several
factors possibly affecting data collection. Channels of distributing survey announcements are
important to expose the surveys to users as much as possible. For instance, not only libraries’
Twitter and Facebook accounts, but also student group sites are useful places to share surveys. In
this study, three weeks was sufficient survey duration. After that, one respondent participated
more than one time, suggesting risk of data reliability. As with other venues for conducting
surveys, incentives for participants could raise response rates over not offering incentives. Survey
fatigue at participating sites made it difficult to increase response rates regardless of the number
of library Twitter users. Lastly, cooperation with interested staff members is critical to diversify
the announcement channels, post the survey regularly, and increase the response rates.
Fourth, this study emphasized library online services by providing an assessment tool. Libraries
are in the online network environment. Since the Internet has become a common source of
information, library circulation and reference services have decreased. Users are communicating
less with libraries offline. Interacting with users online has become more important for libraries to
deliver information. Libraries have used online channels including email, chat, and different types
of platforms such as social media. However, libraries’ use of those platforms are still passive.
Beyond traditional circulation of library collections, library information could be disseminated
through social media to users who need information. Effective and efficient delivery information
including text, images, and videos about subject areas through social media could guide the
rationale and directions of library online services based on service quality assessment.

102

5.3. Conclusions
The primary goal of this dissertation is to determine the applicability of E-S-QUAL for measuring
the service quality of libraries’ social media services. Based on the findings of this study, the
modified E-S-QUAL is a valid instrument to measure the user-perceived service quality of
Twitter in academic libraries. A key strength of the present study was to apply E-S-QUAL to a
library online service which had never been investigated, and to assess its psychometric
properties empirically through a user survey. The instrument is a unique tool that reflects features
of library services using online applications, and measures the quality of those services. The
modified E-S-QUAL is composed of four distinctive dimensions and has a nomological network
supported with related constructs. Although the psychometric properties of the modified E-SQUAL were supported, dimensionality and validity tests diagnosed possibility of within-measure
and across-measure correlational systematic error. In order to improve the scale, applied actions
and future research are suggested. General wording, respondents’ differences in tendency to agree,
and continuous administration such as items in sequence could cause those errors (Viswanathan,
2005). The possibility of errors can be reduced by the following actions. Shared wording in
different constructs should be reworded or removed. Items’ sequence on the questionnaire should
be placed differently or dispersed, and fillers such as unrelated items could be located between
constructs (Viswanathan, 2005). Then, further studies will be necessary for testing these
modifications on items and measures and validating the further revised statements qualitatively
and quantitatively. Use of focus group interviews and the Delphi method are reasonable
approaches to increase content validity of the modified statements. Comparative studies could
assess the instrument as being more adaptive by conducting online surveys at different sites.
The findings of this study provide insights for measuring user-perceived service quality and
maintaining social media use in institutions. For practitioners, this study offers a validated

103

instrument to implement service quality assessment of social media services in libraries as well as
potentially other non-profit institutions. This study helps librarians establish a service evaluation
strategy by understanding survey procedures and online recruitment methods, and guides them to
utilize survey results by understanding the data interpretation. The measurement of service
quality will assist service institutions to develop a strategic plan for improving online services to
exceed user expectations and better allocate resources. Understanding user perceptions of services
based on the results of evaluation can help to identify factors that influence service quality. In
turn, such insights and service improvement strategies will guide development of institutional
policies for use of social media.
For researchers, the results of this study will be of value for examining applications of E-SQUAL to information services and for developing instruments for measuring e-service quality in
non-profit institutions. Researchers can compare this study’s results with others to interpret their
outcomes from studies about different social media applications and institutions such as Facebook
services in public libraries. The findings of this study will help researchers understand issues of
measurement errors and apply improvements to studies in other settings. Based on the items and
dimensions of this study, researchers could consult the results to expand and/or reduce them to
identify scales in different contexts. This study contributed to the research methodology of online
surveys by identifying response rate issues when researchers use social media as data gathering
venues. This study adds to a growing body of literature on both e-service quality and the
evaluation of library services by empirically evaluating the applicability of an assessment
instrument to a library social media service context.
The generalizability of this study’s results is subject to certain limitations. This study sample is
small, with Twitter services in only five academic libraries. Also, this study had difficulties in
collecting balanced samples from each participating library. Therefore, future research is

104

desirable for a replication of this study in different types of libraries as well as a larger sample of
academic libraries and services in order to reflect a broad spectrum of respondents. The low
response rates on a couple of sites and service provider groups might cause sample bias. It is
recommended to replicate this study with higher response rates to ensure as representative a
sample as possible. Further studies will achieve a more robust service quality instrument by
clarifying statements and testing in different service settings.
This research has raised questions for further investigation. Potential directions for future studies
are 1) further exploration of different social media services, 2) comparative studies for user
groups, 3) investigation of different kinds of measurements for gaps in e-service quality, and 4)
examination of developing service improvement strategies based on service quality
measurements.
First, it is recommended to extend research of the modified E-S-QUAL’s applicability to other
services such as Facebook, Instagram, and YouTube. Comparing the results from different
applications could provide psychometric properties to validate the instrument further, or identify
different scales for services. The understanding of service quality for each application will help
service providers determine applications for their users.
Second, this study’s sample did not support known-group validity. Because understanding
perception differences of service quality between service providers and users is important to meet
users’ expectations, further comparative research between them will be necessary to identify if
any differences of perceived service quality exist for library social media services. Further
research needs to examine more closely the links between different groups and service quality.
Third, further investigation and experimentation into gaps in e-service quality are strongly
recommended. Parasuraman et al. (2005) did not apply gap measurement in their tests, but

105

measuring differences between different perspectives is still important to identify the weaknesses
and strength of services. Zeithaml et al. (2000) identified different gaps between service quality
perceptions of users and service providers in online service environments. Specifically, further
research in the information gap, which is caused by discrepancies between user expectations of
finding/receiving appropriate information and service providers’ beliefs about enough
information for their users, would be of great help in understanding insufficient information to
users from a service. Examination of identifying constructs related to the information gap will be
worthwhile in library social media services.
Fourth, another possible area for future research direction would be to investigate relationships
between service quality measurements and service improvement strategies. Evaluations aim to
diagnose current problems to improve services. In what ways do managers utilize the results of
service quality measurement for service delivery strategies and institutions’ policy development?
Exploration of this question will help to provide sustainable and outstanding services.
Information is more valuable when it is connected and flows rather than kept in stock. Libraries
face challenges for improving the effectiveness of information delivery and communication with
users in the environment of multiple channels of networks and various information formats.
Social media applications help libraries engage in those networks and provide information
services. Evaluation of user perceptions of social media service quality is an important step to
address challenges and identify service improvement opportunities. This exploration of the
applicability of E-S-QUAL offers a new framework for library service evaluation and presents
important implications for practice and research. Service managers will obtain benefits of
services improvement by understanding what influences user perceptions of service quality, what
users expect from online services using applications, and how to deliver what users want to
acquire from the services.

106

BIBLIOGRAPHY

1.

Abdullah, N., Chu, S., Rajagopal, S., Tung, A., & Yeung, K. (2015). Exploring libraries' efforts in inclusion
and outreach activities using social media. Libri: International Journal Of Libraries & Information Services,
65(1), 34-47.

2.

Aharony, N. (2011). Twitter use in libraries: An exploratory analysis. Journal of Web Librarianship, 4(4),
333-350.

3.

Aharony, N. (2012). Facebook use in libraries: An exploratory analysis. Aslib Proceedings, 64(4), 358-372.

4.

Agichtein, E., Castillo, C., Donato, D., Gionis, A., & Mishne, G. (2008). Finding high-quality content in social
media. In a proceeding of WSDM’08, February 11-12, 2008, Palo Alto, California, USA.

5.

Agosto, D. E., & Abbas, J. (2009). Teens and social networking: How public libraries are responding to the
latest online trend. Public Libraries, 48(3), 32-37.

6.

Akinci, S., Atilgan-Inan, E., & Aksoy, S. (2010). Reassessment of E-S-QUAL and E-RecS-Qual in a pure
service setting. Journal of Business Research, 63(3), 232-240.

7.

Alanezi, M. A., Mahmood, A. K., & Basri, S. (2012). A proposed model for assessing e-government service
quality: An E-S-QUAL approach. In a proceedings of International Conference on Computer & Information
Science (ICCIS), June 12-14, 130-135.

8.

Ali, M. H. (2012). E-S-QUAL model in internet banking: A study from customers' perspectives. The Journal
of International Management Studies, 7(2), 75-78.

9.

Allison, P. D. (1999). Logistic regression using the SAS system: Theory and application. Cary, NC: SAS
Institute.

10.

American Association for Public Opinion Research. (2011). Standard Definitions: Final Dispositions of Case
Codes and Outcome Rates for Surveys. 7th edition. AAPOR.
http://www.aapor.org/Response_Rates_An_Overview1.htm#.UzL1V_lcgpo

11.

Ayu, A. R. R., & Abrizah, A. (2011). Do you Facebook? Usage and applications of Facebook page among
academic libraries in Malaysia. The International Information & Library Review, 43(4), 239-249.

12.

Babbie, E. (2009). The practice of social research. (12th ed.). Cengage Learning.

13.

Balfe, M., Doyle, F., & Conroy, R. (2012). Using Facebook to recruit young adults for qualitative research
projects: How difficult is it? CIN: Computers, Informatics, Nursing, 30(10), 511–515.

14.

Barnes, S. J., & Vidgen, R. T. (2002). An integrative approach to the assessment of e-commerce quality.
Journal of Electronic Commerce Research, 3(3), 114-127.

15.

Baruch, Y., & Holtom, B. C. (2008). Survey response rate levels and trends in organizational research. Human
Relations, 61(8), 1139-1160.

16.

Bauer, H. H., Falk, T., & Hammerschmidt, M. (2006). eTransQual: A transaction process-based approach for
capturing service quality in online shopping. Journal of Business Research, 59(7), 866-875.

17.

Barrios, M., Villarroya, A., Borrego, A., & Ollé, C. (2011). Response rates and data quality in web and mail
surveys administered to PhD holders. Social Science Computer Review, 29(2), 208-220.

107
18.

Batterham, P. J. (2014). Recruitment of mental health survey participants using Internet advertising: Content,
characteristics and cost effectiveness. International Journal of Methods in Psychiatric Research, 23(2), 184191.

19.

Becker, C. (2009). Student values and research: Are millenials really changing the future of reference and
research? Journal of Library Administration, 49(4), 341-364.

20.

Bejune, M., & Ronan, J. (2008). Social software in libraries (SPEC Kit 304). Washington, DC: Association of
Research Libraries.

21.

Bodnar, J., & Doshi, A. (2011). Asking the right questions: A critique of Facebook, social media, and libraries.
Public Services Quarterly, 7(3-4), 102-110.

22.

Boshoff, C. (2007). A psychometric assessment of E-S-QUAL: A scale to measure electronic service quality.
Journal of Electronic Commerce Research, 8(1), 101-114.

23.

Bradley, P. (2007). How to use Web 2.0 in your library. London: Facet Publishing.

24.

Bruin, J. (2006). Newtest: Command to compute new test. UCLA: Statistical Consulting Group. Retrieved
from http://www.ats.ucla.edu/stat/stata/ado/analysis/

25.

Callegaro, M., & DiSogra, C. (2008). Computing response metrics for online panels. Public Opinion Quarterly,
72(5), 1008-1032.

26.

Calvert, P. J. (2001). International variations in measuring customer expectations. Library Trends, 49(4), 732756.

27.

Cavanagh, M. F. (2015). Micro-blogging practices in Canadian public libraries: A national snapshot. Journal
of Librarianship and Information Science, January, 1-13.

28.

Charnigo, L., & Barnett-Ellis, P. (2007). Checking out Facebook.com: The impact of a digital trend on
academic libraries. Information Technology and Libraries, 26(1), 23-34.

29.

Chen, D. Y. T., Chu, S. K. W., & Xu, S. Q. (2012). How do libraries use social networking sites to interact
with users. In a proceeding of ASIST 2012, October 28-31, 2012, Baltimore, MD, USA.

30.

Cheung, C. M. K., Chiu, P.-Y., & Lee, M. K. O. (2011). Online social networks: Why do students use
Facebook? Computers in Human Behavior, 27(4), 1337–1343.

31.

Chiou, J.-S., Wu, L.-Y., & Sung, Y.-P. (2009). Buyer satisfaction and loyalty intention in online auctions:
Online auction web site versus online auction seller. Journal of Service Management, 20(5), 521-543.

32.

Chiu, M. H. P., & Lin, Y. Y. (2012). Virtualizing library processes and interactions: A content analysis of
library Facebook profiles. In a proceeding of the IATUL Conferences. Paper 20. Retrieved from
http://docs.lib.purdue.edu/iatul/2012/papers/20

33.

Choi, C. (2012). Is your library ready for a social media librarian? In a proceeding of ALIA Biennial 2012
Conference, July 11-13, Sydney, Australia.

34.

Choi, J., Jung, J., & Lee, S. W. (2013). What causes users to switch from a local to a global social network site?
The cultural, social, economic and motivational factors of Facebook’s globalization. Computers in Human
Behavior, 29(6), 2665-2673.

35.

Chu, M., & Meulemans, Y. N. (2008). The problems and potential of MySpace and Facebook usage in
academic libraries. Internet Reference Services Quarterly, 13(1), 69-85.

36.

Chu, S. K., & Du, H. S. (2012). Social networking tools for academic libraries. Journal of Librarianship and
Information Science, 45(1), 64-75.

37.

Coleman, V., Xiao, Y., Bair, L., & Chollett, B. (1997). Toward a TQM paradigm: Using SERVQUAL to
measure library service quality. College & Research Libraries, 58(3), 237-249.

108
38.

Comrey, A. L., & Lee, H. B. (1992). A first course in factor analysis. Hillsdale, NJ: Erlbaum.

39.

Connell, R. S. (2009). Academic libraries, Facebook and MySpace, and student outreach: A survey of student
opinion. Libraries and the Academy, 9(1), 25-36.

40.

Connolly, R., Bannister, F., & Kearney, A. (2010). Government website service quality: A study of the Irish
revenue online service. European Journal of Information System, 19, 649-667.

41.

Cook, C., & Heath, F. M. (2001). Users' perceptions of library service quality: A LibQUAL+ qualitative study.
Library Trends, 49(4), 548-584.

42.

Cook, C., & Thompson, B. (2000). Reliability and validity of SERVQUAL scores used to evaluate perceptions
of library service quality. The Journal of Academic Librarianship, 26(4), 248-258.

43.

Cronbach, L. J., & Meehl, P. E. (1955). Construct validity in psychological tests. Psychological Bulletin, 52(4),
281-302.

44.

Cronin, J. J., & Taylor, S. A. (1992). Measuring service quality: A reexamination and extension. Journal of
Marketing, 6(July), 55-68.

45.

Cuddy, C., Graham, J., & Morton-Owens, E. G. (2010). Implementing Twitter in a health sciences library.
Medical Reference Services Quarterly, 29(4), 320-330.

46.

Dann, S. (2010). Twitter content classification. First Monday, 15(12). Retrieved from
http://firstmonday.org/ojs/index.php/fm/article/view/2745/2681

47.

Del Bosque, D., Leif, S. A., & Skarl, S. (2012). Libraries atwitter: Trends in academic library tweeting.
Reference Services Review, 40(2), 199-213.

48.

Deutskens, E., Ruyter, K. D., Wetzels, M., & Oosterveld, P. (2004). Response rate and response quality of
Internet-based surveys: An experimental study. Marketing Letters, 15(1), 21-36.

49.

Devoe, K. M. (2009). Bursts of information: Microblogging. The Reference Librarian, 50, 212-214.

50.

Ding, D. X., Hu, P. J. H., & Sheng, O. R. L. (2011). e-SELFQUAL: A scale for measuring online self-service
quality. Journal of Business Research, 64, 508-515.

51.

Doshi, A. (2012). Just the right tweet at just the right time. Reference Services Review, 40(2), 221-223.

52.

Dowd, N. (May 7, 2013). Social media: Libraries are posting, but is anyone listening? Library Journal,
138(10), 12.

53.

Duggan, M., Ellison, N. B., Lampe, C., Lenhart, A., & Madden, M. (2015). Social media update 2014. Pew
Research Center’s Internet & American Life Project. Retrieved from
http://www.pewinternet.org/files/2015/01/PI_SocialMediaUpdate20144.pdf

54.

Emery, K., & Schifeling, T. (2015). Libraries using Twitter better: Insights on engagement from food trucks.
In a proceedings from ACRL '15, March 25 - 28, 2015, Portland, Oregon.

55.

Einasto, O. (2014). Investigating e-service quality criteria for university library: A focus group study. New
Library World, 115(1/2), 4-14.

56.

Ellahi, A., & Bokhari, R. H. (2013). Key quality factors affecting users' perception of social networking
websites. Journal of Retailing and Consumer Services, 20(1), 120-129.

57.

Farkas, M.G. (2007). Social software in libraries: Building collaboration, communication, and community
online. Medford, NJ: Information Today.

58.

Fornell, C., & Larcker, D. F. (1981). Evaluating structural equation models with unobservable variables and
measurement error. Journal of Marketing Research, 28(1), 39-50.

109
59.

Forrestal, V. (2010). Making Twitter work: A guide for the uninitiated, the skeptical, and the pragmatic. The
Reference Librarian, 52(1-2), 146-151.

60.

Franklin, B., & Plum, T. (2006). Successful Web survey methodologies for measuring the impact of
networked electronic services (MINES for LibrariesTM). IFLA Journal, 32(1).

61.

Fuentes-Blasco, M., Saura, I., Berenguer-Contrí, G., & Moliner-Velázquez, B. (2010). Measuring the
antecedents of e-loyalty and the effect of switching costs on website. The Service Industries Journal, 30(11),
1837-1852.

62.

Garcia-Milian, R., Norton, H. F., & Tennant, M. R. (2012). The presence of academic health sciences libraries
on Facebook: The relationship between content and library popularity. Medical Reference Services Quarterly,
31(2), 171-187.

63.

Gerbing, D. W., & Anderson, J. C. (1988). An updated paradigm for scale development incorporating
unidimensionality and its assessment. Journal of Marketing Research, 25(2), 186-192.

64.

Goetsch, D. L., & Davis, S. (2006). Quality management: Introduction to total quality management for
production, processing, and services (5th ed.). Upper Saddle River, NJ: Pearson Prentice Hall.

65.

Grevet, C., Terveen, L., & Gilbert, E. (2014). Managing political differences in social media. In a proceeding
of CSCW'14, February 15 - 19 2014, Baltimore, MD, USA.

66.

Gerolimos, M., & Konsta, R. (2011). Services for academic libraries in the new era. D-lib magazine, 17(7/8).
Retrieved from http://www.dlib.org/dlib/july11/gerolimos/07gerolimos.html

67.

Glazer, H. (2009). Clever outreach or costly diversion? An academic library evaluates its Facebook
experience. College and Research Libraries News, 70(1), 11-19.

68.

Gr nroos, C. (1984). A service quality model and its marketing implication. European Journal of Marketing,
18(4), 36-44.

69.

Gr nroos, C. (1988). Service quality: The six criteria of good perceived service. Review of Business, 9(3), 1013.

70.

Guidry, J. A. (2002). LibQUAL+™ spring 2001 comments: A qualitative analysis using Atlas.ti. Performance
Measurement and Metrics, 3(2), 100-107.

71.

Hampton, K. N., Goulet, L. S., Rainie, L., & Purcell, K. (2011). Social networking sites and our lives. Pew
Research Center’s Internet & American Life Project. Retrieved from
http://pewinternet.org/Reports/2011/Technology-and-social-networks.aspx

72.

Harinarayana, N. S., & Raju, N. V. (2010). Web 2.0 features in university library web sites. The Electronic
Library, 28(1), 69-88.

73.

Hébert, F. (1993). Quality of interlibrary borrowing service in large public libraries in Canada. (Doctoral
dissertation). University of Toronto, Canada.

74.

Helgesen, Ø., & Nesset, E. (2011). Does LibQUAL+ account for student loyalty to a university college library?
Quality Assurance in Education, 19(4), 413-440.

75.

Hendrix, D., Chiarella, D., Hasman, L., Murphy, S., & L. Zafron, M. L. (2009). Use of Facebook in academic
health sciences libraries. Journal of the Medical Library Association, 97(1), 44-47.

76.

Hernon, P., & Altman, E. (2010). Assessing Service Quality: Satisfying the Expectations of Library Customers.
Chicago, IL: American Library Association.

77.

Hernon, P., & Calvert, P. (2005). E-Service quality in libraries: Exploring its features and dimensions. Library
& Information Science Research, 27(3), 377-404.

110
78.

Hernon, P., & Nitecki, D. (2001). Service quality: A concept not fully explored. Library Trends, 49(4), 687708.

79.

Hernon, P., & Whitman, J. R. (2001). Delivering Satisfaction and Service Quality: A Customer-based
Approach for Libraries. Washington, DC: American Library Association.

80.

Hinkin, T. R. (1998). A brief tutorial on the development of measures for use in survey questionnaires.
Organizational Research Methods, 1(1), 104-121.

81.

Ho, J., & Crowley, G. H. (2003). User perceptions of the reliability of library services at Texas A&M
University: A focus group study. The Journal of Academic Librarianship, 29(2), 82-87.

82.

Holmberg, K., Huvila, I., Kronqvist-Berg, M., & Widen-Wulff, G. (2009). What is Library 2.0? Journal of
Documentation, 65(4), 668-681.

83.

Hooper, D., Coughlan, J., & Mullen, M. (2008). Structural equation modeling: Guidelines for determining
model fit. Electronic Journal of Business Research Methods, 6(1), 53-60.

84.

Hsieh, K. J., Hsieh, Y. C., Chiu, H. C., & Feng, Y. C. (2012). Post-adoption switching behavior for online
service substitutes: A perspective of the push–pull–mooring framework. Computers in Human Behavior, 28(5),
1912-1920.

85.

Hu, Y. C., Wang, J. H., & Hung, L. P. (2012). Evaluating microblogging eservice quality using ANP. Journal
of Multi Criteria Decision Analysis, 19(1-2), 89-111.

86.

Huang, E. Y., Lin, S. W., & Fan, Y. C. (2015). M-S-QUAL: Mobile service quality measurement. Electronic
Commerce Research and Applications, 1-17.

87.

Ingle, S., & Connolly, R. (2006). Methodological and research issues using E-S-QUAL to measure online
service quality in Irish SMEs. Irish Journal of Management, 27(2), 25-32.

88.

Jun, Z., Liangliang, C., & Fubin, L. (2009). E-S-QUAL: Its applicability in evaluating E-government web sites
service quality. International Symposium on Information Engineering and Electronic Commerce, 515-518.

89.

Kandulapati, S., & Bellamkonda, R. S. (2014). E-service quality: A study of online shoppers in India.
American Journal of Business, 29(2), 178-188.

90.

Kayongo, J., & Jones, S. (2008). Faculty perception of information control using LibQUAL+™ indicators. The
Journal of Academic Librarianship, 34(2), 130-138.

91.

Kieftenbeld, V., & Natesan, P. (2013). Examining the measurement and structural invariance of LibQUAL+®
across user groups. Library & information Science Research, 35, 143-150.

92.

Kilian, T., Hennigs, N., & Langner, S. (2012). Do Millennials read books or blogs? Introducing a media usage
typology of the Internet generation. The Journal of Consumer Marketing, 29(2), 114-124.

93.

Kim, H. M. (2014). Evaluation of the applicability of E-S-QUAL for assessing the service quality of social
media: A case study of an academic library’s Facebook service. In a proceeding of 2014 Library Assessment
Conference, Aug 3-6, Seattle, WA.

94.

Kim, H. M., Abels, E. G., & Yang, C. C. (2012). Who disseminates academic library information on Twitter?
In a proceeding of ASIST 2012, Oct 28-31, Baltimore.

95.

Kim, M., Kim, J-H., & Lennon, S. J. (2006). Online service attributes available on apparel retail websites: An
E-S-QUAL approach. Managing Service Quality, 16(1), 51-77.

96.

Kim, H. M., Yang, C. C., Abels, E. G., & Zhang, M. (2012). A qualitative analysis of information
dissemination through social media in a digital library. In a proceeding of JCDL' 12, ACM/IEEE-CS joint
conference on Digital Libraries, 339-340.

111
97.

Kim, Y. M., & Abbas, J. (2010). Adoption of Library 2.0 functionalities by academic libraries and users: A
knowledge management perspective. Journal of Academic Librarianship, 36(3), 211-218.

98.

Kiran, K., & Diljit, S. (2012). Modeling Web-based library service quality. Library & Information Science
Research, 34(3), 184-196.

99.

KMO and Bartlett's Test. (n.d.) In IBM Knowledge Center. SPSS Statistics 20.0.0. Retrieved from http://www01.ibm.com/support/knowledgecenter/SSLVMB_20.0.0/com.ibm.spss.statistics.cs/

100.

Kotler, P., & Armstrong, G. (2013). Principles of Marketing. (15th ed.). Englewood Cliffs, NJ: Prentice Hall.

101.

Kroski, E. (2008). Web 2.0 for librarians and information professionals. New York, NY: Neal Schuman
Publishers.

102.

Kyrillidou, M., & Giersch, S. (2005). Developing the DigiQUAL protocol for digital library evaluation. In a
proceedings of the 5th ACM/IEEE-CS Joint Conference on Digital Libraries, ACM Press, New York, NY.

103.

Kyrillidou, M., Thompson, B., & Cook, C. (2011). Regrounding LibQUAL+® for the digital library
environment: An analysis of the DigiQUAL data. In proceedings of 9th Northumbria International Conference
on Performance Measurement in Libraries and Information Services, Aug 22, York, England.

104.

Ladhari, R. (2010). Developing e-service quality scales: A literature review. Journal of Retailing and
Consumer Services, 17, 464-477.

105.

Landis, C. (2010). Measures of success. In Landis, C., A Social Networking Primer for Librarians (pp. 85).
New York, NY: Neal-Schuman Publishers.

106.

Landrum, H., Prybutok, V. R., Kappelman, L. A., & Zhang, X. (2008). SERVCESS: A parsimonious
instrument to measure service quality and information system success. The Quality Management Journal,
15(3), 17-25.

107.

Lane, F. C., Anderson, B., Ponce, H. F., & Natesan, P. (2012). Factorial invariance of LibQUAL+® as a
measure of library service quality over time. Library & Information Science Research, 34(1), 22-30.

108.

Le Gac, M. A. O. (2010). Twittering libraries: How and why New Zealand public libraries use micro-blogging.
(Master thesis). Victoria University of Wellington, New Zealand.

109.

Lee, J., Cha, M. S., & Cho, C. (2012). Online service quality in social commerce websites. In a proceeding of
iCETS 2012, Tianjin, China, August 29-31, 2012, 335-351.

110.

Lilburn, J. (2012). Commercial social media and the erosion of the commons: Implications for academic
libraries. Portal: Libraries and the Academy, 12(2), 139-153.

111.

Lin, K.-Y., & Lu, H.-P. (2011). Why people use social networking sites: An empirical study integrating
network externalities and motivation theory. Computers in Human Behavior, 27(3), 1152-1161.

112.

Lin, S.-P., Chan, Y.-H., & Tsai, M.-C. (2009). A transformation function corresponding to IPA and gap
analysis. Total Quality Management & Business Excellence, 20(8), 829-846.

113.

Linh, N. C. (2008). A survey of the application of Web 2.0 in Australasian university libraries. Library Hi
Tech, 26(4), 630-653.

114.

Liu, T. H. (2012). Effect of e-service quality on customer online repurchase intentions. (Doctoral dissertation).
Lynn University, FL.

115.

Loiacono, E. T., Watson, R. T., & Goodhue, D. L. (2002). WEBQUAL: A measure of website quality. In a
proceeding of American Marketing Association: Winter Marketing Educators’ Conference.

116.

Loudon, L., & Hall, H. (2010). From triviality to business tool: The case of Twitter in library and information
services delivery. Business Information Review, 27(4), 236-241.

112
117.

Lynch, J., Carver, R. Jr., & Virgo, J. M. (1996). Quadrant analysis as a strategic planning technique in
curriculum development and program marketing. Journal of Marketing for Higher Education, 7(2), 1732.

118.

MacCallum, R. C., Widaman, K. F., Zhang, S., & Hong, S. (1999). Sample size in factor analysis.
Psychological Methods, 4(1), 84-99.

119.

Mack, D., Behler, A., Roberts, B., & Rimland, E. (2007). Reaching students with Facebook: Data and best
practices. Electronic Journal of Academic and Special Librarianship, 8(2). Retrieved from
http://southernlibrarianship.icaap.org/indexv8.html

120.

Mahmood, K., & Richardson, J. V. (2011). Adoption of Web 2.0 in US academic libraries: A survey of ARL
library websites. Program: electronic library and information systems, 45(4), 365-375.

121.

Malhotra, N. K. (2004). Marketing research: An applied orientation. (4th ed.). Englewood Cliffs, NJ: Prentice
Hall.

122.

Maness, J. M. (2006). Library 2.0 theory: Web 2.0 and its implications for libraries. Webology, 3(2). Retrieved
from http://www.webology.org/2006/v3n2/a25.html

123.

Marimon, F., Vidgen, R., Barnes, S., & Cristóbal, E. (2010). Purchasing behaviour in an online supermarket:
The applicability of E-S-QUAL. International Journal of Market Research, 52(1), 111-129.

124.

Marshall, C., & Rossman, G. B. (2011). Designing qualitative research. (5th ed.). CA: Sage Publications.

125.

Martin, B. D. II. (2011). A Survey of student, staff, and faculty perceptions of thirteen Pennsylvania State
owned libraries using the LibQUAL+™ protocol. (Doctoral dissertation). Indiana University of Pennsylvania,
PA.

126.

Matthews, J. R. (2007). The evaluation and measurement of library services. Westport, CN: Libraries
Unlimited.

127.

McQuail, D. (1983). Mass communication theory: An introduction. London: Sage Publications.

128.

Meng, J., & Mummalaneni, V. (2010). Measurement equivalency of web service quality instruments: A test on
Chinese and African American consumers. Journal of International Consumer Marketing, 22, 259-269.

129.

Michaelidou, N., Siamagka, N. T., & Christodoulides, G. (2011). Usage, barriers and measurement of social
media marketing: An exploratory investigation of small and medium B2B brands. Industrial Marketing
Management, 40(7), 1153-1159.

130.

Milberry, K., & Anderson, S. (2009). Open sourcing our way to an online commons: Contesting corporate
impermeability in the new media ecology. Journal of Communication Inquiry, 33(4), 395, 399-400, 402, 409.

131.

Miller, K. F. (2008). Service quality in academic libraries: An analysis of LibQUAL+TM scores and
institutional characteristics. (Doctoral dissertation). University of Central Florida, FL.

132.

Mohammadian, M., & Mohammadreza, M. (2012). Identify the success factors of social media (marketing
perspective). International Business and Management, 4(2), 58-66.

133.

Mundt, S. (2013). Evaluating the marketing success of libraries’ social media presences. In a proceeding of
IFLA World Library and Information Congress, 17-23 August 2013, Singapore. Retrieved from
http://library.ifla.org/196

134.

Nagata, H., Satoh, Y., Gerrard, S., & Kytonaki, P. (2004). The dimensions that construct the evaluation of
service quality in academic libraries. Performance Measurement and Metrics, 5(2), 53-65.

135.

Nitecki, D. A. (1995). An assessment of the applicability of SERVQUAL dimensions as a customer-based
criteria for evaluation quality of services in an academic library. (Doctoral dissertation). University of
Maryland, College Park, MD.

113
136.

Nitecki, D. A., & Hernon, P. (2000). Measuring service quality at Yale University’s libraries. The Journal of
Academic Librarianship, 26(4), 259-273.

137.

Nunnally, J. C., & Bernstein, I. H. (1994). Psychometric Theory. New York, NY: McGraw-Hill.

138.

Oliver, R. L. (1981). Measurement and evaluation of satisfaction processes in retail settings. Journal of
Retailing, 57(3), 25-48.

139.

O’Neill, M., Wright, C., & Fitz, F. (2001). Quality evaluation in on-line service environments: An application
of the importance-performance measurement technique. Managing Service Quality, 11(6), 402-417.

140.

O'Reilly, Tim. (2005). What is Web 2.0: Design patterns and business models for the next generation of
software. O’Reilly Media, Inc. Retrieved from http://oreilly.com/web2/archive/what-is-web-20.html

141.

Overall, J. E., & Klett, C. J. (1972). Applied multivariate analysis. New York, NY: McGraw-Hill.

142.

Panagiotopoulos, P. (2012). Towards unions 2.0: Rethinking the audience of social media engagement. New
Technology, Work and Employment, 27(3), 178-192.

143.

Parasuraman, A., Berry, L. L., & Zeithaml, V. A. (1991). Refinement and reassessment of the SERVQUAL
scale. Journal of Retailing, 67(4), 420-450.

144.

Parasuraman, A., Zeithaml, V. A., & Berry, L. L. (1985). A conceptual model of service quality and its
implications for future research. Journal of Marketing, 49(3), 41-50.

145.

Parasuraman, A., Zeithaml, V. A., & Berry, L. L. (1988). SERVQUAL: A multiple-item scale for measuring
consumer perceptions of service quality. Journal of Retailing, 64(1), 12-40.

146.

Parasuraman, A., Zeithaml, V. A., & Malhotra, A. (2005). E-S-QUAL: A multiple-item scale for assessing
electronic service quality. Journal of service research, 7, 213-233.

147.

Park, J. H. (2009). Differences among university students and faculties in social networking site perception
and use: Implications for academic library services. The Electronic Library, 39(3), 417-431.

148.

Petnji, Y. L. H., Marimon, F., & Casadesus, M. (2011). Customer's loyalty and perception of ISO 9001 in
online banking. Industrial Management & Data System, 111(8), 1194-1213.

149.

Phillips, N. K. (2011). Academic library use of Facebook: Building relationships with students. The Journal of
Academic Librarianship, 37(6), 1-11.

150.

Pinto, M., & Manso, R. A. (2012). Virtual references services: Defining the criteria and indicators to evaluate
them. The Electronic Library, 30(1), 51-69.

151.

Posey, J. A. (2009). Student perceptions and expectations of library services quality and user satisfaction at
Walters State Community College. (Doctoral dissertation). East Tennessee State University, TN.

152.

Powell, R. R. (2006). Evaluation research: An overview. Library Trends, 55(1), 102-120.

153.

Powers, A. C., Schmidt, J., & Hill, C. (2008). Why can’t we be friends? The MSU Libraries find friends on
Facebook. Mississippi Libraries, 72(1), 3-5.

154.

Rafiq, M., Lu, X., & Fulford, H. (2012). Measuring Internet retail service quality using E-S-QUAL. Journal of
Marketing Management, 28(9-10), 1159-1173.

155.

Ramos, M. S., & Abrigo, C. M. (2012). Reference 2.0 in action: An evaluation of the digital reference services
in selected Philippine academic libraries. Library Hi Tech News, 29(1), 8-20.

156.

Roszkowski, M. J., Baky, J. S., & Jones, D. B. (2005). So which score on the LibQual+™ tells me if library
users are satisfied? Library &Information Science Research, 27(4), 424-439.

114
157.

Roy, A., Khare, A., Liu, B. S. C., Hawkes, L. M., & Swiatek-Kelley, J. (2012). An investigation of affect of
service using a LibQUAL+™ survey and an experimental study. The Journal of Academic Librarianship,
38(3), 153-160.

158.

Sahadev, S., & Purani, K. (2008). Modeling the consequences of e-service quality. Marketing Intelligence &
Planning. 26(6), 605-620.

159.

Sánchez-Fernández, J., Muñoz-Leiva, F., & Montoro-Ríos, F. J. (2012). Improving retention rate and response
quality in Web-based surveys. Computers in Human Behavior, 28, 507–514.

160.

Santouridis, I., Trivella, P., & Tsimonis, G. (2012). Using E-S-QUAL to measure internet service quality of ecommerce web sites in Greece. International Journal of Quality and Service Science, 4(1), 86-98.

161.

Santos, J. (2003). E-service quality: A model of virtual service quality dimensions. Managing Service Quality,
13(3), 233-246.

162.

Saracevic, T. (2000). Digital library evaluation: Toward an evolution of concepts. Library Trends, 49(3), 350369.

163.

Seth, N., Deshmukh, S. G., & Vrat, P. (2005). Service quality models: A review. The International Journal of
Quality & Reliability Management, 22(8/9), 913-949.

164.

Shoniwa, P., & Hall, H. (2007). Library 2.0 and UK academic libraries: Drivers and impacts. New Review of
Information Networking, 13(2), 69-79.

165.

Stone, S. (2014). Breaking the ice: Facebook friending and reference interactions. Reference & Users Services
Quarterly, 54(1), 44-49.

166.

Stuart, D. (2010). What are libraries doing on Twitter? Online, Jan/Feb (3), 45-47.

167.

Tate, M., & Evermann, J. (2010). The end of ServQual in online services research: Where to from here? eService Journal, 7(1), 60-85

168.

Thompson, B., Cook, C., & Kyrillidou, M. (2005). Concurrent validity of LibQUAL+™ scores: What do
LibQUAL+™ scores measure? The Journal of Academic Librarianship, 31(6), 517-522.

169.

Van Niekerk, B., & Maharaj, M. (2013). Social media and information conflict. International Journal of
Communication, 7, 1162-1184.

170.

Viswanathan, M. (2005). Measurement error and research design. CA: Sage Publications.

171.

Voida, A., Harmon, E., & Al-Ani, B. (2012). Bridging between organizations and the public: Volunteer
coordinators' uneasy relationship with social computing. In a proceeding of the SIGCHI Conference on Human
Factors in Computing Systems, 1967-1976.

172.

Walia, P. K., & Gupta, M. (2012). Application of web 2.0 tools by national libraries. Webology 9(2). Retrieved
from http://www.webology.org/2012/v9n2/a99.html

173.

Wallace, D. P., & Van Fleet, C. (2001). Library evaluation: A casebook and can-do guide. Englewood, CO:
Libraries Unlimited.

174.

Wan, G. (2011). How academic libraries reach users on Facebook. College & Undergraduate Libraries, 18(4),
307-318.

175.

Weiss, C. H. (1998). Evaluation: Methods for studying programs and policies (2nd ed.). Upper Saddle River,
NJ: Prentice Hall.

176.

White, M. D., & Abels, E. G. (1995). Measuring service quality in special libraries: Lessons from service
marketing. Special Libraries, 86(1), 36-45.

115
177.

Wolfinbarger, M., & Gilly, M. C. (2003). eTailQ: Dimensionalizing, measuring and predicting etail quality.
Journal of Retailing, 79, 183-198.

178.

Wu, K. W. (2006). Service quality, customer satisfaction, and customer loyalty in consumer electronics etailers: A structural equation modeling approach. (Doctoral dissertation). Lynn University, FL.

179.

Wu, K. W., & Ding, M. C. (2007). Validating the American customer satisfaction index model in the online
context: An empirical study of U.S. consumer electronics e-tailers. International Journal of Business and
Information, 2(2), 199-220.

180.

Wu, Y.-L., Tao, Y.-H., Li, C.-P., Wang, S.-Y., & Chiu, C.-Y. (2014). User-switching behavior in social
network sites: A model perspective with drill-down analyses. Computers in Human Behavior, 33, 92-103.

181.

Xia, Z. D. (2009). Marketing library services through Facebook groups. Library Management, 30(6/7), 469478.

182.

Xie, I., & Stevenson, J. (2014). Social media application in digital libraries. Online Information Review, 38(4),
502-523.

183.

Yang, Z., Jun, M., & Peterson, R. T. (2004). Measuring costumer perceived online service quality: Scale
development and managerial implications. International Journal of Operations & Production Management,
24(11/12), 1149-1174.

184.

Yang, H., & Tsai, F. (2007). General E-S-QUAL scales applied to websites satisfaction and loyalty model.
Communications of the IIMA, 7(2), 115-126.

185.

Yaya, L. H. P., Marimon, F., & Fa, M. C. (2012). Assessing e-service quality: The current state of E-S-QUAL.
Total Quality Management & Business Excellence, 23(11-12), 1363-1378.

186.

Yep, J., & Shulman, J. (2014). Analyzing the library’s Twitter network using NodeXL to visualize impact.
College & Research Libraries News, 75(4), 177-186.

187.

Yoo, B., & Donthu, N. (2001). Developing a scale to measure the perceived quality of an Internet shopping
site (SITEQUAL). Quarterly Journal of Electronic Commerce, 2(1), 31-47.

188.

Yu, L., Hong, Q., Gu, S., & Wang, Y. (2008). An epistemological critique of gap theory based library
assessment: The case of SERVQUAL. Journal of Documentation, 64(4), 511-551.

189.

Zada, V. V., Abbasi, S., Barazesh, F., & Abdi, R. F. (2012). E-service websites quality measurement through a
revised E-S-QUAL. AWERProcedia Information Technology and Computer Science, 1, 1569-1574.

190.

Zehir, C., Sehitoglu, Y., Narcikara, E., & Zehir, S. (2014). E-S-Quality, perceived value and loyalty intentions
relationships in Internet retailers. Procedia – Social and Behavioral Sciences, 150, 1071-1079.

191.

Zeithaml, V. A., Berry, L. L., & Parasuraman, A. (1996). The behavioral consequences of service quality. The
Journal of Marketing, 60(2), 31-46.

192.

Zeithaml, V. A., Parasuraman, A., & Malhotra, A. (2000). A conceptual framework for understanding eservice quality: Implications for future research and managerial practice. MSI Working Paper, No. 00-115,
Cambridge, MA: Marketing Science Institute.

193.

Zeithaml, V. A., Parasuraman, A., & Malhotra, A. (2002). Service quality delivery through web sites: A
critical review of extant knowledge. Journal of the Academy of Marketing Science, 30(4), 362-375.

116

APPENDIX A: FOCUS GROUP INTERVIEW PROTOCOL

Do I have your permission to record this interview?
[If “Yes” from all participants, turn on recorder]
My name is Haemin Kim and I am a doctoral student at the College of Computing & Informatics at Drexel
University. I’m conducting a research study evaluating the service quality of academic libraries’ social
media. The purpose of the study is to explore the applicability of an instrument to assess service quality in a
library social media setting. “Service quality” indicates an overall impression based on customers’
judgment about a service’s overall excellence or superiority resulting from a comparison of expectations of
excellence with perceptions of performance (Parasuraman et al., 1988).
I will ask you to complete a questionnaire by yourself. Then, I will engage all of you in a discussion to seek
your opinions about the survey statements. The complete session should take about one hour and thirty
minutes.
Participation in this survey is voluntary. Once we begin the interview, you may decline to answer any of
the questions I ask and you may request that we end the interview at any time. There are no known risks for
participating in this study. The interviews will be transcribed and stored separately from any identifying
data concerning you (i.e. name, email address, telephone number, etc.). We will use all data anonymously,
making sure that you cannot be identified through your words.
If you have any questions regarding this survey, please contact me, at hk433@drexel.edu. You may also
contact my advisor, Dr. Danuta A. Nitecki, at dan44@drexel.edu . If you have any questions or concerns
regarding your rights as a research participant you should contact Human Research Protection at
HRPP@drexel.edu and 215-255-7857.

117

1.

Please complete the questionnaire, thinking critically for the discussion if any questions and
statements are unclear to you, have vague terms, and/or difficult to answer

2.

In section A,

3.

4.

a.

Do you agree that the questions are asking about your use of social media and library service?

b.

How difficult are the questions to answer?

c.

Which questions have vague terms?

In section B,
a.

Do these statements measure the service quality of the library’s Facebook and Twitter
services?

b.

Which statements are unclear for survey takers?

c.

If anything, what would you change or add?

In section C,
a.

What statements are unclear to answer?

b.

If anything, what would you change or add?

5.

In section D, what statements are unclear to answer?

6.

Do you have any additional comments or suggestions regarding how the survey statements can be
improved?

Are there any issues, factors or anything else which I did not ask, but which you believe I should have
asked to measure how academic libraries use social media?

118

APPENDIX B: THE MODIFIED ESQUAL INSTRUMENT

Introduction & Consent
Welcome!
Thank you for participating in this survey on The Service Quality of Libraries’ Twitter Use. Please
complete the following questions to the best of your ability. The survey consists of 41 questions across 4
sections. The survey typically takes up to 20 minutes to fully complete. This survey will be available on the
library Twitter from MM DD, 2014 to MM DD, 2014.
As a way to thank you for your participation in this survey, you will be offered the option of entering a
drawing to win a gift. The random drawing will take place on MM DD, 2014 and the winner will be
notified on the same day via email. In order to submit your email address to be entered into the drawing,
you will be redirected to a separate web form to complete upon submission of this survey.
Who can participate in this survey?
Users of _____ University Library's Twitter service can participate in this survey.
Both members and non-members of _____ University can participate in this survey if you have
used the Twitter service.
You will be asked to describe your experiences with your use of this library’s Twitter services.
Think about your use of the library Twitter service.
o

You would be aware of library postings on your wall.

o

You might read the postings or click the links for checking details.

o

You might visit the library Twitter page to see more information.

o

And others…

The purposes of a library’s Twitter service are as follows:
o

Communicate between library and users

o

Share information about library’s news, events, and seminars

o

Suggest useful information from other sources

o

Ask and answer questions

o

Encourage participation

o

And others…

119
You will evaluate the quality of library’s service using Twitter in terms of information usefulness,
entertainment, reliability, efficiency, system availability, and privacy.
This survey will ask you about your perceptions of the uses of Twitter as a library service source.
Your participation in this survey might not benefit you directly, but will contribute to building knowledge
about social media use in academic libraries, the understanding of users’ perceptions of the services, and
developing successful strategies to improve the experience of social media uses in academic libraries.
There are no known risks for participating in this study.
No information identifying personal responses will be collected in this survey. You are not required to
submit information that could disclose your identity. Information that discloses your identity will not be
released without your consent unless required by law. Participants will not be identified in any reports or
publications. Participants’ responses will only be used in the survey analysis, and will be treated
confidentially. Your anonymity and confidentiality will be respected. Any email address which you would
submit for the prize drawing will be used for only that purpose and will be discarded afterwards.
If you decide to stop participating at any point during the survey, you can contact the researcher to remove
your data. However, the research will be not able to exclude your data when the analysis is completed and
your data is published.
The _____ Libraries are partnering with Drexel University to conduct this research survey. If you have any
questions or concerns about this survey, please contact Haemin Kim hk433@drexel.edu
Taking part in this survey is entirely up to you. You have the right to refuse to participate in this survey. If
you decide to take part, you may leave the survey at any time without giving a reason and without any
negative impact. By completing the survey you are providing your consent to use the data for research
purposes.
Please indicate that you understand the information presented above, and consent to participate in this
survey.
 I understand and consent to participate in this survey.

120
Section A
Directions: Please answer the following questions.
A1. How did you learn about your library’s Twitter service?
_____ The link on the library’s websites
_____ Library postings shared by my friends
_____ Library postings shared by other departments in the university
_____ Library’s marketing
_____ Friends’ recommendation
_____ I didn’t know the service before I take this survey.
_____ Other:___________________________________

A2. How many times do you check your Twitter account? Please describe your answer below.
(i.e. Twice per day; Four times per week)
[

]

A3. How many times were you aware of the West Virginia University Library's Twitter postings over the
last week?
_____ times
A4. What kind of information interests you on the library’s Twitter?
[

]

A5. What kind of information does not interest you on the library’s Twitter?
[

]

Section B
Directions: Based on your experience as a user of your library’s Twitter service,
A Column: Please show the extent of your agreement that each statement describes the importance
of the service in an ideal setting.
B Column: Then indicate how well this library delivers the feature described by each statement (1
= Strongly Disagree, 5 = Strongly Agree).
If you think a statement is not applicable, please check N/A box.

121
"Library information" indicates any content posted and shared by a library on the Twitter service.

Services Features

B
This library delivers this
feature
Strongly Strongly
Strongly
N/A
Agree Disagree
Agree

A
Ideally, this feature is important
Strongly
Disagree

B1.
B2.
B3.
B4.
B5.
B6.
B7.
B8.
B9.
B10.
B11.
B12.
B13.
B14.
B15.
B16.
B17.
B18.
B19.

B20.

B21.
B22.

This service makes it easy to find
library information that I need.
This service makes it easy to get
library information.
It enables me to get to library
information quickly.
Library postings on Twitter are well
organized.
The site loads its pages fast.
Library information at the Twitter site
is simple to use.
The Twitter site enables me to get to
library information quickly.
The organization of posts on the
Twitter site works well for using
library information.
This service delivers timely
information.
It gives responses for my questions
within a suitable time frame.
It provides information that I expect in
a timely manner.
It provides information that I’d like to
receive.
It has information about what is going
on in the library.
It is truthful about the information it
provides.
It delivers accurate information.
The Twitter site is always available for
this service.
This Twitter site launches and runs
right away.
This Twitter site does not crash.
Pages at this site do not freeze after I
enter my comments.
The library does not share information
about my behavior (browsing pages,
clicking links, etc.) on its Twitter
account with others.
The library does not share my personal
information on Twitter with other
sites.
The Twitter site protects information
about my personal data.

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

122
B23. Identify any other expectations for excellent library’s Twitter services not mentioned in the above
statements. Please describe the features in each line, and indicate the extent to which it is important as well
as the library’s delivery (1 = Strongly Disagree, 5 = Strongly Agree).
Ideally, this feature is
important

Services Features

This library delivers this
feature

B23-a. [

]

1

2

3

4

5

1

2

3

4

5

B23-b. [

]

1

2

3

4

5

1

2

3

4

5

B23-c. [

]

1

2

3

4

5

1

2

3

4

5

Section C
Directions: Based on your experience as a user of the library’s Twitter service, please rate the service on
each of the following statements using a 10-point scale (1 = poor, 10 = excellent).

C1. Overall quality of the library's Twitter service.
Poor
1

2

3

4

5

6

7

N/A

8

Excellent
9
10

N/A

8

Excellent
9
10

N/A

8

Excellent
9
10

C2. The information and services available at this library’s Twitter.
Poor
1

2

3

4

5

6

7

C3. The overall convenience of using this service.
Poor
1

2

3

4

5

6

7

C4. The extent to which the library’s Twitter service gives you a feeling of being in control of what you
intend to do.
Poor
1

2

3

4

5

6

7

N/A

8

Excellent
9
10

N/A

8

Excellent
9
10

C5. The overall value you get from this service for your efforts.
Poor
1

2

3

4

5

6

7

123
Directions: Indicate your likelihood of engaging in each behavior on a 5-point scale (1 = very unlikely, 5 =
very likely).
How likely are you to…
Very
Unlikely

Statement
C6.
C7.
C8.
C9.
C10.

Say positive things about this service to other
people.
Recommend this service to someone who
seeks your advice.
Encourage friends and others to follow this
service.
Consider this service to be your first choice for
future library information.
Keep following this service in the coming
months.

Very
Likely

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

N/A

Section D
Directions: This is the final section. Please answer the following questions.
D1. Are you male or female? ______Male ______Female ______ Others
D2. In what year were you born? ______
D3. Are you a member of your university community? _____Yes _____No
D3 (if Yes) -a. How would you identify yourself as a member of your university community?
_____ Undergraduate student

_____ Master’s student

_____ Doctoral student

_____ Faculty

_____ Library staff

_____ Staff

_____ Other: __________
D3 (if No) -b. How would you identify yourself?
_____ Undergraduate student

_____ Master’s student

_____ Doctoral student

_____ Faculty

_____ Library staff

_____ University staff

_____ Other: __________

Thank you very much for completing the survey!
If you want, please leave your email address for a prize drawing. Email Address ____________________

124

