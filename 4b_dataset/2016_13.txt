©2016

Michael John Cole
ALL RIGHTS RESERVED

Representing the Search Session Process
By
Michael John Cole
A dissertation submitted to the
Graduate School-New Brunswick
Rutgers, The State University of New Jersey
In partial fulfillment of the requirements
For the degree of
Doctor of Philosophy
Graduate Program in Communication, Information and Library Studies
Written under the direction of
Nicholas J. Belkin
And approved by

New Brunswick, New Jersey

January 2016

ProQuest Number: 10095932

All rights reserved
INFORMATION TO ALL USERS
The quality of this reproduction is dependent upon the quality of the copy submitted.
In the unlikely event that the author did not send a complete manuscript
and there are missing pages, these will be noted. Also, if material had to be removed,
a note will indicate the deletion.

ProQuest 10095932
Published by ProQuest LLC (2016). Copyright of the Dissertation is held by the Author.
All rights reserved.
This work is protected against unauthorized copying under Title 17, United States Code
Microform Edition © ProQuest LLC.
ProQuest LLC.
789 East Eisenhower Parkway
P.O. Box 1346
Ann Arbor, MI 48106 - 1346

ABSTRACT OF THE DISSERTATION
Representing the Information Seeking Task Process
by MICHAEL JOHN COLE
Dissertation Director:
Nicholas J. Belkin
Information search is a cognitive process by which users work to satisfy an information
need or solve a problem. Information system performance could be improved if it had
a grounded belief about the user and their goal. To accomplish this, a system needs to
recognize and predict user states and aspects of their task, including search intentions.
High fidelity representation of user mental states during search would best capture the user
situation and presumably allow for better calculation of actions to take to help the user
achieve their task goal more quickly and/or with higher quality outcomes.
While there is research to infer user search context based on their activity with system,
such as page use and query submissions, there has been little work to model user search
session actions from a cognitive perspective. The dissertation addresses the development
of a framework and methodology to represent some aspects of user information processing
states in the information search process by exploiting eye movement patterns in the reading
information acquisition process. This work is situated within a user-centered and cognitive
model of the entire information seeking session.
Information processing states were learned for participants in a user study where tasks
were varied by complexity and other factors likely to influence search strategy and tactics.
The learned information processing states were examined as patterns of user search actions
to investigate whether task differences could be distinguished. In principle, such a model
could help to ground system inferences and predictions about the current search state of
the user and some aspects of their task goal, i.e. what they are trying to accomplish. The
results show tasks can be distinguished using information processing state patterns.
The results are discussed and potential for application in personalization and making
simulated users considered. Limitations and directions for research are identified.
ii

Acknowledgments
Portions of this dissertation have appeared in several publications:
Michael J. Cole, Jingjing Liu, Nicholas J. Belkin, Jingjing Liu, Chang Liu, Jun Zhang,
and Xiangmin Zhang, ”Usefulness as the criterion for evaluation of interactive information
retrieval”, in Proceedings of HCIR 2009 (Nov, 2009).
Michael J. Cole, Jacek Gwizdka, Ralf Bierig, Nicholas J. Belkin, Jingjing Liu, Chang
Liu, Jun Zhang, and Xiangmin Zhang ”Linking search tasks with low-level eye movement
patterns” in Proceedings of the 17th European Conference on Cognitive Ergonomics (Delf,
The Netherlands: Aug, 2010).
Michael J. Cole, ”Simulation of the IIR user: Beyond the automagic.”, in Azzopardi,
Leif and Järvelin, Kalervo and Kamps, Jaap and Smucker, Mark D., ed., Proceedings of
the SIGIR 2010 Workshop on the Simulation of Interaction: Automated Evaluation of
Interactive IR (Amsterdam: IR Publications, 2010).
Michael J. Cole, Xiangmin Zhang, Nicholas J. Belkin, Chang Liu, and Jacek Gwizdka
”Knowledge effects on document selection in search results pages”, in Proceedings of SIGIR
2011 (Beijing, China: ACM, 2011), pp. 1225-1226.
Michael J. Cole, Jacek Gwizdka, Chang Liu, Nicholas J. Belkin, Ralf Bierig, and Xiangmin Zhang, ”Task and user effects on reading patterns in information search”, Interacting
with Computers 23, 4 (2011), pp. 346-362.
Michael J. Cole, Jacek Gwizdka, Chang Liu, and Nicholas J. Belkin, ”Dynamic assessment of information acquisition effort during interactive search”, in Proceedings of the
American Society for Information Science and Technology Conference (2011) vol. 48, no. 1
(New Orleans, LA: ASIS&T, 2011), pp. 1-10.
Michael J. Cole, Jacek Gwizdka, and Nicholas J. Belkin, ”Physiological data as metadata”, in Bennet, Paul N. and El-Arini, Khalid and Joachims, Thorsten and Svore, Kysta,
ed., SIGIR 2011 Workshop on Enriching Information Retrieval (ENIR 2011) (Beijing: ACM,
2011).
Michael J. Cole, Chathra Hendahewa, Nicholas J. Belkin, and Chirag Shah ”Discrimination between tasks with user activity patterns during information search”, in Proceedings of
the 37th International ACM SIGIR Conference on Research & Development in Information
Retrieval (New York, NY, USA: ACM, 2014), pp. 567-576.
Michael J. Cole, Chathra Hendahewa, Nicholas J. Belkin, and Chirag Shah, ”User activity patterns during information search”, ACM Trans. Inf. Syst. 33, 1 (2015), pp. 1:1-1:39.
Work in the dissertation was supported by:
Google Faculty Research Award “Automatic Identification of Information Searcher Intentions During an Information Seeking Session” N.J. Belkin (PI) and C. Shah (Co-PI).
Google Faculty Research Award “Implicit Detection of Relevance Decisions and Affect
in Web Search” J. Gwizdka (PI).
IMLS grant LM-06-07-0105-07 “Personalization of Digital Library Experience”
N.J. Belkin (PI), J. Gwizdka (Co-PI), and X. Zhang (Co-PI).

iii

Table of Contents

Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

ii

Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

iii

List of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

xi

List of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

xii

1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1

1.1. The context and approach of the dissertation . . . . . . . . . . . . . . . . .

1

1.1.1. Units of human search interaction . . . . . . . . . . . . . . . . . . .

2

1.1.2. Search session structure and personalization . . . . . . . . . . . . . .

4

1.1.3. Task sessions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5

1.2. The problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7

1.2.1. Becoming user-centered . . . . . . . . . . . . . . . . . . . . . . . . .

8

1.2.2. Modeling the ISS as a way to personalize . . . . . . . . . . . . . . .

9

1.3. The knowledge gap addressed by the dissertation . . . . . . . . . . . . . . .

10

1.4. The study overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

10

1.5. Potential contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

11

1.6. Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

12

1.7. Overview of the dissertation . . . . . . . . . . . . . . . . . . . . . . . . . . .

14

2. Literature review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

15

2.1. Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

16

2.1.1. Motivating tasks have properties that affect search behaviors . . . .

17

iv

2.1.2. Task stages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

19

2.1.3. Task strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

20

2.1.4. Discussion and summary . . . . . . . . . . . . . . . . . . . . . . . . .

22

2.2. Intentions and Plans . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

25

2.2.1. Theory of intention . . . . . . . . . . . . . . . . . . . . . . . . . . . .

25

2.3. Neural correlates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

26

2.3.1. Neural correlates of intention . . . . . . . . . . . . . . . . . . . . . .

26

2.3.2. Neural correlates of attention allocation . . . . . . . . . . . . . . . .

26

2.3.3. Discussion and summary . . . . . . . . . . . . . . . . . . . . . . . . .

28

2.4. Intention and plans: Discussion and summary . . . . . . . . . . . . . . . . .

30

2.5. Plan recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

31

2.5.1. Plan recognition: Discussion and summary . . . . . . . . . . . . . .

33

2.6. Behaviors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

34

2.6.1. Information seeking actions and behaviors . . . . . . . . . . . . . . .

34

2.6.2. Summary and discussion . . . . . . . . . . . . . . . . . . . . . . . . .

36

2.6.2.1. To what degree are searching behaviors determined by the
user? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

37

2.6.2.2. Approaches to search behavior models . . . . . . . . . . . .

39

2.7. Cognitive architecture: decision-based approaches . . . . . . . . . . . . . . .

39

2.7.1. Serial processing and hierarchical cognitive expression . . . . . . . .

40

2.7.2. Decisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

42

2.7.3. Summary and discussion . . . . . . . . . . . . . . . . . . . . . . . . .

43

2.8. Eye movements and information processing . . . . . . . . . . . . . . . . . .

44

2.8.1. Eye movements and task

. . . . . . . . . . . . . . . . . . . . . . . .

44

2.8.1.1. Eye movements, tasks and attention allocation . . . . . . .

44

2.8.1.2. Cognitive processing states . . . . . . . . . . . . . . . . . .

45

2.8.2. Eye movements and information processing by reading . . . . . . . .

46

2.8.3. Discussion and summary . . . . . . . . . . . . . . . . . . . . . . . . .

48

v

2.9. Structure and coherence . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

49

2.9.1. Coherence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

51

2.9.2. Calculating coherence . . . . . . . . . . . . . . . . . . . . . . . . . .

52

2.9.3. Sequence Coherence . . . . . . . . . . . . . . . . . . . . . . . . . . .

52

2.9.4. Partial conditionalized exchangeability . . . . . . . . . . . . . . . . .

53

2.9.5. Conditional exchangeability . . . . . . . . . . . . . . . . . . . . . . .

54

2.9.6. Summary: Coherence and exchangeability . . . . . . . . . . . . . . .

56

2.10. Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

58

3. A model of the ISS process . . . . . . . . . . . . . . . . . . . . . . . . . . . .

60

3.1. A generative model of task sessions . . . . . . . . . . . . . . . . . . . . . . .

61

3.1.1. Overview of the development framework . . . . . . . . . . . . . . . .

62

3.1.2. Behaviors and coherence . . . . . . . . . . . . . . . . . . . . . . . . .

63

3.1.3. Focus on the information seeking episode . . . . . . . . . . . . . . .

64

3.1.4. The ISS is the highest level of observable motivating task . . . . . .

64

3.1.5. System predictions about a user’s task depend on seeing characteristic
behaviors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

65

3.1.6. Recognizing plans could allow for identifying the leading task . . . .

65

3.2. Task production model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

66

3.2.1. Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

66

3.2.2. Generation of search actions

. . . . . . . . . . . . . . . . . . . . . .

68

3.2.3. An example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

69

3.3. A model of the production of information seeking behaviors . . . . . . . . .

74

3.4. Theoretical framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

75

3.4.1. Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

79

3.5. A summary of the modeling proposal . . . . . . . . . . . . . . . . . . . . . .

80

3.5.1. Models of finite Markov chains . . . . . . . . . . . . . . . . . . . . .

81

3.6. Chapter review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

81

vi

4. Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

84

4.1. User study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

84

4.1.1. TCE purpose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

84

4.1.2. Study methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . .

85

4.1.2.1. Motivating task classification . . . . . . . . . . . . . . . . .

85

4.1.3. Study overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

86

4.1.4. Participants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

87

4.1.5. Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

87

4.1.6. Motivating tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

88

4.1.7. Study motivating tasks . . . . . . . . . . . . . . . . . . . . . . . . .

88

4.1.7.1. Background Information Collection (BIC): . . . . . . . . .

88

4.1.7.2. Copy Editing (CPE): . . . . . . . . . . . . . . . . . . . . .

89

4.1.7.3. Interview Preparation (INT): . . . . . . . . . . . . . . . . .

89

4.1.7.4. Advance Obituary (OBI): . . . . . . . . . . . . . . . . . . .

90

4.2. Motivating task classification . . . . . . . . . . . . . . . . . . . . . . . . . .

90

4.2.1. Distances between motivating tasks . . . . . . . . . . . . . . . . . .

91

4.2.2. Participant assessments of motivating task difficulty . . . . . . . . .

92

4.3. Representing the ISS as an interaction sequence . . . . . . . . . . . . . . . .

93

4.3.1. Using coherence . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

94

4.3.2. Task structure trees and coherence . . . . . . . . . . . . . . . . . . .

95

4.4. Task structure and attention allocation . . . . . . . . . . . . . . . . . . . . .

96

4.5. Representation of observations . . . . . . . . . . . . . . . . . . . . . . . . .

96

4.5.1. Eye movements and information processing states . . . . . . . . . .

97

4.6. Reading eye movements . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

99

4.6.1. Reading speed and reading length . . . . . . . . . . . . . . . . . . .

100

4.6.2. Cognitive effort measurements related to longer reading sequences .

101

4.6.3. Regressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

102

4.6.4. Perceptual space of reading . . . . . . . . . . . . . . . . . . . . . . .

102

vii

4.6.5. Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

104

4.7. Processing the eye movement observations . . . . . . . . . . . . . . . . . . .

105

4.7.1. The E-Z Reader reading model . . . . . . . . . . . . . . . . . . . . .

106

4.7.2. Grouping fixations into reading sequences . . . . . . . . . . . . . . .

108

4.8. Creating the information processing state space . . . . . . . . . . . . . . . .

109

4.8.1. Labeling information processing states . . . . . . . . . . . . . . . . .

111

4.8.2. Feature development . . . . . . . . . . . . . . . . . . . . . . . . . . .

112

4.8.2.1. Feature collinearity . . . . . . . . . . . . . . . . . . . . . .

114

4.8.3. Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

115

4.9. Learning task structure from segment coherence . . . . . . . . . . . . . . . .

118

4.9.1. The task session forest

. . . . . . . . . . . . . . . . . . . . . . . . .

118

4.9.2. Tree coherence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

119

4.9.3. ISS coherence and tree selection plan . . . . . . . . . . . . . . . . . .

120

4.9.4. Query segments and ISS subtask tree structure . . . . . . . . . . . .

120

4.9.5. Identifying ISS subtask structure using coherence n-grams . . . . . .

123

4.10. Research questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

124

4.11. Analysis procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

126

4.11.1. Data observations used in the analysis . . . . . . . . . . . . . . . . .

126

4.11.2. Eye fixation processing: segmenting the eye fixation logs . . . . . . .

127

4.11.3. Clustering the ISS observations . . . . . . . . . . . . . . . . . . . . .

129

4.11.4. Information processing state analysis . . . . . . . . . . . . . . . . . .

131

4.11.5. ISS state sequence processing . . . . . . . . . . . . . . . . . . . . . .

131

4.11.6. Tasks as transition matrices . . . . . . . . . . . . . . . . . . . . . . .

133

4.11.7. Tasks as N-gram distributions . . . . . . . . . . . . . . . . . . . . . .

134

4.12. Chapter summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

135

5. Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

137

5.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

137

5.2. Participant performance and behaviors by task . . . . . . . . . . . . . . . .

137

viii

5.3. Results relating to RQ1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

138

5.3.1. Can one distinguish states of actions based on the reading feature
vectors? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

139

5.3.2. Clustered Page types . . . . . . . . . . . . . . . . . . . . . . . . . . .

141

5.3.3. Clustering on query sequence feature vectors . . . . . . . . . . . . .

144

5.3.4. Feature importance in query segment clusters . . . . . . . . . . . . .

146

5.3.5. Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

148

5.4. With respect to RQ2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

148

5.4.1. Are there identifiable action sequences? . . . . . . . . . . . . . . . .

148

5.4.2. Coherence model . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

151

5.5. With respect to RQ3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

154

5.5.1. N-gram distributions . . . . . . . . . . . . . . . . . . . . . . . . . . .

154

5.5.2. A geometric interpretation of task difference distances . . . . . . . .

156

5.5.3. State transition matrices . . . . . . . . . . . . . . . . . . . . . . . . .

158

6. Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

161

6.1. Overall results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

161

6.1.1. RQ1 Can common sequences of user actions that take place in an ISS
be identified? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

162

6.1.2. RQ2 Do sequence action classes exist in information seeking episodes
or portions thereof that have regular pattern properties? . . . . . . .

165

6.1.3. RQ3 Are such sequences of behaviors with regular pattern properties
associated with motivating task type? . . . . . . . . . . . . . . . . .

167

6.2. Task difficulty . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

169

6.3. Eye movement patterns and information processing states . . . . . . . . . .

172

6.4. The information seeking process is not ergodic . . . . . . . . . . . . . . . .

173

7. Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

176

7.1. The goals of the dissertation . . . . . . . . . . . . . . . . . . . . . . . . . . .

176

7.1.1. To what degree have the goals been met? . . . . . . . . . . . . . . .

177

ix

7.2. Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

180

7.2.0.1. Development of an empirical approach to representing user
mental states associated with information processing . . . .

180

7.2.0.2. A representation of the search task process that is congenial
to computation . . . . . . . . . . . . . . . . . . . . . . . . .

181

7.2.0.3. A theoretical model of the search process grounded in theory
of human action . . . . . . . . . . . . . . . . . . . . . . . .

181

7.2.0.4. A theoretical model of the search process with explicit relationships to task constructs . . . . . . . . . . . . . . . . . .

182

7.2.0.5. Evidence for a cognitive-behavior link hypothesis . . . . . .

183

7.2.0.6. The search task process as an exchangeable process . . . .

183

7.3. Final thoughts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

183

References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

185

x

List of Tables

3.1. Notation for figure 3.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

78

4.1. Study task classification system (after Li 2009, modified). . . . . . . . . . .

86

4.2. TCE (Journalism study) motivating tasks . . . . . . . . . . . . . . . . . . .

90

4.3. TCE motivating task pair facet value differences} . . . . . . . . . . . . . . .

92

4.4. Page-level reading features for clustering . . . . . . . . . . . . . . . . . . . . .

113

4.5. Page cognitive effort modeling features

. . . . . . . . . . . . . . . . . . . .

116

5.1. Participant task-session behaviors . . . . . . . . . . . . . . . . . . . . . . . .

137

5.2. Cluster sizes (k-mediods) . . . . . . . . . . . . . . . . . . . . . . . . . . . .

141

5.3. Page feature clusters: Important features . . . . . . . . . . . . . . . . . . .

142

5.4. Query segment cluster classes. . . . . . . . . . . . . . . . . . . . . . . . . . .

145

5.5. Important features for information processing states: Query segment clusters
(labeled 1, ... 7 ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

147

5.6. Task N-gram subsequence frequencies: Task type similarities . . . . . . . .

155

5.7. Markov models of activity: Task transition matrix similarities . . . . . . . .

159

xi

List of Figures

2.1. Xie’s model of interactive information retrieval [217]. . . . . . . . . . . . . .

17

2.2. Neural attention system [56] (L,R= left, right hemisphere) . . . . . . . . . .

28

2.3. Belkin’s information behavior model . . . . . . . . . . . . . . . . . . . . . .

36

2.4. Minimal task structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

50

2.5. Growing a task instance . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

51

3.1. A model of task production . . . . . . . . . . . . . . . . . . . . . . . . . . .

74

3.2. Framework of spaces and relationships between user states and observables.

77

4.1. TCE study: Participant assessed motivating task difficulty (a)Pre-task (b)Posttask . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

93

4.2. Grouping eye fixations into reading sequences . . . . . . . . . . . . . . . . .

106

4.3. Part of a user session represented as a sequence of learned information processing states. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

111

4.4. A trivial search task where the observed state sequence is 5,2. . . . . . . . .

121

4.5. Tree 1 and Tree 2: Two possible structures for a ISS. The observed state
sequences are the leafs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

122

4.6. Simple task 3 with observed state sequences at the leafs. . . . . . . . . . . .

123

4.7. Representing an ISS: State sequences, state models and transition matrices

132

4.8. Aggregating ISS representations . . . . . . . . . . . . . . . . . . . . . . . . .

133

5.1. Page reading feature vectors model fit by cluster number. . . . . . . . . . .

140

5.2. Number of clusters for TCE query segments: Reading sequences including
page level feature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

145

5.3. Observed frequencies of state sequences (length 2,3,4) by task. . . . . . . .

150

5.4. GLM coherence model: ISS query segments in test collection.

154

xii

. . . . . . .

5.5. Task locations - Task facet space . . . . . . . . . . . . . . . . . . . . . . . .

156

5.6. Task locations: ISS information processing state sequence frequency space
(bi-grams) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

157

5.7. Task locations: ISS information processing state sequence frequency space
(Markov transition matrix similarity) . . . . . . . . . . . . . . . . . . . . . .

xiii

159

1

Chapter 1
Introduction

Information search is a cognitive process by which users work to satisfy an information
need or solve a problem. The information seeking process expresses the user’s evolving
search intentions and plans which drive the search. Information system performance could
be improved if the system could recognize or predict the user’s task or their information
seeking state.
Patterns of user actions may reveal essential properties of the information seeking process. This dissertation develops a user-centered model of the process of user interaction
with the system using observations of user interaction patterns. In principle, such a model
can explain or predict a user’s current state and some aspects of their task goal, i.e. what
they are trying to accomplish. The dissertation develops a methodology to learn some user
mental states, specifically information processing states, from eye movement patterns. A
user study is implementing the approach is presented and evaluated. The results show tasks
can be distinguished using information processing state patterns.

1.1

The context and approach of the dissertation

People engage information systems on an extended basis in order to gain information to
solve some problem or satisfy an information need. The purpose of information retrieval
(IR) systems is to support the user in that process. A high performance system will both
provide appropriate access to information collections and support user actions to optimize
the process [15]. A system might take many actions if it had a grounded belief about the user
and their goal. For example, it might alter query reformulation strategies; re-rank search

2

results; change the user interface; engage the user with suggestions, such as query suggestions, subtask suggestions, or propose an overall search strategy; offer situation-appropriate
resources, such as summaries of recent actions, automatic content saving, or note taking;
or even provide affective support to the user by giving them words of encouragement or
reminders of progress so far.
To improve such personalized support it is useful to be able to recognize or predict user
states and aspects of the user’s task. A specific problem is that these are cognitive conditions
and are not observable. Another challenge is to enable general applicability of a method
by avoiding use of the information content in the information objects encountered in a
particular session. Modeling the user’s observable actions during search to learn regularities
and relationships between behaviors, tasks, and user activities is an approach to the problem
that can avoid using the information object content and yet infer aspects of the user’s mental
states during an information search session.
This dissertation develops an empirical grounding for a user-centered system interaction
process model by connecting observable eye movement patterns with a user’s (mental)
information processing states. The model uses the inferred information processing states
to learn a representation of an observed information seeking session from the sequence of
user actions in the session. That representation is explored to find relationships with search
tasks and their structure.

1.1.1

Units of human search interaction

Constructs relating to information search are both abstract and complex. There is no
uniform nomenclature covering searching and search tasks. To facilitate the introductory
discussion and motivation, it is helpful to define briefly several key terms and constructs as
used in this dissertation.
There is great variability in common and scholarly language of the units of human
interaction during information search. This dissertation works from the user’s perspective
of interaction.
 intention - A user mental state. This is a primitive of human experience.

3

 plan - A user mental state relating to a general process or procedure. A search plan

might be to examine only news stories from quality newspapers.
 event - An event is a most basic unit of interaction. It is a two-step cognitive inter-

action with an information object. The first step is recognition of the object followed
by an evaluation of the object’s usefulness.
 action - A user act that affects the world. For the dissertation, this is a search action

on the interface to the information search system. An example is to make and issue
a query. Another is to select and read a document in a ranked list of links.
 behavior - A behavior can be thought of as frequently used or habitual actions. It can

be a single action or a sequence of actions. An example of an information behavior is
to open the top ten links in a search results list without following out links in a given
selected document.
Tasks are a central concern of information science. Information search tasks are often in
service of a problem the user would like to address. The dissertation distinguishes several
aspects of tasks in the context of information search:
 motivating task - This is the problem or need that causes a user to initiate a search

for information.
 information search session - A sequence of information seeking activities that relate

to a motivating task.
 subtask - A task with a goal that supports a higher level task goal.
 information search task structure - An information search session consists of a sequence

of one or more subtasks each of which may have ordered sequences of subtasks. Consider a search to answer a specific question where the user finds they must understand
the definition of a technical term to evaluate the search results. This situation spawns
a child subtask and so creates a unit of task session structure.
 task session segments - Logical sequences of information search activities. For example,

4

the actions from issuing a query to issuing the next query (or ending the search session)
are a query segment.
 action sequence coherence - This is a sequence of user actions that ’hang together’.

That is, they have some common reason for having been generated by the user. Actions
taken after a search query might be coherent because they are related to the same
search intention.

1.1.2

Search session structure and personalization

When a user searches for information they usually have a general plan in mind they believe
will allow them to achieve their overall task goal. For nontrivial searches this general plan
is implemented in pieces. This is especially true in complex or otherwise difficult searches,
where the general plan may change as knowledge is gained during the search. Each plan
piece embodies a local plan to accomplish something that the user believes will be useful to
the process of achieving the overall task goal.
The existence of a general plan for the search session and its implementation in a sequence of local plans can induce structure over user search action sequences. Such structures
can be hypothesized to emerge from the user’s directed activity to achieve their overall goal.
Structure units might be observed in relationships between local groupings of user behaviors.
One possible way for a system to personalize a user’s search experience is to detect
structure in user interactions that are indicative of user plans, expectations, or their task.
Such a system could act to provide local personalization support. It might also be able
to handle the difficult problem of whole-session personalization if it could detect in-session
user interaction structures that revealed aspects of the user’s overall task goals. Examining
user interaction patterns holds promise for general applicability because it is not tied to the
properties of the information content, which is specific to a task search session.
The main idea of the dissertation is to model the user search process as action sequences
and investigate the potential to detect user search states or aspects of their task. This work
involves both search activity recognition and representation, and user plan recognition. An
effective model could be useful for practical personalization of information systems because

5

it addresses the problem of recognizing when a person is in a state as well as what they
might be trying to accomplish. A system could continuously formulate beliefs about the
user and their task and take personalization actions when a confidence threshold is reached.
Detection of user action sequence and behavior structures in an information search
session might support whole-session as well as in-session personalization. For example, the
search session structures or their constituents:
 may have regular time-series relationships,
 may have regular relationships to characteristics of the user’s motivating task,
 may have regular relationships to characteristics of the person’s local subtask.

One way to investigate the existence of such relationships is to model the production of user
actions and expressions of behaviors in the information search session process.
A successful predictive model could be useful in several ways. If there are temporal
relationships in the structure, in-session observation of structure in a user’s behavior might
be used to predict future actions. Motivating task characteristics might also be inferred from
observations of structure. Sequences of user behaviors might provide a context measurement
of the immediate activity. Information search session structure characteristics may have
strong association with kinds of tasks or user characteristics, and allow for a wide range of
personalization moves by the system.

1.1.3

Task sessions

Task is a basic unit of human experience involving a sequence of attention allocations along
with other goal-directed activities. Task is a complex construct and it is used variably in
the information science literature. This variable use generally fails to distinguish distinct
components of the person’s overall information task search session. It is useful to distinguish
three units that describe aspects of the search task construct:
 the motivating task,
 the activity of searching for information that is useful to meet the task goal, and

6

 the immediate search tasks used sequentially by the user to make progress in the task

session.
The dissertation will use task to denote the motivating task. The motivating task has a goal
of addressing the need that compels a user to engage a search for information. It is rooted
in the problem or recognized gap in knowledge that causes the user to seek information to
address their need [13, 15].
The main observable part of the user’s information finding activity will be called the
information seeking session (ISS). An ISS covers all of the information seeking activity. An
ISS may include actions that do not involve information search systems, for example asking
a colleague. The information seeking goal of the ISS is fixed and guided by the motivating
task.
The practical work of the dissertation considers ISS instances that consist of extended
interactions with information systems. This is the typical object for investigation in interactive information retrieval (IIR) studies.
The activity within a suitably complex ISS includes some number of immediate search
tasks. These are often expressed in queries to a search engine. Search tasks reflect both
user intentions and user beliefs about how to effect progress towards the ISS goal. Task
activity units within the ISS are subtasks. Subtasks often have hierarchical relationships to
other ISS subtasks.
The structure of a user’s task interaction that is visible to an information system is the
ISS structure. The ISS structure emerges from the relationship of the successive search
intents that drive the subtasks.
The dissertation goal is to model the ISS as a sequence of subtasks by describing a
process that creates those subtask actions. The model proposes a relationship between user
search behaviors and the process by which subtasks are implemented. The main implementation focus of the dissertation is to make a cognitively-centered representation of an ISS
to allow computation of session models using machine learning. With future research and
development, the ultimate goal is to make a predictive model that can be used to recover
the structure of an ISS from observation of the sequence of user interactions with the system

7

without prior knowledge of the motivating task or consideration of the page content.

1.2

The problem

The key issue for information retrieval (IR) systems is to overcome the performance plateau
that has been encountered in the effectiveness of support for information seeking. Information seeking is irreducibly interactive, yet the design of IR systems has traditionally focused
on responding to a single query. Systems do not take account of user or their motivating
task, or of the properties of the continuing interaction sustained by the user as they move
through the ISS. Taking account of the user’s situation has potential for significant improvement in the performance of systems [209, 193]. Motivating task characteristics, user
properties, and interaction properties provide a rich source of new features that can be
exploited in system design to better support the user’s activities and to help users achieve
the motivating task goal that caused them to seek information.
Information science research has long recognized that much information seeking behavior
in IR systems involves a series of actions, often including multiple queries and exploration
of links provided in search results. These information seeking sessions consist of sequences
of intentions and can be associated with distinct types of interactions with the information
system and the information objects made available by the system [10, 9, 16]. Examples of
user intentions include learning a domain vocabulary, learning the types of contents available
in a database, exploring for a consensus or variety of opinions on some topic, and so on.
System search performance could be improved if a system could learn user intentions. Yuan
and Belkin [223] provide an example of supporting different intentions during an ISS.
The IR community recognizes the need to support complex searches and to move beyond
the traditional paradigm of single query responses. An active line of research concerns the
problem of how to support a search session as a whole and within the search session subtasks.
Examples include formal modeling of search sessions [75], an adaptive system that modifies
a relevance model by observing the user [7], and dynamic user interest models derived from
user actions within and over query sequences [206]. Workshops on future directions for
IIR research at Dagstuhl [76], NII Shonan (2012), and Lorne (SWIRL) [3] have identified

8

integration of motivating task and ISS information into context models as a key challenge
for effective personalization of systems. The TREC Session Track was an effort to build
systems that take account of context and user actions to improve search performance for
the next query in a session.

1.2.1

Becoming user-centered

To understand interaction, it is essential to take account of the user. Information seeking
is a process situated in an information environment encountered by users. Users control
the process: they initiate it, make choices at every step, and decide when to terminate the
session. A system and environment can be more or less cooperative, or confining, in this
endeavor.
It follows that to improve system performance one needs to learn properties of the
user [14], such as their level of knowledge or aspects of their cognitive capabilities, and
or characteristics of their motivating task and current subtask. It is therefore useful to
be able to recognize and model user activities as behaviors during information seeking to
understand when user actions should be supported and how best to provide that support.
The task construct has a central role in information seeking and a long research history.
A motivating task is the occasion that initiates the process, informs the interaction steps
and the relationship to other steps, and sets criteria for a successful process endpoint.
Descriptive models of episodes of human information search [11, 112, 12] provide a starting
point for understanding some observable features of these processes. However, these models
do not provide detailed representations suitable for developing user interaction models or
able to be specifically exploited in system design. In contrast, Belkin’s ISS-dialog model
[16] and Pirolli’s information foraging model [150] provide approaches to making cognitive
representation models.
Motivating task characteristics influence the information seeking activity of users in
an ISS including search behaviors [131, 201, 199, 200, 74]. Relationships exist between
motivating task complexity, information use during the ISS, and the search strategies and
information sources used during search [35, 198, 34, 118]. Motivating task properties affect

9

ISS page use behaviors, including reading eye movement patterns [48]. There is evidence
personalized systems that exploit the user’s motivating task characteristics can improve the
effectiveness of search and information retrieval [103, 104, 207, 119].

1.2.2

Modeling the ISS as a way to personalize

It seems reasonable that a system with knowledge of the user’s motivating tasks could
apply more effective personalization strategies. Since the motivating task shapes the ISS,
a research direction to improve system performance is to model the ISS with the goal of
predicting when and why users take search actions.
User actions in an ISS can be used to identify segmentation and other forms of structure.
Search interaction is often highly conditionalized and the result or state of one interaction
influences the next. It is also clear that there are long-range effects on interactions. For
example, a series of interactions may be carried out as part of a strategy or a tactic. Past
queries in an ISS often affect the next query [158, 211, 119]. Query reformulation sequences
may indicate user knowledge of the domain and motivating task.
Users apply search strategies and tactics within an ISS and those strategies and tactics
have been described [10] and classification schemes have been developed [17, 221]. Acting
on these strategies and tactics generates sequences of actions that are associated with one
another. It is plausible such action sequences are distinguishable from action sequences produced when a user adopts a different strategy or tactic. These generative effects of strategies
and tactics provide one way to segment an ISS and thereby generate task structure.
The existence of long-range effects makes the entire ISS the natural unit of practical
analysis for the problem. A motivating task type or property might bias user search behavior
selection and so affect the local and global ISS structure. If the smaller units of analysis, such
as local action sequences, are considered alone, they may not be able to give a complete
account of the session. This is a basic challenge for ’bottom up’ approaches to context
prediction [206, 83].

10

1.3

The knowledge gap addressed by the dissertation

When a user searches for information they usually have a general plan in mind they believe
will allow them to achieve their overall task goal. For nontrivial searches, and especially
in complex or otherwise difficult searches, this general plan is implemented in pieces. Each
piece embodies a local plan to accomplish something that the user believes will be useful to
the process of achieving the overall task goal.
The absence of a model and methodology to represent a user’s local and global plans in an
ISS is a key problem for understanding and supporting users. A plan-based perspective can
provide a user-centered understanding of how to support a user’s actions in an appropriate
search context. The sequences of action taken to implement a plan can be evidence for a
specific search intention. This connects the problem of learning an ISS plan structure with
learning its intentional structure.
To learn plan structure it is necessary to segment the ISS into distinct units and then
to characterize relationships between those units. Two specific knowledge gaps exist. First,
there is no computationally-congenial user-centered representation of the process that produces the ISS plan structure. Second, a technique to calculate the ISS intentional structure
from observations of user actions is not available. These are gaps in the knowledge of search
interaction personalization techniques. The first problem is addressed in detail in the dissertation along with exploration of techniques to achieve the problem of calculating intentional
structure.

1.4

The study overview

To address the basic problem of learning the ISS plan structure, the dissertation will first
develop a general model of the search process based on the theory of human action [8]. The
theory of human action is the received view of how humans formulate and take action in
the world. The central component is intention with a commitment to a plan to implement
the intention. The elements and process of this abstract theory have physical analogs in
brain organization and neural processing [144, 146, 214].
The dissertation develops an empirically-grounded technique to observe user mental

11

states based on reading eye movement patterns. Eye movements are cognitively controlled
[72] and indicate information processing states [161, 166]. The eye movement data set used
in the dissertation is from a user study of journalism students (N=32) performing realistic
journalism tasks designed to affect search behaviors.
The eye tracking logs are used to fashion a rich representation of a user’s textual information processing states during their web search. Each page interaction is represented with
a vector of eye movement features. These page vectors are clustered and these clusters are
taken as indicative of information processing states. Each page interaction by the user in
a session is labeled as belonging to one of the learned information processing states. This
provides a cognitively-grounded representation of the search process.

1.5

Potential contribution

The motivating intuition of the dissertation work is that the observed structure of an ISS
emerges from switching in user search plans as they work towards their motivating task
goal. Changes in search intention are hypothesized to be the cause of the search plan
changes. ISS structure can be represented as relationships between temporally contiguous
subsequences within the complete sequence of ISS actions taken by a user. Such relationships may reveal essential motivating task characteristics. Collections of ISS instances may
cluster and provide direct evidence for classes of motivating tasks by displaying distinctive
structural properties. Representation of ISS structure may allow calculation of measurable
features, for example complexity, recursiveness, or repeated action segments, that might be
detectable during sessions and so enable inference about the user’s motivating task.
To achieve this vision, a cognitively-centered representation of the ISS is developed in
the dissertation. This representation is tested to demonstrate it can recover at least some
aspects of ISS structure and distinguish between tasks. This is a foundational step on a
road towards a robust practical model that can detect tasks and user states from structural
interaction properties.
Modeling user behavior in terms of ISS structure may allow an information system to
predict aspects of the user’s local and global plans during a session. Such an understanding

12

can underwrite meaningful system response to support user actions and so improve system
effectiveness. A system could anticipate user moves, and interact differently in ways that
align its support for the user to the user’s information search plan in the immediate search
situation. Insight into a user’s global plan could enable a system to enhance the user’s
capacity to address the overall motivating task goal, for example by offering memory aids
or even guiding the user.
This level of support would be richer than that available now, where systems rely primarily on similarity to query content to enable access to collection documents. Concrete
examples of such support might be automatic structured note taking or providing organizational aids for a user in an aspectual search task. A system might re-rank or filter search
results, e.g. re-ordering search results more appropriately for the task, reformulate queries,
e.g. via query expansion reflecting some logic in expressed query sequences. If the system
detected an evolving ISS structure indicative of user exploration for different aspects of a
complex topic, it could re-rank search results to optimize diversity. Many other possibilities
exist.
Successful development of the model will also provide a research tool to investigate dynamic aspects of user search interaction and make richer user models. This could contribute
to making simulations of interaction. Simulated interaction systems would be a new tool and
open new methodologies for research into interaction and evaluation of information system
performance. The SWIRL 2012 workshop identifies development of suitable abstractions
of interaction in complex information environments as the key challenge for this nascent
research area [3].

1.6

Summary

For complex search, the effectiveness of IR system support might be substantially improved
by taking account of the user and their motivating task as a search session unfolds. One
way to address the problem is to better understand the process generating user actions to
make ISS and user models that may allow prediction of a user’s goals.
Motivating task properties affect user search behaviors in various ways. There is a

13

consensus in the IR research community that integration of motivating task and user session
actions to make context models is a key challenge for effective personalization of systems.
The dissertation addresses part of that problem by modeling the ISS process, making a
suitable cognitively-centered representation of an ISS, and relating it to the motivating task
type.
This addresses a gap in knowledge of search interaction personalization techniques relating to learning the plan structure of an ISS. In particular, it lays a foundation for a
computational model of the process by which an ISS’s plan structure is produced. The
search process model is based on the theory of human action, which couples search intention with an implementation plan. This provides a generative model of user search actions.
Each ISS is produced by the user adopting a sequence of search intentions and associated
plans. Plan switching generates a tree-like structure in the ISS as it unfolds. The root is the
overarching motivating task plan that guides the information seeking episode with subtasks
as child nodes, some of which may have child nodes, and so on. An intuitive tree for an ISS
is one where the leafs in the tree are query segments. Each query segment is the output of
the search process model of a search intention and implementation plan.
The dissertation develops a technique to infer user (mental) states during an ISS from
sequences of reading eye movements on pages during the session interaction. These are
taken to reflect user information processing states and employed to label user page actions.
The main potential contribution of the dissertation is to provide a cognitively-grounded
and user-centered model of the search process. This provides a user-centered framework
that is congenial to computation and also, in principle, generalizable.
Several important simplifications are made to demonstrate a practical implementation
of these ideas. These inevitably make for limitations that need to be addressed in future
work. Some relate to practical limitations for application of the models in operational
environments.

14

1.7

Overview of the dissertation

After a literature review concentrating on information motivating tasks and their features,
and then ISS search behaviors the dissertation explores information interactions from the
perspective of theory of human action. Then a theoretical framework is presented. It
conceptualizes a motivating task-driven ISS as the sequence of subtask units that result
from the succession of implemented search intention plans. There is also some exploration
of search action sequence coherence.
Then the dissertation turns to a methodology to make a cognitively-centered representation of the ISS as a sequence of user information processing states. First, observations of
user actions are classified. Those labeled observations are analyzed for evidence of search
behaviors by comparing collections of ISS instances by their motivating task. The collections of ISS structure observations are grouped by motivating task type and analyzed for
similarity to test the hypothesis that motivating task types have characteristic collections
or sequences of search behaviors in the ISSs they produce.
Finally, the limitations of the approach and methodologies are discussed along with
directions for future research. Potential applications in personalization of information search
systems are explored. The possible contributions of the work to full session search system
evaluation from the perspective of making synthetic users for automated search interactions
is also discussed.

15

Chapter 2
Literature review

Recognition of the lack of global rational decision-making is at the heart of modern information science [13]. In nontrivial searches, a user achieves their information seeking task
goal in a dynamic process that implements one or more search intentions in a general plan
of extended interaction with an information environment. This activity is manifested as
a sequence of interactions. Representation of search activities and associated information
behaviors as experienced by users carrying out their tasks should therefore focus on interaction. A plausible way to improve search system performance is to support the user’s actions
and that pushes interactive search processes and tasks to center stage [15, 75, 117, 208, 132]
The literature review plan is to first look at the task construct and its classification into
subtypes and to review specific task properties or structures have been identified in previous
research. Review of the task construct will distinguish identified structural properties of
tasks, specifically levels of task, from general and descriptive work on information seeking
tasks. The research work on task inevitably addresses observations of user task behaviors.
The next section explores production of meaningful human actions from the intention and
planning perspective. The understanding of a behavior as a coherent sequence of actions
is then explored. The review then turns to a brief discussion of cognitive architecture with
a focus on serial attention and the production of coherent sequences of actions arranged
in hierarchical structures. Finally, some methodologies to classify actions and sequences of
actions are reviewed. Their suitability to the problem of learning ISS structure as sequences
of behaviors is discussed.

16

2.1

Tasks

A fundamental characteristic of the concept of task in information science is that there are
levels of tasks. That is, in an ISS a user experiences and carries out subtasks that are related
to other subtasks in a roughly hierarchical relationship. The motivating task is the cause
for an instance of information seeking behavior expressed in an ISS and in the subtasks
within the ISS. The motivating task itself is likely related to other tasks for the user, and
may be part of an extended task expressed over multiple ISS instances. A motivating task
may also be related to a general life activity, for example a “quest”, or a hobby.
Xie [217, 218] has developed a planned-situational interactive IR model based on the idea
that plans are formulated in situations. Plans and situations co-determine user strategies,
selection criteria, and other actions in the course of the ISS process. Xie’s work is in the
spirit of the situated action approach[191] and interactionist approaches to planning. She
emphasizes the importance of the leading goal of the task in motivating the search for
information. Four levels of user goals are identified:
1. the long-term goal
2. the leading search goal
3. the current search goal
4. the interaction intention
Users engage systems to solve their problems, not to simply get information [15]. So, there
is a often a categorical distinction between the long-term goal of the user and the main
information goal.
Xie characterizes work tasks in three dimensions (stages, time frame, nature) and search
tasks in three dimensions as well (type, domain, origination). In her model the higher level
goal/tasks determine the lower level goal/tasks. The low level goal/tasks are involved in
interactions with the physical systems and are responsible for the observable user actions
in information seeking.
Xie’s model provides an account of information seeking strategies as intentions combined
with information acquisition tactics, and access to information resources. The intended

17

activity and the situation combine to determine which information strategies are actually
employed. One virtue of this model is the capacity to explain the dynamics of information
strategy use over a task episode.
Figure 2.1: Xie’s model of interactive information retrieval [217].

[205] provide a model of problem solving in a web environment. It is based on an
empirical study and identifies several levels of interaction between the user, the interface,
and the information space (Web). This model is user-centered and focused on the factors
that cause user actions. The interface is seen as facilitating user actions in the information
space, while the user is directly affected by their situation, cognitive behavior and affective
state. In the general situation of problem solving, user cognitive factors play a critical role
because they are central to the analysis of the problem. It is this analysis that drives the
strategy of the user in seeking information.

2.1.1

Motivating tasks have properties that affect search behaviors

Previous research has examined numerous task types with respect to their effects on user
behaviors. Task types have been classified along various dimensions, standards, and definitions, including different levels of task complexity and difficulty, closed vs. open-ended
tasks, known-item vs. subject search tasks, to name a few. Search behaviors have included

18

task completion time, number of web sources used and web pages viewed, and use of web
browser functions. Generally, this work has focused on the concept of task as motivating
task rather than the task(s) that are implemented. A consequence is that the task properties identified in this research cannot be easily mapped onto the construct of the observable
task and task levels that might be discerned in user activities.
One motivating task property that has been found to affect user search behavior is task
complexity. A series of studies by [35, 198, 34] have looked at relationships between task
complexity, information use, and the search strategies and information sources used during
search. The operational definition of task complexity focused on a person’s uncertainty
at the beginning of the process given their knowledge about the task. Representation of
this uncertainty involves the degree to which they knew the task outcome, details of the
process to use, or the information requirements to satisfy the task. Task complexity was
investigated by looking at outcomes as task complexity increased and was found to be related
to information type and information source selection during the task. Users utilized more
information sources, processed more information objects, and engaged in more problem
solving as complexity increased. For more complex tasks it was more difficult to predict the
types of information needed. There was also a tendency to apply authority-based strategies
for information selection.
[118] reported that objective task complexity, defined as the number of discrete requirements to achieve the task goal, affected many aspects of searching behavior, including the
number of search systems consulted, portals visited, web result pages and items viewed,
query reformulations, and time to complete the task. [198] has developed a model integrating task complexity and user actions.
Other aspects of motivating tasks have been considered in relation to behavior effects.
[131] found users spent more time and made more moves in performing tasks where there
were many related facts (an “open-ended task”) vs. tasks where only one correct answer
exists (a “closed task”). [157] found that users tended to adopt more structured and analytic
search patterns when engaging in specific tasks than in general tasks and that general tasks
caused more use of browsing features in systems. [108] investigated factual, interpretive,
and exploratory tasks, and found significant correlations between task type and the number

19

of pages saved, the ratio of viewed to saved pages. [81] studied fact-finding tasks of varying
complexity and found that subjective measures of task difficulty were correlated with the
number of web pages visited, web page dwell time, deviation from the optimal path, and
the linearity of the navigation path. The objective task complexity was found to affect
the relative importance of those factors as predictors of the subjective assessment of task
difficulty. [102] compared web browser-based interactions with four types of tasks: factfinding, information gathering, browsing, and transactions. They found the information
gathering task had the greatest time on task, number of viewed pages, and most intense use
of browser functions, and concluded it had the highest implied complexity. [118] studied
behavior effects using intellectual vs. decision/solution tasks. Intellectual tasks resulted in
greater use of retrieval systems, higher numbers of viewed pages, and longer queries. She
also found users tended to provide higher self-assessments of task success for intellectual
tasks.

2.1.2

Task stages

[112] reports results of a longitudinal study of high school and college students carrying out
a complex information seeking task (writing a term paper) over several months. She found
the students progressed through distinct stages both in information seeking with similar
changes in their affective state. The stages, each with an associated goal, were:
Initiation The task concerns recognition of an information need and was associated with
uncertainty and apprehension.
Selection This concerns the need to focus on a particular topic or adopt an overall search
strategy. Identification of the requirements from the information need are guides.
Exploration Users concentrate on extending understanding within the topic area or developing a sense of the topic. Specific activities, like query formulation depend on
the ability to express their information need. Conflicting information may become
available and this leads to confusion, and doubt, both about the information and the
user’s ability to complete their goal.

20

Formulation An understandable perspective on the topic emerges to makes sense of the
information gathered thus far. Perhaps the user formulates a working hypothesis and
seeks to test it. At this point a user will feel more confident about their eventual
success. Kuhlthau noted that many users never achieved this stage.
Collection With a clear perspective in hand, a user can engage in a directed and focused
search for additional information. Searches and queries are designed to refine and
support the focus. Users are in a better position to judge relevance.
Presentation Users are able to determine they have completed the process because the new
information is redundant or of little additional importance. Relief and satisfaction, or
disappointment, are characteristic feelings, reflecting the overall success of the search
process.
[201] provide confirmation of Kuhlthau’s stages in a study of 11 students working on their
master’s thesis. [199] showed task stage had a specific impact on decisions to change search
tactics, query reformulation strategies, the types of information selected and their evaluation criteria. Building on this work, [200] has developed a theory of information retrieval
processes that is task-centered and identifies how tasks interact with the various task phases.
In this theory the action of performing the task drives the search process, selection of tactics,
and so on.

2.1.3

Task strategies

[17] classify search strategies on the web into four behavioral dimensions.
 patterns of query formulation and reformulation – for example short queries and ses-

sions with minimal reformulations)
 patterns of use of operators and search modifiers,
 patterns of results viewing, and
 patterns of search topics.

21

Strategies could be characterized especially by recognition of minimization of one or more
of these behavior patterns. [40] relied on a think aloud protocol to classify search strategies
into patterns of search, emphasizing navigational paths taken.
These usage patterns exist in other settings, e.g. OPAC search. [70] provide a conceptual
framework for on line bibliographic retrieval and identify key elements affecting search
as setting, user, request, database, search system, searcher, searcher process and search
outcome. They provide facets for each of these elements and suggest relationships between
them.
Xie [217] reported on a user study that looked at the relation between informationseeking goals and user behaviors to understand the motivations in information seeking
strategy selection. A detailed description of their types of behaviors was used to identify
a hierarchy of user goals. The interactive intention of the user was abstracted from the
behavior analysis and connected with information seeking strategies. In [219] another user
study, conducted in both a corporate and academic setting, task constraints and other
properties of the situation in which the motivating task arises were used to identify task
dimensions. Work tasks and search tasks are distinguished. The nature of the task for the
user, for example whether the task is familiar or unusual, the time frame for completion, and
task stages are identified as explicit dimensions for work tasks. For search tasks, dimensions
include the task originator (self or other), aspects of the search goal, for example whether
it is a known item search, and whether the task goal was open to being revised. This work
shows that users will switch goals and make other intention changes in ways that are related
to particular task dimensions.
[10] distinguishes search strategies from tactics at the level of ’moves’ by a user. Moves
are specific actions that advance a search and can be contrasted with a collection of intentions, a plan for a search, resources, and methods to be used. In all, 29 tactics are
identified with four levels of search tactics and search moves. First there are specific actions
applied during the search process monitoring. Tactics include file structure tactics, search
formulation term tactics, and idea tactics. Idea tactics focus on ways to gain new ideas
and including thinking, brainstorming, meditation. There are also pattern breaking tactics
and topic management tactics, such as broadening or narrowing the topic or changing it

22

altogether. Search moves include query formulation and query reformulation.
[220] provides a review and taxonomy of search strategies and tactics. She makes a
distinction between operational vs. conceptual moves. Search strategies are combinations
of moves and tactics. They can be concept oriented and classified, for example as Bates’s
’building block’, ’pearl-growing’, ’successive fractions’, and several others. The main search
strategies are classified as browsing and directed search plan strategies. Directed strategies
can be active, where users make a decision before a move to focus on a particular facet,
concept, use a system feature etc. Directed strategies can also be reactive to the results
of a move. For example a user can decide to change focus, reformulate a query, or recover
from some type of error (for example a user mistake or system interface issue). Included in
search strategies are various types of strategies for query reformulation, search biases, such as
search engine preferences or formulation styles (e.g. use of advanced search or meta-search
engines), and tactics like link-following. These aspects of search strategy are intimately
associated with problem solving strategies that are individualistic and even idiosyncratic.

2.1.4

Discussion and summary

One general characteristic of much of the work on task properties and behavior effects has
been a focus on the motivating task. Generally, the research has had a strong descriptive
flavor. Task as motivating task is a mental construct and can be contrasted with the concept
of task as it is carried out. A critical distinction is that in the latter case, task is potentially
available for study as an observable object. For example, one can study task instances such
as search sessions.
Motivating tasks set the stage for task instance execution and motivating task characteristics can affect search behaviors. However, describing user actions under some motivating
task is not the same as relating the observed properties to the specific task and subtasks
executed by a user. As such, the extensive body of work examining task from the perspective of motivating task does not connect cleanly to session level tasks as an object of study.
In fact, the task construct addressed in much of the research is not a clearly defined entity.
When one considers task level, it is common for the descriptions to conflate multiple

23

levels of tasks. The task references slide between talking about task at various levels, task
as an object that motivates actions, and task as a process, for example behaviors that seem
to be repeated. One consequence is that the task properties identified in this work are not
easily mapped to identity conditions that can be represented in useful forms. This is true
even for observations that may relate to task structure properties, such as complexity. The
’complexity’ of the motivating task may be variably defined, but in any case it is quite
different from the complexity of the task as it is carried out by the user.
Ellis and Marchionini both describe information seeking behaviors, but can be distinguished somewhat in that Ellis isolates behaviors and describes them independently of one
another, while Marchionini is explicitly concerned to identify the behaviors as part of a
process. For both Ellis and Marchionini the behaviors identified in their studies are described at quite a high level and there is no guidance to associate them with particular
actions of the user and specifically with contiguous sequences of actions by the user. For
example, “define and understand the problem” [133] is itself likely to consist of a number
of activities and processes and can be a complicated task in its own right. In both cases,
however, the behaviors identified are intuitive and mix task phase-dependent behaviors, for
example, starting a task and reaching its conclusion, with behavioral processes that seem
to be more generic. For example, some of the described behaviors, e.g. “formulate a query”,
“examine results”, “extract information”, might be employed multiple times and recursively
within an information seeking episode. To summarize, the task processes in information
seeking described by Ellis and Marchionini are at a descriptive level and cannot be reduced
to a computation representation because identifying features of these behaviors that can be
isolated in observations are not addressed. Further, even though they are empirical, these
behavior categories depend on human assessment and are therefore top-down because their
recognition depends on a human’s theoretical understanding of the behaviors involved in
carrying out a task.
Kuhlthau’s task stages are a classification of stages of experience in search rather than
a description of a sequence of stages for any particular search. Importantly for the present
work, Kuhlthau studied users who engaged multiple search sessions over an extended period.
While the initiation and presentation stages correspond to ordered units they do not always

24

relate to sequences within a task session. A user may not reach the presentation stage as
defined if their search was not comprehensive, or there are other criteria for recognizing the
leading goal has been satisfied. Even the initial recognition of information need is not always
at the beginning of a session (although it seems a session must in some sense always begin
because an information need is recognized), it may occur within a session as new questions
emerge, etc. Although Kuhlthau’s work does not show task structure of individual sessions
it does provide a user perspective on information seeking. It establishes the process as
a temporal and constructive activity with affective as well as cognitive components that
depend on the phase of progress in task activity. Task stage can be seen to affect physical
action, the user’s affective state, and the appropriateness of subtasks.
The history of scholarly work shows tasks have structure. A leading task can be thought
of as being carried out through a composition of other tasks. The leading goal has changing
characteristics over time and its subtasks are generally presumed to have a hierarchical
relationship. Much of the empirical work, e.g. that by Kuhlthau, Ellis, and Vakkari is
based on behaviors of user groups and has led to the development of summative behavioral
models. Unfortunately, in this work the understanding of task as motivating task makes
it hard to connect their description of task properties to definable properties in observable
instances of tasks carried out at the session level and below. Xie’s work to model task and
search strategies provides an explicitly cognitive approach while incorporating empirical
observations. It is a high level model of a production system. Xie’s approach does not
focus on a description of the process of task implementation or address how one might learn
behaviors from observation of user actions made while executing hierarchical strategies.
It is interesting that the ideas of task and goal are often conflated in the literature
with little effort to distinguish the two and examine how they impact ideas of behaviors or
strategies. This is despite a seemingly clear distinction: a goal is the endpoint at which a
task is judged completed if it is not abandoned before that point. It seems reasonable to
characterize a task as some basic procedure, which may have multiple satisfactions, that
needs to be carried out to advance to the endpoint. A completed (successful) task achieves
the goal. This distinction between task and goal seems compatible with Xie’s model and
with the other work on tasks, behaviors, and strategies.

25

Given that tasks are a cause of user behaviors of interest to interactive information
retrieval (IIR), it follows that differences in the properties of tasks may result in different
behaviors. A wide range of empirical work based on selection of intuitively distinct task
types shows there are indeed differences in behavior. This supports the idea there are tasks
of different types and that it is plausible there are characteristic patterns of behaviors.
Other empirical work identifies a number of task properties and correlations with observable
behaviors.

2.2

Intentions and Plans

This work is firmly situated in a cognitive view of information behavior [14, 15, 91]. User
behaviors are meaningful because they advance the user towards their leading goal. For
information system design it is desirable that a predictive model for task structure as sequences of behaviors be able to explain the meaning of observed search behaviors. This
section reviews work on behaviors, including information seeking behaviors, in the context
of the intention-based theory of human action. The literature establishes a causal linkage
between observable actions and user mental states that underwrite the meaningfulness and
coherence of action sequences.

2.2.1

Theory of intention

Brentano [27] argued intentions were irreducible mental states. Bratman [24] develops a
causal account of intention. A ’simple view’ of intention is defined: An action can be
intentional only if it is caused by a specific mental state held by the agent. Bratman argues
the simple view covers cases where intention is associated with thinking, but that it is false
in general because of automatic actions where one does not think. Others have defended
the simple view as a general analysis of intention1
This causal view of intention has become the received view and is embedded in the work
on human action theory. Audi [8] provides a survey. It has also become a basis for work in
agents and planning [25, 43].
1

See [62] and [137]for the current state of play.

26

There are two types of intention. One can intend to do something in the future and one
can intend to do something now. Future intentions are fundamentally distinguished from a
current intention [180, 59, 24]. Future intentions constrain any current intention. A current
intention is one that might be acted upon.

2.3
2.3.1

Neural correlates
Neural correlates of intention

There is evidence for the existence of intention as a neural activity correlate of the mental
state and for its relation to human action, at least in the form of motor actions. Okuda
et al. [144] identify the ventrolateral prefrontal cortex (VLPFC) (Broadmann Area 47)
as being specifically activated when subjects held intentions of future activities. Petrides
[149] describes the VLPFC as a control area for subject plans and intentions that interacts
with other brain regions that provide access to information appropriate for future behaviors.
Dove et al. [64] showed there are increases in VLPFC activity when presented visual stimuli
under intention conditions.
Intentions related to task-specific representations activate the medial and lateral prefrontal cortex [85]. Paus [146] found that the anterior cingulate cortex (ACC) activation is
consistent with the degree of intentional effort, motivation and conscious volition [214] to
undertake a task.
Intentions associated with motor activities to carry out movement actions have been
found to activate the premotor and parietal cortex [61]. Lau et al. [114] were able to
show that stimulation of the premotor cortex delays the subject’s perception of their motor
intentions, suggesting a causal pathway between the formation of intention and execution
as an action in the world.

2.3.2

Neural correlates of attention allocation

One way to represent tasks, including search tasks, is in terms of the sequence of attention
allocation. The human attention allocation process is complex and is a vibrant research
area with many open questions. The work centers on orienting and allocation of visual

27

attention, but there is also considerable work on audio and other modalities.
There is a basic distinction in attention allocation processes between attention shifts
that are caused by some external stimulus, for example a flash of light, and attention shifts
that are goal-driven [216]. An information seeking task is goal-directed and so is the process
of attention allocation.
There are differences in brain activation for goal-directed attention allocation vs. reactive
attention shifts. Stimulus-driven attention shifts involve the midbrain superior colliculus,
while goal-driven attention shifts involve higher level cortical areas, especially in the parietal
region [159, 160, 134].
Eye movement and fixations are a primary means of orienting attention. The frontal
eye field (FEF) The FEF is located in the frontal cortex (Broadmann area 8) and contains
a mapping of retinal coordinates. It communicates with the muscles that control the eye
and has been shown to be responsible for voluntary eye movement.
Corbetta et al. [55, 56] have proposed that the dorsal component of the frontoparietal
network has primary responsibility for voluntary goal-driven attention shifts (Fig 2.2) with
the intraparietal sulcus (IPS) coordinating with the FEF. Coordinated IPS-FEF activity
results in programming a latent saccade in the FEF. There are questions about the timing
and order of the activation [88, 39] and one study showed the order of activation of the IPS
and FEF depends on whether the attention shifts are stimulus- or goal-driven [33].

28

Figure 2.2: Neural attention system [56] (L,R= left, right hemisphere)

2.3.3

Discussion and summary

It is desirable to have a complete causal account in a cognitively-centered description of the
information seeking process. The identification of neural correlates of intention, planning,
and attention allocation via eye fixations provide a physical grounding for the cognitive
processes at the center of the ISS process models. This grounding underwrites empirical
observations of search behaviors, such as selection of web links in coordinated motor movements and in reading eye movements that are used to learn the ISS process models. It
also shows how the theoretical foundation for the ISS process model, i.e. application of the
theory of human action, can be grounded in real world causal mechanisms.

29

Empirical research in information science makes the implicit assumption that userdirected actions are observed directly, as in user studies, or indirectly, as in search log
analysis. Attention allocation is essential to the process of user-directed actions. User study
measurements usually observe decision-making or attention. Limitations on this type of research often acknowledge attention-related assumptions, for example whether page dwell
time represents actual user attention.
Attention allocation details may be essential to gain a complete understanding of information search interactions. For example, a complete web page interaction description
would take account of both the user’s reaction to the page and then its processing by the
user. This is a point to collate results from human factors research and HCI of lower level
cognitive processes, e.g. cueing effects etc., with the higher cognitive level processes that
concern IIR. Computational attention models may address this interface for integration of
these research streams. Lee et al. [115] provide a review of the current knowledge in the
area and implications for making computational attention models.
The neural details of intention, planning, and attention are matters for cognitive science
and not information science. For the dissertation, it is important that a concrete outline
exists of the causal mechanism by which a user allocates attention during search tasks. In
the context of search interactions, user attention allocation takes two forms. One involves
the user’s volition to perform the motivating task and the ISS. The other concerns user
reaction to external stimulus in the information environment, for example a picture in a
page or an interface element.
IIR research is mostly interested in goal-directed attention. The mechanisms of goaldriven attention allocation are under cognitive control. For example, they direct the eyes
in the process of servicing motivating task and subtask goals. Attention allocation is a
natural element to fashion an ISS representation. It connects directly with observations
of eye movements. This provides a rich basis to investigate user-driven search, and it is
gratifying to have an end-to-end outline of how this process works.
Pure user-driven search is an idealization. Study designs to investigate realistic information search such that it yields only user-driven search is exceedingly difficult. Attention

30

shifts due to exogenous stimuli can be expected. Still, in a carefully designed study, assumption of an idealized search task may be warranted. That is, analysis can proceed
under the assumption that only the user’s motivating search task goals drive the allocation
of attention and stimulus-driven attention allocation events have de minimus influence.
A couple of conclusions seen reasonable from the foregoing. First, it seems plausible a
general representation of an ISS can be based on patterns of attention allocation. Second,
eye movements reveal that attention allocation. This grounds the use of eye fixation patterns and shows why measurements of the patterns are sufficiently rich to model essential
properties of the ISS construct, including structure.
Finally, the neural mechanisms of attention allocation connect to work in vision and
reading research that show eye movement in tasks is cognitively controlled. Attention
research also shows how higher level cognitive functions control the saccade programming.
It happens that eyes remain fixated until the meaning of the word has been acquired. Taken
together, they provide a causal mechanism that supports the claim that sequences of eye
fixation measurements can be correlated with sequences of semantic information processing
states. Eye movement and information acquisition through reading is reviewed later in this
chapter.

2.4

Intention and plans: Discussion and summary

A large body of work in several disciplines has converged to show it is reasonable to attribute
intentions to users based on observations of their actions. Precognitive research provides
evidence for causal linkage between actions and intentions and co-location of intention and
planning activity in the brain. So intentions and planning have neural correlates that cause
physical actions. It is intuitively plausible that intentions have causal effects on other
cognitive processes such as information acquisition and processing.
Search behaviors are intentional in a way that is consistent with the simple view: A user
has recognized a need/task and has made a decision to carry out a task. It seems clear the
decision to do something is guided by the overarching task/goal, whether in the sense of
the motivating task or as a sub-task in the ISS. To say one is attending to the task/goal is

31

to say one contemplates intentions from a limited list which are germane to the goal before
selecting one (or none) to implement.
Consider the search interaction as seen by the system in the user-centered framework.
An effective system has a goal of learning the user’s intent and plan. To solve this problem
the system might learn from expressions of interest in queries, actions on semantic representations of information objects, or inferring properties of the user’s motivating task or
ISS subtask.
The system can take the user to be an intelligent agent. The problem of learning a
user plan from interaction observations can be transformed to learning the agent program
that produced the interaction sequence. This move from identifying the (equivalent) Turing
machine running on another computer to inferring the plan of the other machine is not so
artificial. Human intention itself provides the basis for causing and so explaining actions.
One is not aware of the act of committing to an intention. It is not unreasonable to see
commitment to a (computational) plan as intention. The human plan to carry out the
intention is not observationally distinguishable from an agent executing a plan.
The distinction between present and future intentions is germane to ISS level production
mechanisms in hierarchical task models. Future intentions, which may be seen as the
intention to carry out a motivating task or subtask in the future, constrain the current ISS
subtask and immediate intention. Current intentions cause actions. Future task intentions
do not. Future task intentions can influence actions via the current intention selection
process (which is unknown and outside of the scope of the dissertation work). This parallels
the relationship between long-term motivating task goals and episodic and ISS goals and
subtasks, such as in the task model proposed by [217].

2.5

Plan recognition

A plan is a design for a sequence of partially-ordered actions to achieve a goal. The action
sequences can be arranged in a hierarchical ordering from a root goal to sub-goals. The
tree leaves are unit goals. Actions can be observable, or partially-observable. Partiallyobservable actions are ones that may reflect changes in hidden states, for example mental

32

states, that influence or cause observable actions.
Plan recognition is the process by which sequences of partially-ordered actions are processed to identify a plan. Plan recognition can be distinguished from recognizing intent.
Intent recognition is the process of identifying only the root goal or intent without making
hypotheses about the plans or implementation of the plans. In contrast, plan recognition
involves production of a hypothesis of the root goal.
The need to recognize the intent of intelligent agents arose with a turn towards interaction in artificial intelligence in the early 1980’s. The problem was framed as one of
attributing intent to an agent by recognizing the program the agent is currently running. In
this analysis, there is no difference between intent coupled with commitment to a plan and
selection of a program to meet a purpose and its execution [43, 151, 36, 101]. Identification
of current plans and agent intention in artificial intelligence has developed with an explicit
attempt to mimic human intention and meaning production in dialogues.
The plan recognition problem was first characterized by [179]. They conducted experiments where humans were presented a sequence of actions and asked to predict the next
action and describe the observed behavior to that point. Subject responses attributed goals
to the unknown agent and there was evidence the subjects inferred a plan for the unknown
agent. Cohen [44] provided additional evidence that humans use plan recognition in formulating hypotheses about future observable actions.
[44] distinguish between cases where the person intends their actions to be observed
and cases where they do not know they are being observed or are indifferent. They refer to
observations of normal actions, including cases of ambivalence about observation, as keyhole
plan recognition.
Plan recognition has a rich literature and has been an important thread in AI work on
agents and also in NLP at the level of discourse processing. A central idea is that agent
plan recognition can be accomplished by observing its actions. Identification of a plan
that uniquely explains the observed actions is taken to justify an inference the agent is
executing that plan. In this view there is no distinction between intention and committing
to execute a plan [43], so one is justified in attributing intention. [36] provides a review of

33

plan recognition techniques that have been used. She also identifies issues that make plan
recognition hard for implementation in real world system. A variety of techniques have
been applied including Bayesian networks, context-free grammar parsing (probabilistic and
non-probabilistic), graph covering algorithms, and marker passing. Marker passing involves
discovery of paths in a concept map understood as schemas of object, properties, and
relationships. The problem is to pick the optimal schema to explain the observations [38].

2.5.1

Plan recognition: Discussion and summary

Plan recognition was developed in the context of artificially intelligent agents acting autonomously and interacting with other agents. The work in the area explicitly looked to
the problem of understanding observable expressions of human intention, interactions, and
meaning production.
Most plan recognition systems have a set of plans as an input. These plans can have
any representation, but are often hierarchical to allow for tractable reasoning. For example
they might be trees resolving to distinct alternative root goals.
In an ISS representation the leafs can be taken to be query action sequences. Such
query action sequences constitute (nearly all) the direct observables of user information
search interactions with the search system. The observable actions taken to satisfy the leaf
subtask goals might be used to infer the parent nodes and perhaps even the motivating task
goal. One might generate the universe of tree structures that can describe the arrangements
of the leaf query action sequences. Each tree would then represent a distinct composition
of plans that describes the ISS. In the spirit of some plan recognition algorithms, the forest
could be an input to a model that predicts the tree that best describes the searcher’s overall
ISS plan that achieved the motivating task goal.
Charniak and McDermott [41] point out that plan recognition is a case of abductive
reasoning with the goal of reasoning to the best explanation of the root goals from the
user’s observable actions. For the current application, the goal is to find the structure that
best ’explains’ the user actions. Later, it will be suggested that action sequences produced
by a single intent are coherent because they generated by a single plan that implements

34

the intention. A measurement of sequence coherence can provide an abduction rule for
reasoning to the most likely representation of the task session structure.

2.6
2.6.1

Behaviors
Information seeking actions and behaviors

Several types of information behaviors have already been explored in connection with the review of work on the relationship between task properties and information behaviors. Types
of behaviors include, information seeking strategies and tactics [16], learning behaviors, situational assessment behaviors [51], various ’moves’ [10], and possibly navigational behaviors.
These types of behavior are likely to be expressed by distinctive sequences of actions, at
least some of which are observable.
At a more basic level, [69] and [133] provide process views of information seeking that
have distinctive types of behaviors. They suggest there is a general evolution of the use of
these behaviors in the course of a search. Ellis identifies six behaviors:
 Starting: Identifying relevant sources of interest
 Chaining: Following and connecting new leads found in an initial source
 Browsing: Scanning contents of identified sources for subject affinity
 Differentiating: Filtering and assessing sources for usefulness
 Monitoring: Keeping abreast of developments in a given subject area
 Extracting: Systematically working through a given source for material of interest.

Marchionini and Mauer provide a more elaborate collection of behaviors as sub-processes
in their study of electronic information seeking. The sub-processes are taken to develop in
parallel, even as they are implemented in serial activities.
 Recognize and accept an information problem
 Define and understand the problem

35

 Choose a search system
 Formulate a query
 Execute search
 Examine results
 Extract information
 Reflect/iterate/stop

Belkin [14] has proposed a model of session level information seeking as a sequence of types
of interaction with a system and information objects. The nexus of this model is a usercentered interaction with the system. These types of interactions are canonical information
seeking strategies (ISS) that are employed by the user conditioned on the task properties and
the point in the task solution process. A system can provide more or less support for these
strategies, making them easier or more difficult to implement in service of the task goal.
There are several dimensions in which a system can affect user strategy implementation, for
example in the effort required to manipulate an interface or the representation of the content
of the information objects made available. These dimensions of ISS support are orthogonal
to the system response to a query by providing access to information objects. From the
perspective of task success, an optimal composition of ISS use through the information
session depends on the task structure. Although the foundations of the model are analytical,
there is empirical support for these behaviors [52].

36

Figure 2.3: Belkin’s information behavior model

2.6.2

Summary and discussion

Ellis and Marchionini both describe information seeking behaviors, but can be distinguished
somewhat. It is important to remember that in those works task is identified with the
motivating task and the analysis of behaviors they provide is in the context of the motivating
task. I have argued above that motivating task is an ill-defined construct. Importantly, these
papers focus on the generalization of behaviors and do not address behaviors as behaviors
within specific session tasks. Consequently, mapping these behaviors to task levels in a task
session is not guaranteed.
Ellis isolated behaviors and describes them independently of one another. In contrast,
Marchionini identifies the behaviors as part of a process. For both Ellis and Marchionini the
behaviors identified in their studies are described a quite a high level and are not claimed
to be unit processes. For example, Marchionini’s “define and understand the problem” [133]
is itself likely to consist of a number of activities and processes. It can be a complicated
task in its own right. Still, the behaviors identified by Ellis and Marchionini are intuitive.
They often mix task phase-dependent behaviors with behavioral processes. For example,
both include starting a task and reaching its conclusion. They also identify behavioral
processes that are more generic and might be employed multiple times and recursively

37

within an information seeking episode, e.g. “formulate a query”, “examine results”, “extract
information”.
The task processes in information seeking described by Ellis and Marchionini are descriptive. They cannot be easily reduced to a computational representation. A specific
shortcoming is the failure to identify distinctive behavior features that might be automatically isolated in observations. Their behavior categories depend on human assessment
and in this sense are empirically-derived. This also means their behavior categories are
top-down constructs because behavior category recognition depends on a human’s abstract
understanding of the use of behaviors to carry out a task.

2.6.2.1

To what degree are searching behaviors determined by the user?

Not all user actions are behaviors expressive of searching intent. In general, the actions
taken during interaction with an information system reflect both the user’s search intent
and the need to manipulate the information system to accomplish searching behaviors. Boiling down behavior sequence observations to the ’essential’ expression of search intention and
plans is desirable but hard to do. Even distinguishing the ’true’ search behaviors from mere
information system manipulation is not easy in practice. Low level actions to manipulate a
menu or click on a link seem not to be expressive of search behaviors, although there is no
question that selection of a particular link to follow or final action of manipulating a menu
are expressive of searching actions. Operationalization of search behavior observations usually conflates the two, presumably with the assumption that system manipulation activity
is a kind of uniformly distributed noise in the observations of the user’s expression of search
behaviors.
Navigational behaviors, such as traversing pages already seen by use of a back button
in a browser, are also problematic. At least some navigational moves are contingent on the
system and do not express a user’s search navigation intent. For example, some moves may
be required before the user can express their desired search behavior such as forcing a return
to a search results page to enter a query. Actions imposed by the system are superfluous
to the user’s search activity because they are not expressions of the user’s search intention
and immediate search plan.

38

Better search session representations might be achieved if ’real search actions’ could
be distinguished from the contingent effects of the system and interface. In practice such
distinctions are difficult. One problem is that even during superfluous moves, a user may
be engaged cognitively with the content. A navigational move imposed by the system can
cause a user to review previously seen information. This is an opportunity for reassessment.
A second look, possibly armed with newly gained knowledge, might cause recognition of a
new choice or otherwise process a page differently.
The goal of user search session representation is to make better information systems.
An idealized cognitive representation may not be of much practical use in that some system
interface will always exist. There is a great deal of room to make interfaces that recognize
how a user is searching and their current knowledge state with respect to the task goal.
One interesting example is presented by [109]. They describe a system that performs clever
dynamic manipulation of SERP content to rerank or change previously seen results. When
a user returns to a SERP, the SERP has been changed. A user intending to retrace steps
to follow a different link path actually experiences a new search interaction along the way.
Navigation actions allowed in the system design, including user options, can shape information seeking behavior expressions. A user might choose to filtering results, e.g. by
breadcrumb labels or pivoting, rather than search to reach a page. Such behaviors may have
task type dependencies, but most likely reflect individual differences [192]. Personalization
support can involve these types of navigational options. A high performance personalization system might guide the user based on superior prediction of the user’s motivating task
goals and search intentions. In some sense, offering complete freedom to the user in options
and taking firm intervention to guide the user are poles for personalization. Effective system design will increasingly involve a blend of the two with a trend towards greater use of
predictive analytics. The dissertation work is concerned with such behavioral analytics.
To learn search session models for behavioral analytics one must use real data from users
working with systems. These systems inevitably impose some actions that corrupt the pure
expression of search intent. Some observed user action sequences are in that sense system
dependent but disentangling those effects is not attempted in the dissertation work.

39

2.6.2.2

Approaches to search behavior models

User actions result from complex cognitive processes applied in differing conditions of task
goals, information system properties, and presented information objects. It is reasonable to
think behavior representations that account for sequence variability will have connections
to the complexity of the sequences from which the behaviors are derived. This suggests one
can hypothesize relationships between statistics of user action sequence complexity, tasks,
and information search behaviors.
Belkin’s ISS model is an attractive frame for making a computational model of the
information search process. First, the constructed ISS classes are analytic and based on
dimensions of information behavior. As such, the classes provide comprehensive coverage
of the information behavior space as it pertains to task. This allows a comprehensive
framework for the formulation of effective hypotheses about task interactions.
The model also structures task sessions as a sequence of distinct information seeking
behaviors. This parallels some ideas of dialog structure. One can see analogies between
local intentions (search intention vs. conversational intention), referents (topical usefulness
or relevance vs. entity reference), and a generative process, for example as proposed by
Grosz and Sidner [77].
[130] apply graph-based analysis to action sequences to learn behavior representations.
The main problem is to handle observation sequence differences for instances of the same
behavior. Some variation in a given behavior is natural when actions are produced by
complex processes in different contexts. This is the situation for information search, so
sequence analysis cast into graph analytics that allow for probabilistic transitions between
action states is an approach that might achieve the dissertation goals.

2.7

Cognitive architecture: decision-based approaches

Behavioral decision-making is complex and involves multiple levels of cognitive processing
[138]. One push in the cognitive description of information science has come in cognitive
architecture-based decision approaches, notably [150]. Much of the other work on tasks

40

and task structure in information science has been top-down and or grounded in empirical observations of presumed behaviors [35, 12, 200, 112, 74, 211, 104]. As a result, the
empirical work on task structure in information science has been based on classifying the
types of activities without identification of specific observables. This is fatal for making
representations an information system might manipulate to infer a user’s task-related state
or predict their future actions and needs.
Until recently, there has been remarkably little data-driven work representing tasks as
sequences of actions in forms suitable for computational modeling. The few examples of
previous research on task actions have used state machines to understand the history of
influence (’memory’) on the latest action. The questions investigated revolve around the
average length of coherent action sequences regarding some task constituent. Early work
by [158] looked at OPAC use and found the actions in service of a specific search goal could
be best fitted to a second-order Markov model. [211] examined query and reformulation
actions and fitted them to a third-order Markov model. The importance of learning computational models of user actions during search interactions as a task session plays out has
been recognized [76, 3]. The TREC Session track started in 2011 and has focused on using
observations of task sessions to improve retrieval effectiveness for the next query in the task
session. Recent work on query sequence context and modeling includes [206, 7, 120].

2.7.1

Serial processing and hierarchical cognitive expression

It is apparent that human apprehension of the world is a series of thoughts. This has been a
foundation of philosophy since the time of Aristotle. Higher level cognitive interaction with
the world involves overt and covert serial attention [216]. Research into visual information
gathering for text, task synchronization, and object search in scenes, provides good evidence
for serial attention models [99, 87, 176, 171].
This sequential apprehension by the user is the input to a task process. It follows
that serial attention is an assumption of cognitive architectures. Cognitive architectures
with substantial development to date involve a person assuming sequences of states in a
computation-like model.

41

This general picture of serial interaction with the world and assumption of a sequence
of mental states matches human experience of information search. For example, a user
can be thought of as progressing through a sequence of knowledge states before arriving
at a point where they are able to meet the need expressed in the motivating task. An
important consequence of serial attention models of human experience and planning is that
sequences of actions can, in principle, be placed into a correspondence with sequences of
mental states that comprise the user’s experience of the process. Hierarchical structures of
activities emerge naturally within such serial attention processes under executive control
switching to different immediate goals.
[184] recalls early discussions in 1954 with Allen Newell about simulation of human
thinking and notes that the impetus was to move away from economic models based on
global rationality because they were at clear odds with the fact of human behavior. They
felt such models could not, therefore, be foundational for human decision making. Simon
instead focused on search and sought “to describe thinking processes as search processes” (p.
4). He began with the assumption “the search [is] a serial, one-thing-at-a-time exploration”
(p. 4). [203] claims the commitment to serial processing was a working hypothesis and
Simon did not argue against parallel cognitive architectures. Nonetheless, all of the cognitive architectures with substantial development to date assume an input of serial attention
objects.
ACT-R [4, 5] is a symbolic representationalist cognitive architecture. It is the leading,
perhaps even received, cognitive architecture at present. Although the model is quite specific
in some places, it has been designed in the spirit of a general framework in which component
systems can be elaborated. The framework has two components: semantic knowledge that
embodies declarative knowledge and a production system to handle procedural knowledge.
The basic idea is that actions are productions that are generated through the proceduralization of declarative knowledge. These productions are available in some stored state and
then ’fired’. Each production has a strength (weight) associated with it and this weight is
usually associated with the probability of triggering the production in a circumstance.
The weight of a production is adjusted or ’learnt’ by virtue of the probability it will
achieve a successful outcome. In particular, the weight (as the probability the production

42

is ’fired’) is the log of the probability the production will succeed. Generally the model is
based on the idea that declarative knowledge is acquired and then made into a procedural
form that is available for use.
SOAR [178] is a symbolic representational model based directly on Newell’s conceptualization of cognition [143]. It uses search in a state space as the central mechanism and
attempts to handle learning as a process of symbolic learning, and so explanation. Other
cognitive architectures are EPIC [107, 106] and CoLiDes [110]. The focus and level of the
architectures differ and in some cases higher level cognitive processes may run in parallel to
determine a cognitive state [110], but they all assume inputs where the person engages the
world in a serial attention process with some attention switching mechanism.

2.7.2

Decisions

An intention coupled with a plan and commitment to action implies a terminal condition
exists. That is, to have an intention and carry out a plan is also to commit to termination
of the sequence under some recognizable conditions. An obvious condition is a recognition
the goal of the intention has been achieved. However, it is also clear every commitment
to an intention-plan must also include recognition of situations where the plan has failed
or the intention is no longer useful in some sense. When a plan is implemented under
some intention, at least four stopping conditions exist: (1) achieving the goal (2) failure
to achieve the goal, (3) recognition the goal is no longer relevant to achieving some other,
perhaps supervenient, goal, (4) idiosyncratic termination (for example, some other intention
asserts itself – “Time to teach!”). [28] and [29] develop an application of Young’s ACT-R
rational decision theory [222] that allows for abandoning a current plan. [28] also shows an
information evaluation situation, link interdependence on a web page, that appears to be a
counterexample to Pirolli’s information foraging theory. [30] provide evidence that users rely
on previously acquired knowledge in a task to guide selection on search results pages and
do not carry out satisfising over the available options on the current page. This is another
counterexample to information foraging and provides support for decision dependency on
sequences of interactions. [75] provides a utilitarian account of the search process by focusing
on the decision of the user to terminate a search intention sequence.

43

2.7.3

Summary and discussion

There is a rich collection of cognitive architectures that implement intention-plan approaches
to action. The details of cognitive architecture are not important for the dissertation work
because the project of inferring plans to correlate behaviors with task structure elements
does not depend upon the causal mechanism by which the actions have been produced.
An important open question is how action sequences are terminated. Each case of
intention-plan execution has a decision as the terminal of the generated action sequence.
This decision may be positive or negative. Observed sequence terminals are aligned with
decisions in nearly all cases. Exceptions will occur when other intentions override the current
plan or because of exogenous or idiosyncratic reasons.
One can proceed under the assumption that all immediate subtasks are effective in
addressing their search intention, even if they are not successful. Of course, this assumption
cannot be correct. User failure to achieve the task goal, especially in subtasks to the leading
task, is an important issue for personalization. When a user fails it may be because the
system did not deliver something it could have. On the other hand, the failure to achieve
the task goal may be baked into the user’s information seeking process. They may, for
example, simply not know much about the topic. Recognizing when plans have failed for
the user is therefore a key goal for personalization. These are ideal moments for the system
to offer assistance in some form. This is an interesting and difficult problem.
[29] consider the case where a negative result, subject to some mechanism (decreasing
rate of uncertainty reduction, etc.) can provide a terminal for a sequence of actions. [30]
and [211] provide evidence for extended use of strategies during interactions. Decisions to
terminate sequences may be connected with the strategies and plans adopted by the user
in that decision conditions are part of the plan.
Should one always infer there is a decision at the terminal of an observation sequence? In
experimental settings, certain decisions can be said to be observable through the resulting
actions. Is it possible to observe the decision itself? Some work to this end has used
brain activity measurements, especially fMRI, to identify decision-making loci and try to
resolve decision-making events. The dissertation work uses eye fixation observations for

44

modeling. [68, 67] used pupil dilation to detect neural decision events. They speculate that
decision events release norepinephrine that causes the relaxation of the muscle controlling
pupil diameter. This research suggests a tantalizing connection between sex, chocolate,
and information search. Decision-making might itself be pleasurable because of a chemical
reward mechanism. This could explain seemingly paradoxical results in information search
studies where participants do more work than necessary to adequately perform a task [80].
Pupil dilation has also been associated with relevance judgments [145].

2.8

Eye movements and information processing

Vision is the primary modality of information acquisition during information search tasks via
IR systems. Specifically, information is located and acquired using eye fixations associated
with a user’s allocation of overt attention to information object content. The reading process
drives much of that information processing.
Study of apperception and its role in learning about the world began with the earliest
explorations into epistemology. Study of eye movements and their roles in cognitive processes has been a central enterprise for cognitive psychology. Studies of eye movement in
reading began in the 19th century with the work of [94]. Understanding the visual system
and its integration with cognitive processing at the neural and higher levels is key to a
number of foundational research questions for cognitive psychology.

2.8.1
2.8.1.1

Eye movements and task
Eye movements, tasks and attention allocation

Eye movements consist of fixations and saccades, very fast movement of eyes during which
eyes do not acquire any visual information. Eye movements are known to be cognitivelycontrolled [72] and they mediate most of the information one gains about the world.
Communication in a dialog shows how a strategy to achieve a task goal can be implemented by adopting a sequence of activities, each with a referential focus. Patterns of
attention allocation are one way humans actively structure tasks. It is a basic strategy to
come to grips with the world and make action on it in the course of tasks.

45

Eye movements provide a low-level behavioral observation of interactive tasks, for example in scene perception and search processing [111, 84]. Even in simple tasks, e.g. making
a peanut butter and jelly sandwich, it has been demonstrated that visual attention is allocated in a chain-like fashion with look-ahead on the objects involved in the immediate
subtask [196].
2.8.1.2

Cognitive processing states

Eye movement patterns in reading are cognitively controlled and reading patterns have long
been studied [161]. A number of results relate eye movements and properties of fixations
to semantic and cognitive processing states. In text-based interactive information retrieval
(IIR), information acquisition is mediated by eye movement patterns in service of the reading
process.
Reading is a cognitively-controlled process where the saccade to the next word is programmed while the person is cognitively processing the text available in the currently attended fixation. The saccade programming has a labile stage. If the next word is recognized
during this stage, the programmed saccade is canceled and a saccade to the next word is
programmed.
Models of the reading process have been developed that explain observed fixation duration and word skipping behaviors, for example the E-Z Reader processing model [176]. A
limitation of the E-Z Reader model is that it does not account for higher-order cognitive processes, for example those involving language comprehension and conceptual processing. The
model provides an explanation of the moment-to-moment reading process when linguistic
processing is running smoothly. E-Z Reader is a lexical model. However, there is evidence
for relationships between fixation duration excesses and comprehension and anaphor resolution [156]. Some aspects of text comprehension have been modeled using eye movement
patterns as inputs to artificial neural networks [53, 54].
Eye movements have been related to search task properties. For example, Cole et al. [46]
developed a Markov state model of reading in pages during information search and found
that transition probabilities for scanning to sustained reading varied by the user’s type of
task. Extension of that work found differences in the influence of page types (search results

46

pages vs. content documents) on text acquisition and page processing when different tasks
are being executed[48].
Simola et al. [183] classified eye fixation sequences using three task types to infer distinct
cognitive processing states using a hidden Markov model. Three task types were employed:
(i) simple word search, (ii) selection of an answer to a question, and (iii) selection of an
item of personal interest. The task types were selected because they are taken to be of
different complexity. The presumed order of difficulty is (i), (ii), (iii). Simola et al. did
not discuss or investigate the nature of the differences in task complexity, however it seems
intuitive to say simple word search (i) is less complex than answer selection (ii) because a
person must lexically process a single word vs. a number of words. Also answer selection (ii)
requires several processes to complete the task and they seem to be more complex in their
cognitive demands: the person must understand the question and test whether a candidate
sentence is an answer. Selecting an item of interest (iii) is more complex than word search
(i) and answer selection (ii) because one presumably compares many topic descriptions and
also because the task goal involves an open-ended and subjective choice. They found that
the best fit HMM had three hidden states and could predict the task at a rate of ˜60%.
Their model predicted the word search task (i) and subjective interest task (iii) with higher
accuracy than the answer selection task (ii). Users were found to begin tasks with a scanning
eye behavior and then switch to reading eye movements and then end in states they called
’decision states’.

2.8.2

Eye movements and information processing by reading

There is a distinction between high acuity text in the foveal region and progressively lower
acuity text in the parafoveal region. It has been shown that some text information can be
extracted from the parafoveal region. Frequently, enough information is acquired to permit
planning a saccade target that is several words away from the current fixation. There
is evidence for recognition and use of word length [97], orthographic features, and some
semantics such as the predictability of the word in context [65] and morphological features
[66].
Processing of text during fixations has been shown to take place in several stages. Lexical

47

processing takes at least 113 ms [177]. The labile lexical processing period for reprogramming the pending saccade runs from 113 ms to 168 ms. The pending saccade will be executed
after the cognitive processing is completed.
This explains why observations of eye movements can be connected with the semantics
of information processing. Eyes remain fixated during the lexical processing period independently of the stimuli, for example even if the word is removed [72]. The next saccade takes
place only after cognitive processing is completed. It has long been known that familiarity
and conceptual complexity of the text processed is positively correlated with the fixation
duration (e.g. [164]).
Various relationships have been demonstrated between reading eye movements and semantic and cognitive properties. If the text is easy to read and it does not require additional
reflection, the reading speed will be greater [168]. Reading speed is affected by word familiarity [212], words used in less frequently encountered senses [181], and when additional
reflection is required to comprehend the concepts involved [139]. Sentence parsing can also
impact reading speed.
Reading speed is associated with several components in the description of reading eye
movements. Fixation duration is an indicator of the cognitive processing required to establish the meaning of the word, and the meaning of the word in context. Rayner et al.
[167] show that conceptual processing is reflected to some degree in eye movements. Text
passages of greater conceptual difficulty resulted in more fixations and slightly longer mean
fixation duration.
Fixation spacing is associated with cognitive processing constraints. Perceptual span is
the amount of text one takes in at a time and studies of reading in different orthographic
systems show it is associated with basic human cognitive processing properties. It has been
demonstrated that fixation spacing while reading Chinese is about three characters [197, 92].
Studies of non-logographic systems showed differences between phoneme-encoded systems,
such as Hebrew, and character-based systems, e.g. English and Dutch. Pollatsek et al.
[153] showed that bilingual Hebrew and Dutch speakers shifted their perceptual span when
switching between reading the two languages. When reading Hebrew the perceptual span
was about 5 characters. In Dutch it was closer to 14. What is striking in these results is

48

that across the orthographic systems, approximately the same number of concepts can be
expressed in the different perceptual spans observed.
The LATER model of neural-decision making for saccade programming [37] explains the
relationship between increasing fixation duration, presumed to be due to semantic processing
requirements, and the location of the next fixation, as a function of competing cognitive
mechanisms. Word familiarity affects the rate at which the mechanism reaches the next
saccade decision threshold, but fixation proximity to the previous fixation increases the
probability of executing the programmed saccade to the next word. The result is that when
the fixation spacing is short, processing of even familiar words will tend not to increase
the average fixation spacing. So decreasing perceptual span is expected to correlate with
unfamiliar words and conceptually difficult passages.
The sequence pattern of fixations is also associated with reading effort. Reading sequences include cases where the next eye fixation will return to a previous point in the text
passage. The number of regressions in a reading sequence, and the fixation durations of the
regression fixation have been associated with the difficulty of reading passages, resolution of
ambiguous (sense) words, conceptual complexity of text, parsing difficulties and the reading
goal [168, 167]. It is a common feature of reading eye movement sequences and can have an
incidence of 10-15% of the total fixations in the reading sequence [22].

2.8.3

Discussion and summary

Eye movements are related in a natural way to general task representation through attention
allocation. Reading couples attention to semantics in the claim that attention, in the form
of an eye fixation, is allocated to the physical representation of the word/concept until its
meaning has been acquired.
Research into the psychophysics of the oculomotor reading process has identified a number of observable features that indicate cognitive processing states. Observable eye fixations
can be associated with semantic and cognitive processing during reading in ways that relate
directly to cognitive effort. Word familiarity, sense disambiguation in context, the conceptual difficulty of a text passage can all be related to eye movement features, specifically the

49

duration of eye fixations, their spacing, and sequence patterns.
Empirical studies show that eye movement patterns are influenced by task types. One
conclusion is that observations of eye fixation sequences are rich enough to make models
of tasks and users performing information tasks. Crucially, eye fixations have a causal
connection to semantic processing states for reading. In particular, there is both a minimum
fixation duration for lexical processing and the eyes are fixed until the person has acquired
the meaning of a word. This means that sequences of reading fixations can be identified.
Another consequence is that sequences of reading fixations can be placed into a one-to-one
correspondence with at least some cognitive information states.
Compared to high level interaction features, such as page type use, mouse clicks, page
dwell time, etc., there are far more observations of eye fixations and movement patters for
a task session. Further, a number of semantic and processing features can be derived from
the sequences of reading eye movement. These both contribute to providing a rich set of
observations that can be input to machine learning algorithms.

2.9

Structure and coherence

The goal of finding structure in data is a central concern for the use of statistical modeling as
a mechanism of scientific discovery. Models as representations of distributions are taken to
describe relationships between features or between mechanisms or processes that produced
the observations for the statistics. The discovery of structure is important because of the
explanatory power it provides and because it is also a basis for testable hypotheses about
the world.
Different modeling approaches can be seen to provide distinct views of both the structure of observations and the form of the structure. [105] introduce a Bayesian approach
to simultaneously discover both structure and structural form (e.g. tree, linear, circular)
among features of concepts.
It is natural for an ISS structure to be seen as a tree. Tree structures emerge because of
the sequential nature of human experience. The serial experience of an information seeking
task, and the switching between intention-plan pairs leads naturally to such a structure.

50

The overall task session is coherent, as is the ISS. Coherence is an essential property
of an ISS. It ensures that all of the sequences of actions are related to a single thing, i.e.
the goal of the ISS, which is closely associated with the motivating task goal. The simplest
structural form of an ISS is a tree with a sequence of intention plans. The hierarchical
relation between the child nodes and the root – the ISS goal – is inferred.

Leading Task Goal

intention
plan

intention
plan

intention
plan

intention
plan

Figure 2.4: Minimal task structure

The task grows as successive intentions are expressed via their associated plans. Two
search intentions can be associated if one intention is in service of the other intention. A
related intention need not be associated in adjacent time order, although that is often the
case. In fact, allowing subservient intentions to be expressed more easily out of order, for
example by helping the user to externalize memory or memoize, is one way for a system to
provide effective support and improve its performance.

51

Leading Task Goal

intention
plan

intention
plan

intention
plan

intention
plan

intention
plan

Figure 2.5: Growing a task instance

2.9.1

Coherence

Coherence is a consequence of the expression of meaningfulness for a collection of actions.
It is an identifying property for action sequences that comprise an ISS realization.
Coherence is a property of ordered data. It is usually considered in the context of
temporally-ordered observations in both continuous and discrete forms. It has intuitive
appeal in characterizing the meaningfulness of sequences and is a central construct for the
semantic analysis of sequences of sentences in dialogs and texts [73, 78, 148, 169].
Coherence is scale independent. It can be a property of sequences of any length, but it
can also be a property of compositions of sequences. It also holds for semantic properties,
for example in the composition of paragraphs into larger units. The same applies for even
larger units. One can talk about the coherence of a book.
Another aspect of coherence is that it is domain independent. One can talk about the
coherence of a sequence of plays in a game as easily as the coherence of signals.
The potential for impact on problems in interactive information behavior comes at several levels. First, coherence is a measure on sequences of user actions. This may be seen as
a trivial improvement over similarity measures on sequences, however. Second, coherence

52

provides a way to talk about the degree to which sequences of user actions can be considered to be related to one another as expressions of a strategy or long range effects of some
interaction history.
One possibility is these two senses of coherence are separable. Each can contribute to
the formulation of methodologies to analyze sequences of interactions. Coherence may be
a key for analysis of interactive information behavior because the coherence of sequences
of user actions is grounded in the meaningfulness of those action sequences to the user.
Segmentation of action sequences based on observations that take account of sequence coherence would seem to also be a segmentation of interaction behavior into its meaningful
units of task session execution. The connection between semantic coherence of user search
actions and the observed action sequences is explained by the causal production of actions
using a plan to achieve a particular goal. For the dissertation it provides a way to connect
the bottom-up observation-driven approach with the user’s unobservable mental states that
guide their actions during information seeking. This permits one to learn the sequence and
structure of user plans, and therefore task structure, by studying sequences of user actions
identified using methodologies to calculate the coherence of action sequences.

2.9.2

Calculating coherence

Calculations of semantic coherence can be accomplished by using co-occurrence, such as
latent semantic indexing [73, 113]. The coherence of a text passage is operationalized as a
property of the distance between words in a sequence. The distance is taken to be indicative
of the semantic relatedness of the words. Latent semantic analysis can be seen as a top-down
approach in that words are produced in proximity to one another because they are related
through the semantic intent of the utterer/author. While the statistics are indicators, it is
the production process that is the source of the observed coherence.

2.9.3

Sequence Coherence

Bioinformatics, especially DNA sequence analysis, has explored several basic techniques
for assessing the coherence of symbol sequences (cf. [42, 227]). Briefly, DNA sequences

53

encode for particular proteins which have an associated structure and biological activity.
The goal is to identify spatially contiguous sequences on the DNA scaffold, which define the
sequential process of building a protein, with explicit relationships to the protein structure
and activity. There are rules relating the DNA sequences and the proteins they produce.
These rules cover segmentation of the sequence. The purpose of the sequence, a kind of goal,
is to manufacture a protein. The sequence, then, encodes a plan. The protein underwrites
the coherence of the DNA sequence in the sense that the protein has an effective biological
role.
Associating protein structure and activity can be difficult due to downstream processes
that determine the final protein configuration. One challenge is to identify the coding
subsequences that map to the final conformation and activity features. Techniques used
include frequency sub-graph mining where the graphs are built by dragging a k-gram window
over the sequence and then checking differences in structure and activity between different
proteins [60].

2.9.4

Partial conditionalized exchangeability

To connect observed user action sequences with behavioral protocols one needs to identify
the relevant sequence classification criteria. Behavioral protocols are somewhat indifferent to
the order of actions or subsequences to the degree there is no alteration of the basic behavior
expressed. This indifference can include sequence length as repeating subsequences may not
impact the behavior expressed. Indeed repeating subsequences may be characteristic of the
behavior. This behavior variability frustrates application of some statistical measures absent
hypotheses about rules that govern the distribution of sequence properties. Such rules might
involve the length of the sequences that can be members of the class, or the conditional
relationships between actions and/or subsequences.
An approach to learning such behavioral rules is to consider the improbability of sequences. For example, it seems likely that long sequences (or minor variations thereof) that
appear with enough frequency are not random or accidental. It is reasonable to privilege
observations of the longest such user ISS sequences as likely manifestations of purposeful
behavior.

54

This intuition can be unpacked a bit. Actions in a search interaction sequence are somewhat independent production choices, so the probability of seeing a sequence of length [n, ...,
m] can be placed into an approximate partial order. The more independent the production
choice, the more likely it is that long sequences will be observed less frequently than shorter
sequences. If long sequences are observed with unexpected frequency, they are more likely
to be instances of a meaningful behavior. In short, improbability implies meaningfulness.
The same reasoning suggests particularly frequently observed short sequences may be constitutive units of behaviors. Their existence or patterns of use in longer sequences may be
characteristic of particular information behaviors. This approach is used by [211] as “MRP”
and[130, 129] as “canonical protocols”.
Frequency-based statistical methods to infer the probable significance of sequences of
actions in searching behaviors are intuitively plausible if one assumes there are a limited
number of expressible information behaviors. Identification of information behaviors has
practical challenges, however. Various types of observational noise can come into play.
Examples include user mistakes, and constraints, real or imagined, on actions imposed by
the system interface or the general information environment.
There are also ambiguities in delineating behaviors across users. Consider a recalloriented task. One user may quit a behavior after identifying a useful item. Another may
quit only after finding several items. Are the users engaged in the same behavior? It seems
clear that a complete description of practical behavior identity criteria will ultimately need
to take account of individual differences.

2.9.5

Conditional exchangeability

Exchangeability is a concept that addresses several issues for interactive information behavior. The basic idea of exchangeability is that a sequence of things can be reordered
without changing a property of the sequence. That is, the sequence property is invariant
over ordering transformations.
Suppose one observes a perceptual sequence red, oblate, stem, sweet that has the property of being an apple. It is obvious the features could be observed in a different order and

55

the sequence would still have the property of being an apple. In contrast, the word ’apple’
also refers to the property of being an apple. Of course the letters of the word ’apple’ are
not exchangeable.
How might sequence exchangeability be germane to session sequence representation?
It seems reasonable to think that some variability in the session sequence does not affect
the information searching properties of the session. So one can hypothesize that ISS’s
represented as sequences of user actions are somewhat exchangeable. It also seems plausible
that the degree of exchangeability could reflect task differences. For example, some tasks
involve explicit subtask ordering.
Exchangeability also addresses a formal problem for representation and computation.
The nature of interaction appears to ensure that observations are not iid (independent and
identically distributed). Similarity, as a mathematical concept, requires iid observations.
Therefore, properties of sequences of actions cannot be measured directly by the similarity of
properties for the actions. This is also true for the sequences of action themselves. Similarity
measures can be applied if the user actions are produced by the same unchanging system.
This is obviously not true in complex and exploratory searching where many important
factors change as the search session evolves.
Knowledge changes can fundamentally alter the actions and their meaning in the search
session. For example, decreases in document dwell time may occur because a user has
learned what to look for to make a usefulness decision from a previous document. These
dwell time dissimilarities are not easily mapped to the user’s information behavior. In
each case the user is working to identify useful documents. The document dwell time is
conditionalized by learning, but the behavior is unchanged.
Conditionalization is an important reason why sequence coherence identification is a hard
problem. The coherence of interaction sequences depends on properties that are not essential
to the individual observations, though they are essential to the observation sequences. How
can one represent sequence actions to allow detection of coherence?
De Finneti’s probability theory [58] is based on comparisons of symmetry rather than
similarity. Sequences can be considered from the perspective of properties related to the

56

invariance of statistics under rearrangement of the sequence elements [226].
Interaction order certainly matters in some cases. It is also true that noise and variability
in sequences is expected. A general strength of an exchangeability approach is the capacity
to allow for noise and variability in sequences in a natural way.
So exchangeability is interesting in connection with the problem of learning ISS structure
for three reasons: it satisfies a formal requirement that observations in interactions are
not iid; it allows for variability and so a natural description of the relationship between
instances of interaction sequences and behaviors (because behaviors are the meaning-laden
units in the analysis); and it enables an understanding of sequence coherence without an
appeal to semantics. Strict ordering of some interactions is expected, but this might also be
accommodated in an exchangeability approach by recoding strict sequences to be a single
unit.
Exchangeability developments include a definition of sequence complexity [135]. Exchangeability is also an answer to the problem of induction and to the speciation problem
[225].

2.9.6

Summary: Coherence and exchangeability

Sequences of actions are coherent because the sequence is meaningful. The source of such
meaningfulness is rooted in the process that produced the actions. The intent, or purpose,
of the adopted process underwrites the coherence of the sequence. Techniques to identify
coherence can be statistical or referential in nature.
Interaction sequences in an ISS exhibit properties that are not unlike texts and dialogues
in some respects. In interaction sequences the implied reference is to the immediate search
intent, rather than the topicality of the processed information objects. The conditionalization of interactions in the action sequence depends on many factors that influence the
expression of a given behavior. Coherence in texts is due to the intent of the utterer or author and normally immune to external factors. Information seeking is different. Exogenous
factors impinge on the user’s expression of the search intent. For example, a user’s search
plan implementation can be affected by interface navigational requirements. It is affected

57

by the vicissitudes of the search system and the collection. A search query pattern and
link exploration may be repeated until a good document is found. Together, these factors
introduce unpredictable constraints and make it hard to uncover the essential expression
of patterns of behavior use. Identifying coherence in the face of these challenges is a core
problem for representing information behavior.
Exchangeability has attractive characteristics for addressing this problem. Action sequences are coherent by virtue of the meaningfulness of the sequence for the user as part
of the process of achieving their task goal. Exchangeability depends only upon symmetry
and therefore makes no assumptions about the distribution of the observation elements.
Remarkably, de Finetti’s theory of probability is also a theory of coherence, both at the
symbolic level, via combinatorial mathematics, and semantic level, as an answer to Hume’s
problem of induction. It may be an effective theoretical basis to address the problem of
learning information behaviors from observations.
De Finetti’s representation theorem concerns fully exchangeable sequences, that is sequences where the position of the elements in the exchangeable sequence is irrelevant. Information behavior has structure in element relationships by virtue of the serial and hierarchical
nature of the cognitive production process that is responsible for the observed actions. At
least some information behaviors depend upon specific actions in the sequence being carried
out in a certain order. This is apparent at the level of sequences of behaviors that comprise
the ISS. When order is important, as it is in conditionalized interaction, one can impose
certain constraints on exchangeability to define partial exchangeability [57]. The potential
for conditional partial exchangeability to address problems of coherence in interaction to
model economic production processes has been recognized [136].
A specific way to achieve an implementation of partial exchangeability is via Markov
exchangeability. For each sequence that begins with symbol N, sequences are Markov exchangeable if they are are exchangeable and the transitions from N to the other sequence
members are the same.
Relaxed Markov exchangeability criteria can be constructed by identifying certain transitions as significant, while taking others to be noise. Such distinctions can be grounded in
real-world observations. Probabilistic relaxed Markov exchangeable models can be achieved

58

by ranking transitions by essentialness to achieve a goal, or by some other property, such
as relative usefulness. Such probabilistic models may be attractive because the essentialness or relative usefulness can be learned directly through appropriate operationalization
on observations. For example, by filtering the observations for model training.
Behaviors do not occur once. Each user may have a repertoire of available behaviors
that can be used to satisfy subtasks in an ISS, from individual actions to types of action
sequences. Compositions of behaviors may themselves be a behavior. For example, implementing a search strategy may be a composition of such behaviors. Exchangeability analysis
can be applied both at the level of raw sequences of actions and the level of sequences of
behaviors, i.e. the sequence of the sequences of symbols for the behaviors.
A behavior sequence is an implementation of an intention-plan and sequences of intentionplans can be considered with respect to their independence. Intention-plans in service of
higher level intention-plans can be expected to reflect some dependencies. Those that are
more loosely coupled, say as part of a general strategy, will be less dependent. The probability of a repeat of a sequence of behaviors may therefore be tied to dependencies in the
intention-plans. If they are independent then the probability of seeing a repeat of behavior
is unexpected and so the repeat sequence is the behavior rather than it being a composition of a repeated behavior. Exchangeability of the behaviors, say in disparate portions of
the session, can then be confirmed because the transitions will be distinguished from the
alternative description as repeats of the shorter sequences.

2.10

Summary

The general dissertation problem concerns learning the structure of an ISS through observations of user actions. The literature shows that the task construct can be distinguished into
subclasses with distinctive properties. Tasks have also been shown to have various structural properties, including level relationships with subtasks, task stages, and task phases.
A number of general task properties have been identified, including task complexity. The
empirical evidence for these task construct aspects consists of observations of the effects of

59

these task aspects on behavior. ISS instances have structure, both in the temporal dimension and in hierarchical relationships between the subtasks that comprise the execution of
the leading task. There is reason, then, to believe one can work from actions to classify
behaviors that correspond to motivating task properties and learn long range relationships
between behaviors in a given ISS. It is therefore plausible that one can learn a representation
of ISS structure.
The literature review shows that it is reasonable to infer search intentions and plans
from observed actions. It also provides grounding for the characterization of sequences of
actions as behaviors. To carry out a task depends on forming an intention, selecting a
plan, and committing to that plan. The actions, which are also individually behaviors, can
be grouped and classified as search behaviors as well. Sequences in a given class may be
recognizable as search behaviors that have been identified in the literature, for example
Bates’s strategies of “chaining”, or “pearling”.

60

Chapter 3
A model of the ISS process

This chapter develops a theoretical model of a user’s expression of information search behaviors in ISSs. The goal is to focus on the ISS process and avoid using the specific (textual)
content in the session. A model that does not involve the topic or the content of the information resources can be more easily generalized and used in sessions involving unseen
topics and information needs. The construction of a model should therefore be based on
observations that do not depend intrinsically on the particular content of the information
objects, or on the search domain or topic, or the type of motivating task.
To accomplish this, the model is focused on user behaviors. Behaviors are user-directed
and reflect the ongoing desire to achieve the task goal. User behaviors are both reasonably
independent of system constraints and the specific content of documents. Yet, they are
likely to reflect adaptations to the nature of the task and progress towards the motivating
task goal.
This model of the information task process is based on the theory of human action. It
centers on the user’s volition to make action on the information environment as mediated
by the information system. This is a picture of active search with plans. That is, people
seek to resolve/solve their complex information problems by sequences of directed actions
rather than random walks or mere sampling in the information space available to them.
The chapter first lays out the theoretical development of the ISS process model. It then
shifts to focus on the sequence of actions produced by the ISS model’s basic task session
unit, i.e. a single search intention coupled with an implementation plan. The goal is to
characterize essential properties of these ISS unit action sequences that can be connected
to a search behavior construct. The overall structure of a task session is plausibly related

61

to the relationships between the behavior instances observed in the ISS.
Behaviors are used in meaningful ways by users. It is proposed that some user action
sequences are coherent by virtue of servicing the same goal. A definition of the coherence of
user action sequences is developed based on the idea that the sequence actions relate to the
same intention and implementation plan. Coherence is also related to essential properties of
the sequences. The working hypothesis is that coherence is associated with the distribution
of action types and the observed patterns of action types in the sequences. These action
types are associated with a user’s information processing states as revealed in the user’s eye
movement patterns during reading.
The last part of the chapter moves from the theoretical ISS process and sequence coherence models to the corresponding representation models. The ISS process representation
model is developed as a finite Markov process. The action sequences generated by the
model are Markov chains. A methodology to learn a model of information action sequence
coherence is then presented. Finally the connection of the models to behaviors and task
structure is explicated.

3.1

A generative model of task sessions

The literature review supports several observations about making an ISS generative model.
First, human information interaction is experienced as a serial process. Second, human information action is a user-driven cognitive process that can be observed as a causal process,
notably through eye movements. Third, over the course of a complex ISS a user typically
carries out a number of subtasks. Fourth, the choices of actions considered are often conditionalized on previous actions, some of which are well removed in time or steps from the
current action.
One can hypothesize that (successful) task session information interactions to achieve a
goal are characterized by acquiring some knowledge, i.e. a concept, that enables satisfaction
of the motivating task information need that initiated the information session. One must
be careful to distinguish the information/knowledge goal from the person’s actual goal.
Satisfactory resolution of an information need is presumably crucial to enable a user to

62

achieve their real world goal [15].
Each instance of search interaction can be seen as an instance of concept use. Each search
interaction has the potential for concept learning. The dissertation presents a generative
causal model of the search task process. It is not unreasonable to suggest that motivating
task goals reflected in the ISS process can be understood in terms of a need to identify and
learn concepts. From this perspective, a generative model of the search task process might
be married to a generative concept model to make a specific general proposal for an IIR
computational framework.

3.1.1

Overview of the development framework

The framework and line of argument leading to the model of the ISS process can be outlined:
1. A motivating task is the impetus for an information seeking episode.
2. A person enters into the ISS process with some general intention and plan in mind to
achieve the goal.
3. The intentions and plans can be seen roughly as subtasks to be accomplished in a
search process such that one can achieve the leading goal.
4. (3) is construed to be a cognitive architecture (intention-plan) of the ISS process. At
its bottom level there are sequences of search intentions. As a production system,
when bound to an implementation plan it creates (causes) actions that carries out
those intentions in sequences of interaction with an information environment.
5. Claim: It is possible to infer aspects of the task/plan a person is attempting to achieve
through observation of actions and sequences of actions.
The first step for this project is to develop a framework and model that grounds inferences
from actions to plans (5) and so to the sequence of plans that guide the ISS process. The
main focus of this work stage is to develop a model of (4) and use it to guide the investigation
of methodologies to implement (5).
The theoretical foundation rests on mainstream developments in philosophy of language,
artificial intelligence, and cognitive psychology. A cognitive stance in representing a user’s

63

interaction with an information system (environment) as information behaviors. This is
central for the representation of the process of information retrieval. Sequences of observations of user actions are classified to fashion a computationally-useful representation of ISS
implementation and structure.
Recalling the research questions, the first general goal is to show behavior sequences,
i.e. habits of actions, exist. The second general goal is to classify them. Achieving these
goals allows one to investigate the structure of relationships between behavior sequences.
Regularities in such structures may be thought of as ISS structure characteristics. Per the
general framework, this amounts to attributing a sequence of intention-plan states to the
user. One result is to demonstrate that ISS structure has a 1-1 correspondence with the
structure of user plans. Learning to distinguish user plans permits learning the user’s ISS
structure. If ISS structures can be distinguished, for example by classification models, then
it is possible to distinguish types of motivating tasks and perhaps properties of tasks from
observations of the behavior sequences.

3.1.2

Behaviors and coherence

A data-driven methodology is used to associate sequences of actions. While each user action
can be taken as an information behavior, i.e. something people do to advance towards their
goal, one is also interested in information behaviors associated with extended sequences of
actions. This level of search behavior might be understood as labels for classes of sequences
of actions/behaviors. From a data perspective, behaviors can be taken as protocols. From
a semantic perspective, behaviors can be seen as habits of actions to achieve something
[2, 189].
Extended behaviors can be learned from action sequences by associating subsequences
and hypothesizing them to be ’habitually related actions’ because of the intention-plan
that produced them. These habits are meaningful because we label them, saying they are
’behavior X’, by virtue of having recognized the user’s intent. This has a link to the idea
of coherence. A sequence can be coherent because the constituents share some property.
Meaningful serial activity has coherence because it reflects aspects of the production system.
In this way coherence provides a bridge from the symbolic to the semantic. This dual role

64

for coherence is recognized and exploited in modeling dialogues.
Coherence has also been linked with symmetry in experience and inductive learning
[226, pg. 12] on exchangeable subsequences. For the ISS process model, coherence can
be a perspective to integrate the top-down user-driven model and the bottom-up learning
methodology. First, it is proposed that the coherence of observable actions can be observed
in the patterns of action sequences. Since these sequences can be associated with search
constructs that have meaning it follows that aspects of meaningful constructs might be
directly observed in an ISS. Put another way, the coherence of sequences enables inductive
learning on the observational sequences and can be linked to extended behaviors, intentions
with plans (which cause coherence), and motivating task properties.

3.1.3

Focus on the information seeking episode

The dissertation makes analysis on the ISS because there is evidence that studying the task
construct at this level can result in insights and representations that can enable system
designs that better support users. The most extensive well-defined unit of user search task
activity is the ISS level.

3.1.4

The ISS is the highest level of observable motivating task

Consider the difference between an instance of an entire task construct, consisting of the
motivating task and the ISS, vs. a yet higher level of task activity such as a quest or a
general goal (“advance my career”). It is clear that the session level task and its constituents
is representable in ways that higher task levels are not.
One basic distinction is the type of intention involved in each. A task session is driven
by a user’s immediate intention and the intentions behind each of the subtasks. Each
intention is acted upon. Higher level goals are rooted in a provisional commitment to
future tasks. Such future tasks may be apprehended by the user but consist of ill-defined,
yet understandable, goals with vague commitments to timing and resource allocation. In
contrast, an immediate motivating task and ISS binds the user’s attention to a specific
intention to achieve a goal. That intention, as carried out in the ISS, spawns subtasks. Each

65

subtask has an intention and commitment to an implementation plan. Serial allocation of
attention leads naturally to hierarchies of subtasks in the process of achieving the task goal
within an ISS.
At levels above a specific information seeking episode, the cognitive production process
that results in such goals (“advance my career”) seems only to induce, from time to time,
motivating tasks that receive immediate attention as session level instances. The production
of specific motivating tasks and the associated ISS by these higher levels of task may be
opportunistic, situationally-induced, or scheduled. The higher level tasks do not require
serial attention, while a session level task requires attention and in some sense is defined by
the attention it receives.

3.1.5

System predictions about a user’s task depend on seeing characteristic behaviors

In view of the practical goal of the dissertation, system predictions concerning a user’s task
during the course of an information seeking session depend upon observing characteristic
behaviors, both in the sense of individual actions and as sequences of actions/behaviors.
Even if motivating task properties cannot be detected, system understanding of a user’s
immediate plan and sequences of plans can be helpful in allowing a system to recognize how
to help the user. Understanding a task as a whole might allow a system to be more helpful
because it can offer various forms of support to help optimize an ISS strategy.

3.1.6

Recognizing plans could allow for identifying the leading task

The dissertation approach may allow for recognition of plan-level behaviors that may be
supported without knowing the higher level task(s) in which the user is engaged. The
ability to adduce a structure of plans that correspond to relationships between ISS subtask
levels, might allow for prediction of aspects of the user’s motivating task. Teevan, et al.
[193] define the potential for personalization in terms of the difference between the search
performance based only on server-side information vs. use of all possible information. It
seems plausible system performance could leap if a system could know the user’s motivating

66

task in addition to the user’s immediate information situation.

3.2
3.2.1

Task production model
Definitions

It is useful to define task, intention, plan, and behaviors to make clear their meaning
in the model of search behavior production and in the research questions and hypotheses
derived from the model. They inform the representations and help to clarify the capabilities
and limitations in the methodology to learn behaviors and task structure as sequences of
behaviors.
For the purposes of this model, the motivating task is taken to be the task that initiates
an ISS. An ISS is a more or less continuous sequence of information seeking activities, for
example a sequence of actions searching for information.
A subtask is a task with a goal that serves or supports achieving a higher level task goal.
Any task may have subtasks required to achieve the task goal. The lowest level subtasks
for this work are determined by fairly basic information processing tasks, for example eye
movements patterns essential to acquire information. A subtask is temporally shorter than
the task it serves. A subtask can serve only one task, although that higher level task may
itself serve a yet higher level task and require the subtask to meet the need of the higher
level task.
Intentions and plans are mental states. As such they cannot be directly observed,
although one can have good grounds for attributing these mental states to users on the
basis of observable actions. This action-based theory of meaning is one of the main results
of work in the philosophy of language and related areas over the last century. As noted in
the literature review, intention-action theories of meaning are associated with the rise of a
focus on interaction in language and artificial intelligence. It is reasonable for intentions
and plans to be central for a model of interactive information behavior, for example as
developed by [16] and [217].
An action is a specific interaction between a user and an information environment,
commonly an information system. Making a query is an example of an action.

67

An event is a unit of interaction. It has structure in the form of a two-step cognitive
interaction with an information object. The first step is recognition of the object (conceptualization of the object) followed by an evaluation of the object’s usefulness. This definition
of event is made to acknowledge the basic process of meaning production for cognition during each interaction. The dissertation focus is on relationship between actions, behaviors,
plans and subtasks. Structure is taken to emerge from these relationships. The details
of the meaning production process are explicitly not considered. One might consider each
interaction event to involve (at least) two actions: recognition and evaluation. In this work
an action is a complete interaction that conflates recognition and evaluation of the information content. In that sense an interaction is an event , i.e. an observation, for purpose of
the sequence analysis. This view makes no distinction between an interaction event and an
action, although they can certainly be distinguished by the causal activities embedded in
each. For the purposes of the dissertation “a sequence of actions” is the same as “a sequence
of interaction events”.
Behaviors are defined as habitual actions. It might be a single action or a sequence
of actions. Action sequences can be meaningful and coherent for the user. A sequence of
actions is the ordered collection of actions from the moment after adopting a new immediate
intention and implementing it with a plan to reaching the terminal state. These sequences
of actions can be classified because they reflect the plan selected to carry out the intention.
These classifications are extended behaviors. To allow practical model application, a goal is
to learn a label for a sequence of actions using unsupervised learning in order to distinguish
sequences of behavior use in the ISS.
A behavior is meaningful because the corresponding action(s) is meaningful. A behavior
does not exist independently of the habitual action(s) that implement the behavior. For
the purposes of information behavior, one can say behaviors supervene on actions. One
consequence of this definition is that behaviors are observable and are not mental states
that are correlated with actions or that cause actions. In particular, a behavior is not a
plan or an intention, nor it is a constituent of an intention or plan. One or more behaviors
can result from making an intention and committing to a plan because the intention-plan
pair causes a sequence of interactions. In this sense, behaviors are implied by intentions

68

and plans, suitably constrained by factors such as knowledge, etc.

3.2.2

Generation of search actions

Human actions are produced after the formation of an intention and commitment to some
means to implement the intention. Every expression of an information behavior is a collection of user actions. Generally we observe these actions to be contiguous. The nature and
scope of possible actions in an information environment define the universe of information
behaviors that may be observed. One can hypothesize that the behaviors of practical interest for information science will be a small subset of this universe. Observations and analysis
of information task behaviors, both empirical, [10, 35, , etc.], and theoretical, for example
in Belkin’s ISSs [16] and the models of [217] and [150], provide insight into the expected
range of behavior types of practical interest and their relation to analytical (Belkin) and
explanatory frameworks (Pirolli).
This dissertation does not address questions about the numbers, range, and types of
information behaviors that humans perform in the real world. The proposed information
action production model (Figure 3) does not limit or pre-suppose a structure in the observable action sequences. Important assumptions in the model are:
1. Actions are produced and experienced in a serial fashion.
2. Only one intention can be addressed at a time, although the work in service of a
current intention may serve other intentions as well.
3. Humans can change their current intention.
4. A single plan is adopted to implement each intention.
It is plain these assumptions do not limit the types of actions that can be taken in an
information environment. They also place no limitations on the sequences of actions, or
sequences of sequences of actions, that can be produced and, consequently, the information behaviors that can be observed in principle. A relation between intention-plan pairs
is reflected in a relation between behaviors. This permits the generation of hierarchical
relationships. For example, suppose one’s commitment to intention B comes about because

69

the goal of B is to produce something needed by a previously held intention A. The switch
from the intention A to intention B structures a hierarchical relationship between the sequence of actions that results from attending to intention A and the sequence of actions
associated with intention B and produced by its plan. From the viewpoint of this model, a
way to represent the structure of an ISS is to describe relationships between the sequences
produced by the plans that carry out that task.

3.2.3

An example

Consideration of a real information task may help to make this picture concrete. This
example can also serve as a guide to Figure 3.
A few years ago I tore my Achilles tendon playing basketball. The specialist made a
diagnosis that the tendon was severed but each end was still attached to bone. There were
two treatment options: surgery to tie together the shredded tendon, or external manipulation to overlap the tendon pieces with a six month confinement in a cast to allow them
to reintegrate. As it happens, Achilles tendon repair is low priority surgery. On the day of
the diagnosis I was informed that the two earliest operating room time slots were early the
next morning and in two weeks. The manipulation and cast could be done at any time. If
I wanted to do the surgical procedure right away I needed to make a decision by 5 am the
next morning.
My information task was to make a choice between the two procedures. To do so, I
needed to conduct an information seeking session. The leading information seeking task was
to learn the risks and expected outcomes of the alternative procedures to enable application
of utilitarian-based decision-making. My intention, then, was to identify the costs and
benefits of the respective procedures.
The first immediate intention was to find descriptions of each procedure with a plan of
using Internet resources. Specifically, the overall plan was to use a standard search engine
to try to find a general description of each procedure and then use a specialized search
engine (PubMed) to get the most current and authoritative information concerning specific
questions. The intention to find descriptions as a first step also caused the formation of

70

several future intention(s). First, there was the future intention of using a different resource
(PubMed) to meet the need of having up-to-date and authoritative information. There
was also formation of future intentions to evaluate any procedure descriptions identified in
the immediate search task for their risks and benefits. Yet another future intention was to
compare the risks and benefits. It is clear these future intentions cannot be described further
at the first step in the information seeking process because the specific actions of evaluating
the risks and benefits depends on having in hand the descriptions of the procedures.
In the example, the first action in service of the immediate information seeking intention
was to perform the actions of opening a browser and going to a search engine query page.
Formulation of a query is itself a mental activity, however it is implemented by actions of
typing, performing cut and paste operations, etc. It is terminated by a decision to submit
the query and its implementation through the action of clicking on a browser button or
using the return key. After waiting a bit and then recognizing the availability of a SERP,
the SERP was evaluated for promising links. This evaluation can lead to opening a link
or deciding to formulate another query. One might say that a decision to open a link is
an indication of minimal success in the goal of identifying potential useful information.
Presumably one opens a link after evaluation with at least a minimal hope it will prove
useful.
Success against the supervenient task of identifying descriptions of the procedures requires one is able to identify pages that usefully contribute to formulating those descriptions.
The query step fails if, after the evaluation of the SERP link snippets, there is a decision
that no link is worth following. In my case, the task of finding descriptions by executing
the subtask of making a query for the purposes of finding useful web pages was still operative. I would end my immediate task of examining search results and formulate a new task
of revising the query, followed (as before) by execution and evaluation of the SERP link
options.
Each of these interactions with the information system was an action ’event’ (Fig 3). An
event consists of two steps. First I needed to recognize the content of the information object
in order to evaluate its usefulness against the goal of my current intention. My attention to
the content depends on mental states, notably my knowledge, but also cognitive capacities,

71

and upon the current intention. That is, my recognition of the information object depends
on what task I am carrying out . This step of recognition is followed by some evaluation
procedure that may result in ’selecting’ the objects as useful and possibly incorporating
some meaningful content into one’s knowledge. [188] provides an explication of this twostep procedure in the context of understanding the meaning of a word or sentence. So I may
have taken a number of actions of this sort, described as events, in service of the intention
of finding a description of each procedure.
A search formulation followed by submission and evaluation of the SERP page resulted in
my selection of a link. That page was then evaluated and deemed not useful because it talked
only in general terms about the surgical procedure. After returning to the SERP I followed
another link and found a forum where one post mentioned they had the surgery recently
but without any details about the procedure. I decided my query was not appropriate
and formulated a new query “Achilles tendon rupture surgical procedure”. The SERP
returned contained several promising links. The first one provided a detailed description
of two variants of the surgical procedure appropriate to my case. After saving this page, I
returned to the SERP and followed another link. That link provided information that was
similar to that in the previous link. It was written as an authoritative description for a
lay audience and provided the names used by practitioners for the surgical procedure. This
document was useful, apart from confirmation of the information in the prior document,
because it named the alternative procedure (“immobilization”). This interaction spawned
a future intention to formulate a query using the term to identify pages describing the
alternative to surgery. After processing several additional pages concerning the surgery, I
decided this part of the search task was successfully completed.
I then switched to the task of finding a description of the alternative procedure. I adopted
the intention of finding information using a search engine with the plan of making a query
and evaluating the results. In making the intention to search with a query I implemented
the previously identified future intention of using “immobilization” in the query. After
receiving the SERP, I followed a link and found only a mention of the immobilization
procedure as an alternative to surgery. Returning to the SERP and following another page,
I again found only a mention with the information that about 20% of people are treated

72

with immobilization. I decided to try a related query and found similar results. After
several searches, I decided that detailed information about the immobilization procedure
was not available. I abandoned the immediate task of searching for information using a
search engine, and adopted a new task and intention of gaining the information by asking
people who had used the alternative procedure. My intention was to post a question in a
web forum. This caused an immediate task of finding an appropriate forum to post such a
question. My intention was to use a search engine to find medical web sites for lay people
that had forums about personal experiences with surgical and other medical procedures. To
that end I formulated a query, and found a link to an appropriate site right away. At that
site, I posted a query inviting people to describe the immobilization procedure and their
outcomes.
This process of failure in an intention caused a new task with a significantly different
specific intention and plan, that is to use services available via a web, a user forum, to solicit
the desired information, as opposed to identifying an existing information object containing
the desired information.
My next intention was to identify the risks associated with each procedure. In service of
this intention, I committed to the intention of evaluating the risks of the surgical procedure
first and at the same time formulated the future intention of evaluating the risks with the
non-surgical procedure. The first risk I considered was the risk of death undergoing full
anesthesia. To implement this intention I used the PubMed system and made a series
of queries and selected some of the results to read the abstracts. This series of actions
constitutes an information behavior that is the same as the one used to find descriptions of
the alternative procedures. This information behavior served the leading task plan as a part
of evaluating the risks of the alternative procedures even as it directly served the intention
of performing a risk analysis of the surgical procedure. I learned the risk of death depends
on underlying health, age, and that there are idiosyncratic factors that cannot be identified.
This result induced succeeding intentions to learn which preexisting medical conditions are
most dangerous, the absolute risks associated with age, and the idiosyncratic death rate.
Each of these intentions were implemented using a similar plan, and resulted in sequences of
actions that could be identified as the same search information behavior as before. Yet each

73

is also a behavior that implements a subtask to the leading task. In fact, in this example,
these are sub-subtasks.
In the case of any of these action sequences, there is a point where one of three options
obtains:
1. The intention is satisfied. That is, roughly, the goal is achieved.
2. There is a meta-cognitive decision that the intention is not satisfied and the intentionplan is abandoned.
3. Something happens to interrupt and cause abandonment of the current intention.
It could be another intention has been adopted (“Time to teach!”), one has become
distracted, or is too exhausted to go on, etc.
For these task ending cases, the actions associated with the situation are the terminal actions
in the sequence of actions.
This example illustrates the general idea of the connection between the leading task,
immediate and future intentions, and the production of actions by implementing a current intention using a plan. It shows how sequences of actions carrying out an immediate
intention are related to one another, and thus how meaningful information behaviors are
produced. Finally, the production of related behaviors, by virtue of the relationship between successive intentions adopted as the task execution unfolds, can be seen to cause a
task structure to emerge in the relationships between these meaningful behaviors. That
structure of relationships parallels exactly the structure of relationships between the intentions and their associated plans.

74

3.3

A model of the production of information seeking behaviors

Figure 3.1: A model of task production

This model, like [217], is centered on intention and plan as the key elements in ISS implementation. It takes task-level information seeking strategies to be carried out as intentions
combined with plans for information acquisition (information tactics). The idea of access to
information resources is understood two ways in this model. First, there is access to internal
information resources by knowledge of concepts and whatever structure (of rules etc.) is
employed to utilize concepts, including reasoning. Access to external information resources
is a two step process (see ’event’ in the model). First, there is some user action in the information environment. That action is followed by comprehension, selection and evaluation
of a specific information resource. This sequence is complex, both in terms of cognitive
psychology and in philosophy. Further explication is beyond the scope of the dissertation,
but it is important to point out that this is the nexus of the specific meaning production
of the action in the task sequence. Stalnaker [186, 187, 188] provides a detailed analysis of
context and meaning in an analogous two step process for word understanding. This two
step process is a staple of phenomenology and the psychology of experience. For example
it is the primary concern of [86]. It is also central to the argument of [213] criticizing the
classical AI program.

75

3.4

Theoretical framework

The dissertation domain is information search. Information science has hypothesized and
investigated various relationships between high-level mental states of the user, such as knowledge and affective states, and search tasks and behaviors in information seeking activities.
The dissertation seeks to model and test some relationships between sequences of search
interactions, i.e. behaviors, and certain properties of information search sessions (ISSs),
such as the structure of subtasks in an ISS. The general idea is to model the process of
searching as sequences of behaviors.
Figure 3.2 presents the scope of the dissertation as a collection of spaces and hypothesized
relationships between them. Table 3.1 provides the notation references. The state notations
in the various spaces should not be taken as claims that each collection of states is discrete
and finite.
The left side of figure 3.2 is the user space. It is expressed in two collections: (α) is
a high-level space of user knowledge states K1 , . . . , Kn , a collection of search intentions,
SI1 , . . . , SIx , and a repertoire of general plans, strategies and/or tactics, P1 , . . . , Pk , to implement a search intention. β is a space of information processing states, IP S1 , . . . , IP Sm ,
which are states assumed by the user while interacting with information objects in the environment, for example when reading text or discerning objects and relationships in images,
or more generally in scenes. Such states are taken to be part and parcel to the extraction of
information that the user consumes in cognitive processes, including those involving knowledge, intentions and plans (α). One approach to representing states is to express them in
terms of the actions taken to process the information object. This might be at the stage of
recognizing concepts encoded in the the information object. It might also focus on the step
of extracting information/knowledge that may be utilized to change the person’s knowledge
state. Such extracted information is usually believed by the user to be potentially germane
to their motivating task goal. However, a user may actively extract information because
it is interesting for reasons of serendipity or curiosity, as is observed from time to time in
real-world search activities.
The search process model supposes that user actions in the search process result from

76

sequential adoption of a search intention, each of which is bound to a plan. One source
of complexity in understanding information search processes is the dynamic evolution of
the state space of knowledge, intentions and plans (α). It is reasonable to assume the
user’s knowledge state changes during the course of a search1 . Such changes seem likely
to influence the formation of search intentions and the propensity to select a particular
plan to carry out the search intention. There are fundamental questions for IR research
about the relationships between knowledge states and search intentions and plans. Such
questions are not within the scope of the dissertation. The dissertation has the modest
goal of investigating relationships between sequences of search intention plans and certain
properties of information search sessions (ISSs). These relationships relate to α →  in
figure 3.2. It is hoped these investigations may contribute to the groundwork for exploring
relationships between the high level mental states of knowledge, search intentions, and plans
during task sessions.
1

It is also true that the global knowledge state of a person can change in a fundamental way because when a
particular knowledge state has changed, the previous state cannot be recovered. That is, one cannot unlearn.
So the knowledge state space has been replaced with a new state space. This is a basic challenge for making
time-series representations of knowledge states because knowledge differences (and other computations) may
be incommensurable.

77

Figure 3.2: Framework of spaces and relationships between user states and observables.

78

Notation
α
β
γ
δ

Ki
SIi
Pi
ISSpi
Fi
IP SOi
IP S i

Table 3.1: Notation for figure 3.2
Reference
High-level user state space (mental)
User information processing state space (mental)
Reading pattern state space (observed)
Interaction feature space (observed)
Information search session property space (observed)
User knowledge state (mental)
User search intention (mental)
User plan (mental)
Information search session property (observed)
Interaction feature (observed)
Information processing state (observed)
Information processing state (mental)

The right side of figure 3.2 concerns the observables of an ISS. Each ISS () has a collection of properties ISSp1 , . . . , ISSpz . Each user interaction during an ISS can be expressed
as a vector of interaction features (δ) < F1 , . . . , Fz >, each of which can take on various
values, including categorical values. An ISS can be represented as a sequence of interaction
feature vectors.
The dissertation hypothesizes that a subset of the feature space (δ) can be used to
fashion an observation of the information processing state of the user (β). Two steps are
needed. First, a state space (γ) is constructed by classifying observed feature vectors in δ.
Then a link hypothesis (γ → β) connects these classes of observed behavior feature vectors
with user (mental) information processing states.
It is obvious that some form of a linkage hypothesis is needed to move beyond statements
of mere correlations between observed ISS features and presumed user mental states. A
framework should allow for predictive models with explanatory power. The dissertation
uses a link hypothesis that ties observations of eye movement patterns during reading to
mental reading information processing states. As shown, there is ample evidence for a casual
relationship between eye movements and goal-directed attention allocation. This includes
evidence at the neural level and in vision and reading research. On this basis it is not
unreasonable to suppose β ↔ γ.
Independently, it seems reasonable to suppose an association between the history of user

79

information processing states (β) and changes in high level user states (α), presumably via
some knowledge-mediated process. The details of relationships between internal information
processing state sequences and user knowledge states, formation of search intentions, and
plan selection, is far outside of the scope of the dissertation. These are matters for cognitive
psychology and not information science. That said, there is evidence for the influence of α
on β in neural attention allocation mechanisms for goal-directed eye movement. There is
also evidence for correlations between (δ) and knowledge states (α), e.g. [45]. The influence of α →  underwrites these correlations. Likewise, there is evidence for relationships
between observations of classifications of reading eye movement patterns (γ) and biases to
use information processing strategies (α), e.g. [90, 48].

3.4.1

Summary

In summary, the general modeling framework for the dissertation can be described as relationships between distinct mental and observational representation spaces. There are mental
spaces of immediate information processing states, and a space of more or less persistent
states of knowledge, intention, and plans. As mental state spaces they are not directly
observable. The observables are characterized as three levels of spaces: (1) the observed
properties of the ISS, (2) the features and values of each step of the ISS, described at a
suitable interaction level, and (3) an information processing state space of the interaction
level, where the states are learned by classifying the observed interaction feature vectors.
A link hypothesis between the observed states of information processing and mental
information processing states is important. The dissertation methodology is motivated by
the idea that observations of reading eye movement sequences can be classified and treated
as observationally-grounded user information processing states.
The dissertation investigation tests a methodology to learn properties of ISSs using
classifications of reading eye movement sequences. This methodology may be generalizable
to other observable behaviors by showing that similar relationships with ISS properties exist
for classifications of those interaction feature vectors. Cole et al. [50] may provide some
evidence for such a correlation.

80

3.5

A summary of the modeling proposal

A basic statement of the proposal is that ISS search intentions are implemented using plans
selected by the user. Each search intention and its associated plan is necessarily embedded
in the user’s current state of knowledge. The intention-plan pair is taken as the producer
of the ISS unit process. A user adopts each intention-plan because they believe the plan
to implement the search intention can produce results useful to make progress towards the
goal of the motivating task. The entire search process of an ISS can be represented as a
sequence of such intention-plan pairs.
The search intentions and plans themselves are unobservable mental states (figure 3.2
(α)). The dissertation approach is to hypothesize that the plans can be modeled as a
production process where the results of the process can be observed in the user interactions
with information objects during the ISS. In this view a plan (α) can be represented as a
process that produces observable sequences of interactions, which can be represented as
sequences of feature vectors (δ). A simple plan process model is an urn that produces a
Markov chain. The dissertation methodology develops and tests this idea.
Plans can be thought of as information processing biases that reflect strategies or tactics
of interaction with information objects. For example, a bias to scan for a concept or word(s)
rather than read text passages. This bias can be captured by supposing a probability
distribution over a repertoire of (mental) information processing states (β). The observable
interactions are expected to reflect these biases. The collection of information processing
states may be discernible over many interactions. One methodology question concerns the
discreteness of states and the size of the space of information processing states. It is possible
the information processing states in β or γ are continuously distributed. Even if discrete
states exist, the state space may be so large as to effectively preclude development of useful
predictive models built on a Markov chain process.

81

3.5.1

Models of finite Markov chains

Sequences of user behaviors, i.e. interactions during an ISS, that are produced by a search
intention plan are hypothesized to be representable as a finite Markov chain. There is evidence that web navigation activity sequences can be usefully modeled as finite Markov chains
[96, 185]. A finite Markov chain is produced by a stochastic process and can be represented
as a sequence of random variables (X1 , X2 , . . . , Xt ). More precisely, the Markov chain is
produced by a stochastic system with a finite state space of size n, S = {s1 , s2 , . . . , sn }.
When the Markov chain has no memory, i.e. transitions between states are independent of
the history of previous states of the system, the state transition probabilities can be defined:
P ( Xt+1 = sj | X1 = si , . . . , Xt=1 = sit−1 , Xt = sit ) = P ( Xt+1 = sj | Xt = sit ) = pi,j
The dissertation work hypothesizes that a Markov chain of users actions has a correspondence to user states that are indicative of the user’s information search process state.
As noted above, the information search process states are hypothesized to be connected
with the user’s knowledge and current understanding of their needs. A user tries to satisfy
their motivating task goal, and expresses that process in their search intentions and plan
implementations.

3.6

Chapter review

This chapter has been concerned with theoretical development of the ISS process model. It
has developed a general framework for analysis of the overall task session, i.e. taking in the
motivating task and the ISS to meet the motivating task goals. It has also proposed a model
of the ISS process and specifically on a unit process of carrying out a search intention with
a plan. Two models have been proposed. The first is a model of the overall task process
as a sequence of user intention-plan pairs in an ISS. The second is a model of interactions
with individual information objects in the ISS. It constitutes a production model of the
intention-plan unit of the ISS.
A couple of claims arose from the theoretical development. First, the task session is the
largest natural unit of task information behavior. In particular, it shows that task constructs
intended to address information activities with a long time scope are not definable in ways

82

that are open to observation and analysis except as observation and analysis as collections
of task sessions. This is because of the distinction between immediate intention and future
intention in the received theory of human action. Examples of such information activities
include, for example, those associated with persistent user interests, such as hobbies and
professional or personal development, such as quests or acquiring principles of learning.
This amounts to the claim that one should distinguish between assertions about properties
of task sessions and these other task constructs on the basis of observability. Individual task
sessions can be observed in ways that allow for objective grounding. The other constructs
can be empirically-grounded only as properties of collections of task sessions.
A second claim from the theoretical development in the dissertation is that the task
session is the only unit of observation of task that allows for a general description of task.
The research literature has established the existence of long range effects in task session
that conditionalize the immediate interactions with the information system. Therefore,
empirical study of interaction sequences is incomplete in a fundamental way if the analysis
is carried out within a model that cannot that account of long range effects. The validity and
generalizability of models depends on assumptions about the relationship between global
properties of the task and the local properties of the interaction units studied.
The approximate success for study of interaction sequences without consideration of the
task session properties can be expected to be closer to Markov Relational Fields for some
tasks where the influence of the independent variables on the observations is quite local.
For more complex tasks (where complexity can be understood in various ways), a greater
global impact can be expected. One consequence might be that predictions based on local
sequences will not be able to say much about the session or make reliable predictions about
tasks and task properties.
Research has demonstrated the existence of long range effects. It seems general models
of information task behaviors must therefore take account of task properties.
The ISS process model proposes a basic unit of user search action production from
which the entire ISS is generated. It claims a single search intention is coupled with a
single implementation plan and produces a sequence of actions. That action sequence is
terminated by a user decision. It is followed by another search intention or a decision to

83

end the ISS. A search query followed by processing of the results is an exemplar of such a
sequence.
Two observations can be made. First, the largest observable unit of any task construct is
the task session. Second, an empirical analysis of information search task behaviors needs to
consider the entire task session, especially if it seeks to make local predictions. Definitions
of task-related constructs should likewise be formulated with references to task sessions.

84

Chapter 4
Methodology

To advance the practical development of the models, a user information search study was
conducted. The study used a variety of realistic work tasks, which were designed to vary in
ways expected to induce differing behaviors and ISS structures. Under these varying search
session conditions, it is hypothesized that a variety of user information processing states can
be learned from observations of eye movement patterns. Likewise, it is hypothesized that a
variety of user action sequences and behaviors to make progress in service the motivating
task goal will also be observed. So it is reasonable to ask how the learned information
processing state representations may be related to the user information seeking behaviors
and the motivating tasks.
This chapter describes the methodology for the study and the data collection and processing procedures. The methodology to learn the information processing state representations is presented. The analysis procedures to explore the usefulness of the models in
characterizing different task types are also described.

4.1
4.1.1

User study
TCE purpose

The user study (N=32), “Task Cognitive Effects” (TCE), that provided data for the dissertation involved university journalism students carrying out realistic journalism tasks. It was
designed to explore the effects of motivating task types on information search behaviors.

85

4.1.2
4.1.2.1

Study methodology
Motivating task classification

The task type classification framework proposed by [118] was used to construct four motivating tasks for the TCE study (Table 4.1). The specific intention in task construction
was to design motivating tasks that differed systematically on several of the facets of task
that were shown by Li to affect search behavior. The motivating search tasks in the TCE
study were varied in the dimensions of: Product (Intellectual / Factual), Goal (Specific /
Amorphous), Complexity (High / Low), and Level (Segment / Document).

86

Table 4.1: Study task classification system (after Li 2009, modified).
Facets

Sub-facets

Values

Operational Definitions/Rules

Physical
Intellectual
Decision (Solution)

A task which produces a physical product
A task which produces new ideas or findings
A task which makes a decision or solves a

Product

Factual information
Image
Mixed product

problem
A task locating facts, data, or other similar
items in information systems
A task locating image(s) in information systems
A task locating different types of items in information systems

Goal
Quality

Specific goal

A task with a goal that is explicit and mea-

Amorphous goal
Combined goal

surable
A task with a goal that cannot be measurable
A task with both concrete and amorphous
goals

High complexity

A work task involving at least five activities

Task
characteristics

Objective
task
complexity

Moderate complexity

Low complexity

Level

4.1.3

during engaging in the task; a search task involving searching at least three types of information sources
A work task involving three or four activities during engaging in the task; a search task
involving searching two types of information
sources
A work task involving one or two activities
during engaging in the task; a search task
involving searching one type of information
source

Document

A task for which a document as a whole is

Segment

judged
A task for which a part or parts of a document
are judged

Study overview

The journalism user study was designed to explore task type influences on information search
behaviors. There were 32 participants, each completing four tasks varied within the task
classification framework. The study logged both high-level
activity, including document
1
interaction and use, and the low-level information acquisition process as revealed in eye
movement patterns. This study was developed as part of the Poodle project [125].

87

4.1.4

Participants

The participants were upper-division undergraduate journalism students recruited from the
university. They had completed at least one journalism writing or reporting class and so
they had familiarity with the types of motivating tasks used in the study. The age range
was 18-27 years old. All of the participants were native English speakers (73%) or had a
high degree of English knowledge. They had an average of 8.5 years experience using web
browsers and strong web search experience. They were informed that compensation would
be either $20.00 or $40.00, depending on their performance as judged by experts. This was
intended to incentivize them to take their tasks seriously.

4.1.5

Procedure

Each participant was given a tutorial in the form of a practice motivating task, to familiarize
them with the specifics of the data collection instruments and procedures and with the
interface they would be using during their searches. They then performed the four web
search motivating tasks described and discussed in section 4.1.6.
Participants could search freely on the web using Internet Explorer (v6). The participants were restricted to this browser because it was integrated with the custom multi-modal
action logging system developed for the study [20]. They were asked to search until they had
gathered enough information to accomplish the motivating task. After participants decided
that they found and saved enough information for the purposes of their motivating task,
their search was replayed, and they were asked to evaluate the usefulness of the information
objects they saved or saved and then deleted. An online questionnaire then asked about
their searching experience, including subjective evaluation of their performance and reasons
for that evaluation. Finally, an exit questionnaire was administered to elicit perceptions of
the search experiences, differences in the motivating tasks, and of their ability to perform
the tasks and overall search experiences. Appendix X presents the various instruments used
in the study.

88

4.1.6

Motivating tasks

The journalism work domain was used for reasons of both validity and convenience. Journalism has a relatively small number of work task types but, of its nature, the motivating
tasks can be associated with any topic. This permitted free choice of the topic. It also
enhanced the realism of the work task, thus enhancing validity.
A journalist will work on the same motivating task type with different topics, so it is
not unreasonable to think their search behaviors will reflect the motivating task type and
not be highly topic dependent. The university journalism department afforded access to
experts to help develop realistic work tasks as well as a participant pool trained for such
professional journalism tasks.
Motivating tasks were identified through interviews with journalism faculty, including
practicing journalists, about typical journalism work, focused on information search tasks
that are part of the training for professional journalists. Motivating task descriptions were
then formalized. Four of the work/search tasks were selected which could be varied according
to facet values in the motivating task classification system. The focus was on facets that have
been shown to affect search behavior, for example the objective complexity of a motivating
task and its specificity. The result of this procedure was four different motivating tasks,
presented in Table 4.2, which varied according to values of the facets in Table 4.1.
The motivating tasks as presented use the normal scenario practice of [23]. In this case,
we used the language of journalism work and the participants were given an assignment and
an associated motivating task to complete.

4.1.7

Study motivating tasks

The motivating tasks used in the TCE study follow.

4.1.7.1

Background Information Collection (BIC):

Your assignment: You are a journalist at the New York Times, working with several others on a story about “whether and how changes in US visa laws after 9/11 have reduced
enrollment of international students at universities in the US”. You are supposed to gather

89

background information on the topic, specifically, to find what has already been written on
this topic.
Your Task: Please find and save all the stories and related materials that have already
been published in the last two years in the New York Times on this topic, and also in five
other important newspapers, either US or foreign.

4.1.7.2

Copy Editing (CPE):

Your assignment: You are a copy editor at a newspaper and you have only 20 minutes to
check the accuracy of the three underlined statements in the excerpt of a piece of news story
below.
New South Korean President Lee Myung-bak takes office
Lee Myung-bak is the 10th man to serve as South Korea’s president and the first to
come from a business background. He won a landslide victory in last December’s election.
He pledged to make economy his top priority during the campaign. Lee promised to achieve
7% annual economic growth, double the country’s per capita income to US$4,000 over a
decade and lift the country to one of the topic seven economies in the world. Lee, 66, also
called for a stronger alliance with top ally Washington and implored North Korea to forgo
its nuclear ambitions and open up to the outside world, promising a better future for the
impoverished nation. Lee said he would launch massive investment and aid projects in the
North to increase its per capita income to US$3,000 within a decade “once North Korea
abandons its nuclear program and chooses the path to openness.”
Your Task: Please find and save an authoritative page that either confirms or disconfirms
each statement.

4.1.7.3

Interview Preparation (INT):

Your assignment: Your assignment editor asks you to write a news story about “whether
state budget cuts in New Jersey are affecting financial aid for college and university students.
Your Task: Please find the names of two people with appropriate expertise that you
are going to interview for this story and save just the pages or sources that describe their

90

expertise and how to contact them.

4.1.7.4

Advance Obituary (OBI):

Your assignment: Many newspapers commonly write obituaries of important people years
in advance, before they die, and in this assignment, you are asked to write an advance
obituary for a famous person.
Your Task: Please collect and save all the information you will need to write an advance
obituary of the artist Trevor Malcolm Weeks.

4.2

Motivating task classification

Using Li’s system the motivating tasks were classified using the values in each facet dimension (table 4.2).
Table 4.2: TCE (Journalism study) motivating tasks
Task

Product

Level

Goal

Complexity

BIC
CPE
INT
OBI

F,I
F
F,I
F,I

Document
Segment
Document
Document

Specific
Specific
Mixed
Amorphous

High
Low
Low
High

F = Factual I=Intellectual

BIC is a Mixed Product, because identifying “important” newspapers is intellectual,
and finding documents on the topic is factual. It is at the Document Level because whole
stories are judged; it has the Specific Goal of finding documents on a well-defined topic; it
has High Objective Complexity because of the number of sources and activities that need
to be consulted/done.
CPE is a Factual Product, because facts have to be identified; it is at the Segment Level,
because items within a document need to be found; it has the Specific Goal of confirming
facts; it has Low Objective Complexity because only three facts need to be confirmed.
INT is a Mixed Product, because defining expertise is intellectual, and contact information is a fact; it is at the Document Level, because expertise is determined by a whole page;

91

Goal Quality is Mixed, because determining expertise is amorphous but contact information
is specific; it has Low Objective Complexity because only two people need to be found.
OBI is a Mixed Product, because facts about the person are needed, but a decision
about how to frame a person’s life is intellectual; it is at the Document Level because entire
documents need to be examined; Goal Quality is Amorphous because “all the information”
is undefined; it has High Objective Complexity because many facts need to be found.

4.2.1

Distances between motivating tasks

A categorical distance, i.e the Manhattan distance, can be calculated for each of the study
motivating task pairs using the motivating task facet values. The facet values are ordered
in the intuitive way. For example, the facet value distance between BIC (Background) and
OBI (Advance obituary) with respect to Goal Quality is 2 because Goal Quality can be
Specific, Mixed, or Amorphous. Mixed lies between the other values.
The distance between two motivating tasks can be calculated as the absolute sum of the
differences in each facet:
P

dist(T aski , T askj ) =

|T aski (value(f )) − T askj (value(f ))| where f ranges over the

f

task facets.

For the purposes of exploration and analysis of relations between motivating task type
properties and their influences on search behaviors it seems reasonable to take the facet
dimensions to be orthogonal to one another. One can imagine there may be correlations
between facets and facet values. However, each dimension is a complex construct and testing
and understanding relationships is a matter for empirical investigation. Such interesting
(and challenging) work is outside the dissertation scope.
Using the orthogonality assumption, Table 4.3 shows the Manhattan distances between
each pair of motivating tasks. One can understand this as a kind of Multidimensional
scaling distance (MDS) measurement. By this measure, BIC and OBI, and BIC and INT
(Interview prep) are nearest to one another and CPE (Copy editing) and OBI are furthest
apart.

92

Table 4.3: TCE motivating task pair facet value differences}

4.2.2

Tasks

Sum facet differences

BIC, OBI
BIC, INT
INT, OBI
CPE, INT
BIC, CPE
CPE, OBI

2
2
2
3
3
5

Participant assessments of motivating task difficulty

The perceived difficulty of carrying out the task is an important property of motivating
tasks from a user-centered perspective. Research has shown that the actions taken by users
in the ISS for the motivating task differ by difficulty [126]. In the TCE study motivating
tasks varied by facets that were expected to contribute to overall task difficulty.
The participants were asked to assess the expected difficulty of the motivating task
before they began each ISS for a given motivating task. They also assessed the experienced
difficulty immediately after completing each motivating task. Figure 4.1 shows the results.
One can see (Fig. 4.1(b)) that Copy Editing (CPE) and Advance Obituary (OBI)
were judged, respectively, as the easiest and most difficult motivating tasks at the post-task
assessment. These are also the most dissimilar tasks as measured by task facet differences in
the classification system (Table 4.3). Further, the retrospective subjective difficulty rankings
match the expected contribution of facets to motivating task difficulty. For example, one
expects amorphous motivating tasks such as Advance Obituary (OBI) and Background
Information (BIC) to be more difficult than specific
motivating tasks, such as Copy Editing
1
(CPE). Recall that the Interview Preparation (INT) task is both amorphous and specific:
the first part is somewhat open-ended in finding germane experts while the second part is
to obtain the experts’ contact information. So its retrospective subjective difficulty ranking
as intermediate between CPE, and BIC/OBI is not a surprise.

93

Figure 4.1: TCE study: Participant assessed motivating task difficulty (a)Pre-task (b)Posttask

4.3

Representing the ISS as an interaction sequence

Each ISS can then be treated as a sequence of user actions. A simple analysis can be based
on the hypothesis that the action sequences are Markov chains. That is, the interactions
are linked and depend only on the previous interaction state. Markov chains to represent
searching have been used by a number of researchers [1, 224].
A simple Markov interaction chain takes account of long range influences only to the
degree that such influences are propagated from step to step. [75] emphasizes changes in
the user “situation” for each query segment. [7] can be seen to have a similar idea of user
situation expressed in the parameters for the inputs to the process that repartitions the
document relevance space. Other session search modeling approaches involve inferred user
states using Markov models, for example user intentions using a Hidden Markov Model
(HMM) [224, 82], and user belief states using a Partially Observable Markov Decision Process (POMDP) [128].
A sufficient statistic for exchangeable Markov chains is the state transitions and transition counts between the states represented in the chain [63]. For the general case of finite
state Markov chains only the initial state and the frequency of sub-chain occurrences are

94

needed [215]. So the distribution of states in a session, properties of encoding sequences of
interactions, and properties of the Markov chain graphs each provide a way to characterize
properties of the complete task session interaction sequence.

4.3.1

Using coherence

The dissertation proposes a theoretical model of a basic task session process unit. Specifically it proposes that the basic process unit is a sequence of actions produced by the user
formulating a search intent and committing to a plan to carry out the intent.
The sequences are Markov chains and are produced by sampling a space of information
processing states. The sampling procedure and the selection biases represent a black box
cognitive process that implements the plan suitably influenced by the search intent. For
example, characteristics of the concepts in the search intent, such as concreteness or abstractness will affect the eye movement pattern bias. For example, if the intent is related
to an entity a user might be biased to scan for specific words. In contrast, if the intent is to
find an abstract concept or relationship, a user might engage more sustained reading and
reflection.
These sequences can have a probabilistic or causal relationship to one another. For example, two passages might be considered as units for analogical reasoning. The dissertation
proposes that such relationships between action sequences reflect relationships between the
search intentions that initiate the action sequence production process.
Search intentions, being metal states, cannot be observed directly. While a long history
of research takes queries to be reasonable proxies for immediate search intentions, it is
acknowledged there is a gap between queries as expressed and the user’s ’true’ intent. A
substantial body of NLP-related work seeks to learn the main concept or concepts implicit
in the query. One general approach is to disambiguate and reason to the most probable
referent. Another goal is to discover ’hidden’ topics.
In order to develop a methodology to learn the task session structure, the dissertation
work builds on the ISS session process model. It develops a model of sequence coherence
related to the output of action sequence Markov chains. The idea is that these output

95

sequences express specific intentions and the actions taken by the user are meaningful, and
so coherent, by virtue of their intention. Action sequences that result from a single intent
or several related search intentions should be more coherent than sequences that cover
relatively unrelated search intentions. The dissertation model proposes that this coherence
might be measured in the pattern properties of the action sequences.
Consider two user action sequences. One is produced by a sequence of queries that
successively refine a search intention. The other is an action sequence produced by two
queries with different search intentions, for example ones that refer to different concepts.
The first action sequence can be thought to correspond to a single subtask. The second
action sequence corresponds (perhaps) to two subtasks. The coherence model hypothesizes
that the first sequence will have fewer exchangeable patterns and so a higher ’coherence’.
This proposal is similar to a sequence complexity measurement. However, it also involves
the state space properties of the sequence generator. If there are more degrees of freedom
for state transitions the coherence of related sequences will be harder to detect. The goal
of the coherence model is to judge whether two observed sequences were likely generated
by the same user intention implementation plan.
This sequence coherence model could be used to explore whether session action subsequences can be related to task session search intention units. The learned coherence model
takes two session sequences as inputs and calculates the likelihood they were produced by
the same or related intention-plan pairs. This could allow inference of hierarchical and
serial task session structure in an ISS. When the model calculates that two sequences are
likely not generated from related intention-plan pairs an intention change is implied. The
structure of a task might be learned from the observed sequences of user actions by applying
the model to all partitions of session action sequences.

4.3.2

Task structure trees and coherence

It is natural to think of describing a task session in the form of a tree graph. Two facts about
search support this intuition. First, human engagement with the world is serial. Veridical
experience is embedded in the flow of time. Second, it is observed that at a given moment
in the search process the searcher is focused on a single search goal. The search may switch

96

to other search goals as the session evolves.
The root of the tree is the leading task. The branches are a hierarchy of subtask units
that themselves may branch. Fig 4.5 shows two simple task trees.

4.4

Task structure and attention allocation

As a general matter, a task involves a strategy of coming to grips with the world and make
action on it. Strategy concerns adoption of a sequence of activities that are believed to be
efficacious to achieve the task goal.
Patterns of attention allocation are one way humans actively structure tasks. One
example is eye movement patterns in natural tasks. Even in simple tasks, e.g. making a
peanut butter and jelly sandwich, it has been demonstrated that visual attention is allocated
in a chain-like fashion with look-ahead on the objects involved in the immediate subtask
[196, 84].
Referential focus is also kind of attention allocation in tasks. In dialog, for example,
changes in referential focus often reflect meaningful structure in conversations.
The dissertation proposes that a useful ISS search process coherence construct can be
developed from changes in attention allocation. The ISS structure emerges from sequences of
attention allocation as search intentions drive the user actions expressed in search behaviors.
It is plausible the properties and patterns of attention allocation may therefore be a way to
represent essential properties of task types. They may also be able to represent aspects of
the structure of tasks. It is intuitively plausible that task types may be distinguishable by
virtue of patterns of structure over the ISS instances of the task type.

4.5

Representation of observations

The models are grounded in empirical observations of user actions and behaviors. This
section develops a basis for representing user actions from a user-centered perspective.
The central idea is to model surrogates of user information processing states based on
eye movement patterns during reading. Such movements are cognitively controlled and
guided by the user’s intentions and needs. It is natural to identify the process of interaction

97

during an ISS with the user’s information processing activities on pages made available
by the information system. A causal grounding for such information processing states is
developed. The restriction to textual information processing is a limitation. It is possible
future research can consider eye movement patterns on images and other interactions on
pages, including structural processing of page layouts.

4.5.1

Eye movements and information processing states

Eye movement is a series of actions. A fixation with little variance about a point in the
visual field is followed by a saccade, which is a rapid ballistic movement to the next fixation.
During the saccade, no signal is acquired1 by the person. One’s conscious perception of the
world is constructed from the data acquired during fixations.
Users typically address their needs in information search tasks via textual information
acquisition, i.e. the reading process. This cognitive activity involves processes of word
meaning access, sentence and phrase parsing, and text comprehension. Reading eye movement patterns have long been studied [161]. Research has established relationships between
eye movements and eye fixation properties and semantic and cognitive processing states. It
is known that eye movements are cognitively controlled [72].
Eye fixations can be connected directly to cognitive states. The eyes remain fixated
until the meaning of the word is acquired [72]. Properties of word meaning, for example
concreteness, correlate with the fixation duration [161]. This fits well with the understanding of task performance as a user-driven activity and with spreading activation models of
memory access to concept representations.
In a basic sense, every search interaction is an instance of concept use. The connection
from reading eye fixations to concept access grounds the claim that user information processing states can be learned and represented to some degree using observations of reading
eye movements. One can hypothesize that such information process states, individually and
in sequences, can be correlated with the user’s experience of search.
Search tasks are user-driven and eye movements are user-directed in service of task
1

There is still some question about this claim. It is clear, however, that at most very little signal may be
acquired.

98

needs. It is therefore also plausible that observed information processing state sequences
can be correlated with the plans employed by users in service of the motivating task goal.
Several models of reading eye movement patterns have been developed. They disagree
mostly about the object of the cognitive control. [141] proposed that words were both the
perceptual unit for cognitive processing and, as orthographic objects, the targets for the
next saccade. This approach to handling the saccade programming problem is the source
of a widely-accepted class of models, for example as developed by [176]. These models have
been able to explain observed fixation duration and word skipping behaviors.
Cognitive capabilities of individuals appear to have some effect on reading behaviors.
[90] measured working memory and then asked participants to read and summarize a text
passage. They used a clustering technique on eye fixation patterns and found four clusters
associated with reading the text. Cluster features were analyzed. Distinguishing features
included the probability of refixing on a previous sentence vs. look-ahead to an upcoming
sentence, and attention to structural text, such as headlines and subject headings. High
working memory participants produced the best summaries and were biased to process structural text. This work demonstrates a cluster-based approach using eye movement patterns
to infer differences in information processing of a text. It shows that individual differences
exist in eye movement patterns and provides evidence for the influence of cognitive strategies
on reading patterns to acquire textual information.
There has been research into the potential to apply reading models to personalize information search systems. [31] developed an eye tracking-based model of information acquisition processing by distinguishing ‘reading’ vs. ‘skimming’ based on the separation
of succeeding eye fixations. Using the labeled regions of text, they found better implicit
query expansion performance when using words from ‘reading’ fixation sequences. [48] found
session-level relationships between eye movement patterns and high level task features, such
as number of documents examined and document use. Other work demonstrated the existence of individual differences plausibly related to task domain knowledge [45]. [95] show
that eye fixation patterns, scan paths, query characteristics, and clicking action behaviors
change over the course of complex search sessions. They also demonstrated task effects on
the relationships between these user action behaviors.

99

[48] implements a line-oriented reading eye movement pattern classification system based
on [175] to calculate cognitive processing features of user reading eye movement patterns
during information search tasks. The same eye movement analysis system is used in the
present work and explained in greater detail below.
Rich and grounded observations of the world can permit development of robust representation models. The foregoing shows reading model-based measurements can be taken as
a rich observational basis for this learning work. Reading eye movements are also attention
instances directed by the user and are causally-connected to the information acquisition
process. This makes plausible the claim they are observable aspects of the information
acquisition process and can be correlated with hidden mental states. These mental states
can be the stuff of a cognitively-informed user-centered model of the search task session
process.

4.6

Reading eye movements

Eye movement patterns in service of reading have long been studied [161]. A number
of results have been established that relate eye movements and properties of fixations to
semantic and cognitive processing states. There is no question eye movement is cognitively
controlled and competing models of reading eye movement patterns disagree mostly about
the object of the cognitive control. [141] proposed that words were not only the perceptual
unit for cognitive processing but also, considered as orthographic objects, the targets for the
next saccade. This approach to handling the saccade programming problem is the source
of a widely-accepted class of models, especially as developed by [174]. These models have
been able to explain observed fixation duration and word skipping behaviors [176]. The E-Z
reader model is described further in section 4.7.1.
The fixation duration plays a key role in linking eye observation to cognitive states
because it is indicative of the cognitive processing required to establish the meaning of
the word or phrase. This cognitive access overhead is consistent with spreading activation
models of word and concept access. The typical time range to acquire word meanings is
150 ms - 300 ms [177].

100

The dissertation adopts the terminology used in many reading studies to describe features of reading sequences [22]. A region is usually defined as a word or phrase.
Regression A fixation to the left of the last fixation in a reading sequence (for left-to-right
languages).
First fixation The duration of the first fixation in a region.
First-pass time The time spent in a region from first entering it until first leaving the
region with a saccade in any direction.
Regression path time The time from first entering a region until moving the eyes beyond
(rightward) the region. If there were first-pass regressions, this will include time spent
in earlier regions following the regression.
Regression probability The percentage of regressive (leftward) eye movements out of a
region; usually limited to first-pass regressions.
Total time The sum of all fixations in a region, including secondary fixations.
Several cognitive effort measurements can be calculated on a reading sequence:
 Simple counts of number of fixations and their durations.
 The total area covered by the reading sequence (the reading length) during the first

pass time.
 The reading speed during the first pass time.
 The perceptual span of reading
 The number of regressions

Further background and operationalization of these measures follows.

4.6.1

Reading speed and reading length

Reading speed is a simple ratio of the amount of text processed (the reading length) by the
total time to process the text. It is clear that if the text is easy to read and it does not require

101

additional reflection, the reading speed will be greater than for passages with less familiar
words, words used in less frequently encountered senses, and when additional reflection
is required to comprehend the concepts involved. Difficulties in sentence parsing are a
confounding factor, although they do relate often to conceptual processing of sentences.
For the dissertation, it is assumed that most of the excess processing is associated with
lexical access and conceptual acquisition and access.
Reading speed is associated with several components in the description of reading eye
movements. First there is the time for lexical acquisition of the word(s). The minimal
time for lexical access is 113 ms [177]. It has long been known that the less familiar the
word and more difficult the concept the longer it takes to lexically access the meaning of
the word. One example of word concept lexical access effects is access to the meaning of
a concrete word vs. one that makes an abstract reference. It has been shown that the
reading process will not execute the next saccade from the current fixation until the current
cognitive processing is complete [71]. So the fixation duration excess above 113 ms is an
indicator of the cognitive processing required to establish the meaning of the word, and the
meaning of the word in context.
Calculations of reading length and reading speed are operationalized as absolute measurements over the eye movement reading sequence. The reading length in the data sets is
calculated as the length of text covered in the reading sequence measured in display pixels.
It does not take account of font sizes etc. Reading speed is measured in pixels/ms. Notice
that reading speed is not the rate of reading eye movements over text. A regression does
not increase the total number of display pixels processed so reading speed declines with
regressions. Reading speed is a function of the duration of the individual fixations in the
reading sequence, the spacing of the fixations (perceptual span), and the regressions in the
reading sequence.

4.6.2

Cognitive effort measurements related to longer reading sequences

For reading sequences containing four or more fixations, two derived cognitive effort measures were calculated, perceptual span and regressions. Both of these measures are derived
directly from reading fixation sequences and relate to higher order cognitive processing.

102

4.6.3

Regressions

A regression is a fixation that returns to a portion of the text already processed in the
reading sequence. This is calculated only when there are enough fixations in the reading
sequence to rule out the case of a landing error for the first fixation. Saccade targeting errors
are typically Gaussian and sometimes the error will be large enough that the orthographic
target is not in the foveal area. It is not unusual to observe a rapid re-indexing fixation to
the beginning of the region, say a word, that was intended for processing. The number of
regressions, the regression path time, and the fixation duration of the regression fixation
have been associated with the difficulty of reading passages, resolution of ambiguous (sense)
words, conceptual complexity of text, parsing difficulties and the reading goal [168, 163].
A regression measurement is operationalized as a count of the regression fixations in a
single reading sequence consisting of at least four fixations.

4.6.4

Perceptual space of reading

Perceptual span is the amount of text one takes in at a time. This is roughly the spacing
of subsequent fixations in a reading sequence. There is evidence for perceptual span as
a low-level bottleneck for reading speed [116]. [162] has reported that perceptual span
shrinks during conceptually difficult passages. Perceptual span seems to describe a measure
of intake exploiting both the foveal and a portion of the parafoveal region, for example the
right-hand side during reading of common European languages.
There is evidence that perceptual span is associated with basic human cognitive processing properties. This evidence comes in studies of reading in different orthographic systems.
It has been demonstrated that the spacing of fixations during the reading of Chinese was
about three characters, roughly one character to the left of fixation and two to the right
[92, 197]. Studies of non-logographic systems showed differences between phoneme-encoded
systems, such as Hebrew, and character-based systems common with European languages
including English and Dutch. [153] showed that bilingual Hebrew and Dutch speakers
shifted their perceptual span when switching between reading the two languages. When
reading Hebrew the perceptual span was 5 characters or so and in Dutch it was closer to

103

9. What is striking in these results is that across the orthographic systems, approximately
the same number of concepts can be expressed.
[37] have tested a neural-decision making model for programming the next saccade on
reading data from [152]. They found that their model, called LATER, was able to explain
the relationship between increasing fixation duration and the location of the next fixation,
as a function of competing cognitive mechanisms. Increasing fixation duration is presumed
to be due to semantic processing requirements, for example word familiarity. Word familiarity affects fixation duration. More familiar words are accessed more quickly and so
the mechanism reaches the next saccade decision threshold sooner. If the saccade decision
point is reached in the labile period, the system can reprogram the pending saccade. If the
decision point is reached outside of the labile period, then the saccade programmed when
the fixation started is executed. In reading, the proximity of the current fixation to the previous fixation reflects the bias of the programmed saccade. That is, the programmed next
saccade will be of about the same length as the previous saccade. So one can see that word
skipping, etc. is the result of the rate at which the meaning of the current fixation target is
accessed and the saccade bias set by the reading fixations already expected. One can also
note this mechanism describes a Markov process where the next fixation location depends
on the previous fixation proximity unless the lexical access to the word happens fast enough
to reprogram the saccade. The reprogrammed saccade jump length is cognitively controlled
and can depend on various semantic and orthographic properties. For example, one may
recognize the word from the first characters, or the next word is recognized or inferred to
be just a connector.
These competing mechanisms can be used to understand perceptual span is not just a
simple derived first-pass measure, but an observation of a cognitive processing feature of
the eye movement data. When the fixation is made to the next word a preprogrammed
saccade is set that is influenced by the previous fixation in the reading sequence. Suppose
the next word is associated with a familiar concept. The fixation duration will then be
shorter and the point at which the saccade can be reprogrammed is reached sooner. If the
period is short enough, then the saccade can be reprogrammed by the guiding cognitive
process. For example, a prior commitment to a short saccade, set because the previously

104

processed words were close together because the concept was unfamiliar, can be changed
to a long saccade when the passage becomes conceptually less difficult. In another case,
when the currently-fixated word is unfamiliar and one has already shrunk the perceptual
span, the probability of making a short saccade is greater. This implies that handling the
semantics of a difficult passage in context will result in extra cognitive effort which can be
seen to be expressed in the average saccade distance during the fixations covering the text
passage. So decreasing perceptual span is expected to correlate with unfamiliar words and
conceptually difficult passages.
For the dissertation, perceptual span is is operationalized as the amount of text taken
in one time in the left-to-right reading segments during the first pass time. Notice that a
regression segments the first pass into left-to-right units. Perceptual span is calculated by
first selecting the units with four or more fixations and then taking the average of the span
between those fixations in display pixels.
Since regression fixations may occur, a reading sequence can have several left to right
subsequences.

X X

(

perceptual span =

j

|fi+1 (x)−f i (x)|)/n

i

m

where:
f is a fixation in a reading sequence,
fi (x) is the fixation x coordinate. For languages where text is arranged top down the y
coordinate would be used.
m is the number of left to right reading subsequences in the reading sequence, and
j = 1, ..., m.
n is the number of fixations in the left to right reading subsequence and i = 1, ..., n − 1.
The reading/skimming distinction made by [31] is similar to the definition of mean
perceptual span, however the reading sequences are classified in a different way.

4.6.5

Summary

Perceptual span and regressions are used with the basic measurements on eye fixation
observations and reading sequences to make a number of features that describe textual

105

aspects of the user’s cognitive processing of pages during an ISS. The derivation of the
page-level feature set is described below.
Eye fixations can be connected directly to cognitive states via access to concepts. The
eyes remain fixated until word meaning is acquired. Research in reading eye movements
fits well with the received views of task performance as a user-driven activity and with
spreading activation models of memory access to access concept representations.
At the most basic level every search interaction is an instance of concept use. The
connection from reading eye fixations to concept access grounds the idea that observations
of reading eye movements can be used to learn user information processing states. One
can hypothesize that such information process states, individually and in sequences, are
correlated with aspects of the user’s experience of search. Insofar as search tasks are userdriven and eye movements are user-directed in service of task needs, it is also plausible
that the observed information processing state sequences can be correlated with the plans
employed by users in service of the motivating task goal.

4.7

Processing the eye movement observations

Eye trackers use cameras to detect the pupils and then apply reverse geometry calculations
to determine the person’s gaze direction. This can be translated to a point on a display.
A fixation is repeated gazes at a location. The stream of gaze points are grouped using an
algorithm to identify fixations. An eye tracking session produces a log of fixation observations, each consisting of a display point and a duration. These fixations are used to make
a representation of the user’s system interactions during an ISS.
Figure 4.2 provides a high level view of the eye movement observations and their processing. The upper part shows a typical observation of the eye fixation pattern on a page.
It is taken from the user study analyzed in the dissertation. The lower part of the figure
summarizes the basic eye movement observation processing procedure. Briefly, the logged
fixations are filtered to identify the lexical fixations, i.e. a fixation with sufficiently long
duration to allow information access via reading. These are grouped into sequential units
of reading for further analysis and modeling. The next section discusses the reading model

106

used to group the lexical fixations into sequences of reading.

Figure 4.2: Grouping eye fixations into reading sequences

4.7.1

The E-Z Reader reading model

The E-Z Reader model is a cognitively-controlled, serial-attention model of reading eye
movements [170, 154, 156, 155, 176, 175]. It takes word identification, visual processing,
attention, and control of the oculomotor system as joint determinants of eye movement in
the reading process. The E-Z Reader model is a processing model and is based on the
assumption that reading is a cognitively-controlled process where the saccade to the next

107

word is programmed while the person is cognitively processing the text available in the
currently attended fixation. The saccade programming has a labile stage. If the next word
is recognized during this labile stage, the programmed saccade is canceled and a saccade to
the next word is programmed.
There is a distinction between high acuity text in the foveal region and progressively
lower acuity text in the parafoveal region. It has been shown that some text information can
be extracted from the parafoveal region and frequently enough information is acquired to
permit programming of the next saccade target that is several words away from the current
fixation. The role of textural information available in the parafoveal region has been studied
extensively, [21, 93, 98, 127, 140, 153, 172, 210]. There is evidence for recognition and use
of word length [97], orthographic features, and some semantics such as the predictability of
the word in context [65] and morphological features [66].
Processing of text during fixations has been shown to take place in several stages. Orthographic recognition takes place in about 40 ms, followed shortly thereafter by phonological
recognition (˜60 ms), and then lexical processing, which takes at least 113 ms [177]. There
is a labile lexical processing period, from 113 ms to 168 ms, during which the next saccade
programming can be reprogrammed with a new saccade target. After that labile period,
the pending saccade will be executed after the cognitive processing is completed. This is
one way in which observations of eye movements can be connected with the semantics of
information processing. Eyes remain fixated during the lexical processing processing period
independently of the stimuli, for example even if the word is removed [72]. The next saccade
takes place only after this cognitive processing is completed. It has long been known that
familiarity and conceptual complexity of the text processed is positively correlated with the
fixation duration [164].
EZ-Reader has had good success in predicting saccades and is a leading model. It is
claimed the model provides an explanation of the moment-to-moment reading process when
linguistic processing is running smoothly [176]. A limitation of the model is noted by [22].
EZ-Reader and related models are lexical processing models and do not address higher
orders of semantic processing, such as text comprehension and text structure integration.
In connection with the ISS process, these semantic connections are needed to connect eye

108

movements to learning events and knowledge acquisition by the user.
Even though EZ-Reader is a lexical model, there is empirical evidence of relationships to
comprehension [163] in the observation of fixation duration excesses for passages with more
difficult comprehension and for anaphor resolution. Some aspects of conceptual processing
can be captured in perceptual span measurements. Domain knowledge might be connected
to EZ-Reader through the LATER neural-decision model [37] which suggests localized intense attention expressed as lexical processing captured in perceptual span measures can
be connected with word familiarity in a language model for a knowledge domain.
The E-Z Reader model is well-suited to the dissertation work in that it allows eye fixations to be grouped into sequences of information processing. These fixation sequences can
then be measured and grouped to characterize information processing states. The fixation
duration properties, as modeled by E-Z Reader, and measurements on patterns of movement
are indicators of some aspects of higher level cognitive processing. This provides a basis
that is potentially rich enough to allow an input of information processing states to model
processes that involve high level cognitive processing which are undoubtedly influential in
the information search behaviors observed in an ISS.

4.7.2

Grouping fixations into reading sequences

A line-oriented reading model based on the E-Z Reader model was implemented to process
the location and duration of participant eye fixations logged by the Tobii eye tracker. A
filter to identify fixations with a conservative threshold duration of 113 ms was applied to
select eye fixations that were likely to result in word meaning acquisition. The reading
model was then used to group these lexical fixations into reading sequences. These reading
sequences are taken to represent the user’s experience of information acquisition via reading.
A conservative threshold of 113 ms was used. Fixations that likely resulted in word
meaning acquisition were identified and grouped into reading sequences.
The analysis in the dissertation is based on representing each task session as a contiguous
collection of reading sequences. These sequences are hypothesized to represent the user’s
experience of information acquisition due to reading during the search session.

109

Figure 4.2 shows the basic data logging flow and application of the reading model to
group the fixation sequences. The Tobii eye tracker records repeated gaze at a location
and applies a velocity-grouping algorithm to identify fixations. The Tobii fixation log is
then processed to group the lexical fixations into reading sequences. The reading model
is then applied to group the fixations. An isolated lexical fixation is called a scanning
sequence. A sequence of eye fixations that are spaced close enough to be taken as a processing
several words is called a extended reading sequence. Examples of extended reading sequences
are highlighted in green. In the rest of the dissertation reading sequence may refer to a
single scanning or extended reading sequence. Reading sequences refers to the collection of
scanning and extended reading sequences. Momentary drop-outs in eye fixation observations
that occurred within otherwise identifiable reading sequences were handled has blinks and
not taken to interrupt the reading sequence.
It is assumed that each fixation deemed lexical is an instance of reading rather than
processing an image or a ’mindless’ stare. This assumption is an idealization and a limitation
of the modeling effort. Image processing fixations can be identified with appropriate efforts
and one direction for future research is to distinguish image and textual processing to make
richer interaction models.

4.8

Creating the information processing state space

Many previous approaches to learning ISS-level behavior features treat the challenge as a
regression problem from an input space of session performance, and/or user property and/or
task property features to a label embedding space. The target embedding space is usually
presumed to have semantic characteristics that relate to user experience or search context
characteristics.
The relationship between the page processing eye fixation features is unknown as it
involves high-level cognitive processes that are not yet understood. Consequently, the dissertation work does not explicitly learn a regression function f : χ → B. Instead, a simple
unsupervised learning approach is adopted. The procedure is to first create collections of
session observation vectors. Then unsupervised learning is applied to find a representation

110

of hypothesized user information processing states during an ISS. Note that this learned
representation does not represent the actual mental information processing state space of
the user. Rather it represents the the cognitive output driving the information acquisition process, i.e. the goal-directed eye movements. This can be thought of as a black box
interface representation of information processing states as observed. It is important to
emphasize there is no one-to-one relationship between the labels learned for these states
and a user’s actual information processing state space.
While a one-to-one relationship between the learned states and the actual information
processing states cannot be asserted, it is reasonable to say some representation of actual
information processing states does exist. The connection between eye fixations and eye
fixation patterns in reading and actual information processing states supports this claim.
With sufficiently rich observations of user attention, e.g. enhanced vectors of eye movement
and other user attention features, it is not unreasonable to think the learned space can
be connected to aspects of distinct actual information processing states. Further work,
beyond the scope of the dissertation, is needed to discovery correlations between the learned
representation space and the user’s information processing state space.
To make practical progress on the main problem, a number of simplifications were made
in developing the learned information state representation. The main simplification is use
of only eye fixation and eye movement patterns. This is a basic limitation of the research.
One direction to enhance this basic attention representation is to add other observable
dimensions of user goal-directed activity. One can add pupil diameter measurements, which
have been shown to correlate with decision-making events [67]. Motor actions, like pointer
device movements and actions, and system interface activity, such as patterns of browser
tab use, can be plausibly associated with intentional and information processing states.
The general framework described can accommodate these additional dimensions of attentional observation as features in the vectors. It is plausible these may lead to significant
improvements in the fidelity of the learned representation.
Another limitation of the approach in the dissertation is methodological. Unsupervised
learning is inherently probabilistic. There is a causal generative model that underlays the
actual user ISS process. A model linking hypothesis is required to be able to discover that

111

generative model. This is more difficult than discriminating between alternative generative
models. Unfortunately, at this time there are no concrete proposals for specific generative
models of information processing. IR research in this area is nascent and is still at the stage
of exploring for framework principles, for example in utilitarian approaches [76].
The dissertation methodology is intended as a practical direction to explore ISS properties, especially for task types and associated properties, from a cognitive perspective. The
hope is that user mental state representation of ISSs can be related to a user’s experience
of the ISS and their experience of making progress towards their motivating task goal. It
may also contribute to proposals for generative ISS process models.

4.8.1

Labeling information processing states

The method begins with a two step process to label information processing state representations. First, a rich representation of user reading during an ISS is constructed. For each web
page processed by user study participants, a vector of eye movement pattern features is constructed as a representation of the information processing activity on the page. Then, the
collections of page information processing vectors are clustered to discover distinct groups.
These groups are taken to be types of page-level information processing. These information
processing classes are the learned ’information processing states’.

Figure 4.3: Part of a user session represented as a sequence of learned information processing
states.
The information processing states are used to represent sequences of ISS actions by the
user. 4.3 shows a portion of an ISS with a state sequence of 5,3,8,5,6,4,2,4,5,3,8. This
says the user was in the ’information processing state’ class labeled as 5 when interacting

112

with the page followed by the state labeled as 3 on the next page, and so on. One way to
represent an ISS session is to make a sliding n-gram window over the sequence of labeled
user page states, which are the user session actions. For example, a 4-gram (with step size
of 1) of the example sequence would be [5,3,8,5 ],[3,8,5,6],[8,5,6,4 ], ...
The states as labeled are also used in the Pólya urn model of the ISS process. The
states are taken to be dimensions in a state space, each with a probability of being selected
in a draw from the urn. Pólya urns are state sequence generators. Urns with different
state spaces will produce different collections of sequences. A sequence is generated by
successive draws from the urn. Two urns might differ in the number of state dimensions
or the particular collection of state dimensions. They can also differ in the probability
distribution of the states. That is, two urns could have the same state dimensions but with
different state selection probabilities.

4.8.2

Feature development

Using the grouped sequences of reading fixations, a total of 26 eye fixation and eye movement
features were developed and measured on each page the user interacted with during a task
session. Apart from the basic features, counts of fixations and durations, the other features
related to groupings of fixation sequences into segments of reading.
A total of eight features make up the cognitive representation for each reading sequence
as described above. Only lexical eye fixations are used, i.e. fixations that lasted long enough
to allow a person to understand the meaning of a word. It is assumed that all lexical fixations
in the log are instances of such semantic processing. However, it is likely that some of these
fixations may have been associated with images or ’mindless reading’. This presumption of
semantic processing for the fixations is a limitation of the dissertation work.
The reading sequence measurements on each page are used to fashion a vector of 26
features. The features include raw counts of fixations and the derived cognitive measurements, such as reading speed and perceptual span. They also include statistics for several
partitions of the page reading sequences. There are features relate to statistics of all reading
sequences on the page. Other features involve statistics of only ’long’ reading sequences,

113

which have four or more fixations. Yet other features measure properties of the reading
sequence in the page with the most fixations (shown in Table 4.4).

Table 4.4: Page-level reading features for clustering
Level

Code

Description

Page

nFix

The number of fixations on the page

Page

sumFix

Total fixation duration on the page

Page

nSS

The number of scanning sequences

Page

durSS

The duration of the scanning sequences

Page

nFixRS

The number of fixations in the extended reading sequence

Page

durRS

The duration of the fixations in the extended reading sequence

Page

medianNRS

The median number of fixations in the extended reading
sequences on the page

Subset

nLongRS

The number of ’long’ (numFix >4) extended reading sequences
on the page

Subset

durLongRS

The total duration of the ’long’ extended reading sequences on

Subset

medianNFixLongRS

The median number of fixations in the ’long’ extended reading

Page

nRRS

The number of regressions in extended reading sequences on

the page
sequences on the page
the page
Subset

nRLongRS

The number of regressions in the long extended reading
sequences on the page

Page

meanPS

The mean perceptual span in the extended reading sequences

Page

RL

The total number of pixels covered by extended reading

Page

meanRL

on the page
sequences in the page
The mean of the reading length for the extended reading
sequences on the page
Page

RSpeed

The total number of pixels processed/total fixation duration

Page

medianFixLADE

The median of the lexical portion of the fixation duration

Subset

medianMaxFixDur

After selecting the longest fixation in each extended reading

Subset

medianLADELongRS

Median number of fixations in ‘long’ extended reading

Local

nFix LRS

Number of fixations in the longest extended reading sequence

Local

durFix LRS

Total fixation duration for the longest extended reading

Local

medianFixDur LRS

Median fixation duration in longest extended reading sequence

Local

maxFixDur LRS

Max fixation duration in longest extended reading sequence

Local

RL LRS

Reading length of the longest extended reading sequence

Local

RSpeed LRS

Reading speed for the longest extended reading sequence

Local

PS LRS

Perceptual span for the longest extended reading sequence

sequence, calculate the median
sequences

sequence

114

The goal for feature development is to make a rich representation of the user’s reading
activity in order to model the user’s page level processing reading states. The features relate
to multiple levels of the construct and structure of the page. Page level features are those
that collect all of the cognitive effort data for the page without filtering. For example, the
total number of fixations uses all of the fixations on the page. Extended reading sequences
refers to all sequences on the page that have at least two fixations. Various descriptive
statistics provide other page-level features. For example the mean of the reading length
is calculated using the collection of extended reading sequences on the page. Features at
the subset level involve a filter to select only some of the eye fixation interactions on the
page. This level of feature indicates a different aspect of user processing. For example,
it is reasonable to think that a user making more long reading sequences on a page is in
a different information processing state as compared to a user who is scanning or briefly
sampling disparate parts of the page. A feature that calculates a statistic about the long
reading sequences captures part of this aspect of user attention and cognitive activity. The
local level is a feature associated with a particular reading sequence, for example just the
longest reading sequence on the page. The idea is that such distinguished reading sequences
might be especially indicative of the user’s behavior or intent.
Overall, the goal is to make a representation that is both rich and distributed in different
ways that might describe the user’s goal-directed cognitive engagement with the page. Such
a distributed representation permits, in principle, the production of richer models of the user
and is more likely to reflect the range of information processing states. As input for model
learning, a distributed representation allows one to make models with greater capacity in the
sense of Vapnik [202]. Models with greater capacity are welcome when complex phenomena
are to be modeled, as is presumably the case for cognitive models of users.

4.8.2.1

Feature collinearity

Some of the features are related to one another in their calculation. So there is a risk of
collinearity in the feature set. Nonetheless, for the modeling purposes of the dissertation
each feature is taken to be a distinct measurement. This is justified because one cannot know
how a person experiences a page, consciously or not, when processing information. Further,

115

there is no obvious grounds to privilege types of reading sequences, e.g. all extended reading
sequences vs. just the long extended reading sequences, as inputs to model learning. The
relative contribution of any single feature to the process of making progress in the ISS is
unknown. An assumed relationship between features, however intuitive, must be recognized
as a hypothesis about a person’s cognitive state mechanism as it relates to the process of
reading information processing during search. It is desirable to avoid such unnecessary
hypotheses and so the risk of feature collinearity is accepted at this stage of investigation.
MDS/SVD approaches can be applied to representations of features, however evidence for
collinearity in the modeling space does not translate cleanly to the relationship between
variables in a causal model [147]. This is a consideration in the selection of higher level
ISS modeling procedures. Ensemble techniques, including Random Forests [26, 18], have
advantages over other techniques, including HMMs, in this regard.

4.8.3

Clustering

After the page features were calculated the pages were aggregated. The cognitive states
were then calculated using an unsupervised learning technique.
The eye fixation logs were processed to identify each reading eye movement sequence and
calculate the cognitive effort vectors as described above. These cognitive effort vectors were
grouped into sequences at the level of pages and a variety of statistics calculated, resulting
in 26 features listed in Table 4.5.

116

Table 4.5: Page cognitive effort modeling features

Page-level Reading Features

Number of fixations on the page
Total fixation duration on the page
Number of single fixation (’scanning’) sequences
Duration of the scanning sequences
Number of fixations in the reading sequence
Duration of the reading sequences
Median number of fixations in the reading sequences
Number of ’long’ (numFix ¿4) reading sequences
Total duration of the ’long’ reading sequences
Median number of fixations in ’long’ reading sequences
Number of regressions in reading sequences
Number of regressions in the long reading sequences
Mean perceptual span in the reading sequences
Pixels covered by reading sequences (reading length)
Mean of the reading length for the reading sequences
Reading length/total fixation duration (reading speed)
Median of fixation duration’s lexical portion (LFDE)
Median of the longest fixations in the reading sequences
Median LFDE for the long reading sequences
Number of fixations in the longest reading sequence
Total fixation duration for the longest reading sequence
Median fixation duration in longest reading sequence
Max fixation duration in longest reading sequence
Reading length of the longest reading sequence
Reading speed for the longest reading sequence
Perceptual span for the longest reading sequence

These observations were then clustered using K-mediods using the pamk provided by
the R fpc package. The pam algorithm is described in [100]. The basic idea is to identify
K representative observations in the data set rather than K “central” points that partition
a Euclidean space. These observations are hypothesized to be exemplars of each cluster

117

’class’. Taken as a group they are proposed as a representation of the input data structure.
The procedure is to first find a set of k-medoids. Then k clusters are formed by calculating
the sum of differences between the observations and each of the k-mediods and partitioning
by minimizing the differences. For the dissertation work, the initial mediod set was not
specified. The pamk algorithm uses a Monte Carlo bootstrap to find a ’good’ initial mediod
set. Then observations are ’swapped’ between the clusters to find a local minimum in the
overall dissimilarity objective function.
This focus on comparison and partition of the observations by differences has several
advantages over the K-means clustering approach. It is more robust because it minimizes
a sum of observation dissimilarities during the partitioning process rather then the sum of
squared Euclidean distances. So it does not make additional assumptions about the metric
of the feature space.
The number of clusters are estimated by calculating the optimum average silhouette
width for the clusters. this silhouette width is a representation of the proposed cluster
that captures the compactness of the cluster. It is connected with the gap statistic to
assist in finding the number of clusters that gives both good separation in the space and
compactness[194].
The pamk results provide an estimated number of clusters that describes the structure
in the data. It is interesting to see if another clustering technique will find a similar number
of clusters. This provides a check that there really are identifiable groups of eye fixation
patterns relating to page interactions. For the dissertation work the learned number of
pamk clusters was compared with the number of clusters suggested by applying hierarchical
agglomerative clustering using the R pvclust package[182]. Ward’s method was used with
bootstrapped p values to infer the optimal number of clusters by calculating the uncertainty
in the hierarchical cluster analysis. The p-values range from 0 to 1, and are calculated by
multiscale bootstrap resampling. The p-value indicates the strength of the support for the
existence of the cluster.
There are minimal assumptions about the calculation of differences in each of the feature
dimensions as required for comparing measurements. However, the clustering techniques
used are not model based and so make no assumptions about the distributions in the

118

data. The result of this procedure is the creation of a state space, where each cluster
label corresponds to a state. This is taken to be a representation of states of (reading)
information processing, as indicted in the (γ) state space in figure 3.2. Using these states,
each interaction in an ISS can be labeled and sequences of reading information processing
states calculated for an ISS.

4.9

Learning task structure from segment coherence

In information search, we observe user actions as a series of query segment sequences.
The theoretical task session search process model hypothesizes a one-to-one correspondence
between a user’s immediate search intent and a query segment. This section develops an
approach to learning the structure of a search task session from observations of the user’s
search actions without consideration of the specific content engaged during the search. It
develops an action sequence coherence measure based on action sequence pattern. This
measurement can be applied to the observation sequences for each candidate task structure
to find the task structure that maximizes the overall coherence for the task.
Subtask and search intent are conflated in the following. This is for convenience, however
there are also interesting questions about the distinctness of these constructs as a practical
matter.
A distinct issue concerns search intents that do not generate observable actions. A
silent intent can be seen as a subtask that immediately spawns another subtask. These
types of intentions make be close to or part of in-session planning and related to tactics and
strategies. In the following subtask and search intent are used interchangeably and further
classification of intentions is not addressed.

4.9.1

The task session forest

Each task tree is a tree graph with some number of branches. An observed search task
session is a sequence of query segments. It may also include some additional actions, like
manipulation of the interface or some calculations or tools used to produce the task goal
solution. For this work, task sessions are taken to be only sequences of query segments.

119

This is a significant simplification. The general case raises a number of interesting questions
for future research, notably the degree to which action patterns in these other task session
activities differ from search.
A task tree can have only a finite number of branches because there are a finite number
of observed leafs, i.e. query segments. Alternative trees can be drawn from the same time
series of leafs. Each tree represents an alternative task structure. There can also be only a
finite number of silent search intents/subtasks, so it follows there exist only a finite number
of candidate task trees for representations of any task session.
The complete collection of such trees is the task session forest for the user task session.
The problem is to learn the structure of the user’s task session. The task is to select the
tree that best fits the observed sequences of query segment actions. The dissertation work is
directed at learning a process that can calculate a coherence measure to allow tree selection.

4.9.2

Tree coherence

The ISS process model claims a query segment has essential properties that are derived
from the mechanism by which it is generated. The generation of a query segment from a
single search intention coupled with an implementation plan is a production process that
grounds the coherence of the sequence of query segment actions.
An ISS can be represented as a sequence of observed query sequences. In the general
case, this is not a complete representation. The user might work with information gained
during the session, for example by doing some calculations, or be distracted by a tangent not
really in the leading goal, etc. In the idealized representation considered in the dissertation,
the ISS can be said to be piece wise coherent. This permits assignment of a coherence
measure to the overall ISS. From that representation one can learn to calculate an overall
coherence of an ISS tree. One approach is to learn on ISSs that are already segmented into
piece wise coherent units. Search query segments and their associated interactions can be
seen to provide such a segmentation.

120

4.9.3

ISS coherence and tree selection plan

Coherence of the ISS as a whole can be investigated by starting with the assumption that
a (somewhat idealized) ISS is everywhere locally coherent in its basic units. It is assumed
the user is focused and works to implement their successive search intents. They do not get
distracted, or switch to another task, etc.
One tree in the ISS forest describes the ISS subtask (and successive search intent) structure. The problem is to select that tree based on user action observations. A selection
desiderata is maximal whole tree coherence in the ISS forest.
The tree coherence can be calculated from coherence calculations of different segmentation of the query segments in the ISS. That is, one can calculate the the coherence of a
tree as some function of the coherence of the tree branches, i.e. the proper subgraphs of
the tree. Simple addition of the subgraph coherence measures is a reasonable place to start,
but it is apparent that other functions could be used. The next section lays out in more
detail the relationship between the coherence of query segments and a ISS tree structure.

4.9.4

Query segments and ISS subtask tree structure

The query segments are the observations of the task session. They correspond to the
succession of immediate search intents that were carried out by the user. There is often
some hidden structure in decision making and intention in an ISS. For example, a user might
decide to break the ISS into subtasks and then implement a subtask with one or more search
intention plans and associated actions. It is easy to imagine the difference between a simple
known item search task and a complex search. The former may be trivially expressed by
the ISS tree in fig 4.4. A complex search will have more than one subtask and probably
some hierarchy of subtasks.

121

Motivating Task - Get to JFK on time.
Subtask 1 - Is flight AA103 on schedule?
QS1 ”AA.com AA103 departure”
5->2
Figure 4.4: A trivial search task where the observed state sequence is 5,2.
The observed query segments might be the result of different ISS subtask tree structures,
for example those depicted in Fig 4.5. The subtasks that give rise to the query segment
actions can be identified with immediate search intents. In fact, the subtask construct and
an immediate search intent may be indistinguishable. The query segments are leafs in the
tree and consist of the sequence of actions taken for the search intent, for example a sequence
of observed eye movement information processing states 5,2.
The query segments have a sequence of actions represented in some fashion. In Fig 4.5
they are represented as cognitive effort cluster classes for the sequence of pages examined.
Suppose coherence, measured by relative exchangeability, tends to be greatest for actions
that result from a single search intention. One expects that the coherence of QS1 and QS2
taken together in the lower tree in Fig. 4.5 will often be greater than QS1 and QS2 in the
upper tree.
This idea can be pushed to hypothesize that the coherence of action sequences is related
to the subgraph to which the action sequences belong. The length of the tree branch is
related to the number of search intentions that influence the sequence of actions in query
segments. Although the query segment actions result from a single search intention, those
actions reflect the way the immediate search intention is related to the higher level subtasks.
This is what is meant by saying the immediate search intent (and the query segment actions)
are conditionalized by the list of subtask intentions (or goals).

122

Motivating Task - ”What is the best flight to Berlin next month?”
Subtask 1

Subtask 2

Subtask 3

QS1

QS2

QS3

4->2->4->4->5

1->3->2->3

3->3->5->1->2->4

Motivating Task - ”What is the best flight to Berlin next month?”
Subtask 2

Subtask 1
QS1

QS2

QS3

4->2->4->4->5

1->3->2->3

3->3->5->1->2->4

Figure 4.5: Tree 1 and Tree 2: Two possible structures for a ISS. The observed state
sequences are the leafs.
In figure 4.6 QS1 and QS2 are not the result of the same search intent. However, their
immediate search intent is conditionalized by a common subtask. One can hypothesize that
QS1 and QS2 taken together will have a coherence that is intermediate to that expected
for the subtask structures of fig 4.5. The proposal hypothesizes that the coherence of the
observed action sequences is a function of the subgraph that covers the observed sequences.
One can also hypothesize that a user in an idealized ISS where they always act with
focus on their search intentions with no distractions, etc., will carry out a sequence of actions
which is coherent for the entire task. It follows that the tree with the greatest coherence is
the most likely representation of the structure of user search intents by which they carried
out the ISS.

123

Motivating Task - ”What is the best flight to Berlin next month?”
Subtask 1

Subtask 4

Subtask 2

Subtask 3

QS3

QS1

QS2

3->3->5->1->2->4

4->2->4->4->5

1->3->2->3

Figure 4.6: Simple task 3 with observed state sequences at the leafs.

4.9.5

Identifying ISS subtask structure using coherence n-grams

The suggested ISS subtask tree forest tree selection procedure has several implementation
challenges. For example, what is the appropriate function to combine coherence measurements in an ISS subtask tree? There are a number of interesting questions for future research
into task structure exploration with coherence modeling.
The dissertation investigates whether a model can be learned to distinguish presumed
coherent sequences associated with search intentions. The sequences associated with query
segments can be assumed to generally be expressions of a single search intention. While the
dissertation does not work out a procedure to recover the detailed task structure in the ISS
as outlined above, the learned model could potentially be applied during an ISS to identify
local ISS subtask structure and indicate some types of specific session events.
Local task structure, i.e. sub-graphs in the ISS subtask structure tree, are hidden in
contiguous sequences of query segments. Query segments are related to these structures because they are hypothesized to align with search intent-plan pairs. The dissertation presents
a model of the search intent plan generation as urn-process generated action sequences.
A successful model could have practical impact. Consider a task session window sliding
over the observed user actions with the coherence model applied to calculate a coherence
value for the window. For reasonably short windows, each window will be likely lay within
a query reformulation sequence [122]. When the query reformulation state changes, the
coherence of that window will be diminished. So, window sequence coherence values indicate

124

changes in the query reformulation state and would allow inference of ISS subtask structure.
One attraction of this approach is the capacity for in-session measurement by comparing
the evolving session sequence observations using the current sequence window and recent
windows. This analysis does not require a whole session for application but can none the
less be potential used to predict whole session properties, including properties of the user’s
task.
The procedure of selecting the best tree description of the evolving ISS subtask structure
is to generate the entire forest of alternatives. Each alternative can be considered as a
hypothesis about the structure of the session. The best hypothesis can be selected in a
Bayesian hypothesis testing approach using the coherence tool to calculate the most likely
match.
An n-gram model of query reformation states or search intent class from sequence coherence has potential for practical in-session application. The practicality of such a system will
be sensitive to the number of hypotheses to test. To achieve effective personalization it is
highly desirable to reach a point of making structure predictions that differentiate between
a small number of hypotheses early in a session. A great deal of further work is needed to
work out the machinery of this idea and test to see if it can overcome practical challenges.

4.10

Research questions

The main practical goal of the dissertation is to develop a foundation for a cognitive representation of the ISS. A number of simplifications are made in the methodology and it
is important to investigate whether a reasonable representation can be constructed and
whether the resulting ISS representations have the capacity to discern ISS structure and
aspects of the motivating task type. Consequently, the dissertation addresses three research
questions:
RQ1 Can common patterns of user information processing in ISS interactions be identified?
RQ2 Do sequence action classes exist in information seeking episodes or portions thereof
that have regular pattern properties?

125

RQ3 Are such sequences of behaviors with regular pattern properties associated with motivating task type?
RQ1 concerns the ability to learn correlates of user information processing states from
observations of user intentional actions. If a collection of distinguishable groups cannot be
identified then the approach will not have the capacity to identify information processing
plans by the user using eye movement patterns. In such a case, it is still plausible that
information processing plans exist but are carried out at a higher cognitive level.
A negative answer to RQ1 would be unfortunate. Eye movement patterns are observable and can connect causally with (mental) information processing states. If those observed
pattern states cannot be grouped and connected with plans, some other approach will be
needed to ground a cognitive computational ISS model. Some other observable with a relatively direct causal relationship to a cognitive process involved in information search would
be needed. It is hard to think of such a candidate. If no structure is found in the distribution of eye movement patterns, RQ2 and RQ3 cannot be addressed using the methodology
and the dissertation’s contribution is limited to the theoretical model development.
RQ2 is an inquiry into the degree to which instances of action sequences can be classified
by their pattern properties. That is, are there distinctive pattern characteristics? This has
practical import in that well distinguished patterns will be easier to identify in application
settings. Such classifications of sequences might be related to the search intentions of the
user.
RQ2 is addressed by building models using the observed user cognitive action classes
as inputs and examining whether there are pattern properties in the observed sequences
of user actions in an ISS that match intuitive structural subunits of an ISS. Specifically,
pattern properties of action sequences after a query are examined. Queries might be taken
to instantiate specific search intentions and so implementation plans may be expected to
vary by the type of search intention. RQ2 concerns the hypothesis that different plans will
generate sequences with distinguishable pattern properties. This is tested by looking for
sequences that are statistically unlikely as would be expected if specific plans are consistently
employed to make process in the ISS. Another check is to see if a model can be learned that

126

distinguishes presumed coherent sequences (query segments) from random sequences.
RQ3 relates to the question of whether ISS structure properties, as observed in behavior
sequences, can distinguish between motivating task types. Specifically, are there differences
in the behavior sequences between tasks of different types? This is a test of the models developed in the dissertation in that differences in behavior sequences are taken to be indicative
of different plans to implement ISS search intentions. The literature shows motivating task
type affects search behaviors. ISS structures that reflect sequences of behaviors might also
be affected by motivating task type.
RQ3 is addressed by showing that ISSs can be distinguished by the action segments and
observed behaviors. The differences between the frequencies of observed sequences are then
calculated by task and examined to see if task pairs can be distinguished from one another.
To address these research questions, the first step is to organize the interaction observations logged in the user study and learn a representation of the user’s ISS actions. Then,
models of these classified actions are learned to build representations of the ISSs from the
user study logs. Finally, the results are examined to see if tasks and task properties can be
distinguished.

4.11
4.11.1

Analysis procedure
Data observations used in the analysis

The observations in this paper is based on representing each task session as a contiguous
collection of reading sequences, representing the user’s experience of information acquisition
due to reading.
Activity sequences for all the users across all tasks for each user study separately (N=109
usable task sessions) were pooled and analyzed. Further the sequences of page interactions
were coded to identify each cognitive effort feature vector with a page type. The page type
code book used the scheme of [79]. There are four page types, distinguished by their format
and by whether the user has already seen the page. The codes were: query search engine
results page (a query SERP) (Q), content page (C), including those accessed from a SERP
and those reached by click-though from another document, Returns to a SERP (L) and

127

revisits to a previously examined (in the query sequence) content page (M).
For the dissertation work, the query SERP pages allow for segmentation of the observations as sequences of interactions for a query. As explained earlier each query can be taken
to be a search intention expression. The production by the search plan for that intention
can be taken to be the sequence of observed interactions starting with the query SERP and
ending when the next query SERP is encountered or the ISS ends. Note that a revisit to a
query SERP could be selection of a another results page for the same query.

4.11.2

Eye fixation processing: segmenting the eye fixation logs

The journalism user study had 32 participants, each performing four tasks. The tasks were
presented in a blocked Latin Square Design. A custom system managed the presentation
of the tasks. Due to technical issues, there were a total of 109 usable task sessions, i.e. ISS
observations.
Chapter 4 described the reading model used to segment the eye fixation data collected
for each ISS in the user study. The model accepts a sequence of eye fixation measurements
and produces a segmentation of the fixations into non-overlapping reading sequences. A
reading sequence may be a single fixation or a sequence of fixations. Some fixations are
not members of a reading sequence because they were of insufficient duration to be lexical.
If these too-short fixations are within a reading sequence they were not used in feature
calculations. It is assumed that sufficiently long fixations were lexical. As noted earlier this
is a limitation because a user may have been looking at an image or possibly engaged in
mindless Reading.
The basic idea in the algorithm is that reading proceeds as sequences of fixations where
the succeeding fixation is within the region previously looked at. This region may be step
wise extended to the right, provided the new fixation is within the ride-hand-side parafoveal
region. Fixation regressions to any point in the previously fixated text are allowed. It is
possible to extend the text region on the left hand side by regression to the beginning of the
reading area. Saccade landing positions are subject to Gaussian errors around the target.
Research has shown that although the center of the fixation may be above or below the text

128

center line, people read just the line of text and not words above or below [89].
The result of the process is to group the fixations that constitute a reading sequence
instance. A reading sequence ends when a fixation is not in the right-hand-side parafoveal
region and is not a regression to a point in the line of text already swept out in the reading
instance.
This reading sequence chinking model used is derived from the E-Z Reader eye movement
processing model [176] in that it uses the parameters of lexical and saccade programming
timing thresholds and the saccade jump limits set by parafoveal processing. In short a
jump beyond the parafoveal window, or a regression saccade outside the previously processed
region of text will break the current reading sequence. The model takes account of Gaussian
landing errors, which are characteristic of saccades.
Isolated lexical fixations provide some semantic information, limited to that available
in the foveal (in focus) visual field [165]. Fixations in a reading sequence provide more
information both because information is gained from the larger parafoveal region [172],
and because of the richer semantic structure available in compositions of text, including
sentences, paragraphs, etc., as compared to isolated units of several words. Importantly,
some of the types of semantic information available through reading sequences may be
crucial for satisfying of user task requirements.
The foveal region is operationalized by taking the Tobii default of 35 pixels for projection
of the foveal radius on the display. The display projection of the parafoveal annulus is
taken to extend from 35 pixels to 120 pixels. As suggested by the E-Z Reader model, the
algorithm distinguishes between the left hand side of the parafoveal region and the right
hand side to model the left-to-right reading pattern of the English text presented in the
studies. Nonetheless, the algorithm is not specific to English and should generalize to many
languages with similar orthographic encoding, i.e. non-logogram or phonetically-encoded
glyphs.
The algorithm for the model is line-oriented and does not address the problem of smooth
transitions in reading blocks of text. Specifically, the model codes the action of reading two
consecutive text lines as two reading sequence instances. The algorithm does not distinguish

129

the type of presentation of reading content. For example, changes in font size or other
characteristics are not considered. A headline is treated the same as a line of text in a
paragraph. Differences in font sizes, etc. impose a limitation on the interpretations of
reading speed and perceptual span because these are calculated in terms of display pixels
rather than character glyphs.
To summarize, the reading model algorithm inputs are successive fixation locations and
their duration. The model outputs a classification of the sequences of fixations as members of
an extended reading sequence, or as isolated lexical fixations called Scan fixations. Reading
behavior that might typically be described as scanning, that is a disciplined processing of
text by skipping some of the text and reading phrases, would be modeled as a series of
short reading sequences by the algorithm. Reading eye movements for each ISS were then
represented using the succession of reading sequences.

4.11.3

Clustering the ISS observations

The observations of user behaviors in each ISS consists of some number of pages, each
represented as a 26 reading feature vector. The observations from all of the usable ISSs
were aggregated and then clustered.
Clustering is an unsupervised learning approach. It uses some partition-based algorithm
with the goal of decomposing the input data into a collection of disjoint sets. The number of
sets is usually an input parameter, but can be tied to some criterion about the relationships
between the members of the sets. In this way the optimal number of clusters, i.e. the
solution with the best separation of groups, can be inferred.
For the purposes of clustering, the features were taken to be independent of one another.
As mentioned in chapter 4, several of the features might be expected to be collinear if only
their measurement procedure is considered. It was suggested that this argument is flawed
because it rests on a speculative hypothesis about the relationship of the measurements to
cognitive objects. The following expands this line of reasoning a bit to justify the treatment
of the vectors in an orthogonal space for clustering.
Eye movements in reading are fully-specified by fixation duration and location. As has

130

been shown, cognitive effort can be correlated with fixation duration via at least word familiarity and sense disambiguation. Since duration is a direct observation, one can say cognitive
effort measured from duration is a primary observation. Reading speed and perceptual span
are measured by first calculating properties of reading sequences of observations, involving
both location and duration of the constitutive fixations. Such reading sequence features
might therefore be taken to be derivative. That said, the use of reading sequences in that
derivation is already theory-laden by virtue of using the reading model to identify the (probably) lexical fixation and segment the fixations into reading sequences. Nonetheless, there
is solid empirical research evidence for these derived features as characteristic of cognitive
measurement that is not merely a sum or function on the individual fixation properties. It
is reasonable then, to treat the derived measures of reading speed and perceptual span as
observationally independent from the number of fixations and fixation duration measures
in analysis and exploratory modeling. A similar argument can be made for regressions.
There is another argument for the independence of the various features. The order of
primacy of the measurements, e.g. from fixation location and duration to inferences such
as perceptual span, does not translate into claims about the reliability of inferences from
the measurements as dependent variables to the hypothesized independent mental variables
(i.e. mental states and mental processes). Both the direct and inferred observations of eye
movements are unanchored in the same way because one does not consider the details of the
underlying mechanisms of both the cognitive control of eye movements or the details of the
involvement of high-order cognitive processing in text comprehension, much less knowledge
acquisition. So even though a fixation duration is a more basic measurement as compared
to reading speed and perceptual span, all of these measures are on the same footing when
they are used as indicators of mental states, given our current understanding of the physical
mechanism of cognition. A similar line of reasoning explains why the learned information
processing states from the clustering of attention feature observations cannot be mapped
1-1 into a space of actual cognitive information processing states.
The number of clusters in the page representations can be inferred from clustering and
then making calculations of the quality of cluster separation. A robust variant of k-means
clustering, k-medoids clustering, was applied using the pamk function provided in the R

131

package fpc. K-medoids clustering proceeds by partitioning around an exemplar in the cluster rather than the calculated center. The optimal number of clusters is determined in the
pamk function by calculating each cluster membership silhouette, which describes how well
separated members are from other clusters, to find the optimal compactness. A Manhattan
metric was used because the feature dimensions are independent and incommensurate cognitive measurements, as explained above. The analysis used standard k-means clustering
and the k-mediods method. The clusters calculated using pamk were used as the state labels
in making session sequences for the main analysis.

4.11.4

Information processing state analysis

Each learned cluster is taken to represent an information processing state and the label for
the cluster is used to denote the state in the session sequence representation, i.e 3,6,1,2,
etc. The most important features contributing to cluster membership can be investigated.
This may provide insight into the way in which a user allocates attention during the ISS.
Each cluster class is understood as a textual information processing type. Feature importance was calculated for each cluster by making a multi-class Random Forests model
[26] for each of the learned clusters. After creating and tuning the random forests model
the cluster feature importance was calculated using the mean decrease in accuracy and the
Gini coefficient [190].
This allows one to learn which features have influence in the cluster membership. From
4.4 one can see these features can be associated with levels of page processing. For example,
the number of fixations relate to a page level in the sense that the location or relation of a
fixation to another fixation is not considered. In contrast, a statistic for a specific sequence
of fixations, the longest fixation sequence on the page, is a local measurement. So one can
also ask about which levels of page processing are contributing to the cluster membership.

4.11.5

ISS state sequence processing

The clustering analysis identifies information process states used during the ISSs. The sequences of states reflect user compositions of information processing actions. An important

132

point for investigation is to examine the properties of sequences, including their frequency
distribution, because it is plausible that patterns of use, or even distinctive sequences, may
be characteristic of the type of task for the ISS. Distinctive or frequent sequences might be
observable indicators of a user implementing particular information processing plans. These
sequences, or compositions of the sequences, may be observable indicators of information
search tactics and strategies.
start

4

S

/

5

/

5



/

w

3

/

/

6

/

3

/

4

/

6

J

1

/

/

4

4

/

1

/

6

/

8

/end

8


1

1

2

3

4

5

6

7

8

0

0

0

1

0

1

0

0



0


0

2

0


0

0
0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

1

0

0

0

0

1

0

0

0

0

0

0

1

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0



1

2
0


0 3

0 4


0 5

1 6

0 7
0

8

Figure 4.7: Representing an ISS: State sequences, state models and transition matrices
Figure 4.7 shows three ways to represent an ISS using the state labels applied to each
interaction page. The sequence of states in the session can also be represented as a state
transition model and a transition matrix in a state space. In the example, the user employed
6 of the states in the 8-dimensional state space.

133

5

/

/

3

O

8




2

/

6

4

1

S

1

2

3

4

5

6

7

8

0

0

0

1

0

2

0

0





1

0 0 0 0 0 0 0 0 2




0 1 0 0 0 0 0 0 3


3 0 0 1 0 0 0 0 4


0 0 1 0 0 0 0 0 5




0 0 1 1 0 0 0 1 6


Figure
Aggregating
ISS
representations
0 4.8:
0
0
0
0
0
0
0 7
0

0

0

0

0

0

0

0

8

The state transition model and transition matrix representation are convenient ways to
represent aggregations of sessions. Figure 4.8 shows the aggregation of the session in figure
4.7 and an ISS with a session state sequence of 4,1,6,3,2. One can see a new state, 2, has
been added as well as a transition from 6 to 3. The transition matrix has been updated
with the total transition counts.
This shows a convenient way to represent tasks as aggregates of all of the ISSs where
users performed a task. Implementation of a task type may vary by the sequences of
information processing states employed for individual search intention plans and/or in the
pattern of plans used to make progress towards the motivating task goal.

4.11.6

Tasks as transition matrices

One way to compare tasks is to compare the transition matrices normalized by the total
number of state observations in the aggregated ISSs for the task. This allows the similarity
of two tasks to be calculated by comparing their respective normalized state transition
probabilities. A simple calculation is to take the sum of the absolute differences over all of

134

the state transition pairs.

4.11.7

Tasks as N-gram distributions

Another way to compare tasks is to count the frequency of subsequences in the task ISSs.
N-grams were calculated on each ISS using a rolling window of one step. The counts of the
sequences were then normalized against the frequency of all subchains of length N in the
user ISSs for the task. It is easy to see this approach is looking at the frequency of traces
of length N in the state transition model for the task. This is a measure of structure within
the graph representation of the task. Tasks with different structures will have different
subchain frequencies.
If one task type as compared to another task type has a different general pattern of
implementation by a user, one expects to see differences in the distribution of the frequency
of information processing state sequences. For each sequence N-gram in an ISS, the number
of observed N-grams in the ISS were counted. These frequency counts were aggregated
by task for N-grams of length 2-4. The observed N-gram frequencies in the tasks were
normalized by the total number of subsequences observed. Then the similarity of task pairs
was calculated:

sim(T1 , T2 ) =

X

|T ask1 (normF req(subsequencei )) − T ask2 (normF req(subsequencei ))|

i

(4.1)

where i is a particular subsequence. In a session sequence, e.g. 4.3, a tri-gram sequence
would include 5,3,2 and its frequency in that session is F. Recall that a task is represented
using all of the user sessions for that task, so the frequency of 5,3,2 is the count looking
over all of the sessions.
These sequence calculations of user behavior task similarity allow for investigation of
task relationships in an abstract space representing user information processing activities.
That is, for behavior sequences of a given length, the distance between two tasks can be
taken to be the difference in the patterns of processing states, calculated as above (Eq. 1).
The locations of tasks in this space of information processing patterns can be fixed.

135

With a collection of tasks, one can calculate the distances between various task pairs and,
assuming a Euclidean space, application of the triangle inequality principle fixes task locations. This geometric interpretation suggests several questions. For example, is there
task grouping in the processing activity similarity space? Another is to ask whether the
task locations in the information processing pattern space have consistent projections of
task ordering onto linear scales. A particularly interesting direction is to explore for task
location relationships that correspond to task facet properties. Observed regularities might
allow for prediction of the locations of new tasks categorized using Li’s scheme.
To summarize, this analysis can be employed to formulate and test hypotheses about
the relationship between task and task type observations in the ISS process space and the
representations of tasks in the categorical space of task types. In particular distances in
the categorical space measured in terms of task facet value difference, can be compared
with differences in tasks in the ISS space represented using the information processing state
sequences.

4.12

Chapter summary

In this chapter a description of the theoretical framework for modeling was provided. That
framework identifies how cognitively-grounded user-centered models of ISSs can be developed from empirical observations of user search actions. Crucially, the framework depends
on an assumed linkage hypothesis between eye-movement patterns and mental (reading)
information processing states. Motivation for such a link hypothesis exists in the research
literature.
A representational model was then presented of the ISS process in terms of a general
view of IIR as a causal model. The specific modeling work of the dissertation developed and
presented in chapter 3 is elaborated as a Pólya urn process. This process model produces
sequences of user actions as Markov chains. These Markov chains are associated with the
search intention plans of the user during the ISS.
In the context of information search sessions, these ISS process units have the property
of being coherent. That is, it is hypothesized that they ’hang together’ because they are

136

produced by a single search intention and plan. A model to calculate a value for this
property given a sequence is developed and related to the overall problem of ISS subtask
structure. The model is tested to determine if it can recover the presumed session structure
reflected in query segments. The relative success of such a model points to a direction for
future work to extract task session structure and learn if task sessions of the same task type
have similar structures. It also has potential to be applied in-session as a way to predict
the user’s task type and task properties.
The next chapter implements these models and analyzes the results of applying these
models to the user study. The user study was designed to implement task with varying properties that induced different information searching behaviors. Previous work has confirmed
task-related behavior differences at several levels [47, 124, 48, 123, 126, 125, 119, 121, 50].
If the session behavior representation methodology is successful then it should be able to
reflect regular patterns of user actions and distinguish tasks in the user study data set.

137

Chapter 5
Results

5.1

Introduction

This chapter takes the results of the user study to build and test the ISS models. The
presentation is organized around the dissertation research questions:
RQ1 Can common patterns of user information processing in ISS interactions be identified?
RQ2 Do sequence action classes exist in information seeking episodes or portions thereof
that have regular pattern properties?
RQ3 Are such sequences of behaviors with regular pattern properties associated with motivating task type?

5.2

Participant performance and behaviors by task

As a general background, basic counts and measurements of participant search behaviors in
ISSs are presented by task in table 5.1. These measurements are the average ISS completion
time (time on task), the average number of web pages visited, the average number of queries,
the average number of information sources (distinct web domains), and average number of
search sources (search engines and site-search facilities).
Table 5.1: Participant task-session behaviors
ISS behavior
ISS duration (min)
Pages visited
Sources used
Queries
Search sources

BIC
mean (var)
17.79 (6.42)
47.77 (18.91)
16.91 (6.94)
17.41 (10.19)
3.14 (1.89)

CPE
mean (var)
8.03 (6.04)
15.41 (9.85)
7.05 (3.51)
5.86 (4.68)
1.50 (0.86)

INT
mean (var)
10.80 (6.44)
28.82 (14.86)
11.05 (4.72)
9.36 (5.49)
1.64 (0.79)

OBI
mean (var)
12.65 (5.78)
39.77 (18.41)
15.95 (6.73)
15.55 (9.54)
2.73 (1.93)

F (p)
9.75
17.09
14.44
10.27
6.63

p
<.001
<.001
<.001
<.001
<.001

138

The results show basic measurements of user behaviors can be distinguished by task.
The BIC (Background Information) task involved the greatest amount of time and was
significantly different from the other tasks. By all of the other measures, BIC involved the
most activity and in some restricted sense, the most effort. CPE (Copy Editing) stands out
has having the fewest pages visited, sources used, and queries issued. The tasks involving
the most sources and queries were BIC and OBI (Advance Obituary).
These results are consonant with intuitions about the task’s facet differences. One
expects that tasks involving intellectual production and amorphous task goals will elicit a
broader search in the collection, both in the dimension of the amount of content examined
and in the diversity of sources that produced or aggregated the content.
The ranking of the tasks in these aggregate behavior dimensions mostly agrees with
the user post-task difficulty assessment ranks. The exception is the post-task difficulty
assessments of OBI and BIC. Participants consistently judged OBI to be the most difficult
task.

5.3

Results relating to RQ1

RQ1 Can common patterns of user information processing in ISS interactions be identified?
The methodology chapter described the data logged during the journalism user study ISSs
and the process by which the eye fixation logs were processed to partition the observations
of each ISS into reading sequences. RQ1 relates to the cognitive actions taken by a user
during an ISS. To address this question, one must first investigate whether the reading
feature-based representation of the cognitive activities of the user leads to distinguishable
actions. Recall that the unit of observation is each page in the ISS represented as a vector
of 26 reading eye movement features.
Reading eye movement patterns are taken to reflect aspects of a user’s information
processing state during an ISS. The following examines whether there is evidence for the
existence of classes of reading eye movements at two levels of processing during an ISS. The
first is an analysis using page segmentation. It uses the reading eye movement observations
that cover a single page in the ISS. The next level uses query segments to aggregate the

139

reading eye movement observations. That is, it is based on the reading eye movements
from the beginning of the SERP (search engine results page) to the end of the page before
another another query is entered or the ISS ends. These levels are intuitive structural units
of an ISS.

5.3.1

Can one distinguish states of actions based on the reading feature
vectors?

One way to address RQ1 is to inquire into the classification of the reading feature vectors.
In particular, can a relatively limited number of groups of reading vectors be distinguished?
To avoid assumptions, an unsupervised learning approach was taken. The input was
observations of a total of 3261 pages in 128 ISSs. After calculating the page reading feature
vectors, the vectors were then aggregated.
Two clustering techniques were applied. Figure 5.1 shows the result of applying k-means
clustering to the page reading feature vectors and then calculating the then calculating the
within groups sum of squares. This is a measure of model fit as a function of the number of
clusters used to classify the input data. One can see there is a rapid improvement in model
fit until the number of clusters is 11 or 12. Then there is a smooth decay and little model
fit improvement after ˜20 clusters.

140

Figure 5.1: Page reading feature vectors model fit by cluster number.
As described in chapter 4, a robust variant of k-means clustering, k-medoids clustering,
was also applied. K-medoids clustering proceeds by partitioning around an exemplar in the
cluster rather than the calculated center. The pamk function provided in the R package fpc
was used with a Manhattan metric because each of the feature dimensions is taken to be
independent and incommensurate cognitive measurements. The optimal number of clusters
is determined in the pamk function by calculating each cluster membership silhouette, and
applying the gap statistic [194] which describes how well separated members are from other
clusters, to find the optimal compactness.
The result of applying the pamk function to the page reading feature vector data resulted
in an optimal partitioning into 11 clusters. That agrees well with the k-means model fit
scree plot results in the observed transition from rapid improvement in model fit to smooth
but incremental improvements.

141

5.3.2

Clustered Page types

Using a 11 cluster fit for the page reading feature vectors, the k-mediods pamk function
Manhattan metric classifications are shown in table 5.2. It shows the number of pages for
each cluster. One can see the pages are not evenly distributed, with clusters 6 and 10 having
the fewest members. Clusters 1, 7, 8 have the most members.

Cluster label
Number of members

Table 5.2: Cluster sizes (k-mediods)
1
2
3
4
5
6
7
824 407 394 538 755 215 951

8
827

9
433

10
105

11
683

The clustered cognitive effort feature vectors can be analyzed to understand how the
classes differ from one another. Recall that the page-level reading sequence features were
grouped by level of attention allocation on the page (page, subset, local ). For each cluster
one can ask which of these groups of features is most influential in determining the class
membership. In the theoretical framework presentation given in chapter 4, there is a link
hypothesis that takes the clustered reading eye patterns as indicative of cognitive information processing states. The levels of attention allocation provide some motivation for this
idea.
Table 5.3 shows the relative feature importance in the clustered classifications of the
page reading pattern features. Each cluster class can be understood as a textual information
processing type. The feature importance was calculated for each cluster by making a multiclass Random Forests model [26] for each of the learned clusters.
The page (black), subset (blue), and local (purple) feature levels are grouped together
in the table. The top six features in each class are highlighted in red. The values are the
decrease in accuracy that occurs if the feature is ignored, so a higher value indicates a feature
that contributes more to the accuracy of the forest prediction that an observation belongs
to a class. The mean accuracy contribution is shown in Accuracy. The Gini coefficient
relates to the proportion of decision trees affected by changing the feature value, that is the
number of trees that change decisions [190].

142

Table 5.3: Page feature clusters: Important features
numLongRseq

medianPageMaxLFDE

medianLFDE

readingSpeed

durRseq

numRseq

durSseq

numSseq

totalFixDur

numFix

25.40

12.19

11.41

10.81

13.74

9.39

27.98

5.44

13.83

5.15

26.05

20.07

17.74

17.91

24.39

25.93

1

10.60

17.60

29.56

11.74

12.72

8.45

13.48

32.15

17.52

8.08

8.19

15.63

13.06

12.69

10.49

15.83

11.38

16.22

2

10.70

10.36

14.77

10.02

8.65

8.13

9.39

7.78

23.88

6.53

21.07

5.74

22.12

17.82

12.72

14.81

23.93

28.75

3

5.32

9.43

9.01

9.05

9.45

6.65

12.19

10.11

4.50

6.94

5.35

11.13

9.82

11.45

6.92

3.54

9.72

4.20

4

6.40

11.31

11.69

11.06

14.04

12.73

12.29

12.80

35.12

24.11

21.43

11.86

17.22

20.48

11.31

14.37

14.53

23.44

5

18.22

10.81

29.53

20.13

5.94

6.06

8.06

12.58

17.76

6.52

16.34

6.12

28.55

15.50

7.94

8.08

18.90

21.90

6

16.66

12.06

17.44

12.24

8.38

6.64

10.22

7.67

16.64

9.32

10.66

5.56

19.59

10.02

11.80

11.79

14.07

18.32

7

6.57

11.70

12.02

11.49

12.78

11.18

16.10

12.07

31.48

30.94

15.62

9.70

18.67

20.04

11.59

16.68

16.19

23.49

8

5.98

10.55

11.04

10.29

8.97

6.70

10.57

14.14

12.94

32.12

14.61

12.14

16.02

16.73

7.53

6.87

12.34

12.51

9

5.34

9.24

9.02

8.86

18.30

17.05

15.44

8.53

9.59

8.29

5.54

8.55

7.39

8.60

7.10

8.01

7.90

8.35

10

1.63

6.86

5.61

5.75

9.34

6.86

7.63

2.90

3.08

0.00

2.17

2.95

2.54

2.61

2.88

1.18

8.38

2.50

11

11.22

12.14

19.14

12.42

11.70

9.67

12.64

16.95

44.11

27.43

29.93

11.75

30.04

24.26

20.82

31.13

25.21

40.55

Accuracy

111.39

173.16

356.20

192.71

157.81

113.32

135.70

204.49

416.21

202.80

174.68

126.97

367.76

304.54

94.15

127.71

286.74

380.29

Gini

Table 3: Important features for the cognitive effort states: Page clusters

durLongRseq
9.28

11.94

pageMeanReadingSeqLength

readingLength

pageMeanPerceptualSpan

numRegRseq

medianReadingSeqFixations

medianLongRSeqFixations

longestRseqReadingSpeed

longestRseqReadingLength

longestRseqMaxLDFE

longestRseqMeanLDFE

longestRseqFixDur

longestRseqNumFix

medianMaxDurLongRLFDE

7.40

12.90

8.46

8.85

12.13

16.20

10.43

12.55

7.61

17.89

13.45

15.59

11.82

29.50

23.10

16.37

3.82

9.94

4.60

7.42

10.18

8.14

8.40

12.49

5.91

13.55

9.41

10.32

9.21

12.16

11.00

10.30

26.02

12.83

17.63

13.61

18.45

15.33

13.22

12.68

4.47

10.18

8.39

6.38

8.03

12.71

14.41

11.91

7.70

15.45

7.55

10.77

12.76

20.80

11.97

12.82

18.65

16.90

11.76

10.75

13.36

14.63

11.70

12.52

39.83

17.00

11.99

12.52

13.25

16.46

14.05

11.38

6.35

15.22

7.37

16.17

16.14

14.60

10.65

10.03

1.80

8.13

3.25

7.72

9.33

7.91

1.88

7.62

30.91

14.74

13.01

11.46

12.72

22.12

14.93

12.93

242.31

161.02

124.26

135.43

166.50

242.33

254.00

179.21

numRegLongRseq

longestRseqPerceptualSpan

[ April 15, 2015 at 18:41 – classicthesis version 0.1 ]

9

143

Looking first at the mean accuracy and Gini coefficients for the relative feature importance, one can see quite a bit of agreement. It shows that page level features are most
important on average. The numbers and duration of fixations in reading sequences and the
total reading length on the page were most discriminatory. The higher level reading features
of perceptual span and regressions, which might relate to aspects of conceptual processing,
have some influence. For the Mean accuracy decrease, the total number of regressions in
reading sequences on a page is the sixth most discriminatory feature. It is less discriminatory, the 12th most important, in the Gini measure. The page mean perceptual span is the
7th most discriminatory feature in mean accuracy, and 11th in the Gini measure. However,
when just the longest single reading sequence on a page is considered, perceptual span is
the 5th most discriminatory feature for mean accuracy and the 8th by the Gini measure.
Turning to the individual clusters, only cluster 3 is completely dominated by page level
features. Three other clusters (1, 5, 8) have one non-page level feature in the top six
influential features. Multiple subset and local features are especially influential in clusters
2 and 7. Subset level features have low influence in clusters 3, 4, 5, 8, 9, 10. Local level
features have strong influence in clusters 2, 4, 5 , 9, 10. For cluster 5 only one Local level
feature has influence, but it is the most influential in the cluster membership.
Cluster 11 is notable in that no one feature is particularly influential. In the table
the eight most influential features for this cluster are highlighted. It is interesting that
they all relate to fixation duration, especially the duration of the lexical processing, and
reading speed. Cluster 11 is a significant fraction of the total observations (11.2%). The
absence of dominance by a small subset of features in the RF model suggests cluster 11
has complexity, so it is interesting to note the influence of lexical processing indicators at
the fixation level. The higher level text processing and comprehension-related features, i.e.
regression, perceptual span, and reading length, are all of low influence.
There are 26 features in the observation vectors. Twenty-two of the features are among
the six most discriminatory features for at least one of the clusters. Only four of the features have little influence in any of the individual cluster models: durSseq (the total scanning
sequence duration on a page), numSseq (number of scanning sequences), medianMaxDurLongRLFDE (the median of the maximum excess lexical fixation times for the long reading

144

sequences on the page), and longestRseqReadingLength (the reading length for the single
longest reading sequence on a page).
While there is ample room for interpretation and speculation, one can see that most
of the clusters are distinguished from one another in feature dimensions and not just by
values within a set of features. This is true at both levels of classification, i.e in the raw
feature vector space and for the levels of page processing features. These results provide
evidence for a rather small number of reading feature vector classes. Further, the discovered
classes distinguish a variety of differences in the information processing of the pages in
the user study ISSs. This supports a claim for distinctiveness in the clusters in ways that
resonant with the idea that these low level behavior representations are indicators of distinct
information processing states experienced by the user during an ISS. Overall, these results
support a positive answer to RQ1.

5.3.3

Clustering on query sequence feature vectors

A page is a natural unit of processing in an ISS. Another natural unit is a query segment.
A query segment starts with the processing of a SERP (search engine result page) and
following pages up to the point that a new query is entered or the ISS is ended. To further
investigate the existence of identifiable processing states, the ISS reading sequences were
grouped by query segment rather than by individual pages, and the same feature vectors
learned.
The clustering techniques used at the page level were applied at the query segment level.
The feature calculations were made by aggregating the fixation data over the pages in each
query segment rather than by pages. To allow for easier comparison the same features
names are used in the query segment cluster data. The page level features relate to the
counts and statistics over the query segment, which consists of perhaps many pages, rather
than just a single page.
If the learned classifications of page feature vectors can be taken as information processing states then one might expect to see a similar number of classes when other ’natural’
units of an ISS are considered. A query segment, i.e. a group of pages visited after a query

145

is issued, is a common unit of analysis in an ISS.
Figure 5.2 shows the k-means model fit by number of clusters. One can see there is no
significant improvement in the partitioning after models for about 8 to 10 clusters.

Figure 5.2: Number of clusters for TCE query segments: Reading sequences including page
level feature
The result of applying the k-mediods pamk function to the query segment reading feature
vector data provided an optimal partitioning into seven clusters. That is in reasonable
agreement with the k-means model fit scree plot results. Overall, there are many fewer
query segments than pages in the ISSs. Table 5.4 shows Cluster 1 is much larger than the
others. Cluster 7 is the smallest and has only 11 members.
Table 5.4: Query segment cluster classes.
Class label
1
2
3
4
5
6
Number of members 580 283 244 105 22 79

7
11

146

5.3.4

Feature importance in query segment clusters

Table 5.5 presents the feature importance in the learned clusters for the query segment data.
It shows subset level features, which reflect the statistics of the long reading sequences, have
significant influence for the mean Gini coefficient improvements over all of the clusters,
and in most of the individual clusters. At the page level the number and duration of
reading sequences is frequently an important feature for the models. Several local features,
including the number of fixations in the longest sequences and total duration have significant
influence. Generally, these features can be connected with dwell time in reading sequences.
As noted earlier, higher level semantic processing that might be connected with regressions
and perceptual span. In the query segment cluster features, perceptual span features do
not stand out as a strong discriminator. The number of regressions over the query segment
is an important feature for clusters 5 and 7. For long reading sequences the number of
regressions was an important feature for four clusters.
Relative feature importance can be explored further, but it is hard to draw conclusions
absent a specific theory about the relation between these features and reading. Further,
such investigation leads towards consideration of page content and layout. One goal of the
dissertation is to present a technique that may be able to be generalized across users and task
sessions. Hence the focus on modeling patterns of user actions as behaviors. Approaches
involving content analysis raise issues for generalization of model. While there are many
interesting questions about connections between features and information processing states,
such investigation and speculation is outside the scope of the dissertation.

actions.

[ April 15, 2015 at 18:41 – classicthesis version 0.1 ]

13

8.08
3.00

longestRseqReadingSpeed
longestRseqPerceptualSpan

3.32

10.24

9.36

4.43

2.86
2.31

longestRseqMaxLDFE
longestRseqReadingLength

4.06

23.75

27.78

11.18

3.48

18.09

longestRseqFixDur
longestRseqMeanLDFE

12.15

longestRseqNumFix

14.68

11.61
11.14

numRegLongRseq
medianMaxDurLongRLFDE

12.95

13.37

medianLongRSeqFixations

25.62

16.01

1.05
14.89

durLongRseq

2.79

medianPageMaxLFDE

2.25

3.04

6.44

7.48

2.25

9.95

0.40

14.47

7.11

5.70

6.81

8.74

13.35

2.37

medianLFDE

2
9.25

numLongRseq

0.40

8.63

numRegRseq

readingSpeed

1.46

medianReadingSeqFixations

2.43

8.51

pageMeanReadingSeqLength

5.12

numRseq
durRseq

2.89

1.12

durSseq

5.94

4.10

numSseq

pageMeanPerceptualSpan

0.99

totalFixDur

readingLength

5.69

numFix

1

-4.47

5.12

11.30

2.89

1.08

5.06

7.36

11.51

5.65

13.54

11.58

12.55

1.22

0.92

5.09

9.73

9.62

-0.87

3.18

9.84

10.31

10.73

0.84

1.82

3.58

5.38

3

1.00

7.31

11.23

5.86

7.86

6.83

3.14

10.84

5.30

12.55

10.93

11.38

7.46

6.44

7.38

10.28

7.73

1.45

2.48

9.91

9.59

10.66

6.14

6.40

6.60

6.53

4

0.00

1.36

-1.00

0.00

1.00

8.10

13.51

9.00

12.61

10.45

20.64

11.89

-1.00

-1.00

0.00

3.53

9.07

-1.70

10.78

0.00

12.24

8.59

5.00

7.58

8.60

9.23

5

4.88

6.77

11.46

5.56

8.64

4.78

7.86

10.87

5.32

12.57

10.91

11.46

7.54

12.60

5.96

10.89

7.67

6.34

2.73

9.48

9.87

10.66

7.30

6.47

6.20

8.25

6

0.00

0.00

1.00

0.00

0.00

6.27

9.11

8.29

14.08

9.13

19.00

12.67

0.00

0.00

0.00

3.49

13.75

1.00

13.29

1.00

14.60

12.10

5.71

11.82

9.89

15.12

7

5.40

13.17

12.95

6.94

8.56

27.07

17.29

11.40

15.10

13.48

18.88

13.89

7.79

7.87

8.09

11.72

15.66

4.51

15.47

9.97

20.01

14.78

9.09

11.83

13.58

15.59

Accuracy

Table 5: Important features for information processing states: Query segment clusters

Gini

2.08

14.03

35.60

8.11

12.54

53.98

81.21

55.10

68.59

70.28

158.32

85.84

10.86

9.59

10.49

31.25

25.38

3.42

21.11

25.12

63.06

39.65

10.48

14.75

17.08

22.79

147

Table 5.5: Important features for information processing states: Query segment clusters
(labeled 1, ... 7 )

This result supports the step in the analysis that allows for a representation of user states.

This is positive result for RQ1, in that classes of cognitive engagement with information

objects in an ISS can be taken to represent an available repertoire of goal-directed user

148

5.3.5

Summary

At two levels of ’natural’ granularity of interaction in an ISS, the number of discovered
clusters in the reading eye movements is ˜7 to 11. These page level and query sequence
level results provide evidence that the basic observational unit of a lexical reading sequence
can be classified into a rather small number of states. This supports RQ1 by showing that
classification of the reading sequences can be achieved and so it is not unreasonable to
analyze ISS sessions using sequences of distinct reading eye movement pattern classes. This
also supports the hypothesis that these classes can indicate presumed mental information
processing states with distinct transitions between states expressed in changes in the eye
movement patterns.

5.4

With respect to RQ2

RQ2 Do sequence action classes exist in information seeking episodes or portions thereof
that have regular pattern properties?

5.4.1

Are there identifiable action sequences?

The foregoing provides evidence a rather small number of identifiable states can be distinguished in observations of reading eye movements during an ISS. It is also interesting to ask
about sequences of such individual actions, which reflect user compositions of information
processing actions. Are there distinctive sequences of these user actions in ISSs? Such
sequences might be observable indicators of a user implementing particular information
processing plans. These sequences, or compositions of the sequences, may be observable
indicators of information search tactics and strategies.
To investigate this, the ISSs were represented as sequences of reading states at the query
segment level. Each reading state is labeled with the cluster identifier (1,2, etc.). N-grams
were calculated using a sliding window over the sequence with a step size of 1. So the 3-grams
for a hypothetical ISS sequence 3,4,5,5,1 are (3,4,5), (4,5,5), and (5,5,1 ). Distributions
of sequences with several n-gram lengths calculated. The counts of the sequences were
normalized against the frequency of all subchains of length N in the user ISSs for the task.

149

Figure 5.3 shows the results for subchains of length 2, 3, and 4. The x-axis is a particular
state subchain of the appropriate length. For example, a subchain of length 4 is 2, 3, 7, 7.
Each of these are a sequence of reading vector state transitions in a Markov chain model of
the ISS observations for a task.

150

Figure 5.3: Observed frequencies of state sequences (length 2,3,4) by task.

151

If there were no significant differences in reading patterns in ISSs, then one expects only
random variations in the state transition sequences. Likewise, if there are characteristic
reading pattern biases in information acquisition and processing during ISSs for a type of
task, one expects to see differences in the distributions of state sequences.
Figure 5.3 shows that some state transition sequences are observed more frequently than
others. In fact one can see that many sequences rarely appear in any of the tasks. Some
n-gram sequences appear more frequently across ISSs for all of the tasks.
While these frequency differences are often small, a number of cases are apparent where
there are rather large differences in the observed frequencies for one or two of the tasks.
A few striking examples are notated, where there is a rather large excess in ISSs for a
single task. It is interesting to see that there are examples for each of the tasks. It is also
interesting to see that state repeats are involved, for example 5,5,5,5 for OBI (Advance
Obituary).
Figure 5.3 provides further support for RQ1 in that the sequences of the states in ISS
are not evenly distributed. Further, the figure suggests support for task type differences in
observed state sequences.

5.4.2

Coherence model

One expects variations in patterns of actions by users during an ISS even when they are
implementing the same plan. One consequence is the order of user actions within a plan
implementation does not matter. This is probably incorrect in general as there are cases
were some sequence patterns may always be seen. This might be due to user commitments
to a sequence of action or reflect system interface constraints) It seems clear that in free
searching a user with the same search intention and plan could have proceeded in a different
sequence. The development of a coherence model was motivated by the desire to capture
this variability.
If there are no regular pattern properties in the ISS information processing state sequences, no model will be able to reliably distinguish between patterns. In an ISS, the
information seeking process model predicts that the action sequences following a search

152

intention-plan pair ’hang together’ because those actions service a single intention. So a
single query segment sequence, defined as the actions following a query up to the next query
(or the end of the ISS), is expected to be ’coherent’. In contrast, if the actions were random
one expects the sequence to have the property of being incoherent.
To test the idea of a search sequence coherence model, it is hypothesized that each query
segment sequence in an ISS is a coherent sequence. The question is whether a model of
sequences with the property of coherence can be learned.
’Coherent’ and ’incoherent’ sequences are the input to the learn the model. The ’coherent’ sequences are the observed information processing state labeled query segment sequences. The ’incoherent’ sequences are random sequences generated using the same state
space as for the query segment sequences. So if the query segment was labeled 3,1,2,4,3,3
the state space has four elements: [3,1,2,4 ]. A random sequence in that state space might
be 2,4,3,1,1. A generated random sequence in the state space is labeled as ’incoherent’.
One can see that the question is whether there are biases in the patterns of the coherent sequences which distinguish them from being random. Notice that a query sequence
produced by the same search intention could have different lengths, so sequence length is a
variable in the model.
The model has three variables. The state space and length of the sequence are described
above. The relative exchangeability is a measurement of the number of equivalent ways of
rearranging the sequence compared to all of the ways the sequence can be distinguishably
rearranged. For example, 1,1,1,1 has only one possible rearrangement. It’s relative exchangeability is 1. In contrast, 3,2,2 can be rearranged as 2,3,2 or 2,2,3 and has a relative
exchangeability of 1/3. This construction is intended to capture the number of possible (but
unseen) observations of the sequence. Again one can see this is related to the complexity of
the sequence.
As a simple test of this idea of coherent, a regression model is learned and tested. All
of the query segments over the ISSs were gathered and 80% selected for training. An equal
number of ’incoherent’ sequences were generated using a Pólya urn with the state space for
each observed query sequence a regression model of coherence was learned on 80% of the

153

query sequences:
coherence(seq) = α ∗ relativeExchangeability(sequence) + β ∗ length(sequence) + γ ∗
dim(stateSpace) + ξ
where α = 0.14737, β = −0.14611, γ = 0.09014
relative exchangeability and sequence length were significant (relative exchangeability p
> 0.001; sequence length p > 0.005).
The model was tested on a collection of coherent sequences, i.e. sequences covering
single query segments in ISSs and random sequences drawn from the same state space. To
further test the results a 1000 cross validation was performed using a 90/10 split on the
ISS query segments. Figure5.4 shows the model was able to distinguish between the query
segment sequences and incoherent sequences. The success of the learned coherence model
shows there are regular patterns in the query segment sequences in the ISSs and so provides
support for a positive answer to RQ2.

154

Figure 5.4: GLM coherence model: ISS query segments in test collection.

5.5

With respect to RQ3

RQ3 Are such sequences of behaviors with regular pattern properties associated with motivating task type?

5.5.1

N-gram distributions

For each task pair, the sequence distribution differences were calculated for the n-grams of
lengths 2 to 5 (table 5.6 ).

155

Table 5.6: Task N-gram subsequence frequencies: Task type similarities
sequence frequency sim
tasks
∆task f acets sim rank
N=2
N=3
N=4
N=5
BIC, OBI
2
1
0.3396 0.7619 1.3779 1.7759
BIC, INT
2
2
0.3478 0.7676 1.4754 1.8575
INT, OBI
2
3
0.3609 0.7943 1.4573 1.8249
CPE, INT
3
4
0.4606 1.0016 1.6532 1.8911
CPE, BIC
3
5
0.4797 1.0064 1.6734 1.9091
CPE, OBI
5
6
0.6179 1.1022 1.6822 1.8969
range
3
0.2783 0.3403 0.3043 0.1332

Table 5.6 shows there are differences in information processing state sequence statistics
by task. The least similar tasks are CPE (Copy Editing) and OBI (Advance Obituary).
The most similar tasks are BIC (Background) and INT (Interview Preparation) and OBI.
It is striking to see the strong correlation between the n-gram frequency differences and
the Manhattan task difference distances expressed in facet value differences. The task pairs
in (BIC, INT, OBI) that are nearest in the Manhattan metric space have similar absolute
differences in n-gram frequency distributions. CPE is somewhat closer to INT and BIC in
the facet space as compared the distance between CPE and OBI.
The information processing state n-gram frequencies show distinct grouping and consistent ordering over all of the task pairs (table 5.6. BIC, INT, and OBI vary in several facet
dimensions, but they are in the same neighborhood in the space. CPE is rather further
away from the other tasks. One can see the n-gram frequency differences are correlated
with facet space distance for N up to 4. At N=5, the ordering of the task-pair sequence
frequency similarities is breaking down.
The task pairs involving BIC, INT, and OBI are bunched together in the n-gram frequency distance space. In contrast the n-gram frequency differences for CPE vs. INT, BIC,
and OBI are greater. The most dissimilar n-gram frequencies are between CPE and OBI,
which are the furthest apart in the space. The grouping of n-gram frequency differences
and correlation with task facet differences is an interesting result.

156

5.5.2

A geometric interpretation of task difference distances

In the previous section, the tasks were tested as pairs to examine whether they could
be distinguished by the frequencies of n-grams in the ISSs. The journalism study task
construction allows for a calculation of distance in the task category space based on the
differences in values for each of the task category dimensions. This provides a description
of an abstract space of all possible tasks. Further, many of the task facets can be related
to intuitions about user experience of the task and understanding of the goals for successful
task completion. So the task categorization space can be thought of as a kind of mental
space and task facet dimensions and values considered in a multi-dimensional scaling (MDS)
space.

Figure 5.5: Task locations - Task facet space
Figure 5.5 shows the distances between the tasks in a task facet space. One can infer a
semi-order for the task distances in a projection onto a scalar as: CPE , [BIC, INT], OBI.
The facet distance takes no account of the problem of incommensurate ordinal variables, so
the metric is truly a rough measure. Still, the analytic grounding of the task classification
system ensures that every task has a unique representation in the space, so the construction
of a Manhattan metric is reasonable.

157

Figure 5.6: Task locations: ISS information processing state sequence frequency space (bigrams)
An n-gram frequency difference space can be constructed reflecting the observed distances between the tasks revealed in the task-pair similarities. Figure 5.6 shows task locations for sequence frequency similarity (bi-grams). An appeal to triangle inequality allows
a projection onto R that provides an ordering of tasks. The most similar tasks by n-gram
frequencies are BIC and OBI. For n-grams of less than length 4, BIC is strictly between
OBI and INT (table 5.6).
Of the three tasks, OBI, BIC and INT, it is observed that CPE is closest to INT. Recall
that the INT (Interview Preparation) motivating task had two elements: the first goal was
to find experts and then the goal was to identify their contact information. The second
task goal element bears a degree of intuitive similarity to the main CPE (Copy Editing)
motivating task goal. So the results showing INT as closest to CPE may be unsurprising
in that ISS action sequences to carry out CPE are plausibly a subset of the ISS action
sequences to achieve the goal of the INT motivating task.
To summarize, in n-gram frequency similarity space the order of tasks is observed to
be [CPE, INT, BIC, OBI]. This ordering corresponds well to the semi-order determined by
task facet value differences. Interestingly, this order also corresponds to the post-task task
difficulty assessments made by the participants. These observations are all consistent with

158

a regular relationship between the degree of difference in the motivating tasks, i.e. task
type, and the patterns of information processing states that describe aspects of attention
allocation during the task type ISSs. This is evidence for regular sequence patterns that
distinguish motivating task types and it suggests potential explanatory connections with
the task classification facets and with participant experiences of the ISSs as difficult or not.
The differences in sequence frequencies for the task pairs is not isolated to just bi-grams.
The n-gram frequency differences persist with increasing n-gram length. Up to length 5, the
only break in consistent ordering is between the (OBI, INT) and (BIC, INT) task pairs. This
n-gram frequency differences provide evidence for larger scale information processing state
sequence differences between tasks of different types. The differences between tasks increase
with increasing n-gram length in a consistent manner across all of the task pairs. The
differences between the groups of task pairs in the task facet space declines with increasing
n-gram length, but the order of the absolute difference values is consistent.

5.5.3

State transition matrices

State transition matrices for each of the tasks were constructed using the observed ISS action sequences. Table 5.7 shows the sum of the absolute differences in the state transition
matrices for Markov models of each pair of tasks. Generally, CPE (Copy Editing) is dissimilar to the other tasks. When this similarity measurement is used to rank the task pairs,
there is a striking correspondence to the Manhattan distance between the facet values for
the tasks. There is not only a rank partial ordering on facet value differences but also clear
gaps in the absolute similarity values for jumps in the facet value difference between two
tasks. This is an interesting and unexpected result.
The statistical significance of the similarity of Markov chain distributions for task pairs
was tested using the Markov chi-square test presented by [19] based on [6]. It tests the
probability that two transition matrices were produced by the same generator. This test
assumes comparison of stationary distributions. In the limit of a countably infinite number of observations, two distributions must have come from different generators if a state
transition is observed in one transition matrix but not in the other. Only a finite number

159

of observations are made, however, so it is possible that a heretofore unseen state transition will appear in the next observation. To handle this problem, missing state transitions
were modified by adding a small amount using De Morgan’s rule in calculating the statistical significance. This is a probably correct upper bounds on the stationary distribution.
Witten-Bell discounting, used in n-gram frequency back-off for NLP corpus processing, may
be an alternative.
The results show that CPE (Copy Editing) can be distinguished from all of the other
tasks at a high significance level. BIC (Background ) and INT (Interview Preparation) were
also significantly distinguishable. If the missing state transition fix value is reduced by an
order of magnitude from the worst case De Morgan process value, then all of the task pairs
are distinguishable with p<<0.05.
Table 5.7: Markov models of activity: Task transition
matrix similarities
P
tasks
∆task f acets sim rank
abs(δ)
M χ2
BIC, OBI
2
1
3.42
0.203
BIC, INT
2
2
3.73
0.010*
INT, OBI
2
3
3.92
0.788
BIC, CPE
3
4
4.55
>>0.001***
CPE, INT
3
5
4.61
>>0.001***
CPE, OBI
5
6
5.45
>>0.001***

Figure 5.7: Task locations: ISS information processing state sequence frequency space
(Markov transition matrix similarity)

160

A Markov model task similarity space can be constructed using the task pair Markov
transition matrix similarity calculation in table 5.7. Figure 5.7 shows the task locations
in that similarity space. Again, an appeal to triangle inequality allows a projection onto
R that orders the tasks. Once again, there is an excellent correspondence to the distances
between task pairs in the task facet value space.

161

Chapter 6
Discussion

The main dissertation work was development of a user-centered model of the ISS process
and a technique to represent user actions in an ISS labeled as a sequence of information
processing ’states’. These states are hypothesized to reflect user information processing
states. The information processing state approach is grounded in observations of user
attention.
Development of a practical methodology to learn and apply an attention allocation
approach was a central concern. To that end, the dissertation adopted a simplified representation of user attentional states by selecting sequences of reading eye fixations on pages
in a search session and then calculating various features plausibly connected with lexical
processing of search content presented by the system. An unsupervised learning approach,
specifically clustering, was applied to these observations to see what page information processing state classes would emerge.
One result is that a relatively small number of clusters of these page-level attention
allocation vectors can be identified. The tasks in the user study were designed to vary in
several dimensions, including complexity and specificity. Another result is that user action
sequences labeled with the learned attention-representation clusters had relationships to
those tasks. Further, regular variations in the sequence patterns by task were discovered.

6.1

Overall results

The first research question concerned user actions of attention allocation on a page. Specifically, it asks whether there were natural classifications of patterns of information acquisition

162

actions on a page. The other two research questions address the characteristics of the sequences of actions a user takes during an ISS, considered as a sequence of page interactions.
They ask whether there are regular patterns of action sequences and whether those patterns
are related to the user’s motivating task type.
The dissertation developed a model of the information seeking process based on the
theory of human action. It proposes that regular sequence patterns exist and explains how
search structures are produced as a user carries out an ISS. In particular, it represents the
information seeking process as a sequence of search intentions, each of which is coupled with
an implementation plan. The ISS structure is the structure of relationships between the
search intention-implementation plan pairs.
The model was developed as explicitly user-centered. A key goal was to make an
empirically-grounded cognitive model of the information seeking process. It focused on
the explicitly cognitive process of information processing and acquisition by reading. The
approach modeled some aspects of the user’s ISS information processing states based on
observed patterns of reading eye movements. This is a cognitive link hypothesis connecting
observable user behaviors with certain mental states of the user germane to the ISS process.
The results provide evidence for such a cognitive link hypothesis between mental information processing states and clusters of eye movement pattern features. Further, the
results provide evidence that this procedure can distinguish between tasks of distinct types
by patterns and structures of user activity.

6.1.1

RQ1 Can common sequences of user actions that take place in an
ISS be identified?

The first research question asked about the distribution of user action sequences in ISSs.
That is, are some actions and sequences of actions more common than others?
A positive answer leads naturally to RQ2, which asks about the frequency of sequences
of such unit behaviors. If RQ1 is not supported, there is no foundation for the rest of
the investigation in RQ2 and RQ3. That is, reading eye movement patterns are not a
useful basis for detecting user information processing plans. It could be that information

163

processing plans exist but are carried out at a higher cognitive level and so not revealed
directly in the reading process.
Eye movements were selected to provide an empirical foundation for attention allocation.
Eye movements provide a direct causal link to certain cognitive states and brain processing
activities that are essential to textual information acquisition and processing.
Reading eye movements over a single page was adopted as the atomic unit of behavior
for the dissertation work. Pages provide a reasonable segmentation of an ISS.
RQ1 can be understood to ask whether eye movement patterns measured as attention
vectors can provide a sensible unit behavior. The results show eye movement patterns can
provide a unit action behavior representation because they can be clustered into a rather
small number of classes.
Further, those clusters have discernible differences in feature importance suggesting that
they vary in basic characteristics. That is, the clusters show differences by features rather
than by values within a feature. This supports the idea that each cluster is related to
distinguishable cognitive state. It is also gratifying to see that the classes of important
cluster features, as indicated by the feature dependence on whole page measures vs. a
subset of reading sequences on the page, also seem to vary by cluster.
A more detailed analysis of relative feature importance between the clusters is tempting
but would be almost entirely speculative. A fruitful investigation requires a theory of
how eye movement pattern features are related to reading and the processing of textual
information in the search process. While there is a great deal of reading research that is
germane, but connections with higher level text comprehension and other cognitive processes
are still open questions. There are also empirical issues for real world studies where page
content and layout vary wildly over search results and web pages. The dissertation user
study and analysis involved only text and reading. The development and analysis assumes
eye movement patterns detected as ’lexical’ are instances of reading text. So the dissertation
analysis and results deal with a considerably simpler search environment than that typically
engaged by a user. It does not address search intentions and attention allocation associated
with image or audio content. This is a basic limitation in the presented work.

164

Further investigation into relative feature importance within these representations of
information processing states is a direction for future research. It is also somewhat skew to
the main dissertation goals. To have a practical impact, it is desirable that a ISS process
representation method should be capable of generalizing to new task sessions. Work to
understand cognitive feature and content interactions is interesting but it is not at all clear
how one might generalize results to new sessions. Perhaps such work could have practical
impact for systems with deep client-side interaction logging.
A basic claim of the dissertation is that reading eye movement patterns are causally
linked to mental states germane to information search as observed. However, it is not
claimed that the learned states correspond directly with actual mental information processing states. One hypothesis is that these eye movement patterns will group because as a user
changes their information processing state to be more effective in implementing the plan
for their search intention. The plan underwrites the idea that one expects to see coherence
in the eye movement patterns because of the user’s method to meet their immediate search
intention.
The work considered the problem from the perspective of representing the ISS as a
sequence of attention allocation driven by a succession of search intentions. The dissertation
developed a search sequence coherence construct. The idea is motivated by the intuition that
search intentions are grouped into coherent units that reflect subtasks, and those subtasks
grouped to achieve higher level subtasks or applied directly to the motivating task goal.
The coherence of attention allocation sequences may be useful and intuitive representation
of the structure of an ISS.
The results provided evidence for a finite number of reading eye movement pattern
clusters at both the level of attention allocation on individual pages and when the reading
eye movement feature vectors were calculated over the pages that covered a query segment.
These levels are unambiguous units of ISS structure. They can be understood in terms
of patterns of goal-directed attention allocation, which connects well with intuitions about
high-level cognitive engagement during search including evaluation, decision-making, and
learning. The representation model suggested a relationship between rather low level information processing states, which are more of less cognitively opaque, and high levels of

165

cognitive search processes where executive actions are formulated and expressed. The high
level of cognitive activity suggests hypotheses about user behaviors expressed in dwell time,
click through actions, and so on.
One expects that larger units of ISS structure, such as query segments and query reformulation intervals, will have the fingerprints of goal-directed attention allocation plans.
Eye movements betray user attention allocation when reading during search. The fact that
the number of clusters learned at both the page and query segment levels is about the same
(˜8-12 clusters) suggests users have a smallish repertoire of attention allocation patterns
used to implement plans.
One can speculate plans of attention allocation at every subtask level in an ISS may be
naturally limited by memory and cognitive resource allocation. A user would not naturally
begin with complicated plans, but rather might be expected to use whatever works well
enough. In future work, it may be interesting to compare the learned information processing
states of experts and non-experts and compare the patterns of use in the same task. Another
of the PooDLE user experiments provides eye tracking data for users of different levels of
knowledge carrying out the same tasks. Application of the methodology in the dissertation
to this independent user study could be one future research project.

6.1.2

RQ2 Do sequence action classes exist in information seeking episodes
or portions thereof that have regular pattern properties?

RQ2 concerns user actions and sequences of user actions based on the learned information
processing state representations. The model proposes that the observed ISS action sequences
are produced by implementation of a search intention plan.
The ISS process model is grounded in the theory of human action. For information
search, this amounts to saying that information search task activities are driven by search
intentions. To actualize search intentions, users adopt and implement a plan. The cognitive
realization of this process is a sequence of goal-directed attention allocation by the user.
Within the textual information search process, attention is revealed in a commitment to
information processing by reading. Eye movement patterns belie this attention allocation

166

and indicate some aspects of the information processing state of the user.
For RQ2, the dissertation work investigated whether the sequence of inferred information processing states can distinguish user search plans in the ISS process. An important
assumption is that a user has a limited repertoire of plans for realizing search intentions.
Given a finite choice of plans, one expects an uneven distribution in the frequency of user
actions and action sequences.
The existence of a limited plan repertoire seems intuitive, but it is not obvious that it
need be so. Humans might create plans as they go along. In such a case, there would be
no significant differences in reading patterns over many ISSs. That is, one expects random
variations in the state transition sequences and a uniform distribution in the state space
transition matrix. On the other hand, if there are task-type characteristic reading pattern
biases in information acquisition and processing during ISSs, one expects to see differences
in the distributions of state sequences and so in the state space transition matrices.
The results show there is an uneven distribution of ISS action sequences, calculated as
observed n-gram frequencies. Some state transition sequences are observed much more frequently than others. It is also the case that some n-gram sequences appear more frequently
across ISSs for all of the tasks. At the same time, for a number of sequences there is quite
a bit of variation by task type. Many n-gram sequences rarely appear in any of the tasks.
Interestingly, some of standout n-grams associated with a particular task involve state
repeats, for example 5,5,5,5 for OBI (Advance Obituary). It is not hard to imagine that
a user might repeat a particular information processing state several times in an ISS for a
task type because that state is especially well-suited to process or acquire the information
germane to making progress in the task. There is a distinction, for example, between the
CPE (Copy Editing) and OBI (Advance Obituary) tasks. CPE is plausibly oriented to a
repeated scanning state, punctuated by focus on a single text fragment that is recognized
as possibly matching or disconfirming the claim fact in the story. The OBI task requires
creation of an intellectual product under decidedly amorphous constraints. Latching on
to the interesting thread that runs through a person’s life, or a consistent character trait,
more likely requires repeated careful reading and refection on text passages. These potential
explanations for the prominence of repeat sequences are speculative. For the purposes of

167

RQ2 it is the differences in the normalized n-gram frequencies that matter, not the specific
state sequences. Examination of the clusters involved and the connection of state transition
sequences to the user’s perception of making progress in an ISS towards the motivating task
goal is an interesting future research question.
One contribution of the dissertation is development of a sequence coherence model and a
motivation for its potential to distinguish query segment sequences from sequences that are
not delimited by query segment boundaries. Figure 5.4 shows that regular sequence patterns
in the ISSs can be detected. The coherence model involves the use of a Pólya urn as an
exchangeable Markov chain generator. The use of the Pólya urn to make state sequences
is a simple representation of the search intention plan implementation. Query segment
sequences are manifestations of search intentions and actions to realize the intentions. The
fact that query segments can be distinguished using this model provides support for planbased sequences. Again, use of the probabilistic representation of a Pólya urn provides
a simplification of the generative process to allow for practical investigation of ISSs from
empirical data.

6.1.3

RQ3 Are such sequences of behaviors with regular pattern properties associated with motivating task type?

The positive results for RQ2 imply there is action sequence structure in ISSs. These results
lead naturally to RQ3, which asks about the ability to distinguish between task types
based on information processing state sequences observed in ISSs. This can be understood
as asking about differences in the plan structures between tasks of different types. The
literature shows motivating task type affects search behaviors, so ISS structures that reflect
sequences of behaviors might also be affected by motivating task type.
Table 5.6 shows there exist clear differences in information processing state sequence
statistics by task. It is interesting to see that the differences in the state sequence statistics
between each of the task pairs matches the differences between the task facets as measured in
the task categorization space. These observations are consistent with a regular relationship
between the degree of difference in the tasks, i.e. task type, and the patterns of the inferred

168

information processing states describing aspects of attention allocation sequences.
This result is striking and suggestive. The further apart tasks are in the categorical space
the greater the difference in the action sequences users applied to make progress in the ISSs
for those tasks. Recall that the tasks were constructed for the user study to be distinguished
in the category space. It was expected that these tasks could lead to different user behaviors.
There was, however, no reason to think that distances between tasks in the abstract space
would be mirrored in distances in the empirical space. It is even more remarkable given the
empirical space task differences are measured using low-level eye-movement patterns. The
figures 5.5 and 5.6 show the locations of the tasks are measured in the abstract task facet
space and in the empirical space of observed bi-gram information processing state sequences.
It is worth noting that essentially the same figure can be constructed for n-grams of length
2, 3, and 4. The relationships begin to break down at n-grams of length 5 because this
begins to exceed the average lengths of query segments in the tasks, especially CPE. So
the tasks are well distinguished when the n-gram size is, on average, within the scope of a
plan implementation to carry out a search intention. It is nonetheless remarkable that the
mapping between the task facet categorical space and the empirical action sequence space
is close to 1-1. The bi-gram space figure shows some non-planar effects.
An analysis of the state transition matrices (table 5.7) provides additional support for
the relationship between differences in tasks and the plan sequences in an ISS. The state
transition matrices were constructed from the Markov chains generated by the search intention plans of the user. In the limit of arbitrarily many ISS sessions for a task by arbitrarily
many users, such a state transition matrix describes the aggregate of all sequences a user
would take to make progress towards the task goal. This is similar to the n-gram view
because it describes the probability of generating a specific n-gram. The state transition
matrix is a rough representation of the possible ISSs for the task type as represented in
information processing state sequences.
As with the n-grams, the task differentiation shows a perfect correspondence to the
Manhattan distance between the facet values for the tasks. Again, there is the same rank
partial ordering on facet value differences along with clear gaps in the absolute similarity
values for jumps in the facet value difference between two tasks.

169

Taken together, these results provide strong support for RQ3. The degree of correspondence between statistics of the observable ISS action sequences and the abstract categorical
space of task facet differences is an interesting and unexpected result.
In summary, the results support the claim that the greater the difference between tasks in
the categorical space, the greater the differences in the action sequences employed by users.
A number of potential explanations might be offered. For example, it could be that the
range of plans considered for tasks varies by task type properties in the categorical space.
It could be that certain plans or plan patterns are particularly efficacious for tasks with
particular properties. Difficult tasks with greater complexity or ones that require synthesis
of an intellectual product may involve a broader variety of plans because of user memory
limitations. These speculations are quite incomplete however and they do not really provide
an explanation for this observation. This is another interesting direction for future research.

6.2

Task difficulty

The TCE study tasks were designed to be different in task facets that were expected to affect
search behavior. The order of post-task task difficulty assessments made by the participants
matches the semi-order observed in the task facet and n-gram differences. CPE was judged
easiest and OBI the most difficult.
Perceived difficulty, task facet distances and user action sequence frequency differences
distinguish between tasks in all task pairs. Further they all also imply in the same ordering
of tasks in a representation space by taking the absolute differences between tasks as a
distance and applying the triangle inequality principle.
With respect to RQ3, these observations all point to a regular relationship between the
degree of difference in the motivating tasks, i.e. task type, and the patterns of information
processing states that describe aspects of attention allocation during the task type ISSs.
This is evidence for regular sequence patterns that distinguish motivating task types and
it suggests potential explanatory connections with the task classification facets and with
participant experiences of the ISSs as difficult or not.

170

One can hypothesize that certain information processing states and sequences of information processing states involve greater perceived cognitive effort. It is challenging to
provide evidence for connections between task facets, processing states and cognitive effort,
and then to perceived task difficulty. Each of these are complex constructs and making an
operational representation to explore relationships between them is none to easy a thing to
do. In no small measure this is because these are all mental states. Further, in the task
classification system, there are several facets that contribute to making a task difficult.
There are intuitive connections between task difficulty and the task facets. It is not too
surprising there is agreement in task pair distinctions and implied semi-ordering based on
absolute differences in the task values. The results showing that ISS performance as action
sequences of information processing states mirror these other measurements is a striking
result. This is support for a hypothesis that the degree of difference in the tasks, i.e. the
task types, are expressed in user actions manifested as patterns of information processing
states. These user action patterns describe task type effects on attention allocation.
This hypothesis suggests one can use experimental results to induce semi-ordering and
perhaps even a metric in the task facet value space. It seems reasonable to think regularities
in people’s information processing state behaviors result from high-level cognitive processes
of goal-directed attention allocation. The construction of the abstract task categorization
space, including the task facet values, involved two types of judgments. First, there are
judgments about how tasks can be distinguished in the abstract. It also distinguishes task
in terms of what people need to do when they perform tasks with those properties. So the
level task facet value is more or less a direct suggestion that a user will be biased to allocate
information seeking attention to a parts of a page, as in CPE (Copy Editing) rather than
evaluating the information object as a whole, as for OBI (Advance Obituary).
From this perspective, information processing state behaviors can induce an order, and
even a metric, in the task type space using the frequency differences in the behavior sequences. One can define a mapping from the empirical task difference space, expressed in
terms of differences of behaviors, onto the task categorical space.
The idea is that user mental states during search are indicated by behaviors. Mental states are correlated with task facets and switches in task facet values during search.

171

Switches might happen when a user gains knowledge. For example a knowledge change can
change the uncertainty and ambiguity of a task as progress is made towards a goal.
A location in the task facet space could provide explanatory and predictive power for the
user’s mental states during search and the behaviors they employ. It could be that regular
relationships can be adduced between user characteristics, notably domain and task knowledge and cognitive characteristics, especially memory capacity, task characteristics, and
exogenous factors such as resource limitations, risk/benefit calculations, time constraints,
affective state and so on.
A key direction for future research is to investigate the usefulness of in-session detection
of information state sequences. Effective detection might allow support of specific personalization moves in the context of the immediate search intention in the ISS, the ISS subtask
and/or the motivating task. One potential attraction of the methodology used in the dissertation is the ability to calculate information processing state sequences over arbitrary ISS
segments. Practical application might not require any knowledge of task session boundaries,
or, in particular, the start of the session.
The results for RQ3 supporting task type differentiation suggest that sequence patterns,
as generated by the user plans that implement the search intention, may be associated
with task properties that presumably involve greater intellectual effort. It has already
been suggested that one way to explore this idea is to look into the differences in feature
importance in the eye movement pattern clusters that are taken to be representations of
mental information processing states.
A system that monitors ISS information processing state sequences could lead to practical applications. The results provide evidence that action sequences can be used to infer
aspects of task type and distinguish between tasks. This might be exploited to find places
in the session where the user has switched from using one group of plans to another group,
perhaps indicating a new subtask or phase in the ISS. A system might intervene or take
action armed with a learned belief about the user’s state or intentions in the context of
their motivating task. That is, the system would possess a hint about the user’s situation
and could make a principled hypothesis about what type of help could be beneficial. A system seeing sequences that indicate the user is working on a complex or difficult task could

172

take action to automatically take notes, bookmark pages, or allowing direct, rather than
linear, navigation to any of the recent pages, or query results. Implicit support could be
implemented by adjusting ranking algorithms by document readability, re-weighting specific
meta-data, or imposing some diversification policy on the ranking. One might also exploit
the ISS process model and predicted sequence properties to identify significant events, for
example, instances of learning, by looking for changes in sequences. The system could then
hypothesize that specific events have induced a change in the user’s knowledge. The system
might then look to use the content associated with the event(s) as part of a personalization
scheme.

6.3

Eye movement patterns and information processing states

The framework for the representational model of the information seeking process depends
on a cognitive link hypothesis. That link is a bridge from the observables of user actions to
cognitive states. One conclusion from the results is that there is evidence that eye movement
patterns can reveal aspects of mental information processing states.
The results provide evidence that eye movement patterns can be used to fashion representations of mental information processing states. Further, those cognitive effort representations might also bear some of the weight of providing explanations for certain information
behaviors. For example, the clustered cognitive effort feature vectors can be analyzed to
understand how the information processing states differ from one another. The features in
Table 5.3 and 5.5 were grouped by level of attention allocation on the page. These cluster
class properties are plausibly associated with changes in cognitive effort and plans.
More generally, one might hypothesize that these constructions of information processing
states could also be a basis to represent certain aspects of the user’s experience of search
interactions. One line of future research is to investigate the coincidence of patterns of
information processing states with independent indicator events of user experiential states,
such as surprise, decision-making, lostness, frustration, etc. A specific idea is to examine
ISS pupil dilation events. Pupil dilation has been associated with surprise and decisionmaking. Pupil dilation events could be compared with changes in patterns of eye movement

173

sequences or higher-level structures in the ISS. The important features in the new sequences
could be examined to learn if there is a correspondence with an explanation for the pupil
dilation event. For example, a dilation event followed by a shift to reading of passages could
suggest a learning experience. This might be one way to do richer cognitive markup on ISS
representations and so deepen the foundation for explanations of user search behaviors.

6.4

The information seeking process is not ergodic

The ISS process model rests on the idea that a user acts to progress towards their task goal
by forming a succession of search intentions. Each intention is realized by adopting a plan.
Each plan is an action sequence generator with a characteristic distribution of sequences.
If a user chooses from a finite number of plans in the course of acting in a task, there will
be some distribution of observed action sequences. If the search intention plans selected by
a user vary by task type, then coverage of the space of all possible action sequences will be
uneven and characteristic of a task type.
This can be connected with a claim that information seeking is not ergodic. The results
concerning RQ2 provide evidence for structure in the search action sequence space. This
structure is seen in the sequences of information processing states at the page level and also
in the sequences of information processing states at the query segment level.
It is not surprising to find that information seeking is not ergodic. Searching is not a
random walk in an information space. The results provide direct evidence for this claim,
however. The ergodicity of human information search does not help much in addressing
problems of improving information search. However, this perspective of thinking about
searching categories as sequence distributions may contribute to a formal foundation for
simulating users and information search sessions.
Simulation of users engaged in interactive information retrieval (IIR) may be a key resource to enable evaluation of IR systems in interactive settings in ways that are scaleable,
objective, and cheap to implement. The difficulties of addressing IIR within the TREC
framework has motivated interest in the potential to employ simulated users as a central

174

element in a new IR system evaluation paradigm. The TREC approach is blind to interaction because it evaluates an abstract relationship of a query and the results provided by
the system. Apart from the fundamental shortcomings of relevance measures for overall
task session performance, there is no notion of a sequence of user actions and the nature of
interaction with IR systems.
From a system perspective, the issue is not simply to simulate users. Rather, one
must simulate users and uses of the system, e.g. tasks. An optimal system must be able to
recognize the results of the user-task construct. Of course, users vary in knowledge, cognitive
capacities, etc. It is plausible these variations are on some continuous scale. Tasks also vary.
For the problem of simulation there is a real possibility of a combinatorial explosion for the
user-task input space. There are obvious implications for the computable characteristics of
the problem.
A combinatorial explosion might be avoided if user and task representations can be
separated and the joint user-task construct handled as a simple composition. The degree
to which user and task representations can be handled independently is an active area
of investigation for information science. The dissertation results providing evidence the
user-task process is not ergodic rules out the most extreme combinatorial explosion of a
continuous space of user interaction states crossed into all possible tasks. Different task
types seem to have different coverage in the interaction sequence space.
The association of tasks with distributions of action sequences and a mapping of distributions into a comprehensive task categorization space is one way to frame simulated
user-task session design. This suggests an approach that locates user tasks in a task category space by using the discriminative power of the distribution of action sequence patterns.
The task category space would be built from empirical data, using tasks as performed by
humans in experimental and operational settings. Other tasks, even purely hypothetical
tasks, could be situated in the categorical task, using category facet values. Those tasks
could then be projected onto the sequence distribution space by interpolation.
The result is a space that relates action sequence distributions to tasks. These sequence
distributions would be ideally further structured by the observed statistics of the task type
structures. This sequence distribution space can then be an input to an IIR interaction

175

simulator.
An IIR session-level evaluation system might work by testing multiple sessions over a
sample of tasks, covering regions in the categorical task space. Each sample would use a
parameter pointing to the sequence distribution space to bias the plans adopted by the
synthetic user in the course of the interaction. This system would need to be coupled with
a search intention generator operating in a goal-directed manner to achieve the task goal.
This search intention generator would be some inferencing engine, for example a hypothesis
generator to make a query coupled with a questioning answering evaluation of the search
results. Such systems are an active area of development in the AI community.

176

Chapter 7
Conclusions

7.1

The goals of the dissertation

There were several goals for the dissertation. First was to develop a general model of the
search process based on the theory of human action. Using that analytical model, the
next goal was to develop a representation of search action sequences and then models of
information seeking sessions. There was also a desire to explore development of a model
of action sequence coherence. The motivating cognitive perspective for all of these goals is
making an objective representation of the user’s succession of attention allocation to make
progress in their motivating task.
Another goal of the dissertation was to develop an implementation of the theoretical
model in a computable form. A specific problem was to learn how to segment the ISS
into distinct units and then to characterize relationships between those units in order to
calculate the ISS structure from observations of user actions.
The dissertation has addressed some aspects of a cognitive framework for interactive information retrieval. One general point was to connect the information science task construct
with user attention allocation. Attention provides a solid underpinning to make a causal
description of how users make goal-directed actions in information search environments.
Another aspect of the work on cognitive foundations was to strengthen the grounds
for inferring the existence of certain user mental states from observed information seeking
behaviors. Using these inferred user states, the dissertation also had a goal of demonstrating
a way to make a representation of goal-directed user actions in task-based information
search. Specifically, it attempted to develop and apply an empiically-grounded method to
make mental state representations that can be plausibly associated with goal-directed user

177

cognitive actions.

7.1.1

To what degree have the goals been met?

The dissertation has articulated a search process model that is grounded in the theory of
human action [8]. It has described the ISS process as application of a unit process model
built on a succession of user search intentions that further progress towards the motivating
task goal. Each of these intentions are implemented through a user selected plan. It is
the intention-plan pair that produces the observable behaviors. This intention-plan unit
is taken to produce a sequence of search actions and is intuitively associated with a query
segment, i.e. the sequence of behaviors observed after the user has issued a query to the
information retrieval system up to the next query or termination of the task.
As a general matter, this goal of the dissertation was largely met.
The dissertation was able to make some progress on the idea of representing action
sequence coherence as units of task progress. This was proposed as a way to address the
problem of learning to segment the ISS and deduce its plan structure.
The theoretical model asserts that action sequence coherence is grounded in the plan
the user adopts to implement each current search intention. The plan is also a production
process. The dissertation work approximates the production process as a Pólya urn that
generates exchangeable Markov sequences. The exchangeability of a sequence associated
with a search intention matches some intuitions about searching. One such intuition is that
for a single search intention the specific actions can be carried out in alternative orders or be
of differing lengths and yet achieve the same goal. Exchangeability also addresses a formal
problem for representing search that arises because observations of user interactions are not
iid because changes in a user’s knowledge and search intentions affect the range of possible
interactions with a system. Exchangeable sequences allow for calculation of complexity and
other measures based on symmetry of sequences rather than calculation of the similarity of
sequences. A Pólya urn is a simple and computationally practical way to flexibly cluster
and model the production of user action sequences. It is well matched to the unsupervised
approach to learning information processing states. The distribution of states and state

178

sequences (as n-grams) can define the urn properties.
Some potential applications for this representation of local behavior sequence coherence
are proposed. These include the idea of doing unsupervised extraction of ISS structure by
measuring the coherence of sequences to find probable sequence boundaries.
One aspect of the dissertation involves working with plans as classes of action sequences
to identify behaviors using sequence properties. A question for future work is to see if
behaviors can be identified by humans as, for example, a “chaining” intention by the user
that produced the sequence in the same way that [179] observed people would attribute
intentions and plans to sequences of agent actions.
Application of the coherence measurements to find these coherent structures may also be
able to induce a partial ordering over them to discover a hierarchy of ISS subtasks. This is
a direction for future work. One goal would be to determine if the induced partial ordering
of coherent sequences can be plausibly associated with a task structure representation. A
more specific hypothesis to test is that partial orders of coherent sequences will correlate
with observed query reformulation intervals [119].
The dissertation work has managed to develop one piece of the theoretical model in a
computable form. In particular the search intention plan has been modeled as a Pólya urn
process. Implementation of other pieces of a general model are subjects for future work. One
important piece is implementation of a decision process, perhaps building off of the work of
Fuhr and Tran [75, 195]. Selections over task topics and selection of user properties might
be addressed using task categories and concept selections from knowledge domains. Such
exploratory work might contribute to refining research objectives for systems to simulate
users interacting with information systems. This could fit into developing an approach to
the difficult problem of whole-task information system evaluation.
The dissertation’s work to elaborate and demonstrate a link from observable behaviors to
user mental states was positive. It helps to validate a causal foundation connecting behaviors
and cognitive processing states. This was addressed using reading eye movement patterns
as information processing behaviors. Then it detailed a semantic and neural connection
between the execution of those behaviors and a presumed cognitive information processing

179

state space. There is certainly more work to be done, but the dissertation has provided
a theoretical and representational model to describe such a cognitive-behavioral linkage in
the context of information search interactions. It has also developed analyses and presented
results supporting the hypothesis that a representation of information processing states can
be learned from observations of user behaviors.
The dissertation goal of showing how inferred mental states allows for useful representation of goal-directed user actions was partially met. A number of simplifications were
made, in particular the unsupervised clustering of reading eye movement pattern features
at the page interaction level. This is a rough measure of attention allocation during a unit
of search interaction.
The dissertation showed that reading eye movement patterns can be clustered into
groups. These groups can be related to information processing states. It is not possible to say they have a 1-1 relationship with actual information processing states, however.
Research shows that eye gaze, which is usually a reliable observation of goal-directed attention, can be correlated with high level user actions such as page use [49]. There are also
several studies showing eye fixations are correlated with mouse movements and scrolling
activity [32, 142]. Such high level action data is available in many settings. Extending
application of the dissertation models to use other observations of user actions is one line
of future research.
The work provides some support for the larger goal of showing the inferred processing
states can represent goal-directed user actions. Reading during search is certainly a goaldirected activity. However, the knowledge that reading eye movements are goal-directed attention allocation was exploited when creating the page processing feature sets, for example
by setting a fixation duration threshold to filter for presumed lexical fixations. The learned
clusters were hypothesized to represent information processing states, and so these might
be thought of as goal-directed information processing states. To the degree that assumptions of goal-directedness were assumed in the feature engineering, one must be cautious
in asserting the results show goal-directed user actions. This might be investigated further
by adding eye movement features not necessarily associated with goal-directed actions to
the page representations. If one found that these features were not significant contributors

180

to learned cluster membership or that their addition caused degraded task differentiation
results using the learned clusters as information processing states, those findings would be
support for the system’s capacity to represent goal-directed user actions.
A limitation in the ability to represent goal-directed actions exists in the selected readingbased feature collection. Research into ’mindless reading’ [204, 165, 173] shows active engagement can be distinguished from merely passing the eyes over text by examining the
eye movement pattern statistics. However, the statistical effects are not large and practical
detection would likely be a great challenge given individual variability.
One way to build support for the usefulness of the inferred mental processing representations could be to use those chains of state representations to explain or predict cognitive
events indicated in observable user actions. Patterns of state use, or changes of patterns of
state use, might correspond with significant cognitive events during search, such as instances
of learning. This is an important and exciting direction for future work. On-line detection
of such events could contribute to a system’s capacity to form a dynamic representation of
the user’s state that would also have explanatory power. If a system had a belief about the
user’s task, detection of such potential turning points in a session could help the system
resolve hypotheses about the user’s needs and anticipate their next actions.

7.2

Contributions

There are several possible contributions of the dissertation.

7.2.0.1

Development of an empirical approach to representing user mental
states associated with information processing

The methodology uses observations of eye fixations to infer a representation of mental
information processing states. The technique is based on unsupervised learning. It has
the virtue that the eye fixation patterns can be understood to have a causal connection
to cognitive states. This inference depends on the fact that eyes remain fixated until (at
least) word meanings are acquired. This connects patterns of eye fixations in reading with
sequences of mental states. The actual mental information processing states are no doubt

181

quite complex. The eye fixation pattern measurement vectors provide only a hint about
aspects of the actual states at best and may only reflect statistical properties of the user’s
actions when they are in those states. Indeed, the representation of a learned mental
’state space’ based on the clusters says nothing about the actual number of states or their
distinguishing properties. The contribution of the dissertation lays in the demonstration
that a simple unsupervised modeling of attention allocation in the form of eye fixations can
distinguish tasks and behaviors, which are rather high level cognitive activities.

7.2.0.2

A representation of the search task process that is congenial to computation

The dissertation work has produced a grounded representation of the ISS process which
connects observable behavior and some aspects of presumed cognitive states of a user. It
has laid out key components in a representational framework with a focus on a key unit
behavior generation process, the search intention plan. That search intention plan unit was
approximately modeled as a Pólya urn. Some further work derived a coherence property
of the sequences. The proposed action sequence coherence measure may help to identify
units of successive intentions. This sequence coherence model may a computational route to
identify intentional process structures in ISS related to user strategies and tactics to realize
overall motivating task goals.

7.2.0.3

A theoretical model of the search process grounded in theory of human
action

The work provides a description and theoretical model of the search process which is explicitly grounded in the theory of human action. The theory of human action is the received
view of how humans make work on the world. Further, the elements and process of the
theory have physical analogs in brain organization and neural processing [144, 146, 214].
Previous research in information science can be seen to implicitly rest on the theory of
human action, but the connection has not been made explicit. It is hoped this perspective
provides better grounding for search process representation.

182

This explicit connection to theory of human action helps to elaborate an explanatory
framework for IIR modeling. That framework is potentially one that can accommodate
alternative approaches to modeling and also inform approaches to the problem of simulating
users and task sessions.

7.2.0.4

A theoretical model of the search process with explicit relationships to
task constructs

Task and task structure has been an important, but difficult to characterize, construct for
information science. Most of the work has either been top-down in its formulation, relying
on human assessment of the key properties, or it has been descriptive and based on empirical
behaviors of information workers. These characterizations make it hard to formulate precise
research questions, for example about differences in motivating task types, that can be
coordinated across research programs.
The dissertation model presents a methodology to learn an objective representation of
an ISS within a user-centered framework. The models make clear distinctions between
an ISS, the structure of an ISS, and constructs of search intent, plans, subtasks, and actions/behaviors. These allow for more precise statements of hypotheses and understanding
of results.
The dissertation has also connected information search task process representation with
high level properties of human task performance. It presents task structure as resulting from
sequences of goal-directed attention allocation. This connection to goal-directed attention
allocation is worked out through a simplified analysis of the user’s reading eye movement
patterns. Other behavior observation representations might be developed to address image search, multi-modal information processing, etc. This may also suggest a direction to
integrate use of information systems in task environments where information search is a
part of a larger task process, for example in an emergency medical situation. One potentially useful representation of information task structure is to investigate the relationship
between structure in two task environments through analysis of behavior sequences based
on representations involving attention allocation.

183

7.2.0.5

Evidence for a cognitive-behavior link hypothesis

The model and methodology that connects reading eye movement behavior with goaldirected attention allocation articulates a cognitive-behavior link hypothesis. This hypothesis is implicit in much IIR research but has not, to the author’s knowledge, been explicitly
addressed. Although there are significant limitations in the methodology to show specific
connections with actual cognitive states, the dissertation results provide evidence for the
hypothesis.

7.2.0.6

The search task process as an exchangeable process

Another potential contribution of the dissertation is the development of a representational
model of the search task process based on sequential plan implementation in an exchangeable
process. This allows for computation and comparisons without use of similarity functions.
The move to an exchangeable process enables calculation of theoretically sound complexity and other measures of search task sessions based on subjective Bayesian approaches.
It addresses a theoretical problem. Human interaction with the world does not generate
iid observations because it is a cognitive process. A user changes as they learn and knowledge gain is characteristic of complex and exploratory information search. Interactions
with an information object cannot be exactly the same when the user is applying changed
concepts during the interaction with the information content. Familiar approximations of
Kolmogorov complexity, such as MDL, depend on similarity measurements and require that
observations be iid. So many calculations one would like to make about sessions, such as
search sequence complexity, can be better grounded by avoiding similarity based calculations.

7.3

Final thoughts

The dissertation goal of providing a computable representation of the observable information
search task session process has not been realized. This is not unanticipated. Overall, the
spirit of the work has been to integrate aspects of IIR in a cognitive framework. On that
score the dissertation can perhaps claim some success in articulating part of a cognitive

184

foundation for interactive information retrieval.
A theoretical and representational model of the ISS process has been proposed. It
claims solid connections to cognitive neuro-science research and to accepted theories of
intentionality and how human make action on the World. It embraces unifying concepts
of task descriptions in terms of user attention and behaviors. These are touch points to
situate information search in larger task processes. It is common that information search
is only a part of many real world task processes. A cognitively-centered representation of
task performance can provide a framework to integrate information search with the user
task processes.
A more complete development of the ISS model sketched out in this dissertation could
provide ways to automatically detect task properties and anticipate user moves through
identification of the structure of the ISS process as it unfolds. Successful development
of such a system could also contribute to the design of systems than can simulate user
search interaction behaviors. Such systems could be used to perform whole task system
performance evaluation.

185

References
[1] Mikhail Ageev, Qi Guo, Dmitry Lagun, and Eugene Agichtein. Find it if you can:
A game for modeling different types of web search success using interaction data.
In Proceedings of the 34th international ACM SIGIR conference on Research and
development in Information Retrieval, pages 345–354, New York, NY, USA, 2011.
ACM.
[2] Philip E. Agre. Computation and Human Experience. Cambridge University Press,
Cambridge, UK, 1997.
[3] James Allan, Bruce Croft, Alistair Moffat, and Mark Sanderson. Frontiers, Challenges, and Opportunities for Information Retrieval: Report from SWIRL 2012
the Second Strategic Workshop on Information Retrieval in Lorne. SIGIR Forum,
46(1):2–32, May 2012.
[4] John R. Anderson. The architecture of cognition. Cambridge, MA: Harvard Univer,
1983.
[5] John R. Anderson and C. Lebiere. The atomic components of thought. Lawrence
Erlbaum, 1998.
[6] T. W. Anderson and Leo A. Goodman. Statistical inference about Markov chains.
The Annals of Mathematical Statistics, 28(1):89–110, March 1957.
[7] Samur Araujo, Gebrekirstos Gebremeskel, Jiyin He, Corrado Bosscarino, and Arjen
de Vries. CWI at TREC 2012, KBA Track and Session Track. In TREC 2012. NIST,
November 2012.
[8] Robert Audi. Action, Intention, and Reason. Cornell University Press, Ithica, NY,
1st edition, 1993.
[9] Marcia J. Bates. Idea tactics. Journal of the American Society for Information
Science, 30:280–289, September 1979.
[10] Marcia J. Bates. Information search tactics. Journal of the American Society for
Information Science, 30(4):205–214, 1979.
[11] Marcia J. Bates. The design of browsing and berry-picking techniques for online
search interface. Online Information Review, 13(5):407–424, 1989.
[12] Marcia J. Bates. Berrypicking. Journal of Documentation, 52:350–351, 1996.
[13] Nicholas J. Belkin. Anomalous states of knowledge as a basis for information retrieval.
Canadian Journal of Information Science, 5(1):133–143, 1980.

186

[14] Nicholas J. Belkin. Intelligent information retrieval: Whose intelligence? In ISI ’96:
Proceedings of the Fifth International Symposium for Information Science., volume 96,
pages 25–31, 1996.
[15] Nicholas J. Belkin. Some(what) grand challenges for information retrieval. SIGIR
Forum, 42(1):47–54, 2008.
[16] Nicholas J. Belkin, Colleen Cool, Adelheit Stein, and Ulrich Thiel. Cases, scripts,
and information-seeking strategies: on the design of interactive information retrieval
systems. Expert Systems with Applications, 9(3):379–395, 1995.
[17] Nicholas J. Belkin, P.G. Marchetti, and Colleen Cool. BRAQUE: Design of an interface to support user interaction in information retrieval. Information Processing and
Management, 29(3):325–344, 1993.
[18] Yoshua Bengio. Learning deep architectures for AI. Foundations and Trends in
Machine Learning, 2(1):1–127, 2009.
[19] Frank Bickenbach and Eckhardt Bode. Markov or Not Markov – This Should Be
a Question. Technical report, Institut für Weltwirtschaft an der Universität Kiel,
January 2001.
[20] Ralf Bierig, Jacek Gwizdka, and Michael J. Cole. A user-centered experiment and
logging framework for interactive information retrieval. In Nicholas J. Belkin, Ralf
Bierig, Georg Buscher, Ludger van Elst, Jacek Gwizdka, Joeman Jose, and Jamie
Teevan, editors, Proceedings of the SIGIR 2009 Workshop on Understanding the User:
Logging and interpreting user interactions in information search and retrieval., pages
8–11. CEUR, July 2009.
[21] H.E. Blanchard, Alexander Pollatsek, and Keith Rayner. The acquisition of parafoveal
word information in reading. Perception and Psychophysics, 46(1):85–94, 1989.
[22] Julie E. Boland. Linking eye movements to sentence comprehension in reading and
listening. In M. Carreiras and Jr. C. Clifton, editors, On the on-line study of sentence
comprehension: Eyetracking, ERP, and beyond, , pages 51–76. Taylor & Francis,
2004.
[23] Pia Borlund. The IIR evaluation model: a framework for evaluation of interactive
information retrieval systems. Information Research, 8(3), 2003.
[24] Michael E. Bratman. Intention, plans, and practical reason. Harvard University
Press, 1987.
[25] Michael E. Bratman, D.J. Israel, and Martha E. Pollack. Plans and resource-bounded
practical reasoning. Computational Intelligence, 4(3):349–355, 1988.
[26] Leo Breiman. Random forests. Machine Learning, 45:5–32, 2001.
[27] Franz C. Brentano. Psychology from an Empirical Standpoint. Routledge & Kegan
Paul, London, 1874.
[28] Ducan P. Brumby. A Model of Single-page Web Search: The Effect of Interdependence
on Link Assessment. In Proceedings of the Sixth International Conference on Cognitive
Modeling, pages 402–403, 2004.

187

[29] Ducan P. Brumby and Andrew Howes. Good enough but I’ll just check: Web-page
search as attenional refocusing. In Proceedings of the International Conference on
Cognitive Modeling, ICCM 2004, July 2004.
[30] Duncan P. Brumby and A. Howes. Strategies for guiding interactive search: An
empirical investigation into the consequences of label relevance for assessment and
selection. Human–Computer Interaction, 23(1):1–46, 2008.
[31] Georg Buscher, Andreas Dengel, and Ludger van Elst. Query Expansion Using GazeBased Feedback on the Subdocument Level. In Proceedings of SIGIR ’08, pages
387–394, Singapore, 2008. ACM.
[32] Georg Buscher, Ryen W. White, Susan T. Dumais, and Jeff Huang. Large-scale
analysis of individual and task differences in search result page examination strategies.
In Eytan Adar, Jaime Teevan, Eugene Agichtein, and Yoelle Maarek, editors, WSDM,
pages 373–382. ACM, 2012.
[33] Timothy J Buschman and Earl K Miller. Top-down versus bottom-up control of
attention in the prefrontal and posterior parietal cortices. Science, 315(5820):1860–2,
March 2007.
[34] Katriina Byström. Information and information sources in tasks of varying complexity. Journal of the American Society for Information Science and Technology,
53(7):581–591, 2002.
[35] Katriina Byström and Kalervo Järvelin. Task complexity affects information seeking
and use. Information Processing and Management, 31(2):191–213, 1995.
[36] S. Carberry. Techniques for Plan Recognition. User Modeling and User-Adapted
Interaction, 11(1):31–48, 2001.
[37] R.H.S. Carpenter and Scott A. McDonald. LATER predicts saccade latency distributions in reading. Experimental Brain Research, 177(2):176–183, 2007.
[38] Glenn Carroll and Eugene Charniak. A Probabilistic Analysis of Marker-Passing
Techniques for Plan-Recognition. CoRR, abs/1303.5711, 2013.
[39] Christopher D Chambers and Jason B Mattingley. Neurodisruption of selective attention: insights and implications. Trends Cogn. Sci. (Regul. Ed.), 9(11):542–50,
November 2005.
[40] C.K. Chang and E.D. McDaniel. Information search strategies in loosely structured
settings. Journal of Educational Computing Research, 12:85–95, 1995.
[41] E. Charniak and D. McDermott. Introduction to Artifical Intelligence. AddisonWesley, Reading, MA, 1987.
[42] N A Chuzhanova, A J Jones, and S Margetts. Feature selection for genetic sequence
classification. Bioinformatics, 14(2):139–143, 1998.
[43] Philip R. Cohen and Hector J. Levesque. Intention is choice with commitment. Artificial Intelligence, 42(42):213–261, 1990.

188

[44] Philip R. Cohen, C.R. Perrault, and James F. Allen. Beyond question answering. In
W. Lehnert and M. Ringle, editors, Strategies for Natural Language Processing, pages
245–274. Lawrence Erlbaum Associates, Hillsdale, NJ, 1981.
[45] Michael J. Cole, Jacek Gwidzka, Chang Liu, Nicholas J. Belkin, and Xiangmin Zhang.
Inferring user knowledge level from eye movement patterns. Information Processing
& Management, 49(5):1075–1091, November 2012.
[46] Michael J. Cole, Jacek Gwizdka, Ralf Bierig, Nicholas J. Belkin, Jingjing Liu, Chang
Liu, Jun Zhang, and Xiangmin Zhang. Linking search tasks with low-level eye movement patterns. In Proceedings of the 17th European Conference on Cognitive Ergonomics, Delf, The Netherlands, June 2010.
[47] Michael J. Cole, Jacek Gwizdka, Chang Liu, and Nicholas J. Belkin. Dynamic assessment of information acquisition effort during interactive search. In Proceedings
of the American Society for Information Science and Technology Conference (2011),
volume 48, pages 1–10, New Orleans, LA, October 2011. ASIS&T.
[48] Michael J. Cole, Jacek Gwizdka, Chang Liu, Nicholas J. Belkin, Ralf Bierig, and
Xiangmin Zhang. Task and user effects on reading patterns in information search.
Interacting with Computers, 23(4):346–362, July 2011.
[49] Michael J. Cole, Chathra Hendahewa, Nicholas J. Belkin, and Chirag Shah. Discrimination Between Tasks with User Activity Patterns During Information Search. In
Proceedings of the 37th International ACM SIGIR Conference on Research & Development in Information Retrieval, SIGIR ’14, pages 567–576, New York, NY, USA,
2014. ACM.
[50] Michael J. Cole, Chathra Hendahewa, Nicholas J. Belkin, and Chirag Shah. User
activity patterns during information search. ACM Trans. Inf. Syst., 33(1):1:1–1:39,
March 2015.
[51] Colleen Cool. The nature of situational assessment in new information retrieval environments. In ASIS’97 (Washington, DC), pages 135–146. ASIST, November 1997.
[52] Colleen Cool and Nicholas J. Belkin. A classification of interactions with information.
In H. Bruce, R. Fidel, P. Ingwersen, and P. Vakkari, editors, Emerging frameworks
and methods. Proceedings of the Fourth International Conference on Conceptions of
Library and Information Science (COLIS4), pages 1–15, Greenwood Village, CO,
2002. Libraries Unlimited.
[53] L. Copeland and T. Gedeon. Measuring reading comprehension using eye movements.
In Cognitive Infocommunications (CogInfoCom), 2013 IEEE 4th International Conference on, pages 791–796, Dec 2013.
[54] Leana Copeland, Tom Gedeon, and Sumudu Mendis. Predicting reading comprehension scores from eye movements using artificial neural networks and fuzzy output
error. Artificial Intelligence Research, 3(3):35–48, 2014.
[55] M Corbetta, J M Kincade, J M Ollinger, M P McAvoy, and G L Shulman. Voluntary
orienting is dissociated from target detection in human posterior parietal cortex. Nat.
Neurosci., 3(3):292–7, March 2000.

189

[56] Maurizio Corbetta, Gaurav Patel, and Gordon L. Shulman. The Reorienting System
of the Human Brain: From Environment to Theory of Mind. Neuron, 58(3):306–324,
2008.
[57] Bruno De Finetti. On the condition of partial exchangeability. Studies in inductive
logic and probability, 2:193–205, 1980.
[58] Bruno De Finetti. Theory of probability. Vol. 1-2. John Wiley & Sons Ltd., Chichester,
1990.
[59] Daniel C. Dennett. The Intentional Stance. MIT Press, Cambridge, MA, 1987.
[60] Mukund Deshpande, Michihiro Kuramochi, and George Karypis. Frequent SubStructure-Based Approaches for Classifying Chemical Compounds. In Proceedings
of the Third IEEE International Conference on Data Mining, ICDM ’03, pages 35–,
Washington, DC, USA, 2003. IEEE Computer Society.
[61] M. Desmurget, K.T. Reilly, N. Richard, A. Szathmari, C. Mottolese, and A. Sirigu.
Movement Intention after Parietal Cortex Stimulation in Humans.
Science,
324(5298):811–813, 2009.
[62] Ezio Di Nucci. Simply, false. Analysis, 69(1):69–78, 2009.
[63] Perci Diaconis. Recent Progress on de Finetti’s Notions of Exchangeability. Bayesian
Statistics, 3:111–125, 1988.
[64] A. Dove, T. Manly, R. Epstein, and A. M. Owen. The Engagement of MidVentrolateral Prefrontal Cortex and Posterior Brain Regions in Intentional Cognitive
Activity. Human Brain Mapping, (29):107–119, 2008.
[65] Denis Drieghe, T. Desmet, and M. Brysbaert. How important are linguistic factors
in word skipping during reading? British Journal of Psychology, 98:157–171, 2007.
[66] Denis Drieghe, Alexander Pollatsek, B.J. Juhasz, and Keith Rayner. Parafoveal
processing during reading is reduced across a morphological boundary. Cognition,
116(1):136–142, 2010.
[67] Wolfgang Einhäuser, Christof Koch, and Olivia L. Carter. Pupil dilation betrays the
timing of decisions. Frontiers in Human Neuroscience, 4(0):12, February 2010.
[68] Wolfgang Einhäuser, James Stout, Christof Koch, and Olivia L. Carter. Pupil dilation
reflects perceptual selection and predicts subsequent stability in perceptual rivalry.
PNAS, 105(5):1704–1709, February 2008.
[69] David Ellis. A behavioural approach to information retrieval design. Journal of
Documentation, 45(3):171–212, 1989.
[70] R Fidel and Dagobert Soergel. Factors affecting online bibliographic retrieval: A
conceptual framework for research. Journal of the American Society for Information
science and Technology, 34(3):163–180, 1983.
[71] J.M. Findlay and I.D. Gilchrist. Visual attention: the active vision perspective. Vision and attention, pages 83–103, 2001.

190

[72] J.M. Findlay and I.D. Gilchrist. Active vision: The psychology of looking and seeing.
Oxford University Press New York, 2003.
[73] Peter W. Foltz, Walter Kintsch, and Thomas K. Landauer. The measurement of
textual coherence with latent semantc analysis. Discourse Processes, 25(2&3):285–
307, 1998.
[74] Luanne Silvia Freund. Exploiting Task-Document Relations in Support of Information
Retrieval in the Workplace. PhD thesis, University of Toronto, Toronto, 2008.
[75] Norbert Fuhr. A probability ranking principle for interactive information retrieval.
Information Retrieval, 12, 2008.
[76] Norbert Fuhr, Nicholas J. Belkin, Joemon Jose, and Keith C. J. van Rijsbergen. 09101
Workshop Report – Interactive Information Retrieval. In Nicholas J. Belkin, Norbert
Fuhr, Joemon Jose, and C. J. Keith van Rijsbergen, editors, Interactive Information
Retrieval, number 09101 in Dagstuhl Seminar Proceedings, Dagstuhl, Germany, 2009.
Schloss Dagstuhl - Leibniz-Zentrum fur Informatik, Germany.
[77] Barbara J. Grosz and Candace L. Sidner. Attention, intentions and the structure of
discourse. Computational Linguistics, 12(3):175–204, July-September 1986.
[78] Barbara J. Grosz, Scott Weinstein, and Aravind K. Joshi. Centering: A framework for
modeling the local coherence of discourse. Computational Linguistics, 21(2):203–225,
1995.
[79] Jacek Gwizdka. Distribution of cognitive load in web search. Journal of the American
Society for Information Science and Technology, 61(11):2167–2187, 2010.
[80] Jacek Gwizdka and Michael J. Cole. Least effort? Not if I can search more. In Gene
Golovchinsky, Rob Capra, Bill Kules, and Cathy Smith, editors, Proceedings of HCIR
2011, Mountain View, CA., October 2011.
[81] Jacek Gwizdka and Ian Spence. What can searching behavior tell us about the difficulty of information tasks? A study of Web navigation. Proceedings of the American
Society for Information Science and Technology, 43(1):1–22, 2006.
[82] Shuguang Han, Zhen Yue, and Daqing He. Automatic Detection of Search Tactic in
Individual Information Seeking: A Hidden Markov Model Approach. In iConference
2013 Proceedings, pages 712–716, 2013.
[83] Ahmed Hassan, Rosie Jones, and Kristina L. Klinkner. Beyond DCG: User behavior
as a predictor of a successful search. In Proceedings of the Third ACM International
Conference on Web Search and Data Mining, pages 221–230, New York, 2010. ACM.
[84] Mary M. Hayhoe and Dana H. Ballard. Eye movements in natural behavior. Trends
in Cognitive Sciences, 9(4):188–194, 2005.
[85] J-D Haynes, K. Sakai, G. Rees, S. Gilbert, C. Frith, and R.E. Passingham. Reading
Hidden Intentions in the Human Brain. Current Biology, (17):323–328, 2007.
[86] Martin Heidegger. Being and time (J. Macquarrie & E. Robinson, trans.), 1962.

191

[87] John M. Henderson. Human gaze control during real-world scene perception. Trends
in Cognitive Sciences, 7(11):498–504, 2003.
[88] J M Hopf and G R Mangun. Shifting visual attention in space: An electrophysiological
analysis using high spatial resolution mapping. Clinical Neurophysiology, 111:1241–
1257, 2000.
[89] Anthony J. Hornof and T. Halverson. Cleaning up systematic error in eye-tracking
data by using required fixation locations. Behavior Research Methods, Instruments,
& Computers, 34(4):592–604, 2002.
[90] Jukka Hyönä, R.F. Lorch, and J.K. Kaakinen. Individual differences in reading to
summarize expository text: Evidence from eye fixation patterns. Journal of Educational Psychology, 94(1):44–55, 2002.
[91] Peter Ingwersen and Kalervo Järvelin. The turn: Integration of information seeking
and retrieval in context. Springer, first edition, 2005.
[92] Albrecht W. Inhoff and W. Liu. The perceptual span and oculomotor activity during the reading of Chinese sentences. Journal of Experimental Psychology. Human
Perception and Performance, 24(1):20–34, 1998.
[93] Albrecht W. Inhoff and Keith Rayner. Parafoveal word processing during eye fixations
in reading: Effects of word frequency. Perception & Psychophysics, 40(6):431, 1986.
[94] E. Javal. Essai sur la physiologie de la lecture. Annales d’ocullistique, 80:61–73, 1878.
[95] Jiepu Jiang, Daqing He, and James Allan. Searching, Browsing, and Clicking in a
Search Session: Changes in User Behavior by Task and over Time. In Proceedings
of the 37th International ACM SIGIR Conference on Research & Development in
Information Retrieval, SIGIR ’14, pages 607–616, New York, NY, USA, 2014. ACM.
[96] Soohyung Joo and Iris Xie. Exploring Search Tactic Patterns in Searching Digital
Libraries. In Hsin-Hsi Chen and Gobinda Chowdhury, editors, ICADL, volume 7634
of Lecture Notes in Computer Science, pages 349–350. Springer, 2012.
[97] B.J. Juhasz, S.J. White, Simon P. Liversedge, and Keith Rayner. Eye movements
and the use of parafoveal word length information in reading. Journal of experimental
psychology. Human perception and performance, 34(6):1560, 2008.
[98] G. Kambe. Parafoveal processing of prefixed words during eye fixations in reading:
Evidence against morphological influences on parafoveal preprocessing. Perception &
Psychophysics, 66(2):279–292, 2004.
[99] Keith S. Karn and Mary M. Hayhoe. Memory representations guide targeting eye
movements in a natural task. Visual Cognition, 7(6):673–703, 2000.
[100] Leonard Kaufman and Peter J. Rousseeuw. Partitioning Around Medoids (Program
PAM), pages 68–125. John Wiley & Sons, Inc., 2008.
[101] H.A. Kautz. A formal theory of plan recognition and its implementation. Reasoning
about Plans, pages 69–126, 1991.

192

[102] Melanie Kellar, Carolyn Watters, and Michael Shepherd. A field study characterizing
Web-based information-seeking tasks. Journal of the American Society for Information Science and Technology, 58(7):999–1018, 2007.
[103] Diane Kelly and Nicholas J. Belkin. Reading time, scrolling and interaction: Exploring
implicit sources of user preferences for relevance feedback. In Proceedings of SIGIR
’01, pages 408–409. ACM New York, NY, USA, 2001.
[104] Diane Kelly and Nicholas J. Belkin. Display time as implicit feedback: Understanding
task effects. In Proceedings of the 27th Annual International ACM SIGIR Conference
on Research and Development in Information Retrieval, pages 377–384, Sheffield, UK,
July 2004. ACM, ACM.
[105] Charles Kemp and Joshua B. Tennenbaum. The discovery of structural form. PNAS,
105(31):10687–10692, 2008.
[106] D.E. Kieras and D.E. Meyer. An overview of the EPIC architecture for cognition
and performance with application to human-computer interaction. Human-Computer
Interaction, 12(4):391–438, 1997.
[107] D.E. Kieras, S.D. Wood, and D.E. Meyer. Predictive engineering models based on the
EPIC architecture for a multimodal high-performance human-computer interaction
task. ACM Transactions on Computer-Human Interaction, 4(3):230–275, 1997.
[108] Jeonghyun Kim. Task as a predictable indicator for information seeking behavior on
the Web. PhD thesis, Rutgers, The State University of New Jersey, New Brunswick,
NJ, 2006.
[109] Jin Young Kim, Mark Cramer, Jaime Teevan, and Dmitry Lagun. Understanding
how people interact with web search results that change in real-time using implicit
feedback. In Proceedings of the 22nd ACM International Conference on Information
& Knowledge Management, CIKM ’13, pages 2321–2326, New York, NY, USA, 2013.
ACM.
[110] Walter Kintsch. The representation of Knowledge in Minds and Machines. Journal
of Psychology, 33(6):411–420, 1998.
[111] Eileen Kowler. Attention and Eye Movements, pages 605–616. New Encyclopedia of
Neuroscience. Elsevier, New York, New York, 2006.
[112] Carol Collier Kuhlthau. Inside the search process: Information seeking from the user’s
perspective. Journal of the American Society for Information Science, 42(5):361–371,
1991.
[113] Thomas K. Landauer. On the computational basis of learning and cognition: Arguments from LSA. In N. Ross, editor, The Psychology of Learning and Motivation,
volume 41, pages 43–84. Elsevier Science, 2002.
[114] H.C. Lau, R.D. Rogers, and R.E. Passingham. Manipulating the Experienced Onset
of Intention after Action Execution. Journal of Cognitive Neuroscience, 19(1):1–10,
2007.

193

[115] Kangwoo Lee and Hyunseung Choo. A Critical Review of Selective Attention: An
Interdisciplinary Perspective. Artif. Intell. Rev., 40(1):27–50, June 2013.
[116] Gordon E Legge, Sing-Hang Cheung, Deyue Yu, Susana T L Chung, Hye-Won Lee,
and Daniel P Owens. The case for the visual span as a sensory bottleneck in reading.
J Vis, 7(2):9.1–15, 2007.
[117] Yuelin Li. Relationships among work tasks, search tasks, and interactive information
searching behavior. PhD thesis, Rutgers University, 2008.
[118] Yuelin Li. Exploring the relationships between work task and search task in information search. Journal of the American Society for Information Science and Technology,
60(2):275–291, 2009.
[119] Chang Liu. Personalizing information retrieval using interaction behaviors in search
sessions in different types of tasks. PhD thesis, Rutgers University, 2012.
[120] Chang Liu, Michael J. Cole, Eun Baik, and Nicholas J. Belkin. Rutgers at the TREC
2012 Session Track. In Ellen Vorhese and Ian Soboroff, editors, The Twenty First
Text Retrieval Conference Proceedings (TREC 2012), Gaithersburg, MD, November
2012. NIST.
[121] Chang Liu, Michael J. Cole, and Nicholas J. Belkin. Personalization of search results
using interaction behaviors in search sessions. In Proceedings of SIGIR2012, pages
205–214, Portland, OR, Aug 2012. ACM.
[122] Chang Liu, Jacek Gwizdka, and Jingjing Liu. Helping identify when users find useful
documents: examination of query reformulation intervals. In Proceeding of the third
symposium on Information interaction in context, pages 215–224. ACM, 2010.
[123] Chang Liu, Jacek Gwizdka, Jingjing Liu, Tao Xu, and Nicholas J. Belkin. Analysis
and evaluation of query reformulations in different task types. In Proceedings of the
73rd ASIS&T Annual Meeting on Navigating Streams in an Information Ecosystem Volume 47, ASIS&T ’10, pages 17:1–17:10, Silver Springs, MD, USA, 2010. American
Society for Information Science.
[124] Chang Liu, Jingjing Liu, Nicholas J. Belkin, Michael J. Cole, and Jacek Gwizdka. Using dwell time as an implicit measure of usefulness in different task types. Proceedings
of the American Society for Information Science and Technology, 48(1):1–4, October
2011.
[125] Jingjing Liu, Michael J. Cole, Chang Liu, Ralf Bierig, Jacek Gwizdka, Nicholas J.
Belkin, Jun Zhang, and Xiangmin Zhang. Search Behaviors in Different Task Types.
In Proceedings of the 10th Annual Joint Conference on Digital Libraries, JCDL ’10,
pages 69–78, New York, NY, USA, 2010. ACM.
[126] Jingjing Liu, Jacek Gwizdka, Chang Liu, and Nicholas J. Belkin. Predicting Task
Difficulty for Different Task Types. In Proceedings of the 73rd ASIS&T Annual Meeting on Navigating Streams in an Information Ecosystem - Volume 47, ASIS&T ’10,
pages 16:1–16:10, Silver Springs, MD, USA, 2010. American Society for Information
Science.

194

[127] W. Liu, Albrecht W. Inhoff, Y. Ye, and C. Wu. Use of parafoveally visible characters
during the reading of Chinese sentences. Journal of experimental psychology. Human
perception and performance, 28(5):1213–1227, 2002.
[128] Jiyun Luo, Sicong Zhang, and Hui Yang. Win-win search: Dual-agent stochastic game
in session search. In Proceedings of the 37th international ACM SIGIR conference on
Research & development in information retrieval, pages 587–596. ACM, 2014.
[129] W.C. Mankowski, P. Bogunovich, A. Shokoufandeh, and Dario D. Salvucci. Finding canonical behaviors in user protocols. In Proceedings of the 27th international
conference on Human factors in computing systems, pages 1323–1326. ACM, 2009.
[130] W.C. Mankowski, P. Bogunovich, A. Shokoufandeh, and Dario D. Salvucci. On Computing Canonical Subsets of Graph-Based Behavioral Representations. In Proceedings
of the 7th IAPR-TC-15 International Workshop on Graph-Based Representations in
Pattern Recognition, page 222. Springer, 2009.
[131] Gary Marchionini. Information-seeking strategies of novices using a full-text electronic
encyclopedia. Journal of the American Society for Information Science, 40(1):54–66,
1989.
[132] Gary Marchionini. Exploratory Search: From finding to understanding. Communications of the ACM, 49(4):41–46, April 2006.
[133] Gary Marchionini and Hermann Maurer. The roles of digital libraries in teaching and
learning. Communications of the ACM, 38(4):67–75, 1995.
[134] Andrew R Mayer, Jill M Dorflinger, Stephen M Rao, and Michael Seidenberg. Neural
networks underlying endogenous and exogenous visual-spatial orienting. Neuroimage,
23(2):534–41, October 2004.
[135] J. McCall. Induction: Algorithmic and exchangeable aspects. In K. Velupillai, editor, Computability, Complexity and Constructivity in Economic Analysis. Blackwell,
Malden, MA, 2005.
[136] John J. McCall. An introduction to exchangeability and its economic applications.
Technical Report 526, UCLA, Los Angeles, September 1988.
[137] Hugh J. McCann. Di Nucci on the Simple View. Analysis, 70(1):53–59, 2009.
[138] Douglas L. Medin and M.H. Bazerman. Broadening behavioral decision research:
Multiple levels of cognitive processing. Psychonomic Bulletin and Review, 6(4):533–
546, 1999.
[139] R.K. Morris. Lexical and message-level sentence context effects on fixation times
in reading. Journal of Experimental Psychology: Learning, Memory, and Cognition,
20(1):92, 1994.
[140] R.K. Morris, Keith Rayner, and Alexander Pollatsek. Eye movement guidance in
reading: the role of parafoveal letter and space information. Journal of Experimental
Psychology. Human Perception and Performance, 16(2):268, 1990.

195

[141] R.E. Morrison. Manipulation of stimulus onset delay in reading: Evidence for parallel
programming of saccades. Journal of Experimental Psychology: Human Perception
and Performance, 10(5):667–682, 1984.
[142] Vidhya Navalpakkam, LaDawn Jentzsch, Rory Sayres, Sujith Ravi, Amr Ahmed, and
Alex J. Smola. Measurement and modeling of eye-mouse behavior in the presence of
nonlinear page layouts. In 22nd International World Wide Web Conference, WWW
’13, Rio de Janeiro, Brazil, May 13-17, 2013, pages 953–964, 2013.
[143] Alan Newell. Unified Theories of Cognition: The William James Lectures 1987. Harvard University Press, Cambridge MA, 1990.
[144] J. Okuda, F. Toshikatsu, A. Yamadori, R. Kawashima, T. Tsukiura, R. Fukatsu,
K. Suzuki, M. Ito, and H. Fukuda. Participation of the Prefrontal Cortices in
Prospective Memory: Evidence from a PET study in Humans. Neuroscience Letters, (253):127–130, 1998.
[145] Flavio T.P. Oliveira, Anne Aula, and Daniel M. Russell. Discriminating the relevance
of web search results with measures of pupil size. In Proceedings of CHI ’09, pages
2209–2212, Boston, MA, USA, April 2009. ACM.
[146] T. Paus. Primate anterior cingulate cortex: Where motor control, drive and cognition
interface. Nature Review, (2):417–424, 2001.
[147] Judea Pearl. Causality: Models, Reasoning, and Inference. Cambridge University
Press, New York, 2000.
[148] C.R. Perrault, James F. Allen, and Philip R. Cohen. Speech acts as a basis for understanding dialogue coherence. In Proceedings of the 1978 Workshop on Theoretical
Issues in Natural Language Processing, pages 125–132. Association for Computational
Linguistics, Association for Computational Linguistics, 1978.
[149] Michael Petrides and A. Baddeley. Specialized Systems for the Processing of
Mnemonic Information within the Primate Frontal Cortex [and Discussion]. Philosophical Transactions of the Royal Society of London B: Biological Sciences,
351(1346):1455–1462, 1996.
[150] Peter Pirolli. Information Foraging Theory. Oxford University Press, New York, 1st
edition, 2007.
[151] Martha E. Pollack. Plans as complex mental attitudes, pages 77–104. MIT Press,
Cambridge, MA, 1990.
[152] Alexander Pollatsek and Keith Rayner. Eye movements and lexical access in reading.
DA Balota, GB Flores d’Arcais, & K. Rayner (Eds.), Comprehension processes in
reading, pages 143–163, 1990.
[153] Alexander Pollatsek, Keith Rayner, and David A. Balota. Inferences about eye movement control from the perceptual span in reading. Perception & Psychophysics,
40(2):123–130, 1986.
[154] Alexander Pollatsek, Keith Rayner, M.H. Fischer, and Erik D. Reichle. Attention and
eye movements in reading, pages 179–209. Routledge, London, May 1999.

196

[155] Alexander Pollatsek, Eric D. Reichle, and Keith Rayner. Tests of the EZ Reader
model: Exploring the interface between cognition and eye-movement control. Cognitive Psychology, 52(1):1–56, February 2006.
[156] Alexander Pollatsek, Erik D. Reichle, and Keith Rayner. Modeling eye movements in
reading: Extensions of the EZ Reader model. The mind’s eyes: Cognitive and applied
aspects of oculomotor research, pages 361–90, 2003.
[157] Liwen Qiu. Analytical Searching vs. Browsing in Hypertext Information Retrieval
Systems. Canadian Journal of Information Science and Library Science, 18(4):1–13,
1993.
[158] Liwen Qiu. Markov models of search state patterns in a hypertext information retrieval system. JASIST, 44(7):413–427, 1993.
[159] R. Rafal, F. Gershberg, R. Egly, R. Ivry, A. Kingstone, and T. Ro. Response channel activation and the lateral prefrontal cortex. Neuropsychologia, 34(12):1197–1202,
1996.
[160] R D Rafal, M I Posner, J H Friedman, A W Inhoff, and E Bernstein. Orienting of
visual attention in progressive supranuclear palsy. Brain, 111 ( Pt 2):267–80, April
1988.
[161] Keith Rayner. Eye movements in reading and information processing: 20 years of
research. Psychological Bulletin, 124:372–422, 1998.
[162] Keith Rayner. Eye movements and attention in reading, scene perception, and visual
search. The Quarterly Journal of Experimental Psychology, 62(8):1457–1506, 2009.
[163] Keith Rayner, Kathryn H. Chace, Timothy J. Slattery, and Jane Ashby. Eye movements as reflections of comprehension processes in reading. Scientific Studies of Reading, 10(3):241–255, 2006.
[164] Keith Rayner and S.A. Duffy. Lexical complexity and fixation times in reading: Effects
of word frequency, verb complexity, and lexical ambiguity. Memory & Cognition,
14(3):191–201, 1986.
[165] Keith Rayner and M.H. Fischer. Mindless reading revisited: Eye movements during
reading and scanning are different. Perception & Psychophysics, 58(5):734–747, 1996.
[166] Keith Rayner, X. Li, C. C. Williams, K. R. Cave, and A.D. Well. Eye movements
during information processing tasks: Individual differences and cultural effects. Vision
Research, 50(21):2714–2726, 2007.
[167] Keith Rayner, Simon P. Liversedge, and S.J. White. Eye movements when reading disappearing text: The importance of the word to the right of fixation. Vision
Research, 46(3):310–323, 2006.
[168] Keith Rayner and Alexander Pollatsek. The Psychology of Reading. Lawrence Erlbaum Associates, Mahwah, New Jersey, 1989.
[169] Keith Rayner, G.E. Raney, and Alexander Pollatsek. Eye movements and discourse
processing. pages 9–36. L. Erlbaum Associates Inc., Hillsdale, N.J., 1995.

197

[170] Keith Rayner, Erik D. Reichle, and Alexander Pollatsek. Eye movement control in
reading: An overview and model, pages 243–268. Eye guidance in reading and scene
perception. Elsevier, Oxford, 1998.
[171] Keith Rayner, Tim J. Smith, George L. Malcolm, and John M. Henderson. Eye
Movements and Visual Encoding During Scene Perception. Psychological Science,
20(1):6–10, 2009.
[172] Keith Rayner, S.J. White, G. Kambe, B. Miller, and Simon P. Liversedge. On the
processing of meaning from parafoveal vision during eye fixations in reading,, pages
213–234. Elsevier, June 2003.
[173] E.D. Reichle, A.E. Reineberg, and J.W. Schooler. Eye movements during mindless
reading. Psychological Science, 21(9):1300, 2010.
[174] Erik D. Reichle, Alexander Pollatsek, D.L. Fisher, and Keith Rayner. Toward a model
of eye movement control in reading. Psychological Review, 105:125–157, 1998.
[175] Erik D. Reichle, Alexander Pollatsek, and Keith Rayner. E–Z Reader: A cognitivecontrol, serial-attention model of eye-movement behavior during reading. Cognitive
Systems Research, 7(1):4–22, 2006.
[176] Erik D. Reichle, Keith Rayner, and Alexander Pollatsek. The EZ Reader model of
eye-movement control in reading: Comparisons to other models. Behavioral and Brain
Sciences, 26(04):445–476, 2004.
[177] E.M. Reingold and Keith Rayner. Examining the word identification stages hypothesized by the EZ Reader model. Psychological Science, 17(9):742–746, 2006.
[178] P.S. Rosenbloom, Alan Newell, and J.E. Laird. The SOAR Papers: Research on
Integrated Intelligence. MIT Press, Cambridge, MA, USA, 1993.
[179] C.F. Schmidt, NS Sridharan, and J.L. Goodson. The Plan Recognition Problem:
An Intersection of Psychology and Artificial Intelligence. Artificial Intelligence, 11(12):45–83, 1978.
[180] John R. Searle. Intentionality: An Essay in the Philosophy of Mind. Cambridge
University Press, 1983.
[181] Sara C. Sereno, P.J. O’Donnell, and Keith Rayner. Eye movements and lexical ambiguity resolution: Investigating the subordinate-bias effect. Journal of Experimental
Psychology: Human Perception and Performance, 32(2):335, 2006.
[182] Hidetoshi Shimodaira. Approximately unbiased tests of regions using multistepmultiscale bootstrap resampling. Ann. Statist., 32(6):2616–2641, 12 2004.
[183] Jaana Simola, Jarkko Salojarvi, and Ilpo Kojo. Using hidden Markov model to uncover processing states from eye movements in information search tasks. Cognitive
Systems Research, 9(4):237–251, 2008.
[184] Herbert A. Simon. Models of Thought. Yale University Press, New Haven, CT, 1979.

198

[185] Philipp Singer, Denis Helic, Behnam Taraghi, and Markus Strohmaier. Detecting
Memory and Structure in Human Navigation Patterns Using Markov Chain Models
of Varying Order. PLoS ONE, 9(7):e102070, 07 2014.
[186] Robert C. Stalnaker. Pragmatic presuppositions. In Milton K. Munitz and Peter K.
Unger, editors, Semantics and Philosophy. New York University Press, 1974.
[187] Robert C. Stalnaker. On the Representation of Context. Journal of Logic, Language
and Information, 7(1):3–19, 1998.
[188] Robert C. Stalnaker. Context and Content. Oxford University Press, New York, 1999.
[189] Matthew Stone. Communicative Intentions and Conversational Processes in HumanHuman and Human-Computer Dialogue. Approaches to Studying World-Situated Language Use: Bridging the Language-as-Product and Language-as-Action Traditions,
2004.
[190] Carolin Strobl, Anne-Laure Boulesteix, and Thomas Augustin. Unbiased split selection for classification trees based on the Gini index. Computational Statistics & Data
Analysis, 52(1):483–501, 2007.
[191] Lucy A. Suchman. Plans and Situated Actions: The Problem of Human-Machine
Communication. Cambridge University Press, New York, 1987.
[192] Jaime Teevan, Christine Alvarado, Mark S. Ackerman, and David R. Karger. The
perfect search engine is not enough: a study of orienteering behavior in directed search.
In CHI ’04: Proceedings of the SIGCHI Conference on Human Factors in Computing
Systems, pages 415–422, Vienna, Austria, 2004. ACM Press.
[193] Jaime Teevan, Susan T. Dumais, and Eric Horvitz. Potential for personalization.
ACM Transactions on Computer-Human Interaction (TOCHI), 17(1):1–31, March
2010.
[194] Robert Tibshirani, Guenther Walther, and Trevor Hastie. Estimating the number of
clusters in a data set via the gap statistic. Journal of the Royal Statistical Society:
Series B (Statistical Methodology), 63(2):411–423, 2001.
[195] Tuan Vu Tran and Norbert Fuhr. Quantitative Analysis of Search Sessions Enhanced
by Gaze Tracking with Dynamic Areas of Interest. In Proceedings of the Second
International Conference on Theory and Practice of Digital Libraries, TPDL’12, pages
468–473, Berlin, Heidelberg, 2012. Springer-Verlag.
[196] Jochen Triesch, Dana H. Ballard, Mary M. Hayhoe, and Brian T. Sullivan. What you
see is what you need. Journal of Vision, 3:86–94, 2003.
[197] Chih-Hao Tsai and George W. McConkie. The perceptual span in reading Chinese
text: A moving window study. In Seventh International Conference on the Cognitive
Processing of Chinese and Other Asian Languages, Hong Kong, 1995.
[198] Pertti Vakkari. Task complexity, problem structure and information actions: Integrating studies on information seeking and retrieval. Information Processing &
Management, 35(6):819–837, 1999.

199

[199] Pertti Vakkari. Relevance and contributing information types of searched documents
in task performance. In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 2–9,
Athens, Greece, 2000. ACM.
[200] Pertti Vakkari. Task-based information searching. Annual Review of Information
Science and Technology, 37(1), 2003.
[201] Pertti Vakkari and N. Hakala. Changes in relevance criteria and problem stages in
task performance. Journal of Documentation, 56(5):540–562, 2000.
[202] V. Vapnik. Three fundamental concepts of the capacity of learning machines. Physica
A: Statistical Mechanics and its Applications, 200(14):538–544, 1993.
[203] Kumaraswamy Velupillai. Computable Economics. The Arne Ryde Memorial Lectures. Oxford University Press, New York, 2000.
[204] F. Vitu, J.K. O’Regan, Albrecht W. Inhoff, and R. Topolski. Mindless reading: Eye
movement characteristics are similar in scanning letter strings and reading texts. Perception & Psychophysics, 57(3):352–64, 1995.
[205] Peiling Wang, W.B. Hawk, and Carol Tenopir. Users’ interaction with World Wide
Web resources: An exploratory study using a holistic approach. Information Processing and Management, 36(2):229–251, 2000.
[206] Ryen W. White, Paul N. Bennett, and Susan T. Dumais. Predicting short-term interests using activity-based search context. In Proceedings of the 19th ACM International
Conference on Information and Knowledge Management. CIKM’10, pages 1009–1018,
Toronto, 2010. ACM, ACM.
[207] Ryen W. White and Diane Kelly. A study on the effects of personalization and
task information on implicit feedback performance. In Proceedings of the 15th ACM
International Conference on Information and Knowledge Management, pages 297–
306, Arlington, Virginia, USA, November 2006. ACM, ACM.
[208] Ryen W. White, Bill Kules, Steven M. Drucker, and m.c. schraefel. Supporting exploratory search: Introduction. Communications of the ACM, 49(4):36–39, 2006.
[209] Ryen W. White, Ian Ruthven, and J.M. Jose. A study of factors affecting the utility
of implicit relevance feedback. In Proceedings of the 28th Annual International ACM
SIGIR Conference on Research and Development in Information Retrieval, page 42,
Salvador, Brazil, 2005. ACM.
[210] S.J. White and Simon P. Liversedge. The influence of parafoveal word length and contextual constraint on fixation durations and word skipping in reading. Psychonomic
Bulletin & Review, 12:466–471, 2005.
[211] Barbara M. Wildemuth. The effects of domain knowledge on search tactic formulation.
Journal of the American Society for Information Science and Technology, 55(3):246–
258, 2004.
[212] R. Williams and R. Morris. Eye movements, word familiarity, and vocabulary acquisition. Journal of Cognitive Psychology, 16(1):312–339, 2004.

200

[213] Terry Winograd and F. Flores. Understanding Computers and Cognition: A New
Foundation for Design. Norwood. N3: Ablex Publishing, 1986.
[214] G. Winterer, C.M. Adams, D.W. Jones, and B. Knutson. Volition to Action—An
Event-Related fMRI Study. NeuroImage, (17):851–858, 2002.
[215] Laurence B. Wolfe and Chein-I Chang. A complete sufficient statistic for finite-state
Markov processes with application to source coding. IEEE Transactions on Information Theory, 39(3):1047–1049, 1993.
[216] R.D. Wright and L.M. Ward. Orienting of attention. Oxford University Press, USA,
New York, 2008.
[217] Hong (Iris) Xie. Patterns between interactive intentions and information-seeking
strategies. Information Processing & Management, 38(1):55–77, 2002.
[218] Hong (Iris) Xie. Interactive information retrieval in digital enviroments. IGI Global
Inc., Hershey, Pennsylvania, 2008.
[219] Hong (Iris) Xie. Dimensions of tasks: influences on information-seeking and retrieving
process. Journal of Documentation, 65(3):339–366, 2009.
[220] Hong (Iris) Xie. Information searching and search models, pages 2592–2604. Encyclopedia of Library and Information Sciences. Taylor and Francis LLC, third edition,
2010.
[221] Iris Xie and Soohyung Joo. Transitions in search tactics during the Web-based search
process. Journal of the American Society for Information Science and Technology,
61(11):2188–2205, 2010.
[222] M. F. Young, Kulikowich J. M., and S. A. Barab. The unit of analysis for situated
assessment. Instructional Science,, 25(2):133–150., 1997.
[223] Xiao-Jun Yuan and Nicholas J. Belkin. Supporting multiple information-seeking
strategies in a single system framework. In SIGIR 2007: Proceedings of the 30th
Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 247–254, Amsterdam, 2007. ACM.
[224] Zhen Yue, Shuguang Han, Jiepu Jiang, and Daqing He. Search Tactics As Means of
Examining Search Processes in Collaborative Exploratory Web Search. In Proceedings
of the 5th Ph.D. Workshop on Information and Knowledge, PIKM ’12, pages 59–66,
New York, NY, USA, 2012. ACM.
[225] Sandy L. Zabell. The continuum of inductive methods revisited, page 351. PittsburghKonstanz Series in the Philosophy and History of Science. Univ. of Pittsburgh Press,
Pittsburgh, PA, 1997.
[226] Sandy L. Zabell. Symmetry and its Discontents: Essays on the History of Inductive
Probability. Cambridge University Press, New York, 1st edition, 2005.
[227] Zhiping Zeng, Jianyong Wang, Lizhu Zhou, and George Karypis. Out-of-core Coherent Closed Quasi-clique Mining from Large Dense Graph Databases. ACM Trans.
Database Syst., 32(2), June 2007.

