SLOUCHING TOWARDS ALEXANDRIA: A CRITICAL ANALYSIS OF THE
SCHOLARLY COMMUNICATION SYSTEM

ABSTRACT

This dissertation provides an historical analysis of libraries and discusses the
broader system of scholarly communication and publishing using mixed methods from
critical media studies, library studies, organizational communication, systems sociology,
and rhetorical studies. It argues that practices of scholarly publishing in the US
university environment are grounded in myths and ideological systems of gatekeeping
which may prevent participants from recognizing dangers and opportunities associated
with digital librarianship. Three such myths operate to support the status quo system of
scholarly communication: the myth of authority, the myth of influence, and the myth of
permanence. These myths portend and reflect structural changes in relationships
governing the intertwining of library and university organizations, including emergent
organizational forms, intellectual property challenges by commercial scholarly
publishers, and new library-centered forms of publication enabled by new technologies.

CHAPTER I
INTRODUCTION: MODELING THE SYSTEM OF SCHOLARLY
COMMUNICATION
Introduction
Scholarly communication exists in the relationship amid four factors: research
and the methods by which it is evaluated, publication of that research, libraries that
preserve and disseminate the research, and the regime of intellectual property (Lyman &
Chodorow, 1998). The Association of College and Research Libraries (ACRL) defines
the system like this:
Scholarly communication is the system through which research and other
scholarly writings are created, evaluated for quality, disseminated to the
scholarly community, and preserved for future use. The system includes both
formal means of communication, such as publication in peer-reviewed journals,
and informal channels, such as electronic listservs (ACRL, 2006).
A key characteristic of scholarly research is that it is typically created as a public good,
with substantial public support through direct and indirect federal and state funding, and
generally with little expectation on the part of scholars for financial rewards (ACRL,
2006). As technology has advanced, libraries have changed dramatically in the services
they offer and in their organizational structures, reflecting the co-development of
libraries and information processing systems and networks as a socio-technical system.
The higher education environment for libraries has also changed, both organizationally
and normatively, with renewed questions about the social value of university research

1

production. Peter Thiel, an entrepreneur associated with Silicon Valley political
libertarianism, encourages some of the brightest minds in the country to forgo higher
education by providing $100,000 over the course of two years to start a new company
and quit school. According to Thiel “it’s fundamentally wrong for a society to pin
people’s best hope for a better life on something that is by definition exclusionary”
(Lacy, 2011), while others suggest that Thiel’s beliefs reflect the interests of an
economic elite deliberately attempting to undermine a sector contributing to social
mobility and middle class growth (Deresiewicz, 2011). Anti-university sentiment is
nothing new in U.S. history; after Eisenhower won the 1952 election, Time magazine
reported that his victory disclosed “an alarming fact long suspended: there is a wide and
unhealthy gap between the American intellectuals and the people” (Hofstader, 1963, p.
4). As Thiel paints professional scholarly life at universities as frivolous at best, scholars
potentially obscure their own agency and self-representations by occluding the ideas
with which they wrestle on a daily basis. They could do otherwise, partly by publishing
their work in venues that are more accessible to readerships outside the academy.
This dissertation explores the constitutive power of myths in scholarly discourses
about libraries and their evolving purpose in a scholarly communication system which is
organizationally and economically strained to a breaking point. In highlighting the
mythological and ideological in discourse, it will also reimagine the position of the
library in the academic and broader culture. It also asks of the most appropriate model
by which to find historical referents for the modern university library: is it more like the
famed Library of Alexandria, with a collection that drew scholars from around the world

2

to sit in its reading rooms? Is it more like the fictional library of Babel, infinite in nature,
containing all truth, decipherable only to one godlike librarian (Borges, 2007)? Is it like
the Memex—a hypertext system that provides ultimate interconnectivity as outlined by
Bush (1945)? Is it something of a commons, as library literature increasingly suggests
(Bolorizadeh & Smith, 2010)? Is it an amalgamation of all of these, or something else
entirely? Addressing these questions also calls into question the role played by the
academic library in academy. This dissertation argues that the digital transition in
librarianship has illuminated many of the myths attending the subsystems contributing to
scholarly publishing and librarianship. Discursively speaking, these myths have been
constructed at organizational boundaries that are becoming increasingly unnecessary or
redundant in the shift from print to digital collections. The argument advanced here is
that libraries can, should, and in many cases, already do play a central role in creating a
reliable system of scholarly communication that provides a prerequisite for the twentyfirst century research university. Paradoxically, inter-institutional dependencies in higher
education are articulated in many of the core activities of libraries, even as these
dependencies threaten to undermine libraries’ key functions.
Statement of the problem and research questions
A second enclosure is on the horizon. This “enclosure movement” is growing out
of new restrictions on intellectual property. The first enclosure, in which land ownership
was transferred to aristocrats, was redistributed later to bourgeois classes, producing a
powerful “logic of enclosure” (Boyle, 2010, p.45). Intellectual property rights are being
extended to cover even the simplest recounting of facts (Boyle, 2010). Commercial

3

publishers in the system of scholarly communication show increasing consolidation,
meaning that the scholarly record is owned by fewer and fewer companies, while
libraries are forced to make increasingly difficult decisions regarding their collections.
All of these pressures come together to create a critical problem. If libraries cannot
afford to continue collecting the research output of scholars because of price increases
from commercial scholarly publishers, researchers at their institutions will not have
access to the materials required to do new research. Scholarship is a cumulative process,
and the system rests on the ability of researchers to gain access to the scholarly output of
the past. This dissertation argues that academic publishing practices are rooted in
traditions that have taken on mythic properties that blind participants in the system both
to dangers and opportunities inherent in the system of scholarly communication. To
make this argument, the following chapters address three questions: first, how is
legitimacy constructed in the scholarly communication process, and does the digital shift
do anything to change that? Second, how has the shift to the digital environment affected
the organizational structures of the scholarly communication system? Third, how have
traditional processes in the creation of scholarship taken on mythic properties that
influence usage of the digital environment and access to research materials?
Delineation of the research field and scope of the project
This analysis rests at the intersection of several conversations about the relative
merits of openness and the free flow of digital collections. Critical scholarship from law
and policy studies of intellectual property (Boyle, 2010; Hyde, 2010) warns of a second
enclosure of culture by private owners of the largest digital collections, and attendant

4

tragedies of the commons. Many who relied on the commons as a cultural resource are
now left at the mercy of the new property owners, which are typically corporate
gatekeepers. In addition to restricting access to library catalogs by licensing them under
exclusive terms, rights holders have also called into question the long-standing doctrine
of fair use, creating a further expansion of gatekeeper power (Gillespie, 2007;
Aufderheide and Jaszi, 2015; Lessig, 2004). Fair use is a doctrine under US copyright
law that allows for use of excerpts of copyrighted material under certain circumstances,
which include parody, criticism, teaching, and reporting (Aufderheide and Jaszi, 2015).
Elsevier and other rights holders are sending cease and desist letters to scholars who post
their work online (Peterson, 2013), and Cambridge, Oxford, and Sage have sued
librarians for creating online systems for course reserves (Smith, 2011). Edwin Mellen
Press sued librarian Dale Askey for libel for suggesting in a blog post that the publisher
is a vanity press (Flaherty, 2013). Much like the music and movie industries, scholarly
publishers are exerting controls that were unavailable to them in the all-print world
(Lessig, 2015). Vaidhyanathan (2005) claims that the mere existence of libraries
threatens content industries and their plans to create a delivery system for content
designed as pay-per-view, since libraries can lend print books an indefinite number of
times while paying for the book only once (under the “first sale” doctrine in the U.S.).
Therefore, the publisher can only make money once. Once made digital, books are
simply data to be distributed and their use can be tracked more efficiently than they
could have ever been in print form.

5

From the library and information sciences literature, the push for reform has been
built almost entirely around Open Access (OA), which ostensibly provides not only
greater impact for research, but also potential cost savings for libraries and means by
which to bypass commercial scholarly publishers (Suber, 2012). In an attempt to avoid
an “openness fetish” (Morozov, 2013, p. 86) the dissertation will reorient the discussion
to provide a different framework through which to analyze the overall system and the
players involved. Authors remain beholden to commercial publishers to publish in their
discipline-defined tenure-worthy journals. By focusing on how certain academic norms
and ideals related to scholarly publishing and libraries have taken on mythic qualities,
the dissertation also aims to shift the scholarly conversation to the overall sustainability
of the scholarly communication system. The critical problem in the current system is that
as commercial publishers consolidate control of the market for scholarly content,
libraries are increasingly unable to afford this content, meaning that scholars lose access
to existing research on which they rely to do new research.
Borgman (2007) groups scholarly communication functions into three categories:
“legitimization; dissemination; and access, preservation, and curation” (p. 66). The latter
two functions tend to fall under the purview of libraries. In an increasingly digital world,
librarians are making more content accessible widely through print to digital conversion.
Libraries have long experimented with technologies and have been working in some
cases to build broad-based infrastructures to make rare and unique research materials
available online (Phillips, 2010). Libraries have more recently transformed into cultural
centers. Many academic libraries now have information commons or learning commons,

6

which are physical spaces within libraries that provide access to information,
technologies, and programming to engage students (Bolorizadeh & Smith, 2010).
Commercialization of information create threats to both culture and democracy,
and libraries are a bedrock of both. Public libraries are “functional expressions of
enlightenment principles,” and “where the public domain lives, the place where we gain
access to the information commons” (Vaidhyanathan, 2005, p. 124). Digital information
creates bends in ethical traditions as well. Libraries have long been vocal proponents of
free speech, privacy, and equal access. To protect privacy, for instance, user data in
libraries were regularly saved only in aggregate, in order to prevent tracking of
individual user reading, searching and other activities. Digital libraries do not always
address such ethical traditions of libraries in their infrastructure. The USA Patriot Act
jeopardized these traditions of patron privacy by making it easier for law enforcement
agencies to acquire data about patrons, but librarians have fought against this from the
moment the Act was presented in Congress (Taylor & Black, 2004). Systems in use at
academic and public libraries, however, are constructed such that these threats to privacy
are minimized. Systems are typically set up such that the link between patron records
and items loaned are maintained in the system only while items are on active loan.
(Breeding, 2016b). As new systems are built, it is crucial that these traditional values be
taken into account, though dangers exist where infrastructure is built by people outside
of the library community (Besser, 2002). Choices made today about how to construct
these systems can limit how the systems will be built on and used in the future.

7

Individuals can create and operate in their spaces on the Internet and host their
own personal publication platforms. Such opportunities for mass distribution had
remained the exclusive domain for large institutions until the era of the web page and the
blog, by which time information was no longer affixed to physical space. Laws like the
Digital Millennium Copyright Act (DMCA) and systems of digital rights management
(DRM) are increasingly used to restrict information, potentially commodifying more of
our cultural interactions than in the past (Gillespie, 2007). Information policies
supportive of DRM and anti-piracy initiatives have been adapted to provide for
enclosure of the online commons, as market-friendly attitudes influenced lawmaking
which followed the maxim that social resources which are not productive assets owned
by individuals are being wasted (Boyle, 2010). Hyde (2010) connects the growth of the
cultural enclosure can to what he calls “cultural aphasia” (p. 241), pointing in particular
to scholarship on James Joyce. Severe restrictions on the use of Joyce’s papers restricted
the use of some of his material, leading to some errors of omission by Joyce scholars and
scathing critiques from reviewers (Hyde, 2010).
The sociology of knowledge provides a claim by Castells (2010) that the
information age yields organizations characteristic of the “network society” (p. 21),
defined as a new kind of social structure and manner of social organization that is global
in nature and constructed on networks. Digital technologies afford the opportunity for
greater ease of managing complex networks on a global scale, redefining identity and
social structures (Castells, 2010; Hardt & Negri, 2009). In an adaptation of these
concepts for library and information studies, Pierce (1992) points to the lack of a

8

foundational theory or a set of “dead Germans” in the field of library and information
science (LIS)—and offers John Stuart Mill (while dead, not German) as a potential
foundational thinker (owing to Mills’ essay On Liberty as a starting point for
considerations of intellectual freedom). Discursive shifts toward a focus on “commons”
in library and information science suggests that his criticism is still being evaluated. The
rich idea of the commons for scholarly communication and publishing would benefit
from a reorientation of analysis from the technical resources of communication to the
organizations and individuals using them. At a fundamental level, the academic
enterprise operates more like what Kelty (2008) refers to as a recursive public.
Conceiving of the system of scholarly communication as a recursive public allows for a
clearer illustration of boundaries within the system and provides a solid foundation on
which to redraw those boundaries. He defines it as:
A recursive public is a public that is vitally concerned with the material and
practical maintenance and modification of the technical, legal, practical, and
conceptual means of its own existence as a public; it is a collective independent
of other forms of constituted power and is capable of speaking to existing forms
of power through the production of actually existing alternatives (Kelty, 2008, p.
3).
As it stands, and traditionally, academic organizational structures allow for the
construction of “intimate publics,” or the collective context on which people come to
rely for preserving their identities, which are then obscured by metrics required to define
their worth. While many scholars resist the corporatization of academia in their work,

9

the metrics and assessment that attempts to measure scholarly productivity create
something of a contradiction, as measurements are subsumed into critique of their
discourse (Eisenhower & Smith, 2009, p. 8). These attempts to measure productivity
mean that scholars are increasingly beholden to metrics that are defined almost entirely
by commercial entities, which can then exert undue influence on the academy (Lyotard,
1984). Scholars continue to publish in the same venues and give away their copyright to
those same entities. Considering scholarly communication as a recursive public allows
for the illumination of myths by clearly outlining the boundaries at which those myths
operate, and allows for a different view of scholarly work, providing a framework to
rebut arguments that scholars and their productivity can be easily measured using a
system of metrics. By conducting a historical analysis of changes in the system of
scholarly communication, three overarching myths can be seen to operate in the system:
the myth of authority (conferred through publication, selection, peer review and other
means of certification), the myth of influence (gained through citation, and defined by
metrics in the current system), and the myth of permanence (granted through collection
and preservation practices).
Myths
Fundamentally, myths are stories that provide substantial support for ideas that
cannot be supported using rationality (Rowland, 1990, p. 103). Rather than representing
the past, they represent narrative justification of the past to support what is in the
present. Socially, they function to justify maintenance of existing structures by outlining
“not merely why we do the things we do, but why we ought to go on doing them” (Frye,

10

1967, p. 28). They can be viewed simply as a “captivating fiction, a promise unfulfilled
and perhaps unfulfillable” (Mosco, 2004, p. 22), and they become stories “you can’t get
out of” (Hyde, 2010, p. 178). Human beings are storytellers who use not reason, but
“good reasons” and our rationality is based on our relationship to narratives (Fisher,
1987). Social myths express values that are dominant in society and are considered true
even if they are empirically untrue, inconsistent within themselves, and incompatible
with other socially accepted myths (Conrad, 2011).
Myths reveal and conceal truths in understanding the role of computer
communication systems that make up the Internet, the World Wide Web, and the broader
global computer network. Mythology surrounding technology often leads to “end of”
myths. Often lost in mythic talk of technologies is that seemingly revolutionary
transformations are often built almost entirely on what has come before them. The myth
of the internet today tells us that it will lead “us to a new sense of community, to
democratic communication, and to a rebirth of education online” (Mosco, 2004, p. 28).
Technologies, particularly those geared toward communication, “reinforce, amplify,
revise, and extend their ideologies,” (Vaidhyanathan, 2005, pp. 20–21) and using
technology creates change in the environment. Communicating through technologies can
alter assumptions about the world, much like having a television in a room changes both
the structure and the function of the room (Vaidhyanathan, 2005). Lincoln (2000)
develops a notion of myth as “ideology in narrative form” (p. xi), and noted that
scholarship that “is interested, perspectival, and partial and that its ideological
dimensions must be acknowledged, ferreted out where necessary, and critically cross-

11

examined” (Lincoln, 2000, p. 208). Myths are inherently political and instill ideology, a
system of ideas and ideals, into human values by adapting the narrative of the political
and raising “it to the level of a near impregnable fortress unassailable by ordinary
mortals” (Mosco, p. 30). Vaidhyanathan (2005) describes ideologies as “malleable
examples of ‘cultural software’” (p. 20) and notes it is possible to examine specific
technologies and how they influence broader systems of ideology.
I’m fascinated by how widespread use of distributive communicative technology
generates, to employ John Dewey’s psychological tenet, “habits of thought.”
These “habits” among individuals build into “cultural habits,” or ideologies,
through discussion, deliberation, and distribution (p. 20).
While new technologies tend to drive the elaboration of utopian visions that take on
mythic functions (Mosco, 2004), myths can also be built up in social or organizational
systems, creating barriers to change. Within organizations, myths work not only to
communicate values but they also “help to constitute the organizational consciousness of
social actors by articulating and embodying a particular reality and subordinating or
devaluing other modes of ‘organizational rationality’” (Mumby, 1987, p. 125). Human
beings are not rational, but rationalizing (Weick, 1981). Individuals in organizations or
institutions seek to understand their purpose as part of the process of creating an
institution. Selznick (2011) points to the “elaboration of socially integrating myths” (p.
151) as one technique by which they do so. Through idealistic language, members of an
institution attempt to distinguish the goals of the institution and determine their overall
sense of mission (Selznick, 2011). Rationalized institutionalized rules grow around

12

work activity such that organizations incorporate those rules as part of their formal
structures. These structures are based not on the work organizations set out to
accomplish, but on “myths in their institutional environments” (Meyer & Rowan, p.
539). There are two crucial elements to these myths: they prescribe technical objectives
based on social objectives and impose rules by which those purposes can be pursued.
Once institutionalized, individuals may lack the discretion to make any changes to the
rules, which are treated as legitimate regardless of their usefulness, and legitimacy is a
key building block for both organizational structures and managerial styles (Meyer &
Rowan, 1981). Rationalized myths are important not because they are true and can be
empirically verified, but because people believe them, and they are taken for granted,
whether or not they conform to reality. A myth, to be successful, must construct an ideal
to which members of the organization wish to aspire, and thus must involve all manner
of policies and procedures in an organization, not simply restricted to special occasions
(Selznick, 2011).
These myths lead to isomorphism, in which organizations attempt to imitate
others around them, leading to various kinds of conformities across industries (Meyer &
Rowan, 1981). Categorical conformities are similarities of language—organizations in a
particular field begin to describe ideas in the same way. Structural conformities evolve
from the building blocks that are considered proper, necessary and legitimate.
Procedural conformities center around processes used to get things done (Meyer &
Rowan, 1981). Organizations who do not use procedures that are deemed appropriate
within an industry can be vulnerable if they are not seen as rational, affecting both

13

customer and industry perception. Personal conformities are tied to the type of actors
that are seen to be required in particular positions in an organization—some industries
began to see MBAs from Ivy League schools as a necessity for managers, for instance
(Meyer & Rowan, 1981). At the level of an organizational field, which includes peer
groups, peer aspirant groups, customers, and suppliers, isomorphism can be either
coercive or mimetic. Coercive isomorphism forces organizations into certain behaviors
based on environmental pressures, while the latter is merely about doing what others in a
field are doing, something that is typical in times of uncertainty (Meyer & Rowan,
1981). Critically, they are legitimating stories and serve as integrating aids to help with
day-to-day activities. Myths work to both maintain control and harmony inside an
organization and to mollify external stakeholders, serve as “institution builders,” that
“create an integrated social organism” (Selznick, 2011). More critically, organizations
pursue isomorphism to gain legitimacy in their institutional environments, incorporating
rationalized elements considered legitimate to ensure survival (Meyer & Rowan, 1981).
When goals start to lose a clear definition, these stories begin to lose their power to
persuade. It is at these points that bureaucracy takes over, and people begin to look out
for their interests before those of the organization—it is then that these organizations and
their members “lose the plot” (Gare, 2007, p. 111). The scholarly communication system
rests uncomfortably in between institutionalized myths of academia, and myths of the
promise of new technology that are increasingly brought to bear on the system.
Next, I will explore how the changing environment in higher education is
illustrated by a history of post-industrial production and work, followed by an outline of

14

trends in technology and library and information science, and begin the process of
recasting the system of scholarly communication as a recursive public.
Shifts in the higher education system
Harvard College was founded in 1636 and was the first institution of higher
education in the New World. By 1861, the number of institutions in the US had grown to
182 (Carrigan, 1990). From 2009 through 2010, there were 4,495 degree-granting
institutions in the US (Institute of Education Sciences, 2012). There have long been
varied and changing ideas of the purpose of higher education. What began as a system to
prepare the economic elite grew into a system to prepare the masses (Hofstader, 1963, p.
357). In 1918, the commission on the reorganization of secondary education proposed
that post-secondary institutions follow the example of secondary schools and shift their
attention to “become mass institutions and to arrange their offerings accordingly” to
better serve the interest of democracy by not limiting higher education to an elite few
(Hofstader, 1963, pp. 335–36). Schement and Curtis (1995) outlined what they referred
to as a “shadow” education system that began to develop in the twentieth century, in
which corporations would have their own internal system of education designed to
educate workers on how to do specific jobs within those organizations. Community
colleges grew out of this and have served similar purposes—the shift here that Schement
and Curtis (1995) note is that education became far more vocationally focused with little
thought for how universities typically operate. Research universities were not immune to
the capitalist shift, as capitalists funded many of these across the US (e.g., Stanford,
University of Chicago), many have relationships with corporations, and many are now

15

expected to create patentable research and bring in significant amounts of external
funding. The shift toward mass institutions creates an environment in which vocational
education partly supersedes academic study (Hofstader, 1963; Schiller, 2000), with a
notion that the university exists to train students to do particular jobs. Arguing for a
middle ground, Nussbaum (2010) contends that proponents of vocational education in
the for-profit environment “have adopted an impoverished conception of what is
required to meet their own goal” (pp. 10–11). A hyper-focus on measurement and
vocation creates a system in which the perceived value of an academic subject is tied to
whether it can be applied directly to a waged labor.
However, Fish (2008) argues that critical evaluation is the key component to
education. Interests, beliefs, and identities should be evaluated first and respected
second, because, as he noted, “interests can be base, beliefs can be wrong, and identities
are often irrelevant to an inquiry” (pp. 10-11). The legitimate role of teachers in colleges
and universities, then, is to share existing knowledge and traditional methods of inquiry
to which students have not yet been exposed, to endow students with the ability to
critically engage with those traditions, and to ensure that they can do this independently
when they leave (Fish, 2008). While Nussbaum (2010) agrees that the education system
is not doing its job if it benefits only the elites, she argued that the focus on vocational
education and teaching to life skills will bring us to produce “generations of useful
machines, rather than complete citizens who can think for themselves, criticize tradition,
and understand the significance of another person’s sufferings and achievements”
(Nussbaum, 2010, p. 2). Hofstader (1963) outlines another tension:

16

Intellectuals in the twentieth century have thus found themselves engaged in
incompatible efforts: they have tried to be good and believing citizens of a
democratic society and at the same time to resist the vulgarization of culture
which that society constantly produces. It is rare for an American intellectual to
confront candidly the unresolvable conflict between the elite character of his own
class and his democratic aspirations (pp. 407-408).
Suber (2012) suggests that funding for research, whether the funding is from private or
public organizations, is effectively a form of charity, as organizations make choices to
fund research that is they define as necessary or valuable. Universities, whether private
or public, are depending on both public and private funds, and are beholden to states and
donors to prove that the research created at their institutions is valuable. At the center of
this struggle is the author that strives for acclaim while railing against the indignities of
class separation. A firmly democratic intellectual class will regularly face
disappointments and these may be concealed while democratic ideals are thriving, as
during the New Deal, but the disappointments are eventually revealed (Hofstader, 1963).
As Nussbaum (2010) asserts, if business wants “technically trained obedient workers to
carry out the plans of elites” (p. 21), then the idea that they might be trained toward
freedom of thought seems incredibly dangerous for the educational system.

17

Library and information science, technology trends
Libraries have a long and rich history, punctuated by wars, destruction and times
of both incredible prosperity and poverty. Ray Bradbury suggested that they are a place
where “you can get a complete education for no money” and noted that he had no money
for college, so he “went to the library three days a week for ten years” (Marelisa, 2012).
Libraries are, according to Neil Gaiman, “about the most important things there are, and
he deems librarians the “thin red line between civilization and barbarism” (IndyPL,
2010). Gaiman goes on to assert that “Google can bring you back 100,000 answers.
A librarian can bring you back the right one” (IndyPL, 2010). As many people as there
are who love libraries fiercely, and who view them as paragons of virtue, there are as
many who would suggest that society “burn the useless things to the ground” (Travisano,
2011). This opposite view holds the Internet up as a replacement for libraries. “The
library is dead; the Internet is alive” (Travisano, 2011). OCLC issued a report in 2010
indicating that the association of libraries with books grew stronger over the five-year
period since they last studied the phenomenon in 2005 (OCLC, 2010). Several scholars
have attempted to outline some key characteristics of the ideal library for the twenty-first
century and beyond. Vaidhyanathan (2005) perceives the ideal library as a
“communication medium,” and describes them as “leaks in the information economy”
(p. 123). These leaks are precisely the kind that many commercial entities would like to
plug; as Gillespie (2007) notes, academic culture seems to be in transition from a culture
of fair use to a culture of “fared use” (p. 62). The ideal library, according to Fitzpatrick
(2011), would be a partner with the university press, creating a center of scholarly

18

publishing that would be “another pivot point between the institution and the broader
scholarly community.” The library could be the partner that “brings the world to the
university,” and the press brings “the university to the world” (p. 180). University
presses should, as Fitzpatrick (2011) describes, be considered an integral part of the
scholarly publishing process, and not a business operated tangentially to the university.
Many schools deploy institutional repositories (IRs) to ensure access to scholarly work,
but because these are usually developed through the libraries, the focus tends to be
purely on access. Including university presses in these projects would allow repositories
to more closely mirror the complete publishing process (Fitzpatrick, 2011, p. 182). The
romantic view of the Internet often ignores the centrality of technology in the twentyfirst century library. In fact, conversations about technology often tend toward either
extreme optimism or extreme skepticism.
Mattelart (2005) finds views on the shift to digital to be too optimistic and shortsighted and suggests that they lead to “techno-mercantile determinism” (p. 160). This
determinism paints those who suggest that there are potential negative societal effects of
an overreliance on technology as opponents of both technology and modernity. Others
see the potential for technology to bring us together in a global network (Benkler, 2006;
Castells, 2010; Hardt & Negri, 2009). The shift to digital allows more control over
information (Gillespie, 2007) with new opportunities, but with potentially deleterious
consequences for our culture (Boyle, 2010; Lessig, 2004). The overflow of information,
for instance, is not a new phenomenon; libraries have long lamented that there is too
much information. While information proliferates, the systems through which it moves

19

become increasingly complex. The ability to link large amounts of data over a network
affords a more comprehensive view of broader patterns (Snickars, 2015). A more
centralized infrastructure in cloud computing, with Google at the front edge, creates a
global machine for processing and disseminating information (Snickars, 2009), this shift,
as Vaidhyanathan (2011) argues, brings both opportunity and cause for worry.
Knowledge sharing through publication is the method for gaining social capital in
academia. While formal and informal structures exist, fixed points such as peer review
provide a bright line beyond which something is considered published and legitimate
(Borgman, 2007). In the case of peer review, Fitzpatrick (2011) proposes following the
model of various social systems online by “separating the question of credentialing from
the publishing process, by allowing everything through the gate, and by designing a
post-publication peer-review process that focuses on how a scholarly text should be
received rather than whether it should be out there in the first place” (p. 32). A commons
is a particular type of intellectual property where multiple people have rights contribute,
edit and publish. The commons includes not just the property, but the individuals and
their rights to operate there (Hyde, 2010). The new medium is more fluid than previous
systems of print distribution and has brought with it new commons and new enclosures.
This second enclosure, through a variety of intellectual property, patent, and technology
legislation, is leading toward “the enclosure of the intangible commons of the mind”
(Boyle, 2010 p. 45) and the redistribution of its value.
Fitzpatrick (2011) places the start of a crisis in scholarly publishing as near 1990,
noting that the financial situation began to get increasingly worse for presses in 2000,

20

following the burst of the dot-com bubble. The crisis does not just affect librarians; it has
significant implications for faculty in academic department and the broader academic
community, including the university press. Thatcher (2013) instead points to a period in
the early 1970s when financial problems in the system appeared to a different set of
players in the system of scholarly communication: the directors of university presses.
During the period between 1969 and 1973, the ratio of book expenditures to journal
expenditures began to drop with a worsening trend over time. Directors at the time
pointed to the danger that although presses had managed to adjust costs and expenditures
to manage financial difficulties, the presses would be forced to make editorial decisions
based less on scholarly merit and more on salability. This tension was expressed in the
relationship between the Association of American University Presses and the
Association of Research Libraries (ARL), pitted against each other when Thatcher &
Rosenthal (1973) testified before Congress that fair use principles as practiced by
libraries were a potential threat to their business models. University presses do not get all
their costs paid up front and as a result the presses have to rely on book sales for revenue
(Thatcher, 2013). In the shift to creating a new system of digital libraries, the focus on
technology and collections often ignores ethical traditions of librarianship, which include
fierce loyalty to reader privacy, equal access, diversity, and serving underserved
populations. Libraries have often relied too much on third parties that do not adhere to
those values to build new systems (Besser, 2002). As scholars and librarians reconsider
their publishing behavior, it will be important to treat technology as a tool and not as an
end in itself. Mythological thinking has been attached to all manner of technologies, and

21

that thinking influences laws and policies surrounding technologies and intellectual
property with far-reaching implications.
Information law and policy, critical media studies
Mythology surrounding technologies drives us to “end of” myths because if
presented with something that seems entirely new, people tend to forget all that has
come before (Mosco, 2004). The telegraph, electricity, and the telephone have all led to
the end of history, politics, and even geography. Often lost in discussions of these
transformative technologies is how they are built almost entirely on what has come
before them.
Indeed, the history of technology suggests that this would be far from the first
time that we have laid claim to the end of history, the end of geography, and the
end of politics. Practically every substantial technological change has been
accompanied by similar claims. The chant goes on: this changes everything.
Nothing will ever be the same again. History is over, again and again and again
(Mosco, 2004, p. 119).
Technologies can often ease these transitions by mimicking those that preceded them.
For example, incunables, books that were published in the 50-year period following the
invention of moveable type, conformed quite closely to the manuscript tradition, with
type that resembled handwriting and illustrations done in color and by hand (N. Howard,
2009), just as technology for reading books in digital form regularly attempts to mimic
the reading of print books. Socrates viewed writing as an invention that would “produce
forgetfulness in the souls of those who have learned it, through lack of practice at using

22

their memory” and “an elixir not of memory but of reminding” paints writing itself as a
disruptive innovation (Plato, 1986, p. 123). Rather than something entirely new,
technologies tend to be built out of parts of previous ones, and in remarkably similar
ways, regardless of the opportunity to do something truly innovative. As Striphas (2011)
suggests, cultures become invested in particular technologies and bestow
“disproportionate amounts of credibility, prestige, and influence on the classes of people
with whom it’s most closely associated” (p. 159).
Advances in technology, legislation, and media conglomeration can be dangers
to culture. Technology and conglomeration make it much easier for corporations to
attempt to exert control over content and distribution, while legislation focuses on
protecting intellectual property, typically in the form of copyright. In its initial inception
in the US, copyright lasted for 14 years, with an option to extend that protection for an
additional 14 years. In 1976, the terms of copyright were extended to life of the author
plus 50 years (or longer for corporate creations) and extended yet again in 1998 under
the Copyright Term Extension Act (Lessig, 2004). The Recording Industry Association
of America (RIAA) and the Motion Picture Association of America (MPAA) are only
two of the institutions that are seeking for more restrictive legislation (Lessig, 2004).
Both organizations have pushed for legislation to make it more difficult for individuals
to make copies of copyrighted materials, and The Digital Millennium Copyright Act
(DMCA) grew out of their concerns. Of particular concern is the erosion of fair use. Fair
use typically allows for someone to use a certain percentage of work for other creative
purposes, parody or educational uses. Under DMCA, fair use is not as easy to discern.

23

Moreover, as long as corporations like Sony and others are lobbying Congress and
driving legislation in this regard, it is not certain that even the protection of the fair use
doctrine will last (Lessig, 2004). This legislation as outlined in DMCA is particularly
insidious because, in addition to making copying illegal, it makes it illegal to circumvent
technologies that prevent copying, or what Boyle (2010) calls “the digital equivalent of
barbed wire” (p. 86). This legislation makes it illegal for anyone to create digital wire
cutters—perhaps no great concern for users with no intentions of creating copies of
creative works that they have purchased, but potentially of grave concern to researchers.
For example, scholars doing research on the various kinds of encryption used to lock
down digital items are left open to lawsuits if they publish the results. According to this
corporate logic, researchers are effectively providing wire cutters to the masses (Boyle,
2010). According to Lessig (2004), legislation around copyright and intellectual property
will have a chilling effect on creativity and culture. Because so much of our culture is
built on what has come before it, making it more expensive and sometimes illegal for
creators to borrow and comment on each other, we cannot then proceed in the same way
we have in the past. As Boyle (2010) notes, the world of research would be similarly
affected.
Recursive public
Kelty (2008) forms his argument about recursive publics around geeks. Geek is
not used in the traditional sense to refer to a particular kind of person—it refers to the
way in which particular people act as a group to mediate the technical infrastructure they
use to act as a group. Geeks develop an affinity through the collective practice of

24

developing, in this particular case, free software. Rather than focus on the kind of people
involved in this practice, he focused on the practices that brought them together to serve
the purpose of creating free software. This collective practice is what constitutes a
recursive public (Kelty, 2008). Collective practices as exercised by scientists are critical,
given that scholarship is “almost always cumulative and collaborative” (Hyde, p. 179)
and that the work of science flourishes when barriers to collective practice are removed.
Stories are also central to the movement of free software, aligning participants toward
particular problems, defending the movement from naysayers, and drafting new
members. The Free Software movement comprises five components: shared source code,
a concept of openness, copyleft licenses, forms of coordination, and a movement or
ideology, and suggests that reframing the practices of the movement is important to
“conceptualize them as a kind of collective technical experimental system” (Kelty, 2008,
p.15). In considering the concept of a recursive public, the internet is best understood as
a series of layers that support each other, allowing for both openness and a lack of
central control, which provides opportunities for creative restructuring of its own social
and technical infrastructure (Kelty, 2008). There are two distinct qualities of recursive
publics:
…the ability to include the practice of creating the infrastructure as part of the
activity of being public or contesting control, and the ability to ‘recurse’ through
the layers of the infrastructure, maintaining its publicness at each level without
making it into an unchanging, static, unmodifiable thing (Kelty, 2008, p. 62).

25

Information products are built from parts of other information products—output from
one person is input from another. As raw materials to create information products come
under increased protection, the cost of creating information products increases. Reduced
access creates the potential for certain dangers—in particular that if rights are drawn too
broadly, scientific progress, criticism, and speech itself would be discouraged. Restricted
access would dampen innovation that follows from existing ideas, concentration of
industries would create monopolies and oligopolies, and the effects of strong networks
would lead to markets choosing inefficient technologies (Boyle, 2010). In order to create
a workable public sphere that calls the members “into collective being as a ‘people’”
(Hyde, 2010, p. 153) readers and writers have to put aside differences in order to act as
civic persons, and that the rules for publication provide cultural norms for such a public.
When the rules are followed, the citizens appear, and when the rules are not followed,
they disappear; writers cannot, as civic actors, take such pride in their voices that they
prevent others from appropriating it without doing a disservice to the public sphere
(Hyde, 2010). The advent of blogs helped rekindle the coffee-house model of circulating
text, but that they were more like the newspaper and pamphlet equivalent, not quite
making room for the longer form of the monograph, which had been under the purview
of libraries. A system that could account for all of these forms would center the library
not just as a repository, but as “fully part of a communications circuit that facilitates
discourse rather than enforcing silence” (Fitzpatrick, p. 180). Barge, Lewis, & Simpson
(2017) point to the recursive nature of engaged scholarship, indicating that it “reflects

26

recursive and reflexive processes between scholars and stakeholders enacted to enrich
both theoretical and practical knowledge” (p. 808).
Research methods & outline of chapters
To make my argument, a historical analysis of changes in the system of scholarly
communication is offered with an analysis of long-term trends in librarianship, with a
focus on how publishers are consolidating and using new technologies to create more
efficient means for them to control the scholarly record. Myths of authority, permanence,
and influence legitimize the process of scholarly communication. The research questions
propelling this analysis are as follows: first, how is authority constructed in the
traditional scholarly communication process, and does the digital transition do anything
to change that? Second, how has the shift to the digital environment affected the
organizational structures of the scholarly communication system? Third, how have
traditional processes in the creation of scholarship taken on mythic properties that
influence usage of the digital environment and access to research materials?
Outline of chapters
Chapter II: what the market will bear
Chapter II outlines the changing nature of the market for scholarly publication,
demonstrating consolidation of the industry under a few commercial scholarly
publishers. It further outlines legislation in the 1990s that permitted media distributors
such as publishers to exert increased legal control over their content in a much more
targeted way, and a view of some of the ways in which individuals and organizations are
pushing back against this legislative control through both legal and illegal means.

27

Chapter III: lies, damn lies & impact factors: the myth of authority
Chapter III explores how authority is constructed in the system of scholarly
communication. I will argue that the myth of authority is built around certain prestige
markers in the system of scholarly communication, which are increasingly reliant on a
system of metrics. I will show that along with an ever-increasing number of publications
and publication venues, scholarly publishers have more and more control of the content
of scholarly research through industry consolidation, placing a financial strain on
libraries and the overall system of scholarly communication. In addition, I will explore
the increased focus on metrics and how scholarly journals have taken on the mantle of
brands, constraining changes to faculty publishing behavior, which is the key to
extracting libraries and universities from the commercial scholarly publishing regime. I
will outline how a rise in predatory publishing creates increased complexity and
confusion in an already tenuous system. To provide an alternative template for changing
that behavior, I will first argue that universities have outsourced the imprimaturs that
bestow prestige in the system of scholarly communication (like peer review and tenure)
to algorithms, metrics and commercial publishers, and that the value commercial
publishers once added to scholarly publications has been drastically reduced.
Chapter IV: discipline & publish: the myth of influence
Chapter IV examines how influence is constructed in the system of scholarly
communication. I will argue that citation behavior is a key element to the myth of
influence and that the foundation of this myth is bound up and concentrated in the social
infrastructure of scholarly disciplines. I will draw from resource dependence theory to

28

illustrate how power is distributed in systems, from Meyer & Rowan (1981) to explore
how myths operate in institutions, and from Mosco (2004) and Castells (2010) to
demonstrate how myths get built up around the social valuation of technologies. I will
argue that influence is fundamentally about infrastructures through which information is
exchanged and demonstrate that not just the content of scholarly communication, but its
underlying infrastructure is coming under increased control by commercial scholarly
publishers.
Chapter V: the widening gyre: the myth of permanence
Chapter V provides an overview of the history of collection development in
libraries and how it is changing, arguing that a myth of permanence is embedded in the
combination of infrastructure and content: context. In addition to an exploration of
changes in library and university organizational structures, this chapter will provide an
overview of changes in the scholarly communication system, including emergent
organizational forms, lawsuits by commercial scholarly publishers, and new librarycentered forms of publication driven by new technologies. I will also explore changing
technological environments and how they have an effect not just on needs for expertise
in library organizations, but also how algorithms and personalized searches are driving
an epistemic shift in the way that content is constructed and consumed, driving a shift
the context of the information environment. Additionally, I will explore how new
pressures in a digital environment threaten longstanding library practices.

29

Chapter VI: nolite te bastardes carborundorum
In Chapter VI, I will reflect on the research questions and discuss how this analysis
relates to debates in library science regarding open access and the technologies driving
the system of scholarly communication. I will outline some future possibilities for the
scholarly communication system and the role of libraries in shaping that process,
together with many challenges. I will argue that scholarship is fundamentally a
deliberative process, and that process need not and should not change whether it is
disseminated electronically or in print. The gestalt of the scholarly communication
system lies in its publicness. Conversations that focus only on access allow for
publishers to continue to exert undue pressure on the system. I will develop a framework
based largely on Kelty’s (2008) concept of recursive public and use it to reframe the
notion of the system of scholarly communication, drawing from Björk’s (2007) A model
of scientific communication as a global distributed information system. Points in the
process help describe key boundaries. His model outlines the whole communication
value chain, “from initial research to the assimilation of research results to improve
every-day life,” and focuses on both communications in formal and informal form. The
communications include data with a particular focus on the traditional methods of
publishing and indexing peer-reviewed articles. New models of publishing allowed by
new technologies, including OA, are more responsive to how readers find and access
online work once it is published (Björk, 2007). I will suggest that if an exhortation is to
be made to “burn the useless things to the ground,” let it be directed at commercial
scholarly publishers, not libraries.

30

CHAPTER II
WHAT THE MARKET WILL BEAR
In this chapter, I will analyze the changing nature of the market for academic
publishing, including how the concentration of publishers has grown smaller since 1973,
while expectations for faculty publication have increased along the same timeframe. I
will then explore the changing legal environment in which the system operates, focusing
on key legislation in the 1990s that provide distributors of digital content increased
control over that content. I will briefly explore two cases in particular, that of Aaron
Swartz, and the recent emergence of Sci-Hub as an illegal distributor of copyrighted
academic publications.
The changing landscape of scholarly publishing
Through commercial scholarly publishers, the content and the rights to it are both being
commodified in ways that were not originally envisioned in the creation of the system of
scientific communication, and the pace at which the catalogs of publishers have
expanded has increased dramatically since their business needs became more reliant on
scholarly content. Expectations for faculty publishing to achieve tenure increased in
colleges and universities, compelling faculty to increase their publication output.
Publishers, both commercial and non-commercial, began to expand their product lines
for books and journals, and libraries saw an increased demand for research materials
(Greco, 2015). Approximately 28,100 scholarly peer-reviewed Science, Technical and
Medical journals existed in August 2012, accounting for about 1.7 to 1.8 million articles
published per year. The number of journals has grown at a rate of 3.5%, and the number

31

of articles at a rate of 3% (Ware & Mabe, 2012). The increase in expectations for
publication output and the increase in actual output for publications can be tracked to the
1970s (Donoghue, 2008), which coincides with both Castells’ (2010) starting point of
the rise of the network society, and Thatcher’s (2013) suggestion that scholarly
publishing had reached a crisis point. The discipline of communication, which Stephen
(2014) traces back to its origins in English departments around 1914, launched a new
journal about once every two years between 1915 and 1970. Since 1970, the rate has
been about three per year, which is an increase of 600% between 1970 and 2010
(Stephen, 2014).
As universities continue to find new metrics through which they can measure
faculty productivity, faculty have demonstrated changes in publishing behavior. While
thirty percent of faculty in 1970 did not publish even one article, surveys indicate that
expectations changed dramatically in the following decades. In a 1969 survey, 21% of
faculty at colleges, 44% of faculty at research universities, and 6 percent of faculty at
comprehensive universities “strongly agreed” that publishing was required to get tenure.
Those numbers rose respectively to 42%, 83% and 43% in a similar survey in 1989
(Donoghue, 2008, p. 52). The expectations did, in fact, increase. A significant number of
colleges and universities increased their expectations for tenure and promotion. In bookdriven disciplines like history and philosophy, the expectation for tenure after World
War II was generally one published book, excellent teaching, and service. As
universities sought recognition and status, expectations grew to two published books,
even three at some of the more prestigious schools. In journal-driven fields, expectations

32

were at two published scholarly articles, which eventually increased to four to six
articles, and even ten in some places (Greco, 2015).
According to estimates, the number of peer-reviewed scholarly journal articles
surpassed 50 million in 2009. At that rate, the number of articles produced in the overall
system doubles at just less than 24 years (Jinha, 2010). Tenure-track jobs are scarcer,
while the number of part-time faculty has increased by 305.3% (Hoeller, 2014). So, there
are fewer full-time tenure-track professors creating increasing numbers of articles in
increasing numbers of journals that libraries need to buy with often decreasing budgets.
Subscription costs from publishers continue to increase at the same time. Over the last
40 years, subscription costs for journals have increased at approximately two times the
rate of healthcare costs (Suber, 2012). Publishers are sometimes divided into three tiers
from the library perspective. The first tier includes the top 5, the second includes society
and university presses, and tier three is composed of all the other small publishers,
difficult to quantify, who are most at risk of being acquired by larger publishers, and are
often ignored by academic librarians, who are most at risk of having their titles cancelled
by libraries. Since publishers in the top two tiers own the titles that faculty most want
available, that is where libraries focus their spending (Ivins, 2005). Before World War II,
scholarly societies accounted for most publication of scholarly journals. By the mid1990s, commercial publishers were responsible for 40% of journals, societies were
responsible for 25%, and educational publishers 16% (Larivière et. al., 2015). Publisher
catalogs tend to contain a large percentage of journals published on behalf of scholarly
societies, with proportions ranging from twenty to forty-five percent of all their

33

published journals. Half of Elsevier’s catalog in the mid-2000’s represented titles
published for societies, and Blackwell’s catalog was entirely society-based journals
(Ivins, 2005).
A shift to digital publication has not had an effect on access or format as much as
it has on the economics of academic publishing and the market for scholarly journals. In
the social sciences, the top five commercial publishers accounted for between 15% and
22% of the market in 1995. These publishers accounted for 54% to 71% of the market by
2013. The humanities, which tend toward a lower publication density, published more
with smaller volume publishers, and the top five commercial publishers account for 10%
of papers in the arts and 25% of those in humanities. The digital distribution of scholarly
publications has been much slower to build in these fields, which have relied more on
monographs and local journals, and do not tend to have a need for rapid publication as
seen in some scientific fields (Larivière et al., 2015). The specialized nature of academic
journals keeps rivalry among the top publishers low because there is no real direct
competition, since academic journals are targeted to specific academic disciplines,
giving each journal its own target audience (McGuigan & Russell, 2008).
The general belief has been that digitization of the publication infrastructure has
led to a higher concentration of scholarly literature under a small number of publishers,
but Larivière et. al. (2015), provide the first broad analysis of the evolution of this
change in market structure, based on journals indexed in Web of Science between 19732013. The authors analyzed data from a relational database they created with data
extracted from Thomson Reuters’ Web of Science (WoS), which includes data for

34

44,483,425 documents. The authors use this approach since scholarly publishing is a
particular kind of publishing and is not a market or industry in the strictest sense.
Around 1973, commercial scholarly publishers began increasing their share of scholarly
publications, with another marked increase starting in the mid-1990s. Reed-Elsevier,
Wiley-Blackwell, Springer, Taylor & Francis and Sage all increased their share of
ownership of the scholarly record. More than 50% of all papers published in 2013 came
from the top five publishers—social sciences with the highest level of concentration,
followed by natural and medical sciences (bolstered by the strength of their scholarly
societies), and the humanities, which were still operating fairly independently and were
focused on monographs (Larivière et al., 2015). This concentration is illustrated in figure
1 on page 36.

35

Figure 1 illustrates the percentage of papers published by the top 5 publishers from 1972-2013, with
Natural and Medical Sciences represented on the left and Social Sciences and Humanities on the right.
Reprinted from Larivière et al. 2015.

36

Figure 2 illustrates the shifting of journals from small to large publishers and from big to small publishers
per year of change in the Natural and Medical Sciences and Social Sciences & Humanities. Reprinted
from Larivière et al. 2015.

Concentration of ownership in the top five publishers in 1973 was between 10% and
20%, increasing by 2013 to 42% and 57%, with a marked increase in the mid-1990s
(Larivière et al., 2015). During the 2007-2008 recession, college endowments also began
to see steep declines, with additional adverse effects due to changes in the Consumer
Price Index. The confluence of all these trends proved troubling for academic libraries,
where they reduced budgets due to lower revenue from endowments and other state
sources (Greco, 2015). This concentration of ownership is one potential explanation for
the large publisher profits. No publisher outside of the top five accounts for more than a
3% share of the journal market, and the top publishers control the most prestigious titles
(McGuigan & Russell, 2008). Resource Dependence Theory points to the true problem.
The organization that controls the resources required by another organization has power

37

over the organization requiring those resources (Pfeffer & Salancik, 2003). With a
greater concentration of scholarly content under fewer publishers, which is required by
researchers in order to create more scholarly content, those publishers have the ability to
exert power in the system of scholarly communication. Figures 3 through 5 show the
percentage of papers published in three broadly defined disciplinary areas.

Figure 3 illustrates the percentage of papers published by the five major publishers, by discipline in the
Natural and Medical Sciences, 1973–2013. Reprinted from Larivière et al. 2015.

38

Figure 4 illustrates the percentage of papers published by the five major publishers in the Social Sciences
and Humanities, 1973–2013. Reprinted from Larivière et al. 2015.

39

Figure 5 illustrates the percentage of papers published by the five major publishers in Physics, 1973–2013.
Reprinted from Larivière et al. 2015.

Figure 6 illustrates the evolution of the mean relative citation impact of papers, by distance to publisher
change, 1995–1998 and 2001–2004. Reprinted from Larivière et al. 2015.

40

An interesting finding in the study is that there is no significant change in impact when
shifting from a small publisher to large, with the mean impact of papers (in terms of
citations) staying below the world average. Production of high impact papers seems not
to be correlated with changing to larger publishers (Larivière et al., 2015).

Figure 7 illustrates the operating profits and profit margin of Reed-Elsevier as a whole (A) and of its
Scientific, Technical & Medical division (B), 1991–2013. Reprinted from Larivière et al. 2015.

The high profit margins of publishers are combined with the fact that two of the key
inputs to journal production are given to them free of charge—the articles that make up
the journals, and the editorial review. That faculty need previously published research to
do new research leaves libraries in a bind and creates an inelastic demand for academic
journals. As a result, publishers can continue to increase prices. The publisher’s role as
intermediary gives them power to charge whatever the market will abide (McGuigan &
Russell, 2008). Publishers tend to justify the profit margins by pointing to the value they
add to the process in pre-vetting submitted papers, support provided for peer review,

41

printing and distribution, but, of Elsevier, a Deutsche Bank analyst pointed out that if
their processes were as complex as they suggest, profit margins that high would not be
available to them (McGuigan & Russell, 2008).
Changes to the legal environment & copyright law
The US Constitution requires Congress to create law at a federal level that
creates incentives for the creation and distribution of new works. This law, copyright
law, bestows exclusive right to copy, sell, and perform original authored works that are
in a fixed tangible medium. This exclusive right, which grants the owner a monopoly for
a limited time, was designed to balance the interest of readers, publishers and authors,
but also to allow for good faith use by journalists, students, scholars, and others.
Changes to copyright law throughout the years have created a matrix of legal protections
that are now referred to as intellectual property rights (Vaidhyanathan, 2001). The first
change was a comprehensive copyright law passed by Congress in 1976. Then, in 1978,
Congress extended the length of copyright for authors to the life of the author plus fifty
years, and for corporate authorship to seventy-five years. Additionally, renewal terms
were forty-seven years, which is a total of seventy-five years. They also broadened the
nature of works protected by copyright and clarified fair use and infringements (Greco
2018). One of two significant revisions to copyright law passed by Congress in 1998
were the Copyright Term Extension Act, which included two key provisions. The act
extended term of copyright from fifty years after the death of the author to seventy and
extended corporate copyright from seventy-five years to one-hundred and twenty years
after creation of a work, or ninety-five years post-publication. It also extended the

42

copyright for all works published before January 1, 1998 from seventy-five years postpublication to ninety-five years (Greco, 2018). Copyright is not just a single right, but a
bundle of rights which includes first, an exclusive right to make copies, but also a right
to allow others to make copies, derivative work, sell or perform the work in public, and a
right to petition a court if others infringe on those rights. Control of these rights can be
transferred or licensed to third parties (Vaidhyanathan, 2001), as scholars do when they
transfer copyright to publishers.
The Digital Millennium Copyright Act (DMCA), a second significant shift in
copyright law, passed in October 1998, and was intended to enforce two treaties of the
World Intellectual Property Organization (WIPO), which were the WIPO Copyright
treaty and the WIPO Performance and Phonograms Treaty. Among other things, the
DMCA made producing or distributing any device designed to specifically reduce or
minimize digital rights management (DRM) systems that control access to works under
copyright (Greco, 2018). In its original form, copyright was created to regulate copying
published works, not the reading or sharing of the works. This legislation effectively
collapsed the distinctions between accessing, using and copying (Vaidhyanathan, 2001).
On one hand there exists a system of technology that allows for incredible freedom of
reuse and creativity, but a system of laws that renders that reuse and creativity illegal.
This level of regulation “fails every important standard of efficiency and justice (Lessig,
2015, p. 266). Focus on the “copy,” Lessig (2015) argues, is part of the problem. Laws
should focus less on protecting copies and reproductions and instead on uses. Fair use,
for example, allows for people can quote or reuse work under copyright without

43

payment or permission (Aufderheide & Jaszi, 2015), but there is a failure in this
objective under the current system of copyright. Given that companies are suing
individuals for fair use violations, the advancing of the fair use doctrine is problematic.
The doctrine was developed with the idea that it would be administered by lawyers at a
corporate level, but it becomes inadequate when Sony is suing teenagers for
infringement of copyright (Lessig, 2015). The intellectual property regime now operates
at a much lower level, and “is implicated in routine creative, communicative, and just
plain consumptive acts that each of us performs every day (Boyle, 2010 p. 51-52).
A more useful system of copyright would be built around what specific uses are beyond
its scope, allowing for flexibility, so that organizations that can afford lawyers can work
to make sense of the law, leaving a simpler and cleaner system to regulate use by
everyone else (Lessig, 2015). Fair use is critical to a thriving cultural environment, as it
is one of the alternatives to strong copyright protection. Another alternative is copyleft
licenses.
Copyleft licenses started in the Free Software movement when Richard Stallman
grew frustrated with increasingly proprietary software and university administrators
unwilling to push back against corporations who would not allow him to customize
installations of software. In protest, he left MIT to found the Free Software Foundation
In an effort to ensure that free software could not be bought and then made proprietary,
he created copyleft licenses. These licenses require that anyone who makes changes to
free software make their changes and improvements publicly available so that others can
continue to make changes and improvements. They must also retain the license, meaning

44

that the license perpetuates itself (Vaidhyanathan, 2001). Creative Commons is a nonprofit that works similarly to layer reasonable copyright protections to make it easier to
build on other people’s work by allowing the original author to make clear at the outset
what kind of use the work can be put to without having to involve lawyers. Creative
Commons licenses apply to other forms of work outside of free software. The content is
marked with the CC mark, and attached to a license, of which there are a range. Original
authors, for example, can choose licenses that allow for any use as long as attribution is
provided, any noncommercial use, any use as long as the same freedoms are attached to
the new work (share and share alike) (Lessig, 2015). PLoS ONE, the journal produced
by the Public Library of Science, requires that all work deposited in their journal be
published under a Creative Commons Attribution (CC BY) license, meaning that authors
who publish in the journal agree that their work can be used, in whole or in part, for any
purpose, even commercial, thereby facilitating freedom of reuse (Lessig, 2004). The
final way around a strong system of copyright is piracy. Two stories in particular are
illustrative of piracy of academic resources. The first is the story of Aaron Swartz. The
second is the rise of Sci-Hub.
The story of Aaron Swartz
Aaron Swartz was a political activist and computer programmer. In 2010, MIT
received word from JSTOR that someone was downloading articles from their servers by
the hundreds of thousands, and that they could trace the intruder to the MIT campus.
Swartz, it turned out, was the intruder (Bombardieri, 2014). Swartz was charged in
federal court under the Computer Fraud and Abuse Act, legislation passed in 1984 to

45

ease the government’s ability to prosecute hackers who stole information or destroyed
computer functionality. The government interprets this law as allowing them to
prosecute based on activities like violating the terms of service for a website or violating
a company’s computer use policy (Kravetz, 2012). By the time he was caught, Swartz
had downloaded 4.8 million articles, which constituted 80% of JSTOR’s archive. MIT
risked losing access to the resource, since their contract with JSTOR promised that MIT
would protect against misuse of JSTOR resources (Bombardieri, 2014). Swartz
surrendered to authorities in 2011 and faced dozens of years in prison and a $1 million
fine if convicted (Kravetz, 2012). The charges under the Computer Fraud and abuse act
centered on the notion that Swartz’s access to both MIT and JSTOR networks was
unauthorized, and while his behavior might have been inappropriate, the fact that he was
logged on to MIT’s network as a guest suggests that his access could be considered
authorized. Ultimately, facing federal prosecution, massive fines, and a long jail term,
Swartz committed suicide in 2013 (Bombardieri, 2014).
The rise of Sci-Hub
Sci-Hub was created in 2011 by a researcher in Kazakhstan, Alexandra
Elbakvan. She created this database in response to a lack of access to research output by
researchers around the world, due to the fact that their libraries are unable to afford the
content, suggesting that the lack of access is a violation of the United Nations’ Universal
Declaration of Human Rights. The website provides access to more than 48 million
scholarly research articles for free. Many of these articles are still under copyright and
are therefore usually kept behind paywalls (Banks, 2016), making it possibly the largest

46

case of copyright infringement on record. Elsevier sued Sci-Hub in a US District Court
in New York, winning the case, and an award of $15 million in damages. Given that the
founder lives abroad and outside the jurisdiction of the court, it is entirely possible that
Elsevier will never get that money (Greco, 2018). Sci-Hub did not comply with a court
order to take down the site, instead continuing operation under a new domain. Elsevier
has filed a new legal complaint, but legal sanctions will likely be difficult to enforce
(Banks, 2016).
In this chapter, I traced the consolidation of scholarly publishing under a small
number of publishers beginning in the 1970s and reviewed legislation passed in the
1990s that gives distributors of content increased control over their content. I reviewed
ways in which content creators have been pushing back against the system through both
legal and illegal means. In the next chapter, I will explore how prestige symbols in the
system of scholarly communication operate under the myth of authority.

47

CHAPTER III
LIES, DAMN LIES AND IMPACT FACTORS
Introduction
In this chapter, I will outline a response to the research question “How is
legitimacy constructed in the scholarly communication process, and does a shift to a
digital environment do anything to change that?” I will do so by articulating the first of
three overarching myths that operate in the system of scholarly communication: “the
myth of authority.” I will argue that this myth manifests itself primarily through prestige
markers in the system: peer review, publication, and tenure. Prestige symbols are signs
and symbols that are considered markers of success in social systems, gathered through
the process of reaching goals or having traits desired by a group (Wilson, 1995). As new
models of publishing emerge, these traditional processes create barriers to change. I will
argue that resistance to change in the system of scholarly communication is bound up in
this myth of authority which operates as a screen to prevent participants in the system
from seeing that the foundation of traditional processes are first and foremost the social
infrastructures, not the technical and procedural infrastructures, that underlie the system.
Scholarly communication tends to be an inwardly focused system of experts talking to
each other. To be considered an expert, and therefore an authoritative voice in a
scholarly conversation, scholars must pass peer review to be published in the right
journals as designated by their discipline—a process that, for tenure-track faculty, is
usually required for earning tenure (Greco, 2015). As the system of scholarly
communication is increasingly driven by technology and new tools are being developed

48

to manage the processes underlying the system, critically examining the myths
surrounding the digital transition for scholarly print publishing and its various tools
foregrounds social and cultural processes contributing to changing relationships between
academic publishing, librarianship, and readerships, rather than relying on technological
determinism to explain any particular phase.
In contrast with Fitzpatrick (2011), who places the scholarly communication
crisis beginning in the early 1990s, which is when libraries began to feel a significant
strain on their budgets, I rely on Thatcher’s (2013) argument that the beginning of a
crisis in the system of scholarly communication began in the early 1970s, around the
time Sanford Thatcher and Arthur J. Rosenthal testified before the Senate Subcommittee
on Patents, Trademarks and Copyrights on behalf of the Association of American
University Presses. Although librarians recognized an apparent crisis when journal
subscription price increases outpaced their library budgets, university press directors had
begun to see problems many years before (Thatcher, 2013). The subcommittee sought to
establish of a National Commission on New Technological Uses of Copyrighted Works,
and Thatcher & Rosenthal (1973), testified that the copying that libraries were allowed
to do under a provision of copyright law negatively affected the proprietary works of
University Presses (Thatcher & Rosenthal, 1973). I will trace the development of the
system of scholarly communication up to the 1970s, and how it has changed after that
time. As Mosco (2004) suggested, by considering a myth as something that occurs early
in the development of a system, it may be possible to uncover the grounding of the myth
in politics and ideology. The myth of authority, I will argue, is tied up in traditional

49

scholarly practice but increasingly buttressed by an overreliance on metrics—or, to use a
more scientific term, data.
Defining authority
Legitimacy is constructed through prestige symbols in the system of scholarly
communication, lending authority to both individuals participating in the system and is
abstracted at an epistemic level in the fixed forms of content they produce within that
system. Weber (2015) outlines three kinds of legitimate authority. Legal authority is
based on rationality and a system of normative rules, with reverence given to an
established order. Those with formal legal authority are given obedience by virtue of
their office and scope of their position. Traditional authority resides more directly with a
particular person who is bound by a particular tradition and carries out established
beliefs within that system—the loyalty to tradition is bound to a prescribed system of
obligations. Charismatic authority rests on affection for a particular person considered to
be of exceptional character or other admirable qualities, who engenders loyalty through
trust in his charisma alone. Legitimacy is what distinguishes between the general notion
of power, exerted through violence or some other form of force. When power is
legitimate, or socially endorsed, it can be considered authority (Weber, 2015). Authority
manifests itself on a higher plane than the strictly descriptive. Although claims from
science and religion do sometimes overlap, where they agree, it tends to be at a
descriptive level (Blackwell, 1998). There is a distinct difference between the two when
it comes to authority. Science derives its epistemic authority from evidence and
rationality, while religion derives its epistemic authority from scripture and tradition.

50

Neither science nor religion are truly rational and each is subject to human fallibility.
Falsification is based on the idea that the rules of science are not fully rational.
Regardless of the fact that rules of science are not fully logical, that is, not fully rational
in the sense that scientific hypotheses cannot prove hypotheses are true, but, only that
they are false, scientists continue to use these rules (Blackwell, 1998, p. 43). Narrative
rationality, which proposes that human beings rely on stories in all manner of discourse,
similarly points to the fallibility of discursive work.
…but all discourse is presented by a fallible human being and is
an interpretation of some aspect of the world occurring in time and shaped by
history, culture, and character. Discourse rarely, if ever, presents an uncontested
or uncontestable truth (Fisher, 1994, p. 23).
Narrative rationality requires coherence and fidelity. Coherence requires structural (or
argumentative) coherence, material coherence (how a story compares with other relevant
discourse), and characterological coherence, which is tied to the integrity and values of
the author. “In each of these features of coherence, values are manifest: consistency,
completeness, and character” (Fisher, 1994, p. 24). Fidelity requires two assessments,
“weighing the elements of a message usually regarded as its reasons and weighing the
values it explicitly or implicitly conveys” (Fisher, 1994, p. 24).
Scientists know now that Copernicus was correct in his description that the earth
revolves around the sun, which was later supported scientifically by Galileo. Scientists
today would agree with Galileo’s scientific approach, though they would, given new
information, take issue with his claim that the sun is the center of the universe. Religious

51

leaders took issue with Copernicus and Galileo because their findings contested a view
of the universe outlined in Genesis, which they considered to be a higher authority than
science (Blackwell, 1998). Similarly, two hundred years ago, even the brightest minds
might have had difficulty with the idea that Earth was 4.5 billion years old, and the
universe significantly older. Primate of Ireland Bishop Usher established through
research on the Old Testament and mathematical calculations that the birthdate of the
world was 4004 B.C. His conclusions were derived in a systematic manner, and his
conclusions “fit nicely into the common view of history as a sacred narrative,
progressing purposefully from an intentional beginning toward a promised
consummation—in short, a teleology” (Rumsey, 2016, p. 88). Fisher (1994)
distinguishes between science and rhetoric, noting that there is a clear difference
between “doing rhetoric” and “doing science” (p. 22). The practice of scientific
discourse is rhetorical—scientists adapt to their audience, use persuasive symbols and
build arguments. Trying to convince an audience of a position is a rhetorical practice,
but science is a specific manner of solving problems (Fisher, 1994). At the level of
epistemic authority, science adopts certain procedures and verification commitments that
have, through trial and error, been deemed by scientists to have been successful in the
past, with hopes that these successes will continue. When these choices are challenged
by other kinds of authority, as in the case of Galileo, the scientific community will
respond predictably in protest to those challenges (Blackwell, 1998). As the church
looks to scripture and tradition for its epistemic authority, scholars look to the traditions
of their disciplines and their canons. Institutional authority is directly tied to epistemic

52

authority, and anything that threatens the institutional authority is also considered a
threat to epistemic authority (Blackwell, 1998). Scholarly journals themselves stand not
just as public records of scholarship, but as their brands, publication in which brings a
particular kind of recognition (Guédon, 2001, p.16). Brands, in the realm of
corporations, stand as “the core meaning of the modern corporation” (Klein, 2002, p.5),
and are a function of marketing, with advertisements as one way that meaning is
communicated. Commercial publishers brought their marketing infrastructure to bear on
the scholarly communication system, adopting strategies like market segmentation, to
target faculty members and librarians in a variety of sectors of academia. Marketing
defines brand image, brand equity and brand personality in order to position a book or
journal in a market. When these segmentation strategies work, they make it difficult for
competitors to break into an area and take revenues from leaders in the market. Brand
marketing is a continual process of maintaining the reputation of the brand (Green
2015).
The system of scholarly communication, broadly speaking, is governed at
various points in its processes by all three types of legitimate authority as outlined by
Weber. There are prescribed rules that must be followed to publish, including making
the right choices of publication venue; the broader academy and individual disciplines
have long-standing traditions about how they do their work, and it is generally important
to make sure the right people or cited, or, best, be the person scholars might be expected
to cite. Better than that, even, Merton (1974) points to eponymy as one of the grander
forms of recognition in science, through which a particular scientist can leave historical

53

marks by having all or some part of his or her discoveries named after them, “as with the
Copernican system, Hooke’s law, Planck’s constant, or Halley’s Comet” (Merton, 1974,
p. 298). As Mosco (2004) argues, the true test of a myth is not whether it is accurate, but
whether the myth is embraced by sanctioned power structures that, “in doing so, keep
them alive” (Mosco, 2004, p. 39). What constitutes knowledge is influenced by power
structures and those who hold authority within those structures. In politics and science,
an authority figure is required to determine what information is acceptable for discourse,
what information constitutes knowledge, which is key for a stable society (Lyotard,
1984). Authority in the system of scholarly communication is theoretically built into the
science and not the medium through which it is communicated, though the various
media have taken on their mantles of authority, made legitimate by social actors
(scholars) operating in the system. Authority is the system by which content is
commodified at the epistemic level. Authority in the current system is abstracted through
brands and metrics; due to concerns about fallibility, human judgment is offloaded into
data. As a first step at examining how authority is accumulated around content and
communication technology, I will explore its role in one area in particular: the fixed
nature of the print form.
The myth of fixity
Rather than considering books and the information on their printed pages as
natural facts, Rumsey (2016) considers them better viewed as “memory machines with
lives of their own” (p. 177). Once thoughts are documented in hard copy form, they
begin “circulating and pursuing their destinies.” Just as scholars have figured out how to

54

share ideas in hard copy form and distribute the ideas contained therein both in the
present and through time so that ideas live on, it is necessary and possible to ensure this
occurs as culture transitions its memory machines to digital form. The trust built in
books and other forms of print is based in part on their fixed form. Inflexibility in form,
in fact, is precisely what can make the transition from one technology to another
difficult, because “fixity and indelibility may form the basis upon which our trust in
printed books is built, but these attributes can just as easily endow these objects with an
air of integrity they may not fully deserve” (Striphas, 2011, p. 12). Striphas (2011)
continues:
… specific goods take on an identity or life of their own seemingly independent
of human involvement, which then becomes an abstract index of their value.
Instead of favoring either of these definitions of commodity, I wish to locate
books in the tension between them. What interests me are those moments in
which they’re treated either as generic stuff or as hallowed objects, as well as the
labor it takes to transform books from the one into the other. This is nothing
other than the work of culture (p. 28).
Print culture constructs boundaries in various forms and myths build up around those
boundaries. These boundaries tend to be procedural at their basic level. The basic notion
of publication itself serves as a boundary. Books have chapters, journals have volumes
and individual issues, and distinguish themselves from other journals by providing
particular types of content. Rumsey (2016) notes: “the mere fact of print carried with it
an implicit imprimatur of authority” (p. 60).

55

Although the authority of books and other printed materials seems baked into
their very essence, the idea of fixity obscures the fact that the ideas contained therein
were not born fully formed into the world. This fixity reverberates throughout the culture
of the printed word. Even the Declaration of Independence, one of the founding
documents of the United States underwent revision on their way to their final draft. The
text, so central to the values of an entire country, were heavily edited on the way to the
final form seen today. One of the document’s most famous phrases: “we hold these
truths to be self-evident, that all men are created equal.” These were not the words of
Thomas Jefferson, but an edit suggested by Benjamin Franklin. Jefferson’s phrasing
painted these truths as “sacred and undeniable.” As Rumsey (2016) notes:
The jarring yet oddly familiar sight of the Declaration of Independence in full
Track Changes mode makes self-evident the disagreements among the Founders
and the compromises they agreed on. The original document renders the past
strangely new—the events dramatic, the motives of the actors complicated, the
conclusion unpredictable (p. 5).
Knowledge derives its authority from its assumed objectivity. In the quest for
knowledge, the values of the participants are clear. Social and natural science are in a
constant state of confirming and disconfirming lines of inquiry, but the rhetorical
transactions around inquiries only cease when the inquiry is confirmed (Fisher, 1994, p.
29). Once something is “proven,” it is considered fixed—at least until someone comes
along to disprove it. However, fixity and indelibility are precisely the factors that have

56

allowed egregious errors to be counted as fact, because they are in purportedly
authoritative texts (Striphas, 2011).
Even before the deluge of information presented by digital distribution, books
broke down barriers to information sharing, creating what Rumsey (2016) refers to as a
“disturbed landscape of memory” (p. 60). As printed works began to circulate, ideas
traveled even further than the bounds of the covers in which they were printed, passing
from person to person, and becoming compelling agents of influencing opinion. Once in
print circulation, factually incorrect information is difficult to fight, for the simple reason
that once something was on the printed page, it became imbued with “an implicit
imprimatur of authority” (Rumsey, 2016, p. 60). Fixity as an inherent quality of print
underscores this imprimatur of authority. By viewing fixity as a transitive rather than an
inherent quality, it is possible to see that fixity only exists when recognized by
individuals, that factors besides the availability of the texts themselves influence readers,
and that the cultural space in which the text exists shapes its reception—thereby focusing
attention more appropriately on social and cultural interactions (Johns, 1998). The
invention of writing itself happened more than once through multiple cultures. As
Rumsey (2016) notes, “Egyptians, Chinese, and Mesoamericans each developed writing
systems of astounding complexity and ingenuity quite independently of each other” (p.
25). These systems, once encountered by others, spread to other cultures, “extending the
reach and longevity of knowledge became a distinct competitive advantage not only over
animals but also over rival Homo sapiens” (Rumsey, 2016, p. 25).

57

A brief history of scholarly journals
As Thatcher and Rosenthal (1973) outline in their congressional testimony, a
typical scholarly book is built using information from articles that were originally
published in scholarly journals. The system by which authors publish in scholarly
journals was built purposely on the foundation of scholarly authority. In 1665, Henry
Oldenburg, then a member of the Royal Society of London, to advance a more dignified
public image for natural philosophers, created The Philosophical Transactions of the
Royal Society of London. His aim was not just to create a “public record of original
contributions to knowledge,” but to establish a process that would bring clarity and
transparency to work done by these philosophers and certify the originality of their
work—in essence operating as something of a “patent office for scientific ideas”
(Guédon, 2001, p. 5). This public registry, Oldenburg hoped, would also guide behavior
within the community. He designed this system explicitly to establish authority in and
for the scientific community.
Johns Hopkins University, founded in 1876, built itself largely around German
traditions in higher education, and was the first university in the US through which a
scholarly journal was published. According to then president Daniel Coit Gilman, a true
university considered the practice of research as the essence of its being. Walter Dill
Scott, president of Northwestern University, echoed this research-focused view in 1921
when he told the faculty that their publication record was considered the official record
of the university’s members. Similarly, Harvard President Derek Bok suggested that,
because peers cannot easily evaluate teaching in one’s institution, nor by those at other

58

universities, a faculty’s published research is, therefore, the common currency that can
be evaluated across boundaries (Carrigan, 1990). Within this system, the only
“university recognized marker of distinction” is publication (Donoghue, 2008, p. 39).
Ira Remson, a chemistry professor, who joined the faculty at Johns Hopkins University
in 1876, requested permission to publish preliminary reports on his research, not as a
way to disseminate knowledge, but as a way to bolster their image with working
chemists and to establish a reputation for their faculty among peers. In 1878, he started
Notes from the Chemical Laboratory, the first publication of its kind in the US, which
would later become the American Chemical Journal (Carrigan, 1991, p. 133). The
evolution of the scholarly journal has been centered almost entirely around creating a
legitimacy structure for scholarly work. Regardless of the communication technologies
in use, capitalist tendencies and hierarchical structures as developed during the Industrial
Revolution continue to influence the structure of higher education.
Commercial impulses encourage more and more digitization because it allows
for “amplification of communication as a commodity form” (Mosco, 2004, p. 156),
transferring its use value to exchange or market value. Through a “mutual constitution of
digitization and commodification” (Mosco, 2014 p. 156), commercial forces increase
their ability to measure and repackage content, which coincides with increasing desire to
measure results of scholarly output more effectively and efficiently. Although the
internet and mobile technologies do much to impart freedom and liberation from
controls, gatekeepers exert centralization of control through centripetal force applied by
large companies like Apple, Amazon, and Google (Striphas, 2011). There is an ever-

59

increasing collection of metrics currently in use that attempts to define the productivity
of faculty and the universities for which they work. While teaching and service have not
been jettisoned completely, the metrics focus most closely on one thing: publication
(Donoghue, 2008). As scholars focus more intently on ensuring they meet these
publication standards, they hand over rights of use and distribution of their work to
commercial scholarly publishers. Use rights are key to the identity of those operating in
a commons, and it is important to the preservation of those identities that those rights not
be commodified (Hyde, 2010, p. 43), but they already have been.
As paid subscriptions and sheer volume of publications increase, libraries have to
make increasingly difficult decisions regarding their collection practices. Donoghue
(2008) notes that the focus on productivity—in the case of faculty research, the number
of articles produced—and perceived status of journals and presses, produces a system
that rewards scholars who are active but not necessarily influential, effectively breaking
the prestige model on which the entire system rests (Donoghue, 2008, p. 39). Different
social situations have different prestige symbols, and prestige is not a constant. Prestige
is derived from signs and symbols that are considered markers of success. These markers
accumulate through the process of attaining goals or possessing traits that are coveted by
the group (Wilson, 1995). Scholarly communication, then, is a complex sociotechnical
system driven by a commodification of texts selected by a prestige hierarchy, and the
increasing volume of publications indicates that publication is not only the foundation of
the system of scholarly communication, but an increasingly crowded space in which to
operate.

60

Measuring productivity in some industries is simple. A company that produces
standardized products need only calculate the ratio of outputs to inputs. Such
calculations are difficult in education, where standards vary both within and across
institutions. As Bowen (2013) states, “this formulation conceals at least as much as it
reveals” (Bowen, 2013, p. 6). The difficulty with calculating productivity and efficiency
does not stop administrators and legislators from trying to make such calculations or
from relying on the results. Educators still find it necessary to prove their economic and
social worth with an ever-increasing suite of statistics, in an attempt to defend against an
oppressive “corporate vocabulary of efficiency, productivity, and usefulness”
(Donoghue, 2008, p. xv). Research faculty with or without tenure in this environment
must improve their metrics or risk being fired for productivity lapses. Entire fields of
research now revolve around assessing these measures. In determining the rankings of
schools, previous methods would have asked relevant experts in the field for their
opinion. Current methods focus on “how many pages each faculty member in the law
school publishes over a five-year period” (Diodato, 1994, p. vii). A cottage industry, in
fact, has grown up around the idea of measuring the effectiveness of individual scholars.
Impact factors measure the influence of journals (Kolowich, 2010). Journal impact
factors are published by the Institute for Scientific Information (ISI), and are typically
used to evaluate both quality of the overall journal, and the quality of the papers
published in the journals (Sombatsompop & Markpin, 2005). The h-index estimates how
important a single scholar’s cumulative contributions to research are and attempts to
measure the impact and broad significance of that work (Hirsch, 2005). The g-index

61

purportedly provides all the benefits of the h-index but provides additional information
that allows for a clearer distinction between scientists and for a more accurate ordering
of scientists (Egghe, 2006). These are just a few examples. Each of these measures
captures some small part of what a faculty member does. Added together, they still
provide no explanation or substantive critique of the scholar’s work. The numbers can
provide an easy shorthand, and even tell a compelling story, but not necessarily the right
one. A notable attempt to use scientific measurement for scholarly production came with
Alan Pritchard’s “bibliometrics” in 1969, “the application of mathematics and statistical
methods to books and other media of communication” (Pritchard, 1969). He proposed
this term as an improvement upon “statistical bibliography,” a term first used by E.
Wyndham Hume in 1922. Due to the shift toward scientific measurement of
productivity, professionals and knowledge workers are now subject to similar anxieties
about the possibility of losing their jobs due to lack of productivity that was brought to
blue-collar jobs through a restructuring that the 1980s (Abbott, 2008b, p. 161). A 2012
report released by the National Academy of Sciences that outlines that productivity in
this environment is not one-dimensional and that there are myriad risks in the use of
overly simplified measures (Bowen, 2013).
Because of the way the h-index is calculated, it tends to favor scientists. A
scholar in the humanities will unlikely have an h-index as high as a scholar in physics
because the humanities tend toward long-form writing, which means fewer publications.
By relying solely on the h-index, humanities scholars can potentially fall victim to a
reification fallacy, by which an abstraction is treated as if it were some concrete event or

62

physical item. When pitted against scientists in virtually any of these numbers games,
humanities scholars, regardless of reputation or influence in their discipline, simply do
not seem to measure up according to just the numbers. In a digital environment, it is
possible to extract data that show not only the number of citations, but the number of
downloads for a particular article, and it is even possible to see browsing patterns of
researchers navigating literature (Kolowich, 2010). In reaction to the increasing demands
from university administrations for metrics, Priem, Taraborelli, Groth, & Neylon (2010)
published a manifesto declaring a vision for a diverse array of metrics designed to
“measure impact in a diverse scholarly ecosystem,” which they called altmetrics. This
system of metrics promises to “create real-time recommendation and collaborative
filtering systems” that can ease the process through which scholars find new material in
their field by providing a real time feed of new publications in an area and measure a
broader range of scholarly work. Their system goes beyond previous systems of
measurement in that it measures citations for articles more quickly and finds references
to scholarly work outside of the traditional system of citation counting. Again, in this
case, there is an addition of even more metrics. The creators of altmetrics boast of the
semantic nature of the data and, in addition to helping scholars filter information, and
helping administrators calculate, this data system promises to help detect fraudulent
activity (Priem et al., 2010).
Donoghue (2008) directs attention to how this kind of measurement tends to lead
to competition and argued that competition is now as fundamental in academic culture as
it is in corporate culture. Publication at intensive research institutions for faculty on the

63

tenure track is no longer optional; it is a requirement. Moreover, to make comparisons
between institutions, the projects must be somewhat comparable, leading to conformity,
or as Meyer & Rowan (1981) would call it, isomorphism—in the very environment
(particularly for research universities) where it is hoped innovation will occur. As
Donoghue (2008) suggests, “in an ironic turn, professors, who like to think of
themselves as autonomous intellectuals, find that their work tends, because it is
constantly evaluated and managed, toward narrow conformity and standardization” (p.
176). Conformity in tenure requirements begins to spread across the country, publication
expectations for assistant professors inflate, research missions creep into schools where
they never existed before, and the education enterprise begins to measure itself against
the expectations of elite institutions (Donoghue, 2008).
Standards and processes developed for a physical environment are being mapped
onto a digital infrastructure that need not be constructed in the same way. Ramsay
(2010), as part of a Hacking the Academy blog series, questions the struggle to shift
toward ways of looking at digital content produced outside of the traditional publishing
process:
For years, I wondered why people are so resistant to electronic publication and
digital projects generally. The answer just didn’t make sense: “We don’t know
how to evaluate that kind of work?” “Really?” I thought. “Here’s an idea: How
about you look at it and decide whether it’s good or not.” But that’s precisely the
responsibility that no wants to have (without cover of darkness). This is the root
of every bit of sanctimonious nonsense you’ve ever heard about “peer review.”

64

Translation: We don’t have a certifying authority to whom we can offload this.
That’s why I believe that creating these certifying authorities for digital work
may end up capitulating to an already broken system (Ramsay, 2010).
Although it seems that new technologies are being fully embraced in academic circles,
much of the work published in digital space outside of the traditional publishing process
is still not considered worthy of the academic enterprise. In fact, in January of 2014, The
International Studies Association (ISA) proposed barring members of the editorial board
of journals published under its imprimatur from blogging. The president of ISA noted
that the policy suggestion was not directed specifically at blogs but put forth as a guard
against people confusing work done by ISA authors as part of their journal work and the
work they do in a more personal space (Straumsheim, 2014).
Lessig (2004) warns that the initial design of technical systems can make it
difficult to make changes to that system in the future, restricting available options.
Borgman (2007) applies this notion to a scholarly context, noting that decisions made
now are going to affect both producers and consumers of scholarly content who have not
yet been born (Borgman, 2007). Lyotard (1984) similarly warns that technology’s focus
on efficiency could be detrimental to a system purportedly focused on seeking truth,
noting that the focus on scientific language creates an “equation between wealth,
efficiency, and truth,” and that decision-makers resort to attempting to describe the
whole through “input/output matrices” and legitimize power based on measures of
efficiency (Lyotard, 1984, p. xxiv).

65

Gare (2007) argues that increased bureaucracy has potentially deleterious effects
on institutions, because when “careerists” become involved in them, goals are often set
aside to make room for power struggles for personal advancement, and the original
mission of the institution—its reason for being—gets left behind. As for the system of
scholarly publishing, it is important to remember that “the bottom line is that scholarly
publishing isn’t financially feasible as a business model—never was, never was intended
to be, and should not be. If scholarship paid, we wouldn’t need university presses”
(Davidson, 2014). The university press has long been a central component of scholarly
publishing, and they were originally intended to publish work from their faculties
(Fitzpatrick, 2011). While their imprimatur remains crucial, new methods of publication
are possible in a digitized publication system. The imprimatur of authority bestowed by
the press carries far more weight in the academy than those of non-academic
publishers—and scholarly journals provide similar cachet. Productivity and impact
measures are tied together in a system to bestow legitimacy on participants and the work
they produce. University public relations departments around the country scramble each
year to either trumpet success at moving up in the U.S. News & World Report college
rankings each year, or to explain away any movement downward on the list. The
importance of these measures is perhaps best evidenced by the fact that scholarly
publishers are now creating tools to aggregate and provide data (at a cost) to the
universities that provide their work product. The myth of authority lies in the imprimatur
of authority conferred by publication.

66

Scholarly communication is best understood as a complex sociotechnical system
(Borgman, 2007). The system has shifted from a gift economy to a reputation economy
(Fitzpatrick, 2011). Lanham (2007) argues that there has been a shift from an
“information economy” to an “economics of attention” (p. xi), in which not scarcity but
an excess of information is the problem, so that attention to information is what now
drives the system. Mosco (2004) explains political economy as “the study of the social
relations, particularly the power relations, that mutually constitute the production,
distribution, and exchange of resources, such as communication” (p. 6). It is particularly
important that scholarly communication be considered as a system, as it “implies a
degree of interrelatedness-of integration, coordination, and logic among the constituent
elements” (Carrigan, 1990, p. 335). From the system level, it becomes clear how the
environment imposes structure on the system, and how all of the assorted parts function
individually and in coordination with one another. Three main systems exert influence
on higher education in the United States. The first are state systems that control many
institutions of higher education and form a system with extensive impact even outside of
publicly-funded institutions. The second is the academic oligarchy, where senior
professors exert their influence, and, finally, the wider commercial market economy,
reflecting choices made by and exchanges between individual elements in the overall
system (Clark, 1983). Scholarship tends to be an inwardly focused system of experts
talking to each other. To be considered expert and therefore an authoritative voice in a
scholarly conversation, scholars must pass peer review to be published in the right
journals as designated by their discipline. Librarians have a vested interest in ensuring

67

their collections contain authoritative research—and, increasingly the corresponding sets
of data—that supports the research process—libraries do not collect everything, but they
do work closely with faculty in various disciplines to ensure that collections are
sufficiently authoritative. Intense pressure to publish often and in the right venues
confers a brand upon journals with high impact factors.
The notion of a brand may be a shortcut used to assess quality that is a function
of marketing and not of academic quality. Brembs Button & Munafò (2013) suggest that
institutionalizing journal rank and the pressure to publish has had negative consequences
for science, because with the focus on the journal itself, focus on the quality of work
goes down, leading to an increase in retractions. It is suggested in some areas that the
whole concept of the journal be done away with entirely (Brembs et al., 2013). In a
system driven by print, the “journal container” was the most efficient method for
delivering scholarly content prior to the digital shift. In a digital environment, the focus
can shift more to individual articles, with pay-per-view access as a possible alternative to
paying for entire journals (Bosch & Henderson, 2014). The value of the results of
scientific inquiry comes after they are made public, and the system was designed as a
way of “claiming and proving property titles” (Guédon, 2001, p. 7). Guédon (2001)
continues:
The lesson to be drawn from all this is obvious: research scientists treat articles
and published journals exactly as Oldenburg had anticipated, i.e., as registers of
intellectual property whose functions are close to that of a land registry. In effect,
journals record the ownership titles (articles) and they define limits and

68

boundaries. Ultimately, scientists are more interested in articles than journal
titles, exactly as anyone would be more interested in locating a particular land
title than a title office. Yet, knowing where the title office lies is obviously very
important as well (Guédon, 2001, p. 16).
Peer review provides “an intimate relationship between reputation and authority in the
intellectual sphere” (Fitzpatrick, p. 35), and together with other measures of assessment
help to determine reputation. A digital environment provides a variety of new
possibilities for “reputation-determining metrics” (p. 35). EBay and Slashdot are just two
examples of online entities that have evaluations systems based on customer feedback
and ratings, and Fitzpatrick (2011) argues that these frameworks and others point to a
potential change in how scholarship is produced and consumed, which can lead to “a
vibrant intellectual commons that will genuinely promote the Progress of Science and
useful Arts” (Fitzpatrick, 2011, p. 83). Cohen (2010) points to this drive for publication
as problematic because while the system is creating a great deal of scholarly content,
there is, as yet, no clear picture of how much actual demand exists for that content. He
goes on to suggest that the social contract rests on engaged reading, and proper
attribution and that both the supply of content and the demand for content need to be
appropriately aligned (Cohen, 2010). Within such a system, the library plays two roles:
as a place to store materials, and as the key customer in the market for an increasingly
large and increasingly more expensive collection of published scholarly output
(Carrigan, 1990). The strain on library budgets makes it difficult for libraries to maintain
the collections necessary to sustain the scholarly communication system. As

69

expectations for faculty production continue to increase, commercial publishers make
record profits—in fact, as outlined in Chapter II, increases in commodification, increases
in reliance on metrics, increases in competitiveness, and increases in publications and
publication venues have all coincided with increases in publisher profits, particularly
since commercial publishers began to take over scholarly publishing. It is in the interest
of their business that these increases continue. The rise of digital publication and the
increased commercialization of scholarly content is creating new opportunities and new
tensions in the culture of publishing.
Factors contributing to change in the publishing culture
The shift toward peer production in digital environments is creating a culture
change throughout various avenues of publication and information exchange. These
shifts are less a cause of destabilization and more of an acknowledgment of a problem—
and the problem is “a reorientation of knowledge and power that includes questions of
enlightenment and rationality, democracy and self-governance, liberal values and
problems of the authority and validation of knowledge” (Kelty, 2008, p.279). In the
system of scholarly communication, researchers are particular in their choices of
information to use in supporting their research. Guédon (2001) notes, concerning
scholarly sorting behaviors on publications, that:
As a rule, preprints will simply not do; not all journals will do, either: scientists
want the best citations from the most authoritative sources possible and this
shows that scientific publishing actually rests on the perception of a pecking
order among journals. Finally, scientists also monitor five to ten “essential” titles

70

they deem fundamental for their specialty. In this manner, they check the
progress of colleagues and potential competitors (Guédon, 2001, p. 15)
Benkler (2006) points to content as one place where there is an increasing amount of
legal control exerted through more restrictive copyright, patent, and trademark
legislation, but also notes that social forces are pulling in the opposite direction—toward
content sharing and a strong drive to participate in communities to create content and
allow for its repackaging and reuse (Benkler, 2006). Changes in culture can lead to
crises of authority. When existing power structures are called into question, and the
information load is overbearing, “the question of what to believe becomes, almost
imperceptibly, a question of who to believe” (Rumsey, 2016, p. 61). Hyde (2010) points
to a key element of the community of scholarship in the system of higher education in
the US, which is that, in order to advance professionally, scholars must demonstrate
quality in scholarship, teaching, and service—the quality being determined by the
community.
The quality of work in each of these spheres, moreover, is judged by the
community[…] Only at the end of that process—after all the letters have been
written by colleagues and students, after the tenure and promotion committee has
met, after the dean of faculty has read the file, and so forth—only then can
professional advancement, both in rank and in salary, come. As in Franklin’s
model, if merit belongs to the work, the community assigns it, not the scholar.
(Hyde, 2010, p. 159)

71

This is the critical contradiction of the myth of authority. Authority is assigned by the
community, but it is currently tied too closely to journal brands. To emphasize this, I
will now explore changes to the information economy, and follow with an outline of new
possibilities for publishing scholarly work.
The information economy reached its current networked status when capital costs
lowered enough to grant access to a broader population. Investments became more
broadly distributed; information could be produced and processed through the efforts of
people who were not geographically collocated. Thus, the increase in peer production is
no different rationally speaking than that of the assembly line at the beginning of the
twentieth century (Benkler, 2006). Three key areas make the current information
environment toxic, as specifically related to copyright law: changes in legal rules, the
advance of technologies, and seismic shifts in the area of media ownership (Lessig,
2004). These issues have affected scholarship as much as they affected other forms of
media production, but a key difference is that peer production is something scholars
were doing long before the internet came along. Björk (2007), in an attempt to
document the entire value chain of the process of scientific communication, outlined the
process using a series of workflow diagrams. The following is the top-level diagram that
provides an overview of the entire process:

72

Figure 8: Top level diagram of Björk’s model of scientific communication as a global distributed information
system. Reprinted from Björk, 2007

Section A3, “Communicate the results,” is the most substantial section of the model. The
outcome of this part of the model is the distribution of scientific knowledge to its
expected readership, without which the results would generally be considered useless.

73

Mosco (2004) explains that commodification occurs when use value is transferred to
exchange or market value. The commodity form of scholarly publication, which is the
form that communication takes on when the production of that communication is
organized primarily through the process of exchange, is expanded through digitization,
because it affords commercial forces increased opportunities to be more flexible in the
way that they control, monitor and measure content.
Wikipedia is possibly the most famous example of a system built around the
notion of peer production. Designed by the Wikimedia Foundation, it is both an online
encyclopedia and a community, evidenced by their statement of commitment: “Imagine
a world in which every single human being can share freely in the sum of all knowledge.
That’s our commitment.” (Reagle & Lessig, 2012, p. 20). While scholars like
Vaidhyanathan (2005) and Benkler (2006), who promote peer production for the cultural
commons, have explored shifting notions of authority with regard to the production,
distribution, and consumption of media and the democratization of those processes,
scholars have ignored how intellectual authority might also be changing (Fitzpatrick,
2001). For example, some academics and librarians have banned the citation of
Wikipedia. This kind of ban may be due to a misunderstanding of the inherent value of
the stored knowledge in Wikipedia—its soul lies not in the entries themselves, but in the
fact that users can see the history of the entries, “where the controversies inherent in the
production of any encyclopedia entry are enacted in public, rather than smoothed over
into an untroubled conventional wisdom” (Fitzpatrick, 2011, p. 16). Fitzpatrick (2011)
continues:

74

More centralized projects, such as Citizendium, that seek to add traditional,
hierarchical modes of review to a project like Wikipedia overlook the facts that
the wiki is in its very architecture a mode of ongoing peer review, and that not
only the results of that review but the records of its process are available for
critical scrutiny (Fitzpatrick, 2011, p. 17).
Myths provide balm for the uncertainty that is inherent in what Mosco (2004) refers to as
a “liminal state.” Not only do myths help us get through uncertainty at the moment, they
allow us to consider the “power and possibility that comes with the release from custom
and the loosening of traditional ties” (p. 32). Additionally, Mosco (2004) observes that it
is important not to elide social structures, human agency, and “the real world of politics.
According to myth, the Information Age transcends politics because it makes power
available to everyone and in great abundance” (Mosco, 2004). Technology has, in fact,
provided some additional room for freedom in the production of scholarship, particularly
in the area of Open Access publishing, but it has also created space for predatory
publishers. I will next provide an overview of OA and predatory publishing, followed by
an explanation of other publishing options currently available that exist outside of the
world of commercial scholarly publishers.
Open access and predatory publishing
In an attempt to address many of the issues in the system of scholarly
communication, and most directly the issue of struggling library budgets, the Open
Access movement began in the early 1990s. The movement gained momentum and took

75

on a more global character beginning with the Budapest Open Access Initiative (BOAI)
in 2002. The statement of principles outlined at that initiative define OA as follows:
By "open access" to this literature, we mean its free availability on the public
internet, permitting any users to read, download, copy, distribute, print, search, or
link to the full texts of these articles, crawl them for indexing, pass them as data
to software, or use them for any other lawful purpose, without financial, legal, or
technical barriers other than those inseparable from gaining access to the internet
itself. The only constraint on reproduction and distribution, and the only role for
copyright in this domain, should be to give authors control over the integrity of
their work and the right to be properly acknowledged and cited (“Budapest Open
Access Initiative Statement of Principles,” 2002).
Supporters of OA have received pushback from commercial publishers as well as faculty
at their institutions. The movement recognized that a scholar is a particular kind of
author:
Imagine a tribe of authors who write serious and useful work, and who follow a
centuries-old custom of giving it away without charge. I don’t mean a group of
rich authors who don’t need money. I mean a group of authors defined by their
topics, genres, purposes, incentives, and institutional circumstances, not by their
wealth. In fact, very few are wealthy. For now, it doesn’t matter who these
authors are, how rare they are, what they write, or why they follow this particular
custom. It’s enough to know that their employers pay them salaries, freeing them
to give away their work, that they write for impact rather than money, and that

76

they score career points when they make the kind of impact they hoped to make
(Suber, 2012, p. 2).
The goal of the movement has been to disrupt traditional forms of scholarly publishing
that are subscription-based, making scholarly output more freely available online to a
much broader audience, and to break free of the oligopoly of commercial scholarly
publishing, a system in which the top five publishers controlled over fifty percent of
scholarly content in 2013, a marked increase which begin in the mid-1990s. These
publishers were Elsevier, Taylor & Francis, Wiley, Springer, and Sage (Larivière et. al.,
2015). Policies and guidelines have been created to guide the distribution of scholarly
work by initiatives like the Budapest Open Access Initiative and the Bethesda Statement
on Open Access publishing (Nelson & Huffman, 2015). There are different models for
OA. When access is provided directly by journals, it is called gold OA. When access is
provided through repositories, typically through deposit of an author final draft, it is
called green OA. Any work that is available only for a fee is referred to toll access (TA)
(Suber, 2012).
The concerns of scholars who have resisted OA initiatives included worries that
OA undermines traditional process of peer review and academic freedom. Open Access
is in fact, compatible with peer review, copyright, and virtually every other process
involved in scholarly publishing. However, as Suber (2012) stated, “cultural inertia
slowed the adoption of OA by leading many people to mistake it for a more radical idea
than it actually is” (p. 168). Adoption of OA has been uneven, partly because of
concerns about peer review and research quality, but partly due to the established

77

reputation of traditional journals, which are critical to the tenure path. When considering
whether to publish in OA journals, tenured scientists are more interested in visibility
than non-tenured scientists, while non-tenured scientists were more interested in
potential career benefits (Park, 2007). For those who have yet to receive tenure, it is still
critical to ensure that they are published in the right journals.
The OA movement is beset with problems familiar to traditional scholarly
publishing as well. Concerns about predatory journals began to crop up in the early
2000s, and it was the OA movement that created the circumstances that allowed their
rise (Nelson & Huffman, 2015). Predatory journals serve a similar function as vanity
presses for monographs and edited volumes. These predatory journals charge article
processing charges (APCs) to authors, but often do not implement a rigorous peer
review. To test this purported process, an author sent a purposefully flawed article to one
of these predatory journals and received an acceptance letter and the instructions on how
to pay the APC on the following day (Shen & Björk, 2015). A heavy focus on
publication counting drives some of this behavior, leading to problems even in the
traditional system of publishing. Impact factors create particular problems, with some
editors rejecting articles not because they are bad scholarship, but because they do not
cite enough articles in the editors’ journals. A particularly egregious example is an
article published in Medical Science Monitor. Four hundred forty-five of the 490 articles
cited by the authors of the article appeared in one other journal, Cell Transportation.
This pattern of citations drove up the impact factor of the journal Cell Transportation by

78

21% over the next year. Three of the four authors of this particular article in the Medical
Science Monitor were editors for Cell Transportation (Morozov, 2013, p. 251).
In an attempt to raise awareness of the problem of predatory publishers, Jeffrey
Beall founded Beall’s list in 2008, later coining the phrase predatory publisher in 2010
(Pyne, 2017). Publishers and journals identified as predatory under his standard are seen
as being devoid of a real peer review process, generally of low quality, and profit-driven
(Nelson & Huffman, 2015). Beall has been considered a hero to some—the OA
movement, in particular, has been critical of his list, suggesting he is overly hostile to the
model (Straumsheim, 2017). Beall’s list recently, without warning, disappeared from the
web. Questions arose as to whether it was in response to legal action. Cabell’s, a
company that helps researchers and librarians find scholarly journals, has been working
with Beall since 2015 on a new blacklist of journals, but they deny having anything to do
with the removal of the list (Straumsheim, 2017). Neylon (2017) suggested that the death
of Beall’s list is a positive move and points instead to the availability of multiple
whitelists as an already existing solution to the problem. PubMed, Web of Science,
Scopus, Directory of Open Access Journals (DOAJ) all provide the information to help
determine whether a journal is worthy of scholarly work. Olivarez, Bales, Sare, & Van
Duinkerken (2018), questioned the quality of Beall’s list, analyzing whether established
journals with a good reputation would pass the criteria Beall outlined. They examined 81
journals, and found that 45 failed on at least one criteria, while 18 failed more than one.
The term predatory creates a frame around publishers that are operating outside
the traditional, commercial scholarly publishers who wish to continue their hold on

79

scholarly output. In considering whether these journals are in fact predatory, it should be
clear precisely what predatory behavior they currently exhibit. If incentive structures in
the academy are constructed such that they focus on counting number of publications, a
publisher is not necessarily predatory, but fulfilling the needs of scholars who need
venues in which to publish (Basken, 2017). On whom, then, is the process said to be
predatory? The author pays system is not inherently broken but does include a
fundamental conflict of interest in that publishers’ profits are tied directly to the number
of articles they accept, which is effectively an invitation for abuse (Stratford, 2012). The
problem lies not so much in the hands of any particular publisher, but on a system that
focuses on publication above all else. Criticism of the author pays model also ignores
that commercial publishers like Elsevier, Taylor & Francis, Sage, Springer and Wiley all
provide the opportunity for authors to pay additional money to ensure their publication is
OA. While Thompson Reuters has been working to index more regional journals,
regional publishers, who often fall into the predatory category, have worked diligently to
get their journals indexed in Web of Science, which is the mechanism through which
their journals can establish an impact factor. The Serbian government, for instance,
requires that authors publish in journals with an Institute for Scientific Information (ISI)
impact factor to gain both academic appointments and PhDs, and this requirement is set
up as a safeguard of legitimacy (Shen & Björk, 2015).
Concerns of scholars and librarians with predatory publishing are growing, but
there are also concerns about the traditional system, including around the prevalence of
publication bias. Publication bias is the withholding of null studies, defined as those

80

studies in which the result proposed is not the result achieved, therefore the conclusions
do not support the outlined hypothesis. These studies are typically not considered
exciting enough for publication, though they would often contribute to an overall body
of knowledge, and in fact, left unpublished, can create a slant across an entire field.
Researchers found that of the null studies done by social scientists, only 20% were
published, and 65% were never written up because the authors assumed that journals
would not accept them (Franco, Malhotra, & Simonovits, 2014). This behavior extends
to how results are published more broadly. Newspapers do not cover initial studies when
there are null results and tend to cover initial findings of studies, but rarely follow up
when those results are disconfirmed (Dumas-Mallet, Smith, Boraud, & Gonon, 2017).
Faculty have a well-established loyalty to journals owned by traditional
commercial publishers, but the stories of two library journals point to the fact that there
are limits to this loyalty. In 2013, the entire editorial board of The Journal of Library
Administration resigned in protest of Taylor & Francis Group’s author agreements,
which they deemed too restrictive of author rights, in that Taylor & Francis either
expected to retain copyright of their work or charge a significant amount of money in
order to allow the authors to retain copyright (New, 2013). In 1998, in response to
increasing subscription prices, the entire editorial board of The Journal of Academic
Librarianship resigned, then moving on to create Portal: Libraries and the Academy,
published by Johns Hopkins University Press (Schwartz, 2013). In fact, many journal
editorial boards have declared their independence, with the first documented case being
in 1989 (Journal declarations of independence, n.d.). Journals manage to keep their

81

monopolies on content through a rule in academic journal publishing that is largely
obsolete because of electronic publishing but still enforced largely through copyright
agreements. The Ingelfinger rule, established in 1969 by the publisher of the New
England Journal of Medicine, prevented authors from submitting to more than one
journal at a time (Larivière et al., 2015). So, each scholarly journal is “a natural minimonopoly in the sense that no other journal publishes the same articles” (Suber, 2012, p.
38). These methods, which constrain an author’s flexibility to contribute to an existing
body of knowledge in favor of arbitrary restriction, are a function of intellectual property
rights, providing a temporary monopoly for the holder of those rights. The status of
journals as brands is particularly problematic, playing into the metrics-driven nature of
the academy today:
In academia, journal brand is everything. I have sat in many committees, read
many CVs, and participated in many discussions where candidates for a
postdoctoral position, a fellowship, or other roles at various rungs of the
academic career ladder have been compared. And very often, the committee
members will say something along the lines of “Well, Candidate X has got much
better publications than Candidate Y”…without ever having read the papers of
either candidate. The judgment of quality is lazily “outsourced” to the brandname of the journal. If it’s in a Nature journal, it’s obviously of higher quality
than something published in one of those, ahem, “lesser” journals (Moriarty,
2016).

82

Authority structures in the academy have been converted to shorthand judgements of
quality based on journal brands and data-driven structures that own and disseminate
content created by and paid for by the academy. The commercial impulse then
encourages more and more digitization because it allows for amplification of
communication as a commodity (Mosco, 2004, p. 156). Digital environments broaden
the commodification of content because there are so many ways in which content can be
measured, tracked and repackaged. Scholarship which has traditionally been done in
print journals, meanwhile, is caught up in a commercial scholarly publishing system that
increasingly adds little true value beyond the brand names of the journals published,
which help to abstract authority through a system of metrics. Lyotard (1984) warned of
validating science through such a process:
This is how legitimation by power takes shape. Power is not only good
performativity, but also effective verification and good verdicts. It legitimates
science and the law on the basis of their efficiency and legitimates this efficiency
on the basis of science and law. It is self-legitimating, in the same way a system
organized around performance maximization seems to be. Now it is precisely
this kind of context control that a generalized computerization of society may
bring. The performativity of an utterance, be it denotative or prescriptive,
increases proportionally to the amount of information about its referent one has
at one's disposal. Thus, the growth of power, and its self-legitimation, are now
taking the route of data storage and accessibility, and the operativity of
information (p. 47).

83

Publishers have a vested financial interest in this system continuing to pivot around their
existence. Peer review is potentially the largest roadblock to progress towards more
innovative methods of scholarship. The epistemic authority of scholarship is inextricably
tied to peer review (Fitzpatrick, 2011). As Blackwell (1998) noted of the Church, “the
institutional authority of the Church is grounded in the epistemic authority of Scripture
and tradition, then whatever threatens, or is perceived to threaten, the former is also seen
as a threat to the latter” (p. 50). Open Access and other non-commercial methods are not
inherently a threat to peer review, although they are often perceived as such by scholars.
Peer review, however, has always first and foremost been part of the social infrastructure
of the scholarly communication system. The tools by which the contents of research
output are made public is of no real consequence to the quality of scholarship as long as
those social structures remain in place. Fisher (1994) suggests that it is important in any
narrative to consider values and whether they are “appropriate to the nature of the
decision or beliefs that the story concerns,” and what the effects of following those
values have “in regard to one's concept of self, to one's behavior, to one's relationship
with others and in society” (Fisher, 1994, p. 24). Scholars value their methods, their
disciplines, their impact, and the latter points to one critical symbolic function of
publishers. As the creators of the content on which the entire system is based, they are
the allocators of academic capital (Larivière et al., 2015). That faculty do not want to
give up on practices manifest in traditional journals is not particularly problematic, given
that practices like peer review are critical junctures in the scholarly communication
value chain. Scholarly practices and their legacies are crucial to a well-functioning

84

system of scholarly communication and should be preserved in a discernible form. Peer
review is a critical part of the scholarly communication system, and publication is
critical to the dissemination of ideas. The measure of the merit of scholarship, however,
has become too closely tied to the shorthand of the journal container through which it is
disseminated, and to a system of metrics that offload human judgement to statistics.
Human judgment cannot be completely removed from the process of evaluating
scholarship. Cultural and social interactions are key drivers of the process. As Rumsey
(2016) notes: “the realm of emotional intelligence, empathy, and imagination—all
necessary for judgment in the context of incomplete information or conflicting aims—is
beyond the reach of our machines” (p.172).
Going “public” through Connexions
New technologies that allow for creation of content and mirror the processes
inherent in the system of scholarly communication have been in production for some
time. Kelty (2008) explored one system in particular that is tied directly to scholarly
content production. Connexions is an open repository of educational materials through
which authors publish content that would traditionally have gone into textbooks. One of
the critical issues facing the creators of Connexions is how to ensure that the process of
creating and publishing textbooks online satisfies traditional notions of authoritative
textbook knowledge. Since online books look nothing like traditional books, the
concepts of authorship, ownership, and other components of the system of knowledge
creation are sometimes called into question. While printed books exist as a single
enclosed container, publications in Connexions are modular, allowing authors and

85

publishers more flexibility in their reuse and modification (Kelty, 2008). Deetz (2008)
noted that the research community has often considered itself as apart from the world,
aspiring to universal knowledge and eschewing ideology. While also understanding that
this disinterested detachment has always been elusive—allowing for the avoidance of
certain kinds of subjectivity, but not provide to enough durable objectivity. The free
software movement, informing the ideology of Connexions, substitutes bookish
objectivity for what Kelty calls a “recursive public,” which is a public that is maintained
by the practice of people who participate in it. A recursive public also forms a social
imaginary, which is a narrative supporting the technical and moral norms and practices,
and a set of rationales for to deciding what is included and excluded as part of those
norms and practices. Its stories illuminate the “shared moral and technical imaginations
that make up Free Software as a recursive public” (Kelty, 2008).
Kelty (2008) uses the idea of a recursive public to support Johns’ (1998)
challenge to the idea of fixity in relation to the culture of print. Johns (1998) questions
the notion that fixity is an inherent quality of print, noting that it is transitive and only
subsists when people make this distinction. Various organizations have grown up in the
scholarly communication arena to provide new methods for creating and disseminating
scholarship in opposition to the commercial enterprise and built more closely on the
model used by Wikipedia such as MediaCommons, the Center for Open Science, and
Openstax (formerly Connexions). The Texas Digital Library is one of many consortia
that provides opportunities for the creation of new journals. Technologies like
CommentPress, a tool similar to Connexions, and made available through

86

MediaCommons, could potentially bring the codex out of seclusion, and allow readers
and reviewers to talk to each other and the author. These suggestions could make the
notion of books as conversations across time more real with the conversation happening
in the book itself, similar to asynchronous forms of communication found on blogs and
message boards, but with the functions of peer review built in (Fitzpatrick, 2011).
Connexions operates similarly, as it makes the textbooks available to many potential
readers at once, with publication taking on a more abstract meaning—authoritative
knowledge is part of a process rather than a fixed point in that process. Establishing
published works as a source of authoritative knowledge was a struggle in the days of the
printing press, and it continues today with the Internet. At a more practical level, open
textbook initiatives are a reaction to the rising costs of textbooks. The cost of textbooks
is often higher than the cost of tuition, and many students report not buying textbooks
because they cannot afford them (Martin, Belikov, Hilton III, Wiley, & Fischer, 2017).
University presses and libraries both serve key functions in the dissemination of
the scholarly record. Publication being a central concern of scholarship, the university
library provides one important mechanism by which those publications are disseminated
by providing discovery and access systems. Without a scholarly record to disseminate,
libraries are incapable of doing work that is central to the academic enterprise. Although
commercial presses are one way for this record to be created, the university press is
more closely aligned with the mission of universities, because for the most part, the
presses are not geared toward making a profit (Courant & Jones, 2015). Fitzpatrick
(2011) notes that originally the university presses were only in the business of publishing

87

work of faculty at their institutions. A university press that is treated as if it is a central
part of the process of creating scholarship, and that is focused on producing scholarship
of merit without worrying about whether the work will provide profit, would bring
universities closer to an ideal of a system in which commercial publishers did not control
content and infrastructure. Such a system would likely save no money, but scholarly
publishing already costs universities significant amounts of money—the focus here
would shift toward to whom this money should go. Universities can give the money to
profit-seeking institutions outside the borders of the academy or invest in their
institutions through their libraries and university presses by investing in technologies
that allow for disruption of the commercial scholarly publishing enterprise.
Creation of textbooks in Connexions follows much the same process as any
traditional publication. The first stage of creating content in the system is what happens
before the system is involved—the composition of the text. The system marks up the text
after it is submitted, creating the structure by which the text is presented, modularized
and potentially transformed. It is the potential transformation after the fact that is
powerful, as it disrupts the notion of fixity—a published document can be transformed in
multiple ways by multiple people and can change regularly depending on the number of
people contributing to the process (Kelty, 2008). During the process of Fitzpatrick’s
(2011) book being on display through CommentPress, a system similar to Connexions,
forty-four commenters left 295 comments, providing a broader range of critique than any
traditional peer review process. Post-launch, it received over 31,000 page loads, with
over 12,000 unique visitors, 3,300 of whom returned multiple times (Fitzpatrick, 2011).

88

These numbers combined with the fact that a review of the project was published months
before the print edition was available is coupled with the fact that scholarly monographs
in the humanities typically sell around 400 copies, suggesting that the work was more
widely read in this environment (Fitzpatrick, 2011). The practice of creating scholarship,
even in a digital environment, need not change any existing social structures of ensuring
authority. What technology has helped to do is illuminate the material practice of the
scholarly communication system. As Kelty (2008) suggested, the processes of writing
and publication have become so naturalized that the cultural norms involved have
become imperceptible, even to its practitioners (Kelty, 2008).
When researching faculty publishing behavior at a Canadian university, Pyne
(2017) found that at one university founded in 2000, researchers in the business school
are increasingly publishing in predatory journals because they have no incentive not to
do so, given the fact that their promotion and tenure are tied directly to how much they
publish. Publishing even in reputable journals, particularly when reputation is defined by
journal rank based on impact factor is no assurance of research quality. Journal rank
does not predict importance and in some cases, predicts unreliability. The design of
impact factors violates basic scientific standards even as it influences appraisal of
journal quality (Brembs et al., 2013). If anything is to create a more reliable scholarly
communication process, metrics are not the answer. The myth of authority demonstrates
that authoritative knowledge, generally considered to be wrapped up in fixed containers,
whether they are monograph or journal, is not so easily discernible. The compatibility of
OA with institutional functions of university libraries, scholarly journals, and university

89

presses would be more obvious, were it not for the operation of myth to occlude and
disfigure the potential benefits of the system to tenure track professors, university
libraries, and university publishers. It does certainly help to maintain high profit margins
for the top five commercial scholarly publishers.
In this chapter, I explored how commercial scholarly publishers and predatory
publishers are gaining control of the content of the scholarly communication system.
Problems with publication in the system are not merely a result of the spread of the
Internet, but a problem with changing social, legal and technical conditions similar to
issues in different print cultures that challenged the book, and its attendant issues
surrounding the nature of what can be considered authoritative. The myth that authority
is derived from content in fixed form has been an impediment to change in the system of
scholarly communication. Kelty (2008) sees the challenge faced in creating and
sustaining a system like Connexions as twofold: first, figuring out what different legal,
technical and social issues need to be addressed today, and second, how to create and
subsequently modify a system such that it assures knowledge that is properly
authoritative. In Chapter IV, I will explore some of the legal, technical and social aspects
of the scholarly communication system and introduce the Myth of Influence, which I
will argue is bound up not in the content of scholarship, but in the infrastructures
through which it is distributed.

90

CHAPTER IV
DISCIPLINE AND PUBLISH – THE MYTH OF INFLUENCE
Introduction
In this chapter, I will outline a response to the question, “How has the shift to a
digital environment affected organizational structures of the scholarly communication
system?” I will do so by articulating the second of three overarching myths, namely, the
myth of influence. I will argue that this myth manifests and sustains itself largely
through citation and peer review as status markers in academic publishing, which
provide a representation of validity, merit, and status. Although peer review is central to
the myth of authority, I argue that authority also operates through systems of influence.
As a precondition for influencing scholarly communication systems, authority
fundamentally pertains to recognizing and validating the social and technical
infrastructures through which information is exchanged and is centered in academic
disciplines. Scholarly societies and university presses were the original disseminators of
research in the system of scholarly communication. Faculty produced the work,
publishers (not for profit) did the labor of distributing the work, and libraries bought the
work at higher prices to subsidize scholarly societies. The RDT perspective suggests
that things changed when these resources came under commercial control.
Resource dependence theory
At an organizational level of communication analysis, resource dependence
theory (RDT) is a network theory that deals with ties between social actors, which can
be represented by individuals, groups or organizations. Networks, or the relationships

91

between and among organizations and individuals in an institutional environment, are a
key component of the theory (Pfeffer & Salancik, 2003). Networks have structure, and
the patterns of ties and the behavior of social actors within the network are key—
relationships and structural constraints matter. This theory assumes that organizations
are dependent on resources from other organizations, which implies that organizations
have some measure of control over what another particular organization can and cannot
do. To survive, an organization must be actively engaged with its environment by
forging relationships to ensure access to resources the organization needs to survive.
This theory also allows us to think about the internal dynamics of the organization,
because choices internally can be based on power struggles among units, and units with
more resources often have more success in implementing their strategies. Boundary
spanning is a key concept here, as organizations (and units within organizations) need
and want to extend their influence beyond their borders. Organizations require resources
to function, and these resources are typically found in the environment in which the
organization is embedded. That environment also contains other organizations, who
often control the resources, which are the basis of power in the network, meaning that
independent organizations depend on each other for survival. The power of one
organization over another is only as much as the need for resources. Power, in this case,
is dependent on relationships and is often mutual (Pfeffer & Salancik, 2003). I
distinguish between power as defined by RDT, and authority as outlined in the previous
chapter, since power pertains to the control of resources, while authority pertains instead
to the legitimization of ideas. Power constitutes control over content which is selected

92

through mechanisms of authority, from production, to ownership and distribution rights
coded into intellectual property law. While closely intertwined, authority operates at an
epistemic level, and power at a political level. RDT treats the environment as its
independent variable and examines how perceived or actual constraints in the
environment can affect the conscious behavior of people in leadership to adapt to
changes in that environment.
Boundaries as infrastructure
Computer-mediated communication (CMC) studies how people communicate,
create relationships, form identities and create community using the computer
technologies—in particular—the internet. Participants in interactions create social
realities by using available resources to construct messages. Most of these resources
come from outside sources, including “temporal structure, external contexts, system
infrastructure, group purposes, and participant and group characteristics” (Baym, 1995,
p. 161). Science, operating in a similar manner, is at its most creative when it works
collectively, collaboratively, and cumulatively, flourishing when “barriers to collectivity
are reduced” (Hyde, 2010, p. 179). The traditional commons consisted of “not so much
the land in question as the land plus the social relations and the traditional institutions
that organize its use” (Hyde, 2010, p.29), and thus it was a social system. Boundaries in
social systems are often difficult to define because the organizations tend to be
structured around behavior, not around people (Pfeffer & Salancik, 2003). As Pfeffer &
Salancik (2003) argue, the focus on physical units rather than behaviors makes drawing
boundaries difficult. This difficulty in defining boundaries may be because individuals

93

are only partly included in any set of organized behaviors, Individuals can be part of an
organization and part of its environment at the same time. A faculty member in a
department of communication, for instance, is part of a department, a university, a
discipline and potentially multiple professional associations. Discursive boundaries are
organizational “lines of demarcation and differentiation” and “shared social,
organizational, and discursive spaces” (Wilson & Herndl, 2007, p. 131). By looking at
how behavior is coordinated, the line between an organization and its environment
becomes clear—the boundary exists “where the discretion of the organization to control
an activity is less than the discretion of another organization or individual to control that
activity” (Pfeffer & Salancik, 2003, p. 32). Work done at these boundaries is a
discursive endeavor, aimed at differentiating one group from another through a
“demarcation exigence” (Wilson & Herndl, 2007, p.129). Boundary objects can also
serve as a rhetorical construct to create an “integrative exigence” that allows for a
“temporary trading zone characterized by rhetorical relations of symmetry and mutual
understanding” (p. 129). An example of boundary objects are knowledge maps used to
create mutual understanding across separate teams at the Los Alamos National
Laboratory. The effort exerted at boundaries then, can both divide and join. The
processes through which these exigencies are managed are not always evident and can
often not be seen by outsiders to those processes (Wilson & Herndl, 2007).
Boundary objects work in two ways. First, they provide meaning and coordinate
practices for a broad range of actors. Second, they express themselves differently
depending on specific contexts (Wilson & Herndl, 2007). They can be either abstract or

94

concrete; they are flexible enough to adapt to individual situations; they are strong
enough not to lose identity when crossing boundaries, and they serve an integral role in
creating a sense of continuity at the crossroads of social systems (Star & Griesemer,
1989, p. 393). Standards and protocols are boundary objects that allow for the exchange
of data and other information across groups. Libraries are classic boundary objects,
which hold contents that can be used by multiple groups in multiple ways. A dataset, for
example, can be interpreted differently from the perspective of different disciplines, even
if they are drawing from the same data (Borgman, 2007). The process of peer review can
be considered as boundary work, considering that a referee is a “status judge who
evaluates the quality of role performance in a social system” (G. Howard, 2012, p. 324).
Alan Sokal, a physicist, submitted a hoax article to the journal Social Text in an
effort to test their peer review process. The content of the article was a conglomeration
of copied and pasted postmodern quotations with ideas made up to form connections
between the quotations The article was accepted by Social Text, and Sokal revealed the
hoax several weeks later (G. Howard, 2012). Hoax articles and other tests of the system
of publishing abound. Springer Publishing and the Institute of Electrical and Electronic
Engineers (IEEE) recently removed over 120 papers from their services after
determining they were generated by a computer (Noorden, 2014). The Social Text case
in particular highlighted the importance of peer review as part of the academic social
system. The incident was dismissed as unimportant because Social Text was not a
refereed journal and Sokal had picked a “soft target,” (G. Howard, 2012, p. 331).

95

Further, his hoax did not reveal any problems with the legitimate peer review system
because, as Howard (2012) states:
Clearly, the fact that Social Text has an “editorial collective” of forty
academics should give the journal more authority than it would have without
such referees but less than if manuscripts were sent to scholars completely
independent of the journal who were chosen solely for their expertise in the
topic of the manuscript (p. 331).
Peer review and its importance to the creation of scholarship has been one of the several
obstacles to reform in the scholarly communication system. Faculty often reject OA
based on a misunderstanding that OA provides a bypass for peer review. However, OA
is simply a mechanism through which content is prevented from being locked behind a
pay wall (Suber, 2012). Peer review is not a naturally occurring process, but a process
that is “mediated through a complex network of social relationships and interactions,
such that the outcome is, at least partly, the result of social negotiation” (G. Howard,
2012, p. 328). Movements like Free Software and OA force us to ask questions about
the nature of both publishers and scholarly societies, as both “have become large,
bureaucratic organizations sedimented in their modes of doing things, sometimes for
good reasons (stability, reliability), sometimes for bad (tradition, fear, self-interest)”
(Fitzpatrick, 2011, p. 184). These movements serve to remind us of the reasons these
organizations were created and the purposes they serve and can point to their
responsibility to the creation and dissemination of scholarship (Fitzpatrick, 2011).
Considering how boundaries are constructed around disciplines both inside and outside

96

the academy illuminates how the social and epistemic boundaries of scholarly disciplines
support the overall academic infrastructure. Arguments for and against OA often
conflate the social and technological infrastructures that make up the system of scholarly
communication. Evidence supports the idea that the social infrastructure is where the
arguments should rest.
Disciplines/social infrastructure
Departmental structures in American universities were created between 1890 and
1910 and have changed very little since their outset, even as “cultural structures - the
pattern of knowledge itself - has greatly shifted” (Abbott, 2001, p. 122). This
department-based structure was unique to American universities, though it eventually
spread to Europe and beyond. As Abbott (2001) notes, “academic disciplines in the
American sense—groups of professors with exchangeable credentials collected in strong
associations-did not really appear outside the United States until well into the postwar
period” (p.123). The focus on disciplinary departments has a tremendous influence on
faculty careers, faculty hiring, and the teaching of undergraduates (Abbott, 2001).
Trowler, Saunders, & Bamber (2012) provided a definition that includes both structural
and social components as comprising a discipline:
A discipline comprises a set of different but clear narratives about a field of
knowledge; its boundaries, procedures and purposes. These incorporate
relative consensuses about a disciplinary saga concerning key figures,
conflicts and achievements. Disciplines take organizational form, have

97

internal hierarchies and confer power differentially, to the advantage of a
minority (p. 9).
Considering faculty as social actors acknowledges that they have some agency to exert
influence on the systems in which they participate at the discipline level, while also
recognizing that organizational structures of the disciplines themselves can make those
changes difficult. There has been, over the course of many years, “a continual ebb and
flow of power and dialogue between the institution, individual, and stakeholder groups”
(Trowler et al., 2012, p. 258), leading to changes in various disciplines, including
communication, psychology, sociology and the sciences. What has not changed is the
structure of universities along disciplinary lines. American universities borrowed
somewhat from the hierarchical structures of German and French universities and
incorporated the Ph.D. degree from the German system, which was later “specialized
into a Ph.D. ‘in something’” (Abbott, 2001, p. 125). This created both a “medium of
exchange between particular subunits of different universities” and a “subsystem of
structures and exchanges organizing universities internally while providing for extensive
but structured career mobility” (Abbott, 2001, p. 125). Isomorphism crept into the
system, as organizational structures across different universities began to look similar,
and these disciplinary structures began to create more keenly structured career paths
based almost entirely on disciplines.
At around the time that universities became departmentalized, national
disciplinary societies formed, often by those outside of academia—although academics
eventually drew the boundaries around these societies to exclude those outside of the

98

academy (Abbott, 2001). Rumsey (2016) suggests that culture is memory formed
collectively, through which people “create a shared view of the past that unites us into
communities and allows large-scale cooperation among perfect strangers” (p.15), and
further describes it as the “collective wit by which we live” (Rumsey, 2016, p. 18).
Abbott (2001) proposes that the reason academic disciplines have persisted in spite of
shifts over the years lies in what he calls a “dual institutionalization” (p. 126).
Disciplines “constitute the macrostructure of the labor market for faculty” (Abbott, 2001,
p. 126) by supplying candidates for jobs and exchanging those jobs at national meetings.
Academic careers are generally tied much more closely to disciplines than they are to
universities. Disciplines are also microstructures at the university level with faculties
across the country sharing a fairly common departmental structure. All arts and sciences
faculties contain more or less the same list of departments. Deviating from this
disciplinary system can severely curtail employment prospects for Ph.D. graduates if
they do not clearly fit into a well-defined “disciplinary market” (Abbott, 2001, p. 126).
Pfeffer & Salancik (2003) propose considering boundary issues not from an individual
perspective, but as a set of “interlocked or coordinated behaviors” (p.32), whereby the
boundary between organization and environment becomes clearer—“the boundary is
where the discretion of the organization to control an activity is less than the discretion
of another organization or individual to control that activity” (Pfeffer & Salancik, 2003,
p. 32).
In addition to the impact on employment prospects, even the process of being
published in particular journals is discipline-centered, considering that the process of

99

peer review is centered not at the university level, but at the discipline level, generally
through scholarly societies. This process not only places an imprimatur on the work
itself but invites the author into a “restricted intellectual space” (Guédon, 2001, p. 17)
that indicates belonging to a social system. Guédon (2001) described the system of
scholarly communication as:
A dense web of institutional and individual hierarchic relationships thus
structures the scientific system and in order to appear in the best publication
spot, it is important to avoid “wrong” steps. Wrong here does not so much
mean “false” as tactical or strategic bad judgment: for example, throwing a
challenging gauntlet without ensuring a sufficient stock of symbolic and
institutional resources. In other words, simple caution dictates that
brilliance—assuming it is present—must be exercised within wellestablished boundaries rather than outside! (p. 17)
The royal academies, which predated scholarly societies, were the first to use peer
review as part of a state infrastructure to monitor which ideas were worthy or safe to be
released publicly. The advent of scholarly societies shifted this process away from statesanctioned forms of censorship into a self-monitored system “creating, in the
Foucauldian sense, a disciplinary technology, one that produces the conditions of
possibility for the academic disciplines that it authorizes” (Fitzpatrick, 2011, p. 21).
Peer review is the foundation of disciplinarity, and a mode that constricts, produces, and
constitutes “academic ways of knowing” (Fitzpatrick, 2011, p. 21). As Fitzpatrick (2011)
says of peer review:

100

…its roots in early modern book censorship are revealed by its continued
appeal to the imprimatur it grants. Peer review thus long pre-dates the
invention of the scholarly journal, originating with the formation of the royal
academies themselves. Membership in these societies required scientists to
demonstrate their bona fides in the form of publication, experimentation, or
invention in order to be eligible for election—arguably subjecting their work
to a form of peer review. Further, early scientists circulated letters among
their peers or read papers in society meetings, reporting the results of their
investigations with the explicit intention of eliciting response. The
application of peer-review processes to scientific journal publishing thus
becomes a further extension of society business (p.22).
Rumsey (2016) illustrates the impact of publication technology on doctrinal authority
and censure with the Catholic Church’s publication of indulgences and offering of an
opportunity for Martin Luther to publish an anti-indulgence message. The printing press
made it difficult for any single organization or individual to monopolize communication
distribution channels. Literate people figured out how to use presses to their personal
advantage in controlling messages.
University presses have a specific set of issues deriving from their relationships
with their institutions. Although presses are associated with institutions, presses operate
apart from them, running mostly independently as a not-for-profit, though they are
expected to act as revenue centers and recover costs through sales. When presses are
subsidized, the money they receive from their institution makes up a meager percentage

101

of the overall budget. The underlying assumption of the university press production
model is that their function should be driven by the market—leaving the press in a
conflicted situation. If the selectivity in publishing is based on profitability rather than
scholarly merit, it could mean that a press might be less focused on fulfilling its
scholarly mission if the press aims to turn a profit. If publication prices are increased,
then their customer base, which is almost entirely research and university libraries,
stands to shrink (Fitzpatrick, 2011).
The technological shift
Mosco (2004) proposes that if myths “evacuate politics” (p.31) from social
problems needing attention and reflection, then the critique of myth is the way to
demonstrate the occluded or disguised influence of politics in problem areas.
If the telling and retelling of the mythic story shields cyberspace from the
messiness of down-to-earth politics, then the critique of the myth, told many
times over in many different ways, gives new life to the view that
cyberspace is indeed a deeply political place. This happens when we expand
the assessment of myths to include not only whether they conform to and
agreed-upon reality. (Will the information highway expand education?) It
also involves assessing what myths mean to the people who produce and
believe in them, and what they reveal about the society that sustains them. It
is here, on the intellectual border, where cultural and political economic
understandings meet, that the analysis of myth becomes particularly
productive.

102

Scholarly publishing and librarianship serves as one of these boundary zones where
mythological thinking predominates decision-making about technological changes or
stasis. It is instructive to review the network environments of these organizations. Baym
(1995) notes that the technical infrastructures of computing networks can shape
interaction in three ways. The physical configuration of a network determines the
number of computers, the speed and geographical boundaries of the system.
Adaptability determines how flexible the system is, and user friendliness includes
flexibility, ability to multi-task, and generally how easy a system is to learn. Modifying
any of these can significantly change the potential communicative strategies for the users
of a system. In these systems, the fundamental element is the users. Any network that
includes the participation of people is not just a technological, but a social infrastructure
(Baym, 2010). Castells (2010) identifies the 1970s as the period when information
technologies became sufficiently diffused to create what he calls an “information
society.” Modes of development became more centered on information, and in these
information-centered modes, patterns of change do not progress in a linear fashion, but
appear more interspersed and spontaneous change, mimicking an evolutionary process.
Castells (2010) argues that out of this shift, a new capitalist form came about at the end
of the twentieth century that is global, flexible and provides a tension between global
networks. These global networks have arisen with individual identity, and with what he
called the “bipolar opposition of the Net and the Self" (p. 3). The Net refers to
organizational forms derived from extensive use of media, and the Self is tied to how
identities are formed in a time of constant structural change. These identities then lead

103

to new forms of social organization, and also to social fragmentation. Identities may be
drawn with ever-stricter boundaries, and it becomes more difficult for individuals to find
shared experiences.
In this condition of structural schizophrenia between function and meaning,
patterns of social communication become increasingly under stress. And
when communication breaks down, when it does not exist any longer, even
in the form of conflictual communication (as would be the case in social
struggles or political opposition), social groups and individuals become
alienated from each other, and see the other as a stranger, eventually as a
threat…The informational society, in its global manifestation, is also the
world of Aum Shinrikyo, of the American militia, of Islamic/Christian
theocratic ambitions, and of Hutu/Tutsi reciprocal genocide (Castells, 2010,
p. 3).
Research on the higher education environment suggest that technological changes to
communication can also put organizations in stressful states, and that identity politics is
not necessarily new to a digital age. For example, Becher & Trowler’s Academic Tribes
and Territories outlines how cultures within the academy (i.e., tribes) and knowledge
within disciplines (territories) are formed and reformed and always centered around
disciplinary identities, whether in content or methodology (Becher & Trowler, 2001).
And yet, because higher education contributes to the skill sets of symbolic
workers, its strategic importance in the economy and society grows. Shifts in occupation
over the years have led to an increase in professional and technical workers and fewer

104

skilled laborers. Status in society was traditionally achieved through inheritance and
entrepreneurship and was largely property-focused. However, there has been an
increasing shift toward education as a marker of status—driven partly by the greater
numbers of jobs requiring higher education. The percentage of people completing high
school grew from 41% in 1960 to 81% in 1996, and the number of college graduates
grew from 7.7% to 24% over the same period (Bell, 1999, p. xvi). The technologies
driving development today “form a complex adaptive system that is the foundation of
the electronically mediated global economy” (Bell, 1999, p. xvii). Industrial societies
operate on a labor theory of value by which industries exchange capital for labor, while
in a post-industrial society, knowledge-based innovation, becomes the basis for
increasing exchange values on information-based commodities (Bell, 1999).
Productivity and innovation, and the increased expectations for these, accelerated rapidly
around 1970; Castells (2010) attributes the acceleration to what he calls “virtuous
circles,” which are systems that evolve parts of their own networks.
Computers create more powerful computers, and as Castells (2010) argues,
efficiency in management systems during the 1980s worked by feeding back information
systems into managerial systems. This process has implications on the system of
knowledge creation and dissemination because in a post-industrial society, “technical
skill becomes the base of and education the mode of access to power; those (or the elite
of the group) who come to the fore in this fashion are the scientists” (Bell, 1999, p.358).
Similarly, Castells (2010) places higher education as integral to what he called “milieu
of innovation.” With federal research funding encouraging more specialization and the

105

ensuing commercialization of publishing, multinational conglomerates now control a
significant percentage of scholarly literature (Lyman & Chodorow, 1998).
Baym (2010) notes that there is a tendency to consider technologies in a
deterministic manner, frequently assuming that they can potentially damage
relationships, language, and communities, and replaces them with “shallow
substitutions” (p.150). A cheerier view, but just as technologically deterministic,
suggests that technology can avert harms or improve conditions—for example, with
larger networks, closer family connections, and a more engaged public. Baym (2010)
articulates a case for the social shaping of technology:
Yet people are adaptive, innovative, and influential in determining what
technology is and will become. We use technology to suit our own aims and
developers redesign and innovate to provide people with better ways to do
the things they didn’t expect us to do. Nowhere is this more obvious than
when looking at social and emotional expression. Rather than be stymied by
the lack of social cues inherent in text-only interaction, people innovated,
making use of punctuation, capitalization, verbalization, and other tools to
convey the social attitudes and feelings they wanted to impart. The internet
was never envisioned as an interpersonal medium. Based on sheer features,
at first blush it seemed poorly positioned to become one. But people took
advantage of the affordances it did offer to make it into a social resource.
Our drive to be social and find means of connecting with one another has

106

been a guiding force in the internet’s transformation from military and
scientific network to staple of everyday life (pp. 150–151).
These social relationships are integral to the concept of interconnectedness, as outlined
by Schement and Curtis (1995). Interconnectedness can be viewed in three dimensions.
At the micro level, it relates to changes in social relationships—while the number of
relationships increases, their depth decreases. Businesses and other organizations at the
meso level build new forms of communication to address environmental uncertainties
and create technologies to process information and improve decision-making. At the
macro level, new technologies and institutions appear to meet demand for connection on
a global scale. This “interconnectedness grows because social organization demands it
and technology allows it” (Schement & Curtis, 1995, p. 65). As Mosco (2004) argues, it
is important to be cognizant of the fact that most of the seductive power of technologies
is often intentionally constructed by the same companies that will benefit from its sale
(p. 41).
Scholars have indicated various reasons for the choices they make in deciding
who and what to cite in their work. Deciding factors include quality of the content itself,
familiarity with people or institutions, recognized journals, and the context of the
content—whether its published in a journal, presented at a conference, or posted on a
blog. Study of the content is important, but trust in a referring social connection reduces
the need to examine content closely. Also important is whether peers will consider
sources properly authoritative. When a source is not peer-reviewed, scholars are more
likely to spend time tracking its citations to ensure that it has been considered as worthy

107

scholarly research, and thus, reducing the likelihood of using misleading information
(Thornley et al., 2015). Fitzpatrick (2011) recommends exploring the nature of social
systems and the “structure of online texts” (p.107) as a worthwhile exercise not because
it will solve the problems of scholarly publishing, but because understanding the ways
that texts circulate within and give rise to communities will be a necessary component of
any successful electronic publishing venture” (p.107). Questioning whether publication
and credentialing should be as inextricably intertwined as they currently are, Fitzpatrick
(2011) notes that peer review might have a lot to learn from social systems like Slashdot
and Digg to become more “peer-to-peer review” (p. 32). Indications are that scholars
have been on this track for some time.
arXiv
In 1991, Paul Ginsparg launched arXiv in an effort to ease sharing of
unpublished manuscripts (preprints) between researchers. Originally designed to
alleviate the burden of printing, reproducing and sending preprints, often to a small
number of friends and colleagues, Ginsparg’s system allowed researchers and graduate
students from around the world to both post and read full-text preprints (Ginsparg,
2011). Preprints are not typically considered authoritative sources (Guédon, 2001), and
many argue that a lack of peer review can potentially lead to bad science spreading
throughout the system of scholarly communication (“The shackles of scientific
journals,” 2017). The National Institutes of Health (NIH) is currently considering
whether preprints should be considered as part of grant applications, with the central
concern that rigor and reproducibility would suffer—preprints only reflect initial

108

findings and have not been through the process of peer review (Krisch, 2017). The
resistance to preprints is one element keeping science chained to journal publication,
which also keeps academic research inaccessible to the public. The fact that arXiv has
operated for over 25 years and is still embraced by the scientific community indicates
that reliance on preprints can work to some degree (“The shackles of scientific journals,”
2017). In only two years the service become a primary resource for scientists globally,
and once researchers realized the service could be used to make claims of intellectual
precedence, the service has had sustained growth (Ginsparg, 2011). However, arXiv
serves only a few quantitative fields, including some in physics, mathematics, computer
science, quantitative biology, and quantitative finance (Davis, 2009). The system does
have methods to ensure the qualifications of its participants. Participants are required to
have endorsements to submit content, and, while some endorsements are granted based
on academic credentials and affiliations with research facilities or academic institutions,
many authors are required to get endorsed by authors who are already participants. To
endorse someone, endorsers must have themselves submitted a certain number of articles
within a subject area to the system. Although this does not constitute peer review, it
does serve as some measure of certification (“arXiv.org help - The arXiv endorsement
system,” n.d.). Work posted in the system can also bring recognition even when not
published elsewhere. Mathematician Grigori Perelman published a mathematical proof
only on arXiv and garnered both a Fields Medal and Millennium Prize (Krisch, 2017).

109

Social science research network
Started in 1994, Social Science Research Network (SSRN) was also designed as
a distribution system for social sciences research, including law, economics, accounting,
information systems and marketing. Like arXiv, SSRN is not a comprehensive
repository of scholarly literature in its subject areas, and does not subject submissions to
peer review, meaning that most of the literature consists of preprints and working papers
(O’Leary, 2006). Although it does not provide peer review, SSRN does use a
gatekeeping function—site administrators can make decisions about whether articles are
searchable through its search engine, arguably anathema to its representation as an open
access system (Kruger, 2013). SSRN’s quality control is based on its system of usage
tracking—they use the number of downloads to determine whether an article is of
importance to other researchers (O’Leary, 2006).
Mendeley
Mendeley is an online tool designed for citation management, but also as a social
network for scholars. Based on the model of Last.fm, which is a social network for
music enthusiasts, Mendeley allows researchers to manage work they are reading, to
manage work they are writing, and to find other researchers with similar interests.
Mendeley was created first to serve as a social network and a citation management
application, rather than as subject matter repository. Though it can be used to share
content between researchers with similar interests, connecting with other researchers is
more algorithm driven (Zaugg, West, Tateishi, & Randall, 2011). Like SSRN,

110

Mendeley’s quality control is based on readership and download counts (Fairclough &
Thelwall, 2015).
Institutional repositories
The first institutional repository (IR) in the US was created at The Massachusetts
Institute of Technology (MIT) in partnership with the Hewlett Packard Corporation in
2002. The DSpace IR system has served as a model and has been replicated across a
variety of other institutions since its inception (Lynch, 2003). Sometimes referred to as
digital repositories, IRs are databases that contain scholarly work and data produced by
faculty, students and staff at their associated institution (Dawson & Yang, 2016). Tools
exist to allow for redistribution of metadata, which is data that describes content, from
IRs to disciplinary repositories, such as arXiv and SSRN, making IRs a potential
infrastructure on which a broader network can be built (C. Lynch, 2003). IRs are open
access as a way to broadly disseminate and showcase their faculty’s scholarly work;
although IRs open contents are subject to challenges of copyright and ownership. At
many institutions, librarians do much of the work to ensure that copyright and ownership
issues are properly addressed, going so far as to create institutional-level agreements
faculty can use to negotiate with publishers, and waivers to be used when publishers are
not receptive (Dawson & Yang, 2016). Providing access to scholarship and data
produced by faculty is one way for more privileged institutions to improve visibility for
their scholarship, and it also allows for partnerships with less well-resourced colleagues
to gain access (Heller & Gaede, 2016). These new infrastructures, including the use of
open source software like Open Journal Systems (OJS), provide new opportunities in

111

scholarly publishing, though the economics are not yet mature. Streams of revenue are
limited due to the obedience to an open publishing model—these repositories do not
have subscriptions, which would help forecast income (B. Lynch, 2017). Yet, they
continue to grow. In December of 2016, OJS reached a new milestone of 10,000 active
journals around the world operating on their platform (Public Knowledge Project, 2016).
Commodifying the infrastructure
Leaving technical capabilities of the disciplinary systems aside, a key claim that
arXiv can make is that SSRN and Mendeley cannot is that it has not been bought by
Elsevier. The purchase of Mendeley puts Elsevier in a position to create a “vertically
integrated tool” (K. Anderson, 2013), and Elsevier noted in a press release that it “will
become Elsevier’s central workflow, collaboration, and networking platform, while we
continue on our mission of making science more open and collaborative” (Bonasio,
2013). Purchase of the system afforded Elsevier access to data on how researchers
collaborate and what they read and share (Lunden, 2013). The purchase of SSRN, which
Elsevier plans to merge with Mendeley, suggested that Elsevier understands that
copyright ownership of scholarly content may not shield them in a potentially open
access driven future. The CEO of SSRN, Gregory Jordan, noted that citation data from
Scopus in addition to Elsevier's broader collection of metrics and data analytics were
some of the key benefits of the deal, creating an end-to-end system through which
content can be published, disseminated and closely analyzed. An additional bonus for
Elsevier was that it will be much easier for users of the SSRN to find Elsevier content
(“Simba Information: Elsevier Doubles Down on Mendeley Strategy with SSRN

112

Acquisition,” 2016). In addition to buying these pre-existing networks, Elsevier sought
and was granted a patent for an online peer review system (Blumenstyk, 2016). As
noted by Harmon & Nazer (2016), Elsevier seemed to have realized that because they
may not be able to control content anymore, they will assert control over as many of the
infrastructures that support scholarly publishing as they can. This continues, as Elsevier
also acquired bepress, a company that provides IR software for universities, noting that
this will allow bepress to expand their product offering while “helping Elsevier drive
further adoption of its research management tools” (Elsevier, 2017). The parent
company of Elsevier has shown increased acquisition in mergers and acquisitions in
each decade since 1970, with a particularly prolific increase starting in 2000. Figure 9
provides a list of these.

113

Figure 9 lists acquisition activity of RELX group from 2000 to 2017. Data from Thomson Reuters (2017).

Elsevier has acquired companies that publish legal, scientific, educational,
business and medical information; companies that provided collaborative opportunities,
companies that provide analytics and data storage solutions; companies that allow for
management of research data; and a variety of companies that provide information
management in medicine-related fields, from diagnostics, drug information, nursing
education and predictive analytics to analyze health care claims. They have even
acquired a company that provides integrated library systems. Their expansion into the

114

medical arena suggests that their interest in controlling the flow of information
obviously extends beyond the academic enterprise into other professional domains.
Taylor & Francis, Sage, and Wiley-Blackwell have demonstrated similar acquisition and
merger trajectories, with an increase in such behavior since 2000. Elsevier is the most
prolific (Thomson Reuters, 2017a, 2017b, 2017c, 2017d). Libraries and researchers see
the ease of sharing content online as a solution to a problem while commercial scholarly
publishers consider it a problem (Fitzpatrick, 2011), unless they can profit from it. In
2002, the library staff at The California Institute of Technology (Caltech) worked to
publish the proceedings of an international conference online. Costs of this initial effort
(there was no pre-existing infrastructure) were estimated to be around $100 per article.
At the time, journal publishers estimated that a peer-reviewed paper cost around $1500
to produce (Douglas, 2002). Actual costs to libraries or faculty for open access journal
publication tend to range from $500 to over $3,000 (Watkinson, 2015).
The open question is how arXiv has managed not to be consumed by a
commercial scholarly publisher. The digital era has shown a striking increase in the
share of scholarly literature published by the top publishers and a much larger
dependence on those publishers by the scholarly community. The natural and medical
sciences have significantly larger scholarly societies, in part because their disciplines are
relatively larger as compared to the social sciences and humanities (SSH). The
American Physical Society (APS) and the American Chemical Society (ACS) were able
to publish print journals and manage transitions to digital publishing without significant
intervention from commercial publishers. The social sciences and humanities tend to be

115

more fragmented, with no umbrella organization to manage the myriad societies or
publish their respective journals. With a large number of subdisciplines further divided
into specialties, these disciplines lacked the means to adapt, and instead entered into
agreements with commercial entities, thus subverting the traditional scholarly
communication process (Larivière et al., 2015).
The influence of Connexions
The Connexions system is explicitly designed around social and communal
advantages of multiple people working together on creating textbooks. An added benefit
deliberately built into its infrastructure is the modularity of content. The creators of
Connexions had a desire to help students see connections across disciplinary
boundaries—connections between, for example, statistics and genetics, and intellectual
property law and engineering (Kelty, 2008). In the late twentieth century, pressure grew
within academia for faculty to work collaboratively across disciplinary boundaries as a
drive toward unity and synthesis. The blurring of genres and restructuring of knowledge
in its many forms is referred to as interdisciplinarity (Klein, 1990). Abbott (2001)
suggests that a particular kind of universal knowledge grows emerges as disciplines
struggle with defining their boundaries:
When there are many different epistemological routes to one place, people who
have taken them will "see" a different thing when they arrive. What is universal
about social science knowledge is the project of getting there and of mutually
decoding our routes. (p. 32)

116

Disciplines evolve through contrast and assimilation, splitting into subdivisions that
often grow into separate disciplines in the process. Specialization, while often denigrated
for creating fragmentation, is often a precursor to interdisciplinarity as a researcher in
one discipline approaches the boundary of another and opens relationships at the
intersections of the disciplines (Klein, 1990). Referring to the Free Software and Open
Source movements, Kelty (2008) indicates that they are not unlike social movements in
that their practices become the most important part of their organizing process, rather
than an ideology. This is the fundamental element that makes them a recursive public—
the concern with the material and practical means by which they organize their activities.
In scholarship, ideologies change over time, as does the focus of research.
Disciplines appear, disappear, and fragment. Even concepts addressed by disciplines
evolve. Terms, concepts, and methodologies in the discipline of communication have
seen significant changes over the course of its history (Gehrke & Keith, 2015). Abbott
(2001) explores changes in the discipline of sociology, noting that the discipline has seen
significant changes over its history in how culture is defined. Björk’s (2007) model of
the system of scientific communication points to something particularly interesting. The
very process of scientific communication was never really designed but has evolved; the
model addressed the process using a series of intricate flow diagrams that map the
activities of researchers, funders, publishers, libraries, bibliographic services, readers,
and practitioners, as a way to understand how the process of scientific communication
works (Figure 11).

117

Figure 10: Do research, communicate and apply the results diagram from Björk’s model of scientific
communication. Reprinted from Björk, 2007.

The emphasis is on traditional peer-reviewed journal articles, but it points to how these
processes have been affected little by shifts in technology. Another compelling aspect is
that even in its intricate detailing of the finer points of the system of scholarly
communication, it is a general model and discipline agnostic. Peer reviewing, seeking
research funding, writing, publishing, and other functions exist across the disciplines. It
is within the disciplines themselves that the boundaries of what qualifies as authoritative
knowledge is constituted. The foundation of the system is in its social infrastructures.
Fitzpatrick (2011) describes an experience using MediaCommons and
CommentPress as a personal experiment in publishing, explaining that publishing texts
online helped to facilitate discussions among motivated individuals, and to create a

118

different kind of social interconnectedness. Connexions is run by people who are
devoted to open systems and standards, and who are not interested in becoming a
profitable textbook publisher. Their concerns like in ensuring they create a useful
publishing infrastructure—the openness allows even for competitors to use the system
(Kelty, 2008). Scholarly societies and libraries are beginning to use avenues for
publication that lie outside of the commercial scholarly publishing enterprise and that are
designed to complement it with tools that are designed around norms of academic
practice. The Scholarly Publishing and Academic Resources Coalition (SPARC)
maintains a list of scholarly societies publishing open access journals. As of May 2017,
the list encompasses over a thousand journals (SPARC, 2017). BioOne is a SPARC
partner collaborating among scholarly societies. The BioOne initiative aggregates
journals from dozens of small bioscience-focused societies to make peer-reviewed
research accessible and allow the scientific societies to have a more cost-effective model
of publishing that will help them remain viable (Johnson, 2000).
Deetz (2008) points to the notion that engagement with outside communities
allows for organizing work around social needs rather than literatures and topics of
study. This type of engagement makes scholarship more like a conversation, but it may
put traditional conceptions of knowledge at risk because there is more opportunity for
the conversation to go in unexpected directions (Deetz, 2008). Systems like Connexions
may not drive collaboration and cooperation, but they are built on an expectation that
collaborative activity is already happening (Kelty, 2008). These new infrastructures can
provide opportunities to take advantage of both Open Source models of collaboration

119

and open access to content while avoiding current publishing infrastructures that drive
the commodification of academic work. As noted previously, it is increasingly common
for scholars to work across disciplinary boundaries. With a different infrastructure or
platform, these connections can be made more visible. Castells (2010) draws an
elaborate picture of a network society. Scholarship has long been a series of
interconnected networks. The people involved in the system, not the technology, created
these networks. The technologies are merely an affordance that allows for making more
and faster connections. Castells (2010) notes that virtual communities and physical
communities need not be set in opposition to one another but allow for a new context in
which to consider human identity—with the Internet being well-designed for
establishing weak ties. Developing a broad infrastructure for scholarly publishing could
prove to be a powerful connector. Commercial publishers understand the power of these
connections and are making inroads to control not just the content of the system of
scholarly communication, but control over the entire value chain.
Development of new technologies for scholarly publishing that provide
competition for commercial scholarly publishers, along with the increasingly acquisitive
behavior of the top five publishers, raises the question of how power is really distributed
in the system. Resource Dependence theory suggests that power accrues to people and
groups within organizations who best reduce uncertainties and address contingencies
that affect control of resources—these are the people who accrue the power to make
decisions on strategic endeavors. Distribution of power within the organization provides
the political context within which interdependence develops. Borgman (2000)

120

understands infrastructures as transparent parts of larger structures, technologies and
social orders. They are learned as part of belonging to a particular group, and they
embody the standards of that group, such that other tools can properly interconnect,
building on a base from which it inherits both strengths and weaknesses. This is most
evident, she notes, when they fail, as in when the power grid fails or a bridge collapses.
Reconsidering the boundaries of the scholarly communication system allows for
a different view of where the discretion to control activities in the system lies, and points
to the contradiction of the myth of influence. Commercial publishers have power over
universities and libraries because they own the content necessary for the operation of the
system of scholarly communication in which universities and libraries are embedded.
They own this content because scholars give this to them free of charge. The power they
do have exists because scholarly societies in many cases have given them control over
the journals in which scholars need to publish. Those journal titles only have any
authoritative power at the epistemic level—that is, they only retain their imprimatur of
authority insofar as the scholars that that publish in them allow them to do so. It is in
these social connections that the myth of influence resides. A powerful expression of this
is reflected in a study by Klein, Broadwell, Farb, & Grappone (2018), which compared
papers published in pre-print repositories to the final published counterparts. Their study
revealed that there was generally no appreciable difference between the two. With a
variety of new options available for publication, a shift is only necessary in the
imagination—a view of the system of scholarly communication as recursive public
allows for a broader conception of the system as a series of influencers working together

121

to create a record of scholarship, and it is less encumbered by ties to particular titles or
technologies. As Rossignoli & Ricciardi (2015) state, “no power relationship is forever,
especially if the stronger partner goes too far in abusing the weaker one” (p.33).
In this chapter, I explored how commercial scholarly publishers are increasingly
exerting control over scholarly publishing infrastructures and therefore, the social
infrastructures of the system of scholarly communication. I outlined a series of emergent
technologies that are currently operating in the system and suggest that influence in the
system is centered in social relationships at the discipline level. In Chapter IV, I will
explore the myth of permanence, which I will argue, is invoked silently or subtly to tie
collection and preservation practice to libraries. The myth of permanence pertains not
only to the content and infrastructure of the system of scholarly communication, but also
to the context of the information in that system.

122

CHAPTER V
THE WIDENING GYRE – THE MYTH OF PERMANENCE
In this chapter, I will outline a response to the question, “how have traditional
processes in the creation of scholarship taken on mythic properties that influence usage
of the digital environment and access to research materials?” I will articulate the third of
three overarching myths with which I began, the myth of permanence. Stated simply,
this myth operates to oversimplify tensions inherent in the practice of collection,
dissemination and preservation of scholarly work. I will argue that this myth manifests
itself largely in how libraries collect, disseminate and preserve content in the digital age
and how commercial scholarly publishers and other commercial entities place pressures
on libraries. Technology has created an epistemic shift in the way that information is
categorized and disseminated, and arguments for and against technological change
within academic circles are embedded in this myth of permanence, which is based not
just on content and infrastructure, but on the marriage of the two: context. According to
Mosco (2004), myths prove powerful because they provide meaning for our lives,
gratifying conclusions, and templates through which reality may be interpreted. Myths
concerning the internet, in particular, tend to be powerful because they fulfill these
characteristics. The stories suggest that communication technologies will become better,
less expensive, and faster. Furthermore, the myths imply that technology will help
realize democratic dreams by providing empowering tools equally to everyone. As
Mosco (2004) phrased it, it is possible to realize “the perennial dream of philosophers
and librarians: to make possible instant access to the world's store of information without

123

requiring the time, energy and money to physically go where the information is stored”
(p.30).
In response to a 1997 plan by the British Library to discard what remained of
their collection of foreign newspapers, Nicholson Baker founded the American
Newspaper Repository to save the newspapers from destruction. In 2001, Baker’s
Double Fold: Libraries and the Assault on Paper was published, and its publication set
off a response from librarians that would nearly singlehandedly create a brand-new
subset of the library literature. Although Baker comprehensively researches the book, he
concedes that it is an activist treatise, and criticizes traditional library preservation
practices. For example, the activist sentiment is evident in chapter titles like
“Destroying to Preserve,” “Slash and Burn,” “The Road to Avernus,” and “Thugs and
Pansies” (Baker, 2001). Baker (2004) and his critics agree that preserving the cultural
and intellectual record is an integral part of the library mission but disagreed on how to
do so and the general scope of that responsibility. The reality of collection and
preservation policies is complicated (Plutchak, 2014). The environment in which
libraries operate today is populated with material and immaterial catalogs, sourced from
university publishers, commercial publishers, OA publishers, predatory publishers, a
wide variety of technology vendors, emerging dissemination and publishing
technologies, a variety of consortia, and various other digital intermediaries. Considering
how to reframe the work of libraries in an increasingly digital world is particularly
challenging, because the word library means different things to different people. It is a
word and an institution tangled up in stereotypes and the deeply ingrained notion that

124

libraries are warehouses for books. As such, library is something of a “self-referential
metaphor” (Stoddart, 2013). A variety of metaphors are used from within libraries in
attempts to communicate their value, including words like digital, place, conversation,
storehouses, partners, and various body parts including heart, feet, muscle, and
circulation system (Giesecke, 2010). Giesecke (2010) notes that library as ecosystem is a
set of metaphors that is useful in framing the work of today’s research libraries,
emphasizing the various species that make up the system and the importance of
relationships in the system—framing the library essentially as that system of
relationships. Libraries have historically served as cultural intermediaries, regardless of
the form of their contents. The idea of permanence of a cultural or scholarly record
looms large over library practice and the public imagination now as it has throughout the
history of libraries.
History of libraries/collection practices
Collections in early libraries were not constructed in the same manner as
collections today. They typically grew out of the needs of a particular regime and
ceased to exist when that regime collapsed or fell out of favor. Greece and Rome would
later bring libraries that broadened their collection principles, but early libraries in the
Near East were some of the first to use procedures that are still fundamental to library
practice today (Casson, 2001). Perhaps the most famously mythological of the ancient
libraries is the Library of Alexandria, founded in approximately 300 BCE. Alexandria,
while ancient, was meant as a universal library, although it was preceded by others.
Clay tablets found at an archaeological site in Syria point to the existence of a library in

125

the royal palace of ancient Elba around 2300 BCE. The first library catalog may have
been discovered at Nippur and was dated at approximately 2000 BCE. Tiglath-Pileser I,
ruler of Assyria in twelfth century BCE, is the first documented founder of a library
(Casson, 2001). Assyria also lays claim to the next founder, King Ashurbanipal, whose
library was larger than any before it, and any other that would follow for about three
centuries. King Ashurbanipal held the Assyrian throne from 668 to 627 BCE and was
an avid collector. In his palace ruins, archaeologists found texts including the Epic of
Gilgamesh, the Epic of Creation and variety of other Near Eastern literature that are
available today (Casson, 2001). These collections not only provided a degree of power
for their owners, but they also contributed to the myth of permanence by sustaining
records of history, literature and scholarship.
The Ptolemies founded the ancient Library of Alexandria with the intention to
bring together far more comprehensive collections than in other earlier libraries. This is
not to suggest the Ptolemies were not striving for similar ends—something of a
monopoly on knowledge. They invited scholars to live and work at this famed
institution, copying and often confiscating and confiscated books from visitors-even
going so far as to ban the export of papyrus in a strategic competitive move to maintain
supremacy over the libraries at Rhodes and Pergamum. Ironically, this drove the
creation of parchment by the Pergamenes, which, for more than a thousand years after,
was the writing medium of choice throughout Europe (Battles, 2003). While
Ashurbanipal, Aristotle, and others were known for their extensive libraries and
collected for personal ends, Alexandria was the first library to aim for a comprehensive

126

collection of knowledge. Generous funding provided to scholars by the Ptolemies, drew
intellectuals from around the world (Battles, 2003). This rapacious approach to
collections at Alexandria placed a high value on knowledge as an asset of the empire.
The goal was to hold everything “from the authoritative manuscripts of the Iliad and
Hesiod’s Works and Days to the most obscure lists of secondary and fallacious
commentaries on Homer, the works pointing out their misattribution, and the works
refuting those works” (O’Donnell, 1998, p. 30). This quest to accumulate and centralize
all published knowledge created the risk of its total loss. As O’Donnell (1998) noted,
“great libraries are problematic in times of war, disaster, or decay, for their fate becomes
the fate of the literatures they contain” (p. 31). Much of what survived through antiquity
did so because small, private libraries were not subject to the same level of decimation
during times of war and civil unrest. “Above all, it is this last point—the needs and
tastes of private readers and collectors—that determines what survives.” (O’Donnell,
1998, p. 31). The idea that the Ptolemies saw the library as “a universal repository
devoted to the preservation of liberal learning” may serve as salve in times when the
reputation of libraries is on the wane, but history demonstrates that “libraries are as
much about losing the truth—satisfying the inner barbarians of princes, presidents and
pretenders—as about discovering it.” (O’Donnell, 1998, p. 31).
Cooperation in collecting, sharing, and disseminating library materials is a
thoroughly modern construction. As libraries throughout history have created
collections based on the whims of kings and the desire to control knowledge, among
private collectors, there has often been a performativity to creating libraries (Battles,

127

2003). Two developments are potential keys to values that modern librarians esteem.
First, books became commercially available, allowing for the creation of large private
collections, which are considered a precursor to the public library at Alexandria.
Second, the Athenian government passed a decree that there should be some central
repository of trustworthy copies of books (Casson, 2001). Throughout much of history,
even with major disruptions along the way, the producers of texts continued to be
patricians and members of the clergy. The idealized version of the library as a bastion of
all-inclusive knowledge has persevered, though any single collection will fall short of
perfection in this regard. While the dream evades reality, it is powerful, and this dream
of a “virtual library” continues (O’Donnell, 1998, p. 39). Before the existence of the
Internet, mass distribution and production of texts were the dominion of institutions—
this power is now available to the individual (Gillespie, 2007).
Before the 1920s, universities tended to have decentralized departmental
libraries. These departmental libraries began to disappear due to a new drive towards
efficiency. The libraries built between the World Wars were more centralized, and as a
result, faculty were further removed from their role in collection development and were
forced to change their research behavior. Specialized reference works and departmental
libraries may be limited in scope, but they are “highly ordered and highly particular,” (A.
Abbott, 2008a, p. 18), and although librarians pushed for more generalized indexes,
“research scholars always want partial indexes, indexes slanted their way, organized by
their way of seeing the world, not by a generic view from nowhere” (A. Abbott, 2008a,

128

p. 18). Systems of classification allow particular areas of practice to remember only
what they need to know. These systems are not, however, simple to create:
All classification systems, however, face a bootstrapping problem. In a world of
imperfect knowledge, any classificatory principle might be good, valid, useful;
you will not know what makes a difference until you have built up a body of
knowledge that relies, for its units of data, on the classification scheme that you
have not yet developed. (Bowker & Star, 2000, p. 276).
Classifications simplify. They tell you “what to forget and how to forget it” (Bowker &
Star, 2000, p. 278). The sciences, for example, do not deal much with their social
history. Those stories are left to historians in a “form of erasure” (Bowker & Star, 2000,
p. 278). They create hierarchies of knowledge, such that certain disciplines in the
sciences need only focus on a particular set of information, like geography or particle
physics. They also allow for hierarchies distributed across temporal planes:
It also operates a distribution in time, saying that all scientific problems can be
progressively unfolded so that at one point along the path in treating a problem
you will need to draw on biology, then chemistry, then physics, then
mathematics. Each type of memory that has been distributed in space will also be
sequenced in time. (Bowker & Star, 2000).
In this way, they also allow for some things to be left behind once they are no longer
useful to current inquiry.
Abbott (2008a) proposes that problems of information overload were in place
long before the Internet, and he points to the growth of the academic population since

129

the 1920s, and to another key suspect: librarians. Librarians in his view focus too much
on indexes to guide research and too much on making “the library a universal
identification, location, and access machine” (p. 25). The digital world of information is
simply an extension of issues scholars in the humanities and social sciences have long
railed against about libraries. An investigation of humanities and social science graduate
students and faculty in the 1950s pointed to the fact that they did not tend to use the
indexes and various sophisticated tools built for them by librarians. They mostly simply
browsed the stacks, reading one book after another, selecting those they deemed useful
along the way. Faculty and graduate students created bibliographies based on what
others told them to read and on the reference lists of others, which were more selective
than general bibliographic indexes (Abbott, 2008a). Librarians may have in fact been
creating similar problems that arise from algorithmic indexing through their own
indexing practice before the Internet came along. Google’s ambition is to make
information accessible universally, but through customizing algorithms Google
contributes to “reinforce the fragmentary state of knowledge that has marked global
consciousness for centuries” (Vaidhyanathan, 2011, p. 138). Accessibility may be a
noble goal, and central to the value system of librarians as well, but when users
potentially miss critical information based on their past searches, personal interests, or
even geography, the algorithmically derived list of results “fractures a sense of common
knowledge or common priorities rather than enhances it” (Vaidhyanathan, 2011, p. 139).
When scholars do research online, citation behavior changes and they are “more likely to
echo a prevailing consensus and to narrow the intellectual foundation on which their

130

research lies” (Vaidhyanathan, 2011, p. 193). For the broader audience, the implications
of this “filter bubble,” as it is named by Pariser (2011) are expansive; for example,
algorithms in Google can track behavior, make assumptions about what users do and do
not like, and present them with information that keeps them in a loop of similar
information. They do not encourage exploration of new ideas, and they do not give us
any idea of what users might be missing. Vaidhyanathan (2011) points out that the
problem here is not necessarily with Google; people are the bigger problem for relying
on it too much, without any real knowledge of how the system works.
Borges (2014) imagines a godlike librarian who holds the key to the mysteries
held within the walls of his fictional library of Babel. Historically, the real-life keys
have been paper indexes that outlined a canon or the list of things that ought to be read
for a discipline or an area within a discipline. The shift to algorithms has changed this
dramatically. Rather than starting with a core group of readings, or canon, from which
one can branch out, the digital brings forth a deluge of information, leaving it to the
searcher to sort out. Moreover, there are no mechanisms built in to point to that canon.
Librarians’ training today includes far less experience with the paper indexes, which are
seen as obsolete. Beyond even the database, libraries are tending toward aggregating
systems that bring information from databases all together in one set of search results,
much like Google—the only difference is that these systems are not attempting to learn
from your past behavior. Tracking user behavior is in direct violation of standard library
ethics (Gorman, 2000). The volume of information in an information society creates a
problem in itself. Bell (1999) argued that, in the information society, the volume of

131

information that individuals must consume and attend to leads to a different kind of
scarcity. Previous theory indicated that individuals had a complete set of information
with which to make decisions. As Bell (1999) argues, “more information is not
complete information; if anything, it makes information more and more incomplete” (p.
467). In a digital environment, the index is no longer defined or outlined by scholars in
a discipline or by librarians, but by algorithms. Filters are a natural part of both library
collections and algorithms. The fictional Library of Babel may contain all the
knowledge in the world, but it is incomprehensible without someone to provide context.
There is one thing that numbers and computers cannot do, but people can “recognize
implied context” (Gradmann, 2012, p. 17). Through indexing and categorization,
librarians contextualize the research process. Through collection and preservation, they
provide one of the foundations for the research process. Rapidly changing technology in
a digital environment has profound effects on practices of preservation and
dissemination. Preservation is a means by which to ensure that documented information
will remain for others to use, but without proper context, information can get lost. As the
information landscape has become increasingly digitized, the environment in which
libraries operate has become significantly more complex, requiring libraries to change
longstanding practice, enter into partnerships with new kinds of organizations, and
generally reconsider the role of their organizations.

132

Changing organizational environments
At the university level, attempts at creating efficiency have included the
convergence of information technology (IT) departments and libraries. These mergers
were first considered in the 1970s. In the 1990s, administrators took the reins and
moved forward with mergers of libraries and IT departments to increase efficiency.
These mergers seemed an obvious solution, since libraries are often the innovators of
technology use on university campuses because they implement discovery and access
technology (Quinlan & McHarg, 2012). In many cases, library directors were chosen to
lead the consolidated organizations, which required additional staff to fill gaps in
knowledge and skill. Those who continue to argue for these mergers suggest that they
not only offer cost-savings, but also serve to explore new ways of spending time and
energy delivering services (Joint, 2011). Detractors of merger practices point to the
disparate missions of the organizations; for example, libraries deliver information and IT
departments support systems and the infrastructure that libraries use to deliver that
information (Massis, 2011). Some models have gone so far as to merge additional
groups such as academic computing services—departments that provide technological
support to faculty research—under an umbrella organization that reports to a chief
information officer (Massis, 2011). Although all of these groups depend heavily on
technology, libraries tend to see technology as a means to an end, and it is not
uncommon for computer specialists to see the development of technology as “the means
and the end” (Quinlan & McHarg, 2012, p. 148). In many institutions, particularly those
that included academic computing services, researchers who were increasingly

133

experimenting with technology looked to these combined organizations for support and
found that their needs were prioritized alongside projects that were essential to the
functions of the university (Quinlan & McHarg, 2012). Some universities later
decoupled the organizations and returned the departments to their independent status.
Those that remained consolidated have determined how to use the individual strengths of
each department without unintentionally erasing what makes them distinct (Massis,
2011). Even within independent libraries, organizational structures have shifted from
collections operations to more process focused operations that are structured around
departments. These department-centered structures are more geared to innovation, as
libraries attempt to lead in practices of research, teaching, and learning as they also look
to support strategic initiatives at the university level (Schonfeld, 2016).
The American Library Association pioneered collaboration among libraries. The
collaboration efforts began in 1876 with the creation of the committee on cooperation in
indexing; this was followed in 1913 by cataloguing college libraries and the shared
acquisition of collections, and, in 1917, with interlibrary loan (ILL). National and
regional catalogs were common by World War II, and library consortia reached their
pinnacle in the 1970s (Horton, 2015). Consortia vary in both geographic makeup, size,
and service offerings. A 2012 survey indicated that there were more than 200 operating
consortia in the United States, the membership of which included over 18,000 libraries
with an average budget of $2.9 million, and an aggregate budget of over $170 million.
The main services provided by these consortia are resource sharing and ILL,
communication, professional development, and continuing education, consulting and

134

technical assistance, and cooperative purchasing of databases. Additional services
provided by consortia include shared catalogs, technical support, advocacy, courier
services, and digitization (Horton, 2015). Examples of large consortia include OCLC,
The Digital Public Library of America (DPLA) and LYRASIS. OCLC is an
international consortium with a membership that includes 23,000 libraries, archives, and
museums across 170 countries, and was initially started in 1967 to provide new
technology to help libraries with cost-savings improved services through shared
cataloging. The OCLC network connects libraries across the world to help in sharing
resources and ensuring access to knowledge. The DPLA was founded in 2013 as a step
toward building America’s premier digital library. Initially created with grant funding
and participation by member libraries, it has also provided funding to other consortia and
institutions to expand access to digital content. LYRASIS is broad geographically and is
the host organization for The International Coalition of Library Consortia. LYRASIS
works across a variety of consortia, typically working through state agencies as their
agent for licensing, and, in some cases, working to create inter-consortia licensing.
LYRASIS is also an agent for the OA movement, working on projects like the
Sponsoring Consortium for Open Access Publishing in Particle Physics (SCOAP3).
SCOAP3 is geared toward moving journals in the field of high-energy physics to an OA
model (Pronevitz, 2015). So far, I have explored changing collection and preservation
practice, changes in information finding behavior and a variety of consortia and other
emerging forms of organization that are creating new challenges for libraries. Next, I

135

will explore trends in economics that create strain on library budgets and examine two
lawsuits brought by publishers that call library practice into question.
Changing economics
The promise of widespread digitization was that information would be cheaper in
a digital environment, but for libraries, the converse has been true. For example, the
print version of the ACCRA Cost of Living Index cost $165 per year. The print version
was discontinued in October of 2014, and the electronic-only version, which does
provide access to previous years’ content, costs $12,700 per year. AGROW World Crop
Protection News cost $3,300 for the print version, which was also discontinued in
October of 2014. The electronic-only version costs $20,000 per year (M. Royse,
personal communication, November 7, 2014). To fight rising costs of electronic-only
versions, libraries have sought ways to achieve economies of scale. These economies of
scale are a central reason for cooperation among libraries. DPLA would not exist
without the collaboration of library consortia, and Big Deal packages allow for consortia
to negotiate significant savings on scholarly journals, thus, allowing broader access
(Horton, 2015). Frazier (2005) describes Big Deals thusly:
A Big Deal is a comprehensive licensing agreement in which a library or library
consortium agrees to buy electronic access to all or a large portion of a
publisher’s journals for a cost based on expenditures for journals already
subscribed to by the institution(s) plus an access fee. Multi-year Big Deal
agreements typically limit the ability of the library to eliminate subscriptions or
reduce expenditures to the publisher while specifying an annual price increase

136

that is less than the price increases that would apply if the library continued to
purchase the individual journals. (p. 50)
A Big Deal is not a database that includes journal articles, but a collection of serials
much like ScienceDirect from Elsevier or Preferred License from Wiley. As Frazier
(2005) notes, the difference is critical because serial holdings are supplemented by
databases, but a big deal changes the meaning of ownership of journals altogether
(Frazier, 2005). One of the changes that technology has brought to libraries is a shift
from ownership to licensing of content. LYRASIS, the Center for Research Libraries,
and other consortia work to help consortia with issues of licensing. The assistance is
needed because there is significant expertise required to manage the process. The
necessary expertise is not just for negotiating prices and managing the licenses, but also
in understanding legal terminology in the agreements, and ensuring compatibility with
the technologies used by libraries for access and use terms as outlined in the agreements.
Some terms make it difficult for libraries to take advantage of their paid-for content,
sometimes restricting access to walk-in users, preventing users from saving personal
copies of PDFs, and restrictions on the libraries’ participation in ILL (Anderson, 2016).
Libraries are creating new methods to make the licensing process less burdensome
because the process of ensuring that contracts complied with fiscal policies and state and
federal laws was creating delays in the process of renewing electronic resources. The
use of master agreements at the University of Tennessee are one example of these new
methods. That libraries are required to coordinate with a contracts office and general
counsel to ensure that lending practices do not run afoul of publisher agreements is an

137

added operational burden (Halaychik, 2015). Restrictions on use of content can pose
challenges for longstanding library practices, and publishers have demonstrated they are
willing to go to court over these issues.
A fair use case brought by three publishers demonstrates that library practice in a
print environment does not translate well to a digital environment, from a legal
standpoint. In April 2008, Oxford University Press, in concert with Cambridge
University Press and SAGE Publications, filed a lawsuit against four individuals at
Georgia State University. In the lawsuit, the publishers alleged that more than 6,700
works were made available through online systems (e-reserves) without permission, as
part of "systematic, widespread, and unauthorized copying and distribution of a vast
amount of copyrighted works” (Albanese, 2010). Two novelties of the suit were that the
lead defendants in the case are not large commercial publishers but university presses,
which purportedly have a mission to serve higher education much like libraries.
Furthermore, the suit skirted the state sovereign immunity doctrine that prevents states
from prosecution in federal court by naming individuals at Georgia State. Rather than
suing the state university system, the suit named President Carl Patton, Provost Ron
Henry and Librarian Charlene Hurt as defendants (Albanese, 2010). For many years
these university presses were shielded from market forces due to their relationships with
universities; however, university presses are now in commercial relationships with the
universities that they must rely on (K. L. Smith et al., 2011). In the initial ruling, Judge
Evans determined based on a four-point test that the use of the materials was fair use, but
only on two of the points. Whether the work was for educational use and subject to

138

copyright favored the university; however, the effect on the value of the works and the
volume used favored the publishers. In the final analysis, the judge outlined a 10% rule
for the volume of work that could be used, therefore ruling in favor of Georgia State
(Fister, 2016). The publishers asked for an injunction that would allow professors to
distribute only 1,000 words per document without asking for permission or providing
payment, which would greatly restrict longstanding academic practice and render fair
use irrelevant (K. L. Smith et al., 2011).
With a transition to electronic systems, faculty are more often providing students
with readings directly rather than putting them on reserve in the library, where librarians
are generally aware of the four-point rule as outlined in the Copyright Act, which
provides a way to determine whether something is fair use. These four factors are the
character of the use (what is being done with the material?), the nature of the work (is it
creative or factual?), the amount taken, and the effect on the market value of the original
work (Aufderheide & Jaszi, 2015). As Fister (2016) notes,
I also suspect that faculty are for the most part less well-informed about applying
the four-factor test to determine whether a specific use is legal or not. They may
also give less of a damn. When you think the purpose of publishing scholarship is
to share knowledge, and when in your experience money from sales doesn’t play
much of a motivating role in their contribution to the progress of science and the
useful arts, copyright can seem like arcane red tape that doesn’t, somehow, apply
when you want to share an article or a few pages of a book with students. (Fister,
2016).

139

The publishers appealed the 2012 decision, and the Eleventh Circuit Court of Appeals
vacated the initial decision, sending the case back with notes on how to adjust the
analysis of fair use. The Court of Appeals, like Judge Evans, rejected arguments by the
publishers on broader principles. Applying the new fair use analysis, Judge Evans again
ruled against the publishers (K. Smith, 2016). The status quo of the scholarly
communication system, which is currently intertwined with commercial publishers,
relies on these flaws being invisible to faculty either through ignorance or apathy (K. L.
Smith et al., 2011). Of critical importance is that Judge Evans’ analysis has
demonstrated that “licensing income for the publishers narrows the scope for fair use by
libraries.” (Smith, 2016). Fair use is a bedrock principle of much of the work that
libraries do, and continued assault on this notion brings much of the enterprise into
question, particularly since content is much simpler to share in digital form.
Less important than the increasing costs of journal subscriptions is the fact that
many of the journals bundled into Big Deal purchases are of questionable value. Big
Deal may save money relative to the cost of buying individual journal subscriptions, but
there is no fundamental difference between commercial journals and not-for-profit
journals that justifies the significantly higher cost of commercial journals. The only
explanation for the high costs is that librarians have been willing to pay them (Frazier,
2005). Odlyzko (2015) argues that decreasing library budgets relative to overall
university budgets indicate that the importance of libraries to universities is in decline,
while scholarly publishers have maintained their importance by maintaining control of
the resources. There is a notable difference in cost between commercial journals and

140

not-for-profit journals produced by scholarly societies. The cost of commercial journals
on a cost-per-page basis can be 100 times higher than that of the least expensive
journals, and cost-per-use is comparably striking. For example, journals from the
American Chemical Society are five to ten times cheaper on a cost-per-use basis than
some produced by commercial scholarly publishers (Frazier, 2005). Odlyzko (2015)
estimates that Elsevier’s revenues per article are around $5,000, which is similar to
revenue generated by scholarly societies, such as the American Mathematical Society,
which he determined can bring in about $5,400 per article.
There are costs associated with running a preprint server like arXiv; however,
most of the work is done by unpaid volunteers contributing user generated content, and
the average costs of running the server are about $10 per article submitted (Odlyzko,
2015). Around 5,000 journals are accounted for in all of the Big Deals, but they tend to
be the higher cost journals. The other scholarly literature not included in the Big Deal
should also be collected, organized and preserved, but Big Deal purchases take up a
disproportionate amount of financial resources. At the University of WisconsinMadison, Elsevier journals make up less than 1% of serial holdings, but Elsevier
accounts for 15% of serial expenditures (Frazier, 2005). Consortia models, Odlyzko
(2015) argues, should be used to broker national deals for electronic content, which is a
prospect supporting publishers to marginalize libraries in favor of publishers’ proprietary
delivery systems (Odlyzko, 2015). Consortia deals create their own set of issues,
however, since money directed at those deals means less money for localized collection
development (Ivins, 2005). Books and journals are in some cases being shifted to off-

141

site warehouses, users are relying on electronic resources, and libraries are seen by some
as less efficient at providing access to content than publishers are (Odlyzko, 2015). This
leads to suggestions that shutting down libraries is a desirable solution to a myriad of
problems including access to content for researchers and strained budgets for libraries.
In 2017, Louisiana State University (LSU) sued Elsevier for breach of contract
after Elsevier cut off access to content for its School of Veterinary Medicine Library.
After determining that the approximately 600 faculty and student users would fall under
the 35,000-user limit imposed by the agreement signed by the main university library,
the school decided to let the separate contract through the School of Veterinary Medicine
Library expire. Elsevier subsequently blocked access to content for users at that library.
In ongoing discussions, Elsevier has, citing Louisiana’s long-arm statute, refused to
accept service of the suit, instead suggesting a commercial solution, in which LSU
would pay approximately $200,000 for additional subscriptions for 2017 (Albanese,
2017). This case highlights a key point in the changing nature of the scholarly publishing
environment. Since libraries do not purchase, but only license content from publishers,
users of the library do not get content from libraries as much as they get content through
libraries. This change in the nature of ownership is what opens space for arguments that
libraries are unnecessary in the age of the internet—the library no longer serves the same
gatekeeping function.
Digital intermediaries
The technological environment in which libraries work continues to get more
convoluted. Libraries use integrated library systems (ILS) to manage their catalogs, link

142

resolvers to ensure searches take users to the full text of content from a variety of
databases, LibGuides designed by librarians for specific subject areas or types of
content, and even resource management systems for electronic resources. It is no easy
task to ensure that all of these systems work together. Technical access often requires
working closely with publishers to ensure access to content (Anderson, 2016).
Collections are increasingly geared toward electronic content, and many libraries are
migrating away from ILS products that are print-focused and toward platforms that can
manage both electronic and print. Additionally, there is a shift toward hosted services,
which provide libraries relief from expenses incurred with the management of local
software and hardware, and vendors of such services new forms of revenue (Breeding,
2015). Discovery services are beginning to replace more traditional catalogs. These
services, while not yet comprehensive, are designed to uncover resources from various
systems like IRs, databases, and other sources through a single interface by creating a
unified index, allowing users to limit results with faceted navigation (Burke &
Tumbleson, 2016). Competitive distinctions among discovery services concern the
quality of the indexes. The two most common services are Summon and Primo, with
Summon widely considered among libraries as having a superior index. Primo, until
recently, had touted its content-neutral stance because Ex Libris, the company that owns
this service, is focused entirely on library technology (Tay, 2017). Transitions
throughout 2015 consolidated power in a smaller number of large companies. In 2015,
Ex Libris was acquired by ProQuest, a company that had been less competitive in the
technology arena but offered a wide range of content and workflow products. The

143

majority of the company is owned by Cambridge Information Group, while Goldman
Sachs holds minority equity (Breeding, 2016). Longstanding library practices are being
called into question, costs to acquire (or license) materials is increasing, and technology
trends indicate a move away from traditional information categorization and
dissemination. Libraries are also developing technologies on their own.
Libraries continue to develop open-source systems for repositories (DSpace,
Fedora, and Hydra are examples), and for discovery interfaces (VuFind and Blacklight),
but the implementation of these systems requires that the systems are aligned with the
needs of and resources available to libraries considering their adoption. With an
increasingly consolidated technology sector, libraries have fewer options available to
them (Breeding, 2016). New technology is one factor that makes libraries increasingly
difficult to manage as organizations but increasing use of technology also has
implications for finding information. Google, Microsoft, and others provide search
engines for free, and, thanks to the desire for convenient access to information, many
researchers turn to these engines when doing research, and libraries can no longer count
on students and faculty using tools provided by the library (Burke & Tumbleson, 2016).
While these search engines seem easier to use, their complexity lies beneath the surface
in personalized algorithms, and people are increasingly relying on these personalized
tools, including Facebook and other social media, for getting their news (Pariser, 2011).
Researchers often consider discovery channels offered by libraries limiting, with faculty
as well as students turning toward free search engines. Additionally, publishers are
providing metadata to companies like Google so that scholarly information can be

144

discovered through their service, Google Scholar. Biases built into search tools were
found as part of the Discovery Tools Project which heavily influenced the kinds of
information that students chose (Burke & Tumbleson, 2016). Additional results indicate
that students tend to rely on nonacademic resources through the Internet and Google for
most of their research and are happy to find information that is “good enough,” (p. 199)
because there is a gap in understanding what are considered valid resources for academic
research (Badke, 2015). Badke (2015) notes:
The main problem here is that students, lacking deep content knowledge, are
unlikely to choose well even if they know the best criteria to use and are well
motivated. Sadly, for the majority of students, neither knowledge of criteria nor
motivation to spend time evaluating is a prominent factor in their research. (p.
205)
Because they lack the in-depth content knowledge of faculty, students rely more often on
relevancy rankings and do not look past the first page of search results. Students also
tend to use the sources themselves with not much care, as studies indicate that,
regardless of source length, three-fourths of their citations point to the first three pages
of the source material (Burke & Tumbleson, 2016). Pariser (2011) remarks that
computers are progressively becoming more like a “one-way mirror, reflecting your
interests while algorithmic observers watch what you click” (p.3). Libraries, too, are
beginning to analyze user behavior to provide suggestions based on catalog holdings
(Pennell & Sexton, 2010), and are replacing federated search with discovery systems
that provide a Google-like single point of departure for identifying library holdings,

145

based on a user desire to search everything at once through an intuitive interface (Burk&
Tumbleson, 2016). Librarians have long taken on the position of guarding the right of
individuals to information. These values need to be carried with us into the digital realm,
particularly as libraries work to ensure that information is seen within its proper context,
and that the divide between "haves" and "have-nots" is as small as possible. Far more
than buildings containing collections of books, libraries have both service and ethical
traditions that are crucial to their functions. Any digital environment that is constructed
may not be sustainable until these traditions are incorporated into its essence (Besser,
2002).
Private partners outside of academia
Libraries have been working to digitize collections and have struck partnerships
with commercial entities like Microsoft and Google beginning in the mid-2000s. With a
combination of private funding and commercial technology, libraries were able to create
larger collections of digitized books than had previously seemed possible. The challenge
in orchestrating these deals is partly that there are myriad models emerging, and
librarians have little knowledge of the commercial side of the equation; business deals
are not typically part of library culture (Kaufman & Ubois, 2007). The technologies
with which information is distributed, through and outside libraries, is increasingly under
control by large corporations. Google Books is likely the best-known example of such a
partnership. A controversial mass digitization project, Google Books, was developed in
partnership with university and public libraries, including the New York Public Library
and university libraries at the University of Michigan, Harvard, Stanford, and Oxford.

146

Books were scanned and converted to text using optical character recognition to help
make the books searchable. Users can search for books, see basic information, and if the
book is no longer subject to copyright, they can read and download the entire book.
Although the collection brings millions of new books to new audiences, legal battles
have plagued the Google Books project, starting with a class action suit by the Authors
Guild, the Association of American Publishers and a few others over copyright issues.
The basis of the arguments has been that Google’s dominance would undermine library
values of privacy, access, and cost (Peltier-Davis, 2011). In addition, Commercial
partners often ask institutions to sign confidentiality agreements in order to keep the
terms of these partnerships secret, in addition to asking for exclusivity of distribution to
digital files, which is in direct conflict with the reasons that libraries enter these
partnerships—to provide the broadest possible access (Kaufman & Ubois, 2007). Due to
budgetary pressures, libraries themselves are realizing a transition to new models like
patron-driven acquisitions (PDA) and demand-driven acquisitions that allow for users to
find information whether the library owns it or not, with the purchase of content based
on use thresholds. While technically more difficult to maintain, for libraries, these
models ensure that their purchases are more closely aligned with the content their users
want (Anderson, 2016).
Google Books is a mass digitization project aiming to provide broad access to
collections of books. The HathiTrust Digital Library is a partnership of research
organizations and libraries from both the United States and Europe, making available
millions of volumes. Started as a collaborative effort to allow for a small group of

147

universities to share their digital collections, HathiTrust now allows access to public
domain and copyrighted content to anyone with access to the internet. Partners in the
project includes state university systems like The University of California System and
the University of Georgia System, but also individual institutions like Texas A&M
University, the University of Tennessee, Harvard University and Yale University.
Partner institutions have access to a broader set of features, including the ability to
download full PDFs of public domain content and the ability to create their collections.
Partner institutions often deposit digitized content from HathiTrust into Google Books
(Peltier-Davis, 2011). The name of the organization is a clue to the values of the
organization:
Hathi (pronounced hah-tee) is the Hindi word for elephant, an animal highly
regarded for its memory, wisdom, and strength. Trust is a core value of
research libraries and one of their greatest assets. In combination, the words
convey the key benefits researchers can expect from a first-of-its-kind
shared digital repository. (Peltier-Davis, 2011, p. 142)
Traditional ethical standards of libraries, including equal access and diversification of
information, are important to defend in a transition to a digital environment, but that
increasingly commodified content and infrastructures are concentrating into fewer
hands, meaning that fewer and fewer works enter the public domain (Besser, 2002). It is
therefore critically important that collections strategies go beyond ensuring that popular
content is available and ensure that a diversity of information is available, eschewing the
impulse toward opportunistic collection development. Tools and business strategies

148

developed through elite political and commercial institutions have limited the distributed
nature of the internet and scientific communities, which are “supposed to be open,
extensible” (Vaidhyanathan, 2005, p. 18). Commercial forces are powerful in this
regard, per Mosco (2004):
Digitization takes place in the context of powerful commercial forces and
also serves to advance the overall process of commodification worldwide. In
other words, commercial forces deepen and extend the process of
digitization because it enables them to expand the commodity form in
communication. From a cultural or mythic perspective, cyberspace may be
seen as the end of history, geography, and politics. But from a political
economic perspective, cyberspace results from the mutual constitution of
digitization and commodification. (p. 156)
The commodification of content expands with expanding abilities to “measure and
monitor, package and repackage” information (Mosco, 2004, p. 156). This
commodification is extending even to the most precious collections inside of libraries
and other institutions built on the idea of preserving cultural heritage. If these collections
are commodified and absorbed into the content offerings of commercial publishers, then
libraries have little on which to rest their existence beyond their ability to index
information.

149

Digitizing special collections
Beginning in the mid-1990s, libraries and other cultural institutions started
digitizing their special collections. Special collections have always been less accessible
to users outside of these institutions, but, most importantly, institutions are far more
likely to hold the intellectual property rights to these collections, therefore do not need to
ask permission for conversion into digital formats. While digitization provide access to
a significantly larger audience, challenges have included the cost of digitizing materials,
cost of building and maintaining the infrastructure, integration into the broader
collections, and figuring out the needs of a suddenly much larger set of users (Maron,
Pickle, & Marcum, 2013). Institutions’ dedication to cultural heritage are challenged by
a range of choices as they figure out ways to use new technology to make their
collections more publicly accessible, and many of these choices direct them to
commercial entities. Deals for mass digitization projects tend to be unique in that there
are varying requirements for collections, and varying business criteria for commercial
entities, making it difficult to balance between institutional missions and business
strategies (Kaufman & Ubois, 2007).
A key point to consider with regard to these collections is that special collections
in libraries tend to be handled not by librarians, but by archivists. Archivists are focused
not on broad collections, but on “primary sources that document the activities of
institutions, communities, and individuals” (Society of American Archivists, 2016).
Legal, administrative, and historical evidence are only some of the uses for these

150

materials, and they are a critically important part of the cultural heritage of institutions
and the broader society. From the Society of American Archivists:
Since ancient times, archives have afforded a fundamental power to those who
control them. In a democratic society such power should benefit all members of
the community. The values shared and embraced by archivists enable them to
meet these obligations and to provide vital services on behalf of all groups and
individuals in society. (Society of American Archivists, 2016)
The distinction between librarians and archivists is illuminating, as archival practice
points to possible solutions to some tensions in a shift to a digital environment for the
dissemination. Archivists, like librarians, focus on collections, but archivists are keenly
focused on preserving very specific content in its original context—a central tenet to the
idea of permanence. Absolutely critical to archival practice is the principle of
provenance, also known by the French as respect des fonds. Provenance relates to the
history of an object, which traces who created it and who owns or has owned it. In
practice, what this means is that records of differing provenance remain separate to
preserve context, and, importantly, determine authenticity, described by Theimer (2012)
as:
“. . . typically inferred from internal and external evidence, including its physical
characteristics, structure, content, and context.” Physical characteristics,
structure, and content are all internal evidence; the external evidence of
authenticity is supplied through context, and so the archival drive to preserve
context is in part motivated by the need to preserve the evidence needed to assess

151

the authenticity of the material. For archivists, preserving context is also about
preserving the conditions that make documents more meaningful to users.”
Because context is critical to archival practice, archivists use finding aids instead of
traditional bibliographic indexes. Finding aids in archives are organized differently than
library catalogs, which is not to suggest that context is not important to librarians. The
context in broader collections tends to derive from the users of those collections. The
deep content knowledge that faculty have and students lack are a form of context.
Although libraries have worked to ensure that the interfaces they provide to users
are simple to use, they have not made the interfaces simpler but have simply masked
their complexity. Norman (2011) suggests that design of objects and systems should be
appropriately complex. For example, an airplane cockpit might seem frighteningly
complicated to the average person, but to pilots, the controls are all organized into
meaningful groups and therefore easy to use. Search engines like Google might seem
simple on the surface, but the complexity is simply built into algorithms that are
invisible to the user. Personalized searches might provide a personalized context, but
they do not and cannot provide an appropriately epistemological context, even narrowed
down to a particular discipline. The cultural record is increasingly commodified and
corporate-owned, and its preservation requires theoretically informed, if critical,
practices of librarianship and archiving. The myth of permanence rests most solidly here,
in this tension between what collections should survive and to whom their existence
should be entrusted. The problem of permanence of digital information is becoming

152

more critical, as more and more content is born that way, however, obstacles grow to its
realization, because of the velocity at which technological change occurs.
The problem of permanence for digital information
Fitzpatrick (2011) points to a key problem with content in digital formats, noting
that Michael Joyce’s Afternoon is an early hypertext rendered nearly unusable since the
hardware and software required to read them have become out of date. Digitization is not
a substitute for preservation. Digital resources are distinctive for creating ease of access
to information but are poor for preservation, which has traditionally been the province of
libraries and archives (A. Smith, 2007). Information that is recorded in any medium will
last only as long as the medium, meaning that the durability of the medium is tied
directly to the durability of the information. Cuneiforms may not have been the first
forms of inscription, but if anything preceded them, those media were so fragile that
there is no trace remaining (Rumsey, 2016). If books were as permanent as assumed,
then they would not require the sophisticated infrastructure developed over centuries to
ensure their protection. A parallel process for the preservation of digital content could be
developed over a much shorter period (Fitzpatrick, 2011). Concerns about potential
global catastrophe are currently informing plans to build libraries to facilitate a restart of
civilization, as needed, together with a proliferation of thought experiments about what
to save and what can be left behind (Rumsey, 2016). Digital content, whether borndigital publications or digitized special collections material, is the fundamental
component of digital libraries, much like print content has historically been the
fundamental component of brick and mortar libraries. Digital content is the fastest

153

growing part of most library collections, but digital content is potentially transient. Until
recently, most digital collections had a backup in paper originals from which the digital
versions had been scanned. There is a growing set of cultural content with no print
equivalent to serve as a backup copy (Worthey, 2013). The permanence of this part of
the cultural record, then, is rendered questionable.
In exploring the transition to digital first formats, Rumsey (2016) posits that the
idea of preserving knowledge forever is long past; consumers replace books and other
forms of physical media with computer code that is easily overwritten, easily rendered
obsolete, and dependent on machines to render its contents readable. Some systems have
been developed in an attempt to address these issues. Lots of Copies Keep Stuff Safe
(LOCKSS) and Controlled LOCKSS (CLOCKSS) are joint ventures of libraries and
publishers to help ensure preservation of digital content. Libraries that use LOCKSS
have a LOCKSS box, which is simply a computer that preserves local copies of digital
content from publishers. Member libraries are not just leasing digital content anymore
with the permission from the publisher. Through systems like LOCKSS, libraries can
take custody of the material, and the LOCKSS box at a given library will provide the
content to users if the copy from the publisher is no longer available (Ferguson, 2007).
The LOCKSS system preserves content in its original form, and also includes a
mechanism through which content can be migrated to new formats on the fly when the
content is requested by a user (Heinrich, 2012). The CLOCKSS systems go a step
further in that libraries can preserve content from member publishers whether or not they
subscribe to it. CLOCKSS is a dark archive through which content is only made

154

available after defined events are triggered, such as when the material is no longer
available from a publisher. The distinction between the two initiatives is that LOCKSS is
community-driven and focused on local library collections, and CLOCKSS is a more
globally focused attempt to preserve collections in the event of business disruptions
(Ferguson, 2007). One of the first journals to be preserved in the LOCKSS system was
The Absinthe Literary Review. The announcement of the journal’s participation in the
LOCKSS program coincided with a severe server crash at the publisher website and the
expiration of the domain registration, which was capitalized on by cyber-squatters who
took over their domain name. The content of The Absinthe Literary Review was
preserved in LOCKSS (Worthey, 2013). Although criticism of Nicholson Baker was
largely valid, he did have one point. The transition of content from analog to digital can
radically transform information and do so in the same way information is lost when
making copies of analog items. For example, microfilm loses around 10% of its
information each time a copy is made. However, born digital content does not have the
same problems. Virtually no information is lost through generations of digital copies
when properly preserved (A. Smith, 2007).
As Anderson (2013) notes, libraries have treated shifts in the scholarly
communication from a print-based system to a digital network as a shift in format, but it
is fundamentally a question of the function of the library in the 21st century. Preservation
of print products is still a contemporary goal. Cooperative efforts are underway to ensure
that libraries preserve print copies of journals and other documents that they remove
from their collections in shared off-site facilities so that a “last copy” is available in non-

155

digital format somewhere. The Western Regional Storage Trust works with institutions
to ensure that complete journal runs were preserved, and Ohio has developed a statewide
network of shared facilities that includes both public and private universities (Schonfeld,
2015). Preservation in the realm of special collections tends to have a different focus.
Artifacts and collections are not preserved because of their curricular relevance or any
instrumental value, but because they have some inherent cultural value, whether that
value is global or local (Anderson, 2013). Most regional preservation efforts center on
the declining necessity for access to content in print form. JSTOR is an example of a
different approach, linking preservation of print to the provider of digital preservation
and access. All things being equal, print access will likely become less important, and
over time, access to digital should continue to grow; therefore, ensuring the preservation
of digital content and the ability to re-digitize when necessary will be critical (Schonfeld,
2015). Anderson (2013) argues that the academic library should shift focus toward noncommodity documents, that is, those in localized collections which are found in special
collections. A localized and specialized collection focus would bypass some of the
controversy over whether OA or toll access is a preferred model for scholarly
communication. This line of thinking, given that OA has been driven largely from
libraries, suggests that libraries have not been partners with researchers in the system of
scholarly communication, but have effectively been attempting to undermine it.
Libraries are not constraining authors’ publication options but offering new
opportunities for researchers to publish outside the commercial publishing enterprise. In
fact, across the US, libraries and university presses are merging operations to create a

156

new enterprise for disseminating scholarship. While the business models are strikingly
different, these mergers point to possible solutions to the publishing problem (Clement,
2011).
An experiment by the libraries at the University of Tennessee points to additional
opportunities for new forms of publication. As part of The Big Read, the Knox County
Public Library chose August Wilson’s A Lesson Before Dying for the book that the
Knoxville community would come together to read. In partnership with the Knox
County Public Library, the Clarence Brown Theatre put on a production of the play
based on the novel. The community participated in book discussions, panel discussions
and a variety of other activities for this event. The University of Tennessee Libraries
entered the partnership with a call for essays and other reflections from the university
and broader community. Essays and artwork were gathered from a variety of disciplinary
perspectives and a variety of community members, including artwork from students at a
local high school. The essays were published in a book through NewFound Press, which
is the digital imprint of the University of Tennessee Libraries. The project was so
successful that a call for papers for the current Big Read novel, Station 11, is now
available (University of Tennessee Libraries, 2018).
Preservation of text has existed throughout history with all manner of constraints
existing with regard to publication options, and commercial scholarly publishers have
exacted many of them. There is a growing tension not just with regard to preserving the
contents of libraries, but whether the institution itself should remain permanently. The
suggestion that libraries are undermining the system of scholarly communication misses

157

a crucial point. Libraries are a part of and not apart from the system of scholarly
communication. Setting researchers and libraries in competition with one another leaves
commercial publishers in a position to continue to exert ever greater influence. Anderson
(2013), reflecting on where libraries should focus their attention in this new
environment, places special collections as be the centerpiece of library collection
activity; however, this ignores the fact that commercial publishers are also working to
digitize special collections, and sometimes the publishers are arguing for exclusive
distribution rights. Thus, special collections are not immune to the commercial
influences in the system (Maron et al., 2013). Regardless of the focus of library
collection behavior, they should not be ignored as a central part of the system of
scholarly communication. As Rumsey (2016) puts it,
What survives war can die from inattention and neglect. The library at
Alexandria ultimately collapsed not directly from wars. It died because people
stopped valuing its contents (Rumsey, 2016, p. 45).
Libraries still serve critical functions in the system of scholarly communication, but their
practices have changed considerably over the last few decades as the shift to digital
content has evolved. They will only continue to serve these critical functions in the
future if people outside the walls of the library fully understand their place in the system.
In this chapter, I have explored how changing organizational environments are
putting pressure on libraries to change longstanding practice and organizational
structures. I outlined changing economic and technology environments, and some ways
in which the digital environment changes the way people consume information. I also

158

have outlined how an idealized but impoverished view of libraries prevents many
outside their walls from seeing the expanding inventory of services they provide, and the
increasing pressure from a variety of technical and economic forces. I also explored how
a shift to a digital environment creates an epistemic shift in how people consume
information and the implications on library practice, and how preservation of the cultural
record and the library as an institution are in danger. The commercial influence of
publishers has begun to extend into the most localized content in libraries in their special
collections- bringing about the commodification of that content as well. In Chapter VI, I
will make a more fully formed argument for considering the system of scholarly
communication as a recursive public, as defined by Kelty (2008), as a way to challenge
the myths of authority, influence, and permanence.

159

CHAPTER VI
CONCLUSIONS: NOLITE TE BASTARDES CARBORUNDORUM
Chapter I outlined how the myth of authority operates in the system of scholarly
communication with a history of the development of scholarly journals, how authority
came to be seen in the form of books, and how the imprimatur of print became the
paradigm on which authority is based. It noted the shift to digital formats and how
digital publishing, as a commodity, is met with increased expectations for publication on
the part of faculty, and an increased reliance on abstractions of the value of scholarly
work with the use of metrics. Chapter II paints a picture of the market for scholarly
communication, demonstrating that ownership of the scholarly record is increasingly
under fewer and fewer publishers, and details changes to intellectual property law and
the effects of those laws on a digital information environment. Chapter III explored the
myth of influence, specifically how there is a divergence between the social
infrastructures of scholarship associated with disciplines, and the technical
infrastructures, which are increasingly under control of commercial interests. Chapter IV
explored the myth of permanence by exploring shifts in the organizational and technical
environments around digital publishing and the changes libraries are making in response.
It also addressed the libraries’ participation in a basic shift in epistemic authority—that
is, in how and why people find and consume information in library settings. This final
chapter reflects on the information in the preceding chapters and constructs an outline of
the scholarly communication practices which form a recursive public, as informed by

160

mobilization of resources model of organizational communication, and by Kelty’s
(2008) history of the open software moment.
To extricate organizations from rationalized myths, Meyer & Rowan (1981) offer
four solutions. First, an organization can resist ceremonial obligations, which leaves the
organization unable to document efficiencies, since they cannot be easily identified
absent the measures provided by the ceremonial obligations. Ceremonial obligations,
like the prestige markers in academia, also provide resources and stability. Resisting
those prestige markers would, based on Blackwell’s (1998) argument, be a threat to the
epistemic authority of the institution. Meyer & Rowan’s (1981) second solution is to
conform rigidly to institutionalized formulas by isolating the organization from external
relations. The cutting of external ties introduces problems when constituents are unable
to perform boundary-spanning activities, but most importantly, organizations that are
institutionalized cannot just conform to myths, they must also preserve the image that
they work. A third option is to accept cynically the irreconcilability between institutional
structure and work requirements, which delegitimizes the institutionalized myths, and
ultimately, the organization. The fourth option is to promise reform, which risks defining
the organization’s current structures as illegitimate, since this strategy indicates a valid
structure as lying in the future. A promise for reform in the system of scholarly
communication can avoid the risks they outline if a focus is maintained on the fact that it
should be a shift not in obligations, but a shift in thinking about to whom producers of
scholarly work are obligated. To demonstrate this, I will recast the system of scholarly
communication as a recursive public. First, I will revisit Kelty’s (2008) definition of a

161

recursive public, then I will outline the five components of a recursive public and relate
each component to scholarly practice. I will then revisit the myths of authority, influence
and permanence. Finally, I will make some recommendations for how to begin to change
the system through what the definition of a recursive public promises: “actually existing
alternatives” (Kelty, 2008, p.3).
The definition of a recursive public is as follows:
A recursive public is a public that is vitally concerned with the material and
practical maintenance and modification of the technical, legal, practical, and
conceptual means of its own existence as a public; it is a collective independent
of other forms of constituted power and is capable of speaking to existing forms
of power through the production of actually existing alternatives (Kelty, 2008, p.
3).
Component one: support by a movement or ideology
The first component necessary to a recursive public is that it be supported by a
movement or ideology. The only component that the Connexions system does not
modulate, Kelty (2008) argues, is that of the movement, though he refers to OA as a
second cousin of what might be a movement for free textbooks. This movement actually
does exist under a different name. Open Educational Resources is an approach to
publishing that has seen some early successes and is broadly focused on all material for
use in education, including textbooks, course readings, syllabi, and assessment tools
(Mallon, 2015). Some of the successes of the OA movement, in addition to the
expansion of Open Educational Resources—of which a system like Connexions would

162

be considered a part—demonstrate that there are existing alternatives to commercial
scholarly publishers. MediaCommons, arXiv, Connexions, the Open Science Framework
offered by the Center for Open Science, institutional repositories, and Open Journals
Systems are among a host of systems that perform in the same way or provide some of
the same functions as traditional scholarly publishing but are using different tools—the
only difference being that they do not often result in a printed volume.
Component two: sharing of source code
These tools, by design, retain critical aspects of scholarly practice including peer
review; it is these practices that can be related to the second component of a recursive
public: the sharing source code. A key aspect of the sharing of source code is the
portability of software. Björk’s (2007) model of the system of scholarly communication
and its discipline agnostic structure suggest that across disciplines scholars share basic
structures that underscore practice. Abbott (2001) traces the history of the field of
sociology and how changes to the field have differentiated objects of study or
methodology, and how these have changed over time in reproductions of fractal cycles.
The discipline of communication has undergone similar changes, first emerging from the
English Department as a separate discipline, and over time splintering into a variety of
sub-disciplines (Gehrke & Keith, 2015). A constant has been the manner in which
research is conducted, as demonstrated by Björk’s (2007) model. The model serves as
something like what Rawls (1999) referred to as “veil of ignorance,” a simple series of
workflow diagrams that force scholars to take a step back from ideologies specific to
individual disciplines. By thinking of the scholarly publishing system as a recursive

163

public, the conversation can shift from one centered on access and begin to focus on the
inner workings of our social processes and how the system exploits free labor to support
a multibillion-dollar industry.
Component three: openness and how it is conceptualized and operationalized
This third component concerns both the technical and ethical aspects of
openness, including what protocols should be used and what market infrastructures
should be involved. From the time Oldenburg produced the first edition of The
Philosophical Transactions of the Royal Society of London, openness has been a driving
philosophy of the system of scholarly communication. It was only when scholarly
societies began to hand off their publications to commercial scholarly publishers that
access to research became more problematic. As argued in Chapter Two, Open Access
publishing, in its basic form, is not incompatible with traditional scholarly practice.
Predatory publishers exist in this arena, but it is critical to understand that predatory
publisher versus commercial publisher is a false choice. Editorial boards of both library
and philosophy journals have successfully jumped to the OA model with the reputation,
if not the name, of the journal intact. Business as usual, under the oligopoly market
structure of the Big Four commercial publishers, is likely to lead to an increasingly
commodified content system with an increasingly large portion of the infrastructure for
creation, analysis, publication, and dissemination under their purview as well. Broader
commercialization in combination with a proliferation of new titles has been a source of
conflicts and some consternation for libraries, which were once the sole subsidizers of
scholarly publications. Commercial publishers have stoked this problem in part by

164

massive catalog acquisitions of copyrighted scholarly work. Here it is critical to revisit
RDT, with its keen focus on control of resources. Publishers can only continue to control
the resources of scholarly output insofar as faculty continue to give them away. Their
marketing infrastructures have segmented faculty into target audiences that further
reinforce brands of journals, abstracting the authority into the brand – authority
presumed by the target audience. Critical to the notion of authority at the epistemic level
is that it is assigned by the community. The actual power to change this system lies with
the individuals creating the content in the first place.
Component four: application of copyright (and copyleft) licenses
The fourth component of a recursive public rests in the application of copyright
(and copyleft) licenses. Open Access enthusiasts regularly use and promote Creative
Commons licenses, and librarians regularly help authors negotiate agreements even with
commercial publishers to help them retain at least some of the protections of copyright
(Suber, 2012). An elaborate system is in place to ensure that the rights of authors can be
protected.
Component five: forms of coordination
This is perhaps the most complex part of refiguring the system. In Connexions,
authors changed the way they coordinated and collaborated in creating academic
textbooks. Scholars have been fluid in their forms of coordination and collaboration over
the history of the academy as disciplines have shifted and they have worked to cross
disciplinary boundaries. It is plausible, if not likely, that enough infrastructure is in place
to consider whether the commercial influence of publishing is worth keeping in whole,

165

in part, or not at all. As an example, the Association of Research Libraries, along with
regional and national repository networks, recently endorsed an international accord to
more closely align repository networks across the globe to improve cooperation and
identify common principles under which they will all operate—an accord created by the
Confederation of Open Access Repositories (Shearer, 2017).
Rethinking authority in the age of e-books
If scholarly publishing supports the prestige hierarchy underpinning the U.S.
system of higher education (Fitzpatrick, 2011; Borgman, 2007), and if its historical
continuity depends on the ongoing operation of mythological thinking about the
traditional authoritativeness of peer reviewed publications appearing in print university
journals and books, then it is likely that these myths will destabilize further. The
economic instability of the publishing system is increasingly seen to matched by an
employment system which may be fundamentally at odds with non-economic values, as
well. Alvarez (2017) summarizes some of the main problems.
Our scholarly imaginations are forcefully limited by a system that concentrates
prestige, cultural capital, financial rewards, and knowledge-defining power at
"the top," a system that makes professional life at "the bottom" not only invisible
but economically unbearable. This is to say that academe’s inequality problem is
not just epistemic. It is interwoven with socioeconomic inequalities in admissions
and hiring that are deeply racialized, gendered, etc., and that supplement
epistemic dominance within universities by diverting more teaching duties to a
growing underclass whose members can barely make ends meet, let alone

166

produce scholarship that senior faculty take seriously. It is not just cold careerists
at Princeton or Chicago holding everyone down by happily hoarding all the
prestige; we are all complicit, more or less, and many of us are complicit out of
necessity, which isn’t an accident. This is a system functioning "as it should."
Professional librarians have intervened into the debate about the weaknesses of the
current relationship between academic publishing and librarianship with proposals of
their own. Beatty’s (2014) critique of the Association of College and Research Libraries’
(ACRL) Framework for Information Literacy in Higher Education outlines how a new
framework proposed in 2012 by ACRL, while offering improvements on the previous
document, still reinforces a market-oriented worldview, and does nothing to challenge
existing forms of power, for example, with commons-based or peer production models.
The framework distinguishes between novice and expert researchers, suggesting that
novices rely on superficial authority markers like author credentials, while experts with
authority recognize schools of thought and disciplinary paradigms. As a differentiator of
quality of scholarship, the distinction is problematic.
To equate expertise with ‘recognizing schools of thought or discipline-specific
paradigms’ is just to make it a slightly more sophisticated form of credentialism.
To be sure, it’s a step towards expertise. Real academic expertise is born from
immersion in a subject to the point that the meanings of these labels break down.
What this threshold concept offers is not expertise, but the credentialism of firstyear graduate students establishing their internal pecking order over a pitcher of
beer (Beatty, 2014).

167

It is through the various prestige markers of peer review, publication, and tenure that the
myth of authority is manifested. The imprimatur of authority sits most firmly in peer
review and publication, as these are the mechanisms through which scholars allocate
academic capital. An increasingly small number of commercial publishers own these
scholarly journals. The relationship of scholars to particular journal brands creates
tension in the system, though technologies exist that allow for a move away from the
journal container as it has been traditionally viewed—in fact, it is entirely possible that
at that point the journal container is not just no longer useful, but detrimental to the
entire system. As Guédon (2001), suggests, journals might offer a public record of
scholarship, but they are private brands in their own right.
These tensions in the system, emphasized by the Thatcher testimony, underscore
social conflicts which have been masked for many years by mythological thinking about
authority, influence, and permanence. Librarians, university faculty and university
presses, rather than working in concert, are in many cases effectively working at odds
with one another. For examples, Fitzpatrick (2011) considers the history of the
University of California Press, which was established in 1893. At its inception, the press
did not publish books, but mostly monograph pamphlets, and there was no real
systemization of the methods they used or the products they created. The products they
did publish were all written by the faculty of the University of California. It wasn’t until
1929 that their editorial board authorized publication of books written by scholars
outside the University of California. In 1933, they formally reorganized as a trade
publisher, and the director requested that all revenues generated by the press be retained

168

by the press. Publishing had been entirely noncommercial prior to this, and all revenues
were returned to the university. This shift toward book publishing, and toward the press
as a business, coincides with the “distancing of the press from the work of its own
faculty” (Fitzpatrick, 2011, p. 178). Fitzpatrick describes the distancing as being
detrimental to the missions of all organizations involved.
…what the university gains in the press’s financial autonomy, it loses in the
press’s service to the university community. Reconnecting university publishing
with the broader university community will require undoing some of the
twentieth century’s business-oriented transformations and returning to the
fundamentals: if the dissemination of scholarship is a valuable part of the
university’s mission, the university must take responsibility for that process and
transform the press into a publishing center whose function is intimately tied to
the work of its own institution (p.178).
Mergers of libraries with university presses have shown some successes. For example, at
Utah State University, the merger of the library and press organizations allowed the
press to continue operations, and subsequently begin a digital imprint called USU Digital
Monographs, which is seen as the final step in fully integrating the two organizations
(Clement, 2011). With libraries finding new methods of publishing journals through
consortia and institutional repositories, the possibilities for a self-contained academic
publishing enterprise exist. Fitzpatrick (2011) notes a fear among university faculty that
in setting up the university press as a publisher for the work of its own university faculty,
the press would collapse into a species of vanity publishing, and thus be required to

169

publish anything submitted by faculty. Even in the early days of the University of
California Press, however, it engaged with subject experts to ensure the quality of its
content. The people in the system of scholarly communication are the ones who bestow
authority on scholarly content, not the publication venues or the publishers.
Rethinking influence in the Google era
An interesting thing to note in thinking of the workings of influence in the
system of scholarly communication is that the university itself is effectively decentered
in the system. While it is true that university administrations and boards of trustees make
decisions on tenure cases, in most cases (except those not respecting academic freedom
and shared governance) a university does not decide whether a scholar’s work is worthy
of publication or granting of tenure until the peers in their discipline do so. The center of
power for making effective changes in the system of scholarly communication lies not
with the university, or with the libraries that sustain them, but in the scholarly societies
which organize disciplines and faculties. Scholarly societies are the social infrastructure
that maintain the feedback loop of influence in scholarly conversations. Fitzpatrick
(2011) notes that both university presses and scholarly societies should be held more
accountable to their memberships for making scholarship available and visible inside
and outside the academy.
Commercial scholarly publishers have taken over increased control of scholarly
content, and they are making inroads to take over vital technical infrastructures as well.
In so doing, they hope to corner the markets for intellectual property rights over the
largest corpii of publications available and also the technologies used to publish them.

170

Elsevier alone has taken over companies in a variety of areas vital to scholarly work,
including data collection, data management, data analysis, integrated library systems and
institutional repositories. Continuing down this path, a future is foreseeable in which a
researcher would have to rely on Elsevier to get data, analyze data, publish the results
and retrieve the article upon publication.
Pfeffer & Salancik (2003) note that boundaries in environments are where one
organization has more discretion to control an activity than another. Faculty do have
discretion in where they publish. Commercial publishers only have the power over the
system that they have because they have been given the content for free or even charged
others for providing it to them, through article processing charges. The bind for faculty
is that the publication venues they require for tenure are typically tied up in a
commercial system, thereby putting their own institutions, through their libraries, in a
budgetary bind and propping up a commercial system that makes billions of dollars on
their free labor. This problem will only ever get solved if members of scholarly societies
can come together and make a change to their publishing and credential-granting
practice. The social infrastructure of the system is its foundation, and its only hope for
fixing the problems that currently exist in scholarly communication. The most critical
part of any nationwide or global system to create, review and evaluate scholarship is
already in place—the people who do the work of creating scholarship.

171

Rethinking permanence in enterprise information systems
New technologies have not only affected the organizational structures of
academic libraries but has brought about an epistemic shift in the handling, organization,
and dissemination of electronic publications, including their metadata. This shift toward
networked technology has also affected library practices of collection, dissemination and
preservation. Technology has created an epistemic shift in the way that information is
categorized and disseminated. Algorithms control how content is discovered in search
engines, and libraries are instituting new systems through which content from a variety
of databases can be discovered through a single interface. Abbott (2008) notes that this
practice is not far from what librarians have always done, perhaps without realizing it,
through creating indexes to information; I have strengthened this argument by pointing
to the cybernetic commodification of publication metrics and other markers of scholarly
influence.
The long-term promise of new technology has been to offer cheaper access to
information, not necessarily better or higher quality information. While cheaper delivery
may have been accomplished in some industries and sectors, it is not always the case for
libraries serving higher education, as a shift to licensing has increased costs for many
titles and collections. Easy access is not cheap, particularly when an organization
requires new kinds of staff to manage new expectations. Libraries face increasing
pressure to consider their collection practices and determine whether offers like “Big
Deal” packages make sensible planning decisions. Librarians also face the task of

172

working more closely with faculty in academic departments to determine the best ways
for the whole system of collections to be rethought and made more sustainable.
Despite these challenges, libraries and librarians are probably up for these tasks,
having always exhibited selectivity in their collecting behaviors. Libraries have focused
on the methods of digital resourcing, but the organizational challenge now is to reframe
the role of libraries in the scholarly system of production, publication, and collection of
knowledge, while preserving the values of the profession. Wolf (2015) offers the useful
notion of librarians as serving as social “middleware:”
It often strikes me that the librarian’s place in the scholarly communications
space is that of the middleware linking together the other stakeholders. I feel as if
librarians are perhaps the only stakeholders with a better than average
understanding of the perspective, practices and policies of the majority of the
other players in research publication. For instance, as librarians, we are often
called on to explain publisher policies and funder policies to researchers, to
explain publisher practices and policies to research administrators, to explain to
publishers the levels of awareness of, say, open access (OA) amongst our
researchers, and so on. Our role is to understand, and in some cases influence, the
perspectives of the other links in the chain, while ensuring our own services help
the smooth flow of information through it. In other words, it could be said that
librarians are maybe at the centre of information flow (both ‘produced’
information such as articles, books, etc., and ‘workflow’ information such as

173

publisher policies, funder mandates, etc.), but not necessarily central to those
information flows (Wolf, 2015, p.78).
Memory and recordings of history are fragile, and professionals worry that libraries
might inadvertently abandon their critical traditional role as cultural and historical
protectors.
On the one hand, computers are seen as the ultimate memory tool capable of
providing access to everything ever written. On the other hand, the digital record
is liable to manipulation, distortion or erasure. In such an environment, we cling
to our libraries and our artifacts even as we dream of ever more encompassing
virtual collections. How do libraries enmeshed in this mythology of computer as
both threat and savior chart a rational course for the future? (Manoff, 2001, p.
379).
Charting the course requires thinking about the inherited system in a different way. In
the Open Software movement, geeks, defined as affinity groups working together to
maintain the social and technical infrastructures through which they work, employ
technical and moral elements to operating in a recursive public—operating systems and
social systems work in concert, since the infrastructure through which geeks do their
work is as important as, and inextricably tied to how they discuss their activity in the
system (Kelty, 2008). As scholars map new tools onto existing infrastructures, university
libraries are in conflicted roles, owing in large part to their being a subsystem of the
university. Universities participate in economic, political, technical, and cultural

174

subsystems of society and myths can mask conflicts between subsystems. As state
legislatures and university administrators urge more accountability through metrics,
commercial scholarly publishers are increasingly creating systems to create and measure
even more metrics and selling those to universities in addition to their traditional
content. I will argue that rather than looking to the library as a place of information
transactions, faculty should consider the library as central to, and librarians as partners in
the academic enterprise.
Although the intentions of the OA movement have been admirable, the focus on
openness has prevented the movement from pulling far enough from existing
commercial structures for publishing scholarly work. Commercial publishers simply
adopted the language of the movement and instituted measures like article processing
charges, supplementing the income they receive from subscriptions by charging authors
to make content open access without then discounting subscriptions paid by libraries.
Sweeney (2014) has suggested that librarians should work together with publishers to
solve these problems. Another approach, however, might be to stop inviting publishers
to self-regulate, because their profits margins rely on the system continuing as it
currently stands. A crucial point to remember about myths is that they “sustain
themselves when they are embraced by power, as when legitimate figures such as the
vice-president tell them and, in doing so, keep them alive” (Mosco, 2004, p. 39). Rather
than keep the myths of authority, influence and permanence alive, I will, based on the
perspective outlined in the previous chapters, my experience as a librarian, and work

175

already being done in the OA movement, offer some recommendations for killing them
off.
Recommendations
Recommendation one: The Association of Research Libraries (ARL), the Association
of American Universities (AAU), the Association of Public and Land-grant Universities
(APLU), and the Association of University Presses (AUP) should hold a joint meeting of
their leadership to begin a conversation about how and through whom scholarly work
should be published, and what changes can be made to address the various problems
outlined here, keeping in mind that Oxford and Cambridge are members of AUP, and
have been instrumental in lawsuits targeting libraries.
Recommendation two: Scholarly societies should take up these issues in earnest at their
legislative assemblies to come to some conclusions about how work is certified within
those societies and associated disciplines in order to provide discipline-specific
frameworks for testing new publication and certification venues.
Recommendation three: Declare independence. Where possible, faculty on editorial
boards of journals owned by commercial publishers should follow the lead of the
editorial boards of library journals and others listed in the journal declarations of
independence (n.d.) here and quit to reform under new journals.
Recommendation five: At the university level, faculty should bring up the problems of
scholarly publishing at faculty senate meetings. At universities where librarians do not
enjoy faculty status, and therefore do not have a seat at these meetings, librarians should

176

be invited. Full professors in particular should bring the full weight of their job security
and status within the academy to help guide reform.
Recommendation six: At the university level and at department level in universities,
reconsider the way in which scholarly productivity is measured. If arguments that do not
rest on publication counting for the granting of tenure have not been convincing, then
better arguments need to be made. If professors were evaluated based on only the 3-5
most influential or high-quality publications (or other work product), how might their
publishing behavior change? If home institutions committed some amount of money to
every tenure-track humanist to use for publication subventions at university presses, how
might that change the system?
Recommendation seven: Rethink the relationship of universities and their libraries and
presses. Many institutions are far down this road already. Most crucially, universities
need to reconsider how the presses are funded. Rather than considering them as a
separate unit that should be able to recover costs or even make a profit, their operation
should be considered a part of doing university business.
Conclusion
What, then, is the proper place for the academic library in the 21st century
research university? In a practical reframing, the library is a key partner in the overall
academic enterprise and a potentially new fulcrum around which publication can pivot.
A broader conversation about reforming the system of scholarly communication should
include scholarly societies, university administrations, scholars, university presses,
librarians, and exclude commercial players with no incentive to change business models.

177

Commercial publishers, with increased control over scholarly journals, are now exerting
control over the infrastructures through which those journals are published and finding
new methods to enhance profits through mechanisms like article processing charges.
Scholarly societies once depended on libraries to subsidize their publication activity.
Given that libraries now demonstrate the ability to publish journals and books, and that
university presses are in many cases merging with library operations, it seems clear that
scholarly societies are now well-positioned to refocus their attention back toward
libraries and away from commercial publishers, which are currently taking content from
scholars so they can sell it back to the universities where the scholars work, only to then
sell the universities systems for measuring scholarly productivity.
Obstacles to changing this system are essentially about recognition of agency at
both organizational and individual levels. Scholarly societies, having once been
dependent on libraries to subsidize publication activity, have the agency to rethink their
relationship with commercial publishers. Scholars have the agency to make different
decisions about where they publish. When the editorial board of The Journal of
Academic Librarianship resigned, going on to create Portal: Libraries and the Academy
(Schwartz, 2013), they demonstrated that it is the coordination of people doing scholarly
labor which has the greatest impact on creating the scholarship, and not the work of
publishers. The same level of quality research people grew to expect from The Journal
of Academic Librarianship can be found now in Portal: Libraries and the Academy. The
research itself, its write-up, editorial production, and review of the work are all tasks
which are already being performed by scholars. Principally, the mechanism for

178

distribution is at issue. Much like the movie, music and TV industries, the scholarly
publishing industry is threatened by the new ways of distributing content. The question
of new expenditures on catalog access and infrastructure hangs in the balance: either
universities can continue to spend with commercial entities outside the academy or
possibly reinvest in their own institutions. The latter possibility is not unthinkable, since
libraries have long subsidized publication in scholarly societies, and are now providing
tools for societies and universities to self-publish once again. The social parts of the
process and the construction of authority, influence, and permanence exist apart from the
technical processes of producing scholarship. Coordination will be critical to ensure
reformed system works for all involved, because as Fitzpatrick (2011) has noted, one of
the reasons that institutional repositories do not broadly have full publication abilities is
that librarians never coordinated with university presses as part of their development.
Libraries are already demonstrating that they can play central role in creating a
reliable system of scholarly communication that is prerequisite for a functioning twentyfirst century research university, even as the current system, through coordinated efforts
of commercial entities, serves to undermine their centrality. Scholarship is by nature a
recursive process. In rethinking the way scholarship is created and disseminated, it is
critical to understand that scholars, like geeks in the open software movement, are the
central element to creating and maintaining the systems through which and by which
their work happens. The social infrastructures of the academy cannot be outsourced.
Advocates of OA have long been on the right track in terms of their goal to free to the
scholarly record from commercial forces, but the focus on open has not gone far enough

179

as a force of structural resistance in that it potentially limits discussion to access to
content, and not the overall social and technical infrastructures through which scholarly
research is created. Refocusing efforts toward the agency of researchers and librarians
to enact change affords new opportunities for change, which are necessary to ensure that
libraries and the universities they support have the tools they need to do their work.
If we are slouching towards Alexandria, let us arrive there at its inception, not its
destruction.