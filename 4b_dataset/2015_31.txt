FROM READING TEXT TO RE-DESIGNING IT:
EBOOK DESIGN INSIGHTS FROM A MIXED METHODS USER STUDY OF
ACTIVE READING

HyunSeung Koh

Submitted to the faculty of the University Graduate School
in partial fulfillment of the requirements
for the degree
Doctor of Philosophy
in the School of Informatics and Computing
Indiana University
May, 2015

UMI Number: 3703332

All rights reserved
INFORMATION TO ALL USERS
The quality of this reproduction is dependent upon the quality of the copy submitted.
In the unlikely event that the author did not send a complete manuscript
and there are missing pages, these will be noted. Also, if material had to be removed,
a note will indicate the deletion.

UMI 3703332
Published by ProQuest LLC (2015). Copyright in the Dissertation held by the Author.
Microform Edition © ProQuest LLC.
All rights reserved. This work is protected against
unauthorized copying under Title 17, United States Code

ProQuest LLC.
789 East Eisenhower Parkway
P.O. Box 1346
Ann Arbor, MI 48106 - 1346

Accepted by the Graduate Faculty, Indiana University, in partial fulfillment of the
requirements for the degree of Doctoral of Philosophy

Doctoral Committee

__________________________
Susan C. Herring, Ph.D.

_________________________
Jeffrey Bardzell, Ph.D.

_________________________
Hamid R. Ekbia, Ph.D.

_________________________
Erik Stolterman, Ph.D.

May, 2015





© 2015
HyunSeung Koh





Acknowledgments
Without endless encouragement and support from the following people, I would not have
been able to enjoy and finish my long journey: my husband, my family, and my familyin-law; my advisor, Dr. Herring, who has been always at my side since I took my very
first baby steps as a scholar; my committee members, Dr. Bardzell, Dr. Ekbia, and Dr.
Stolterman; my department faculty, Dr. Rosenbaum, Dr. Jacob, Dr. Shaw, and Dr.
Sugimoto, and colleagues, Lala, Wayne, Tim, Lois, Dan, Seungmin, Apple, Lai, Inna,
Peter, Shannon, Ali, Wei-Chu, and Madelyn; other departmental faculty, Dr. Carspecken,
Dr. Pugh, Dr. Jones, Dr. Potter, and Directors of Graduate Studies; Dr. Kennedy at the
Center for Survey Research (CSR); consultants including Stephanie Dickinson at the
Indiana Statistical Consulting Center (ISCC); Steve Egyhazi and Chris Golden of
Collaboration Technologies in the University Information Technology Services (UITS);
Dr. Kou and Roger Crandall at the Center for Language Technology & Instructional
Enrichment (CeLTIE); all participants from around the world and faculty and other
doctoral students at the Doctoral Consortiums I attended; all my friends; and the
University Graduate School’s generous funding for my dissertation research.
Special thanks to my father, now in heaven since last September, whose loss was
so sudden, and with whom I had been dreaming of sharing the moment at graduation
commencement when he would be so proud to see me receive the doctoral hood.



HyunSeung Koh
FROM READING TEXT TO RE-DESIGNING IT:
EBOOK DESIGN INSIGHTS FROM A MIXED METHODS USER STUDY OF
ACTIVE READING
The rate of acceptance of ebooks – books in digital formats – is growing rapidly
(DeSilver, 2014; Milliot, 2008; Ramaiah, 2005; Springer, 2008). Yet studies show that
for active (serious) reading people still prefer to read on paper and employ skimming
strategies when reading from a computer screen (Hillesund, 2010; Liu, 2005; Olsen,
Kleivset, & Langseth, 2013; Springer, 2008; Wexelbaum & Miltenoff, 2012). These
studies imply that currently available ebook devices do not fully support the needs of
people who want to use ebooks for active reading. Thus, there is a need for new ebook
designs that better serve active reading.
As a means to come up with new insights into novel ebook designs to meet this
need, this study investigates the nature of one key aspect of active reading, reader-text
interaction, through collecting a variety of behavioral and non-behavioral data in natural
and naturalistic settings, thereby filling a research gap identified from a review of the
literature on active reading in HCI, education, and literary criticism. The study adopts a
position of naturalistic inquiry (constructivism) and utilizes mixed methods, including
both quantitative components (an online survey) and qualitative components (document
examination of annotations), as well as a video study (distant observation) and follow-up
interviews. The study was designed to answer three broad research questions: What is
occurring between the reader and text? What does each occurrence mean in the context of



active reading? How might the findings of this study be translated into explicit, tangible
design?
Cluster analysis and binary logistic regression for the quantitative components
and abductive (grounded theory) and retroductive analytical methods for the qualitative
components of the study revealed that active reading for heavy annotators and strong
advocates of annotating documents involves dynamic, three-dimensional mental and
physical activities. These include 14 thematic categories of re-arranging the original text
hierarchically (HR) to distinguish levels of importance and re-arranging it horizontally by
isolating and foregrounding (TX, SL, EN) and linking (LN) segments; re-designing the
text by tagging (TG), adding to (AR, MN, EV, AD, EX, SH), or detaching from (RV) it;
and manipulating reading environments, including properties of both the media and
physical surroundings (MD).
The study concludes by recommending that ebook devices for heavy annotators
and strong advocates of annotating documents be designed in a way that supports or even
promotes dynamic, three-dimensional mental and physical activities that have not been
fully supported by previous static, two-dimensional text designs. Furthermore, in order to
support such activities holistically, it is recommended that ebook device researchers and
designers come up with new metaphors (e.g., active reading as assembling Lego blocks,
as creating a map while navigating a new city, or as renovating the interior design of a
house) by shifting from the old paradigm of reader-as-consumer of static, linear text to a
new paradigm of reader-as-producer of dynamic text, a paradigm that grants the reader
greater power to manipulate the components of text and medium independently in
different ways.



__________________________
Susan C. Herring, Ph.D.

_________________________
Jeffrey Bardzell, Ph.D.

_________________________
Hamid R. Ekbia, Ph.D.

_________________________
Erik Stolterman, Ph.D.



Table of Contents
Chapter 1. Introduction ....................................................................................................... 1
1.1 Research topic and motivation .................................................................................. 1
1.2 History, definitions, and perspectives on relevant terms .......................................... 2
1.2.1 Ebooks................................................................................................................ 2
1.2.2 Hypertext............................................................................................................ 6
1.2.3 Interaction design ............................................................................................... 8
1.2.4 Active reading .................................................................................................. 12
1.2.5 Annotation(s) ................................................................................................... 18
1.3 Reader-response criticism and three representative approaches ............................. 19
1.3.1 Reader-response criticism ................................................................................ 19
1.3.2 Three representative approaches ...................................................................... 20
1.4 Research questions .................................................................................................. 22
1.5 Outline of the study................................................................................................. 24
Chapter 2. Literature Review ............................................................................................ 25
2.1 Active reading in three disciplines .......................................................................... 25
2.1.1 Active reading in HCI ...................................................................................... 25
2.1.2 Active reading in education ............................................................................. 28
2.1.3 Active reading in literary criticism .................................................................. 33
2.1.4 Conclusion ....................................................................................................... 37
2.2 Methods of research on active reading ................................................................... 39
2.2.1 Active reading in HCI ...................................................................................... 39
2.2.2 Active reading in education ............................................................................. 42



2.2.3 Active reading in literary criticism .................................................................. 45
2.2.4 Conclusion ....................................................................................................... 47
2.3 Summary ................................................................................................................. 49
Chapter 3. Overarching Research Approaches ................................................................. 51
3.1 Naturalistic inquiry (Constructivism) ..................................................................... 51
3.2 Development as a way to integrate quantitative and qualitative components ........ 55
3.3 Methodological approach........................................................................................ 56
3.3.1 Quantitative components: Non-experimental approach................................... 56
3.3.2 Qualitative components: Reader-response criticism ........................................ 57
3.4 Analytical approach ................................................................................................ 62
3.4.1 Quantitative components: Frequency, cluster analysis, and logistical regression
................................................................................................................................... 62
3.4.2 Qualitative components: Grounded theory (abduction) and retroduction ....... 65
3.5 Quality assurance criteria ........................................................................................ 71
3.5.1 Quantitative components: Content validity, reliability, and other practical
criteria ....................................................................................................................... 71
3.5.2 Qualitative components: Trustworthiness........................................................ 78
Chapter 4. Methodology ................................................................................................... 82
4.1 Quantitative components ........................................................................................ 82
4.1.1 Instrumental (online questionnaire) design ...................................................... 82
4.1.2 Data cleaning and analysis ............................................................................... 94
4.2 Qualitative components .......................................................................................... 96
4.2.1 Procedures and settings .................................................................................... 97



4.2.2 Phase 2: Annotation study (document examination) ....................................... 98
4.2.3 Phase 3: First follow-up interviews ............................................................... 109
4.2.4 Phase 4: Video study (distant observation) .................................................... 126
4.2.5 Phase 5: Second follow-up interviews ........................................................... 134
Chapter 5. Results ........................................................................................................... 140
5.1 Quantitative components ...................................................................................... 140
5.1.1 Demographic information about the survey respondents (descriptive statistics)
................................................................................................................................. 140
5.1.2 Characteristics of active reading practices (cluster analysis) ........................ 148
5.1.3 Factors predicting the frequency and the type of annotation (binary logistic
regression) ............................................................................................................... 162
5.2 Qualitative components ........................................................................................ 166
5.2.1 Fourteen thematic categories of reader-text interaction in active reading (as a
result of initial and intermediate coding) ................................................................ 166
5.2.2 Relationships among the fourteen themes of reader-text interaction in active
reading (as a result of advanced coding)................................................................. 186
5.2.3 Numerical characteristics of qualitative components .................................... 196
Chapter 6. Discussion ..................................................................................................... 201
6.1 Quantitative components ...................................................................................... 201
6.1.1 Demographic information about the survey respondents .............................. 201
6.1.2 Characteristics of active reading practices ..................................................... 201
6.1.3 Factors predicting the frequency and type of annotation ............................... 202
6.2 Qualitative components ........................................................................................ 204



6.2.1 Types of reader-text interaction in terms of the three approaches of readerresponse criticism.................................................................................................... 204
6.2.2 Types of reader-text interaction beyond the three approaches of readerresponse criticism.................................................................................................... 205
6.2.3 Readers’ intentions, needs, and desires underlying different types of readertext interaction ........................................................................................................ 205
6.2.4 Translating findings into the design of interactivity: A composition model of
reader-text interaction ............................................................................................. 206
6.3 Summary ............................................................................................................... 212
Chapter 7. Conclusion..................................................................................................... 216
7.1 Summary ............................................................................................................... 216
7.2 Design implications .............................................................................................. 217
7.3 Metaphors for active reading ................................................................................ 219
7.4 Theoretical, methodological, and practical contributions ..................................... 220
7.5 Limitations and directions for future research ...................................................... 223
References ....................................................................................................................... 226
Appendices...................................................................................................................... 241
Appendix A.1: Online questionnaire for the pilot study ............................................. 241
Appendix A.2: Online questionnaire for the larger study ........................................... 247
Appendix B.1: Invitation/recruitment email message for the pilot study with student
participants .................................................................................................................. 253
Appendix B.2: Invitation/recruitment email message (including the link to the online
questionnaire) for the pilot study with faculty members ............................................ 254



Appendix B.3: Invitation/recruitment email message (including the link to the online
questionnaire) for the larger study .............................................................................. 255
Appendix B.4: Second invitation/recruitment email message (including the link to the
online questionnaire) ................................................................................................... 256
Appendix B.5: List of 10 schools and 37 departments that offered both master’s and
doctoral programs at Indiana University Bloomington as of March 22, 2012 ........... 258
Appendix C.1: Reminder email message .................................................................... 260
Appendix C.2: List of ALA-accredited programs (from Table of Contents in the
Directory of Institutes Offering Accredited Master’s Programs, March 1, 2012) ...... 261
Appendix C.3: List of major codes (from Classification of Instructional Programs,
2010, at the National Center for Education Statistics website) .................................. 264
Appendix D.1: Content validity in the initial questionnaire: Omission...................... 266
Appendix D.2: Content validity in the initial questionnaire: Redundancy ................. 267
Appendix D.3: Content validity in the initial questionnaire: Clarity and conciseness 268
Appendix D.4: Test-retest reliability within a participant for the pilot study ............. 271
Appendix D.5: Test-retest reliability for each of the 50 questions for the pilot study 272
Appendix D.6: Duration of survey for the pilot study ................................................ 279
Appendix D.7: Interface design (presentation) of the initial online questionnaire ..... 280
Appendix D.8: Technical problems of survey for the pilot study............................... 281
Appendix E.1: Selecting independent variables for follow-up binary logistic regression
with annotation frequency........................................................................................... 282
Appendix E.2: SPSS Outputs for binary logistic regression with annotation frequency
(with simultaneous entry) ........................................................................................... 289



Appendix E.3: Selecting independent variables for follow-up binary logistic regression
with Annotation Type ................................................................................................. 292
Appendix E.4: SPSS Outputs for binary logistic regression with annotation type (with
simultaneous entry) ..................................................................................................... 299
Appendix F: Invitation/recruitment email message for the annotation study in the
second phase ............................................................................................................... 303
Appendix G.1: Invitation/recruitment email message with multiple options for the first
follow-up interviews in the third phase ...................................................................... 305
Appendix G.2: Invitation/recruitment email message with two options for the first
follow-up interviews in the third phase ...................................................................... 307
Appendix H.1: Preliminary questions for the first follow-up in-person or Skype
interviews in the third phase (with more open-ended questions) ............................... 308
Appendix H.2: Questions for the first follow-up email or Skype interviews in the third
phase (with more guided closed-ended questions) ..................................................... 309
Appendix I: The codebook, after the annotation study and follow-up interviews, for the
video study (distance observation) and its follow-up interviews................................ 319
Appendix J.1: Invitation/recruitment email message to old participants in previous
phases for the video study and follow-up interviews in the fourth and fifth phases .. 347
Appendix J.2: Invitation/recruitment email message to (electronic) mailing lists for the
video study and follow-up interviews in the fourth and fifth phases .......................... 348
Appendix J.3: Invitation/recruitment email message to directors, associate deans, and
secretaries for the video study and follow-up interviews in the fourth and fifth phases
..................................................................................................................................... 350



Appendix J.4: List of schools and departments that offered doctoral programs at
Indiana University Bloomington as of September 5, 2013 ......................................... 352
Appendix K: Scheduling email message to the finalized 22 participants for the video
study and follow-up interviews in the fourth and fifth phases.................................... 354
Appendix L: Instructions for the video study from the IRB study information sheet 355
Appendix M: Information sheet for the video study ................................................... 358
Appendix N: Examples of coding from the pilot study .............................................. 359
Appendix O: An example of observation notes for the video study ........................... 360
Appendix P: Preliminary questions for follow-up interviews in the fifth phase ........ 361
Appendix Q.1: The codebook after the video study and follow-up interviews: Static
(written) annotations/notes.......................................................................................... 362
Appendix Q.2: The codebook after the video study and follow-up interviews: Dynamic
movements .................................................................................................................. 369
Appendix Q.3: The codebook after the video study and follow-up interviews: Other
external activities (beyond one document, one application, or one device) ............... 372
Appendix R: The final codebook ................................................................................ 373
Appendix S: IRB Human Subjects paperwork ........................................................... 382
Curriculum Vitae



List of Tables
Table 1: Strengths of three disciplines in the study of active reading .............................. 38
Table 2: Summary of research questions and methods in the three disciplines of active
reading research ................................................................................................................ 48
Table 3: Summary of three groups of researchers in terms of the flexibility of the
quantitative-qualitative distinction.................................................................................... 54
Table 4: Steps of data analysis (taken from Table 5.1: Steps of Analysis, Stern & Porr,
2011, pp. 62-63) ................................................................................................................ 69
Table 5: Three representative phases of coding (taken from Table 7.1 Phases of coding,
Birks & Mills, 2011, p. 116) ............................................................................................. 70
Table 6: Comparison between pre and post data: Moderate correlations ......................... 76
Table 7: Comparison between pre and post data: Weak correlations ............................... 77
Table 8: Summary of variables used in the questionnaire ................................................ 86
Table 9: The 19 participants for the annotation study and the order of analysis ............ 102
Table 10: Example of initial coding (1) .......................................................................... 106
Table 11: Example of initial coding (2) .......................................................................... 108
Table 12: Example of intermediate coding ..................................................................... 109
Table 13: The 18 participants for the first follow-up interviews .................................... 111
Table 14: Rubin and Rubin’s first type of interview classification (taken from Table 1.1:
The variety of qualitative interviews, Rubin & Rubin, 2005, p. 5) ................................ 115
Table 15: Schedule for participation in the third phase .................................................. 118
Table 16: Example of intermediate coding ..................................................................... 121
Table 17: Intermediate coding: Static annotations/notes ................................................ 123



Table 18: Intermediate coding: Dynamic movements .................................................... 125
Table 19: Intermediate coding: Other external activities ................................................ 126
Table 20: Participants for the video study ...................................................................... 129
Table 21: Summary of thematic categories in the old codebook (after the annotation study
and follow-up interviews) and the new codebook (after the observation study and its
follow-up interviews) ...................................................................................................... 137
Table 22: Thematic categories in the old, the new, and the final codebook ................... 138
Table 23: Frequency and distribution of current location (country) of residence affiliated
with the respondents’ institutions ................................................................................... 141
Table 24: Frequency and distribution of English variations ........................................... 142
Table 25: Frequency and distribution of gender ............................................................. 143
Table 26: Frequency and distribution of age .................................................................. 144
Table 27: Frequency and distribution of academic status ............................................... 145
Table 28: Frequency and distribution of full-time status ................................................ 146
Table 29: Frequency and distribution of major(s) .......................................................... 147
Table 30: Frequency and distribution of annotation/note-taking while active reading .. 149
Table 31: Agglomeration schedule for variable#2 annotation type ................................ 149
Table 32: Re-formed agglomeration table for variable #2 annotation type .................... 150
Table 33: Number of cases in each cluster for variable #2 annotation type ................... 150
Table 34: Final cluster centers for variable #2 annotation type ...................................... 151
Table 35: ANOVA table for variable #2 annotation type ............................................... 151
Table 36: Agglomeration schedule for variable #6 format ............................................. 152
Table 37: Re-formed agglomeration table for variable #6 format .................................. 152



Table 38: Number of cases in each cluster for variable #6 format ................................. 153
Table 39: Final cluster centers for variable #6 format .................................................... 153
Table 40: ANOVA table for variable #6 format ............................................................. 154
Table 41: Agglomeration schedule for variable #7 device ............................................. 154
Table 42: Re-formed agglomeration table for variable #7 device .................................. 155
Table 43: Number of cases in each cluster for variable #7 device ................................. 155
Table 44: Final cluster centers for variable #7 device .................................................... 156
Table 45: ANOVA table for variable #7 device ............................................................. 156
Table 46: Agglomeration schedule for variable #3 place ............................................... 157
Table 47: Re-formed agglomeration table for variable #3 place .................................... 157
Table 48: Number of cases in each cluster for variable #3 place ................................... 158
Table 49: Final cluster centers for variable #3 place ...................................................... 158
Table 50: ANOVA table for variable #3 place ............................................................... 159
Table 51: Agglomeration schedule for variable #4 tool ................................................. 159
Table 52: Re-formed agglomeration table for variable #4 tool ...................................... 160
Table 53: Number of cases in each cluster for variable #4 tool...................................... 160
Table 54: Final cluster centers for variable #4 tool ........................................................ 161
Table 55: ANOVA table for variable #4 tool ................................................................. 161
Table 56: Findings of binary logistic regression with Annotation Frequency................ 163
Table 57: Findings of binary logistic regression with Annotation Type ........................ 165
Table 58: Fourteen themes that explain the nature of reader-text interaction in active
reading............................................................................................................................. 166



Table 59: Grouping the 14 thematic categories as time-wise processes of active reading
(based on the final codebook in Appendix R) ................................................................ 187
Table 60: Grouping the 14 thematic categories in terms of the depth of engagements of
active reading .................................................................................................................. 189
Table 61: Ultimate reasons for reader-text interaction ................................................... 192
Table 62: Goals and ultimate reasons for reader-text interaction ................................... 194
Table 63: Comparison across three types of readers by three devices in the video study
and follow-up interviews in terms of purpose(s), major(s), amount of prior knowledge,
degree of interest, and level of readability ...................................................................... 195
Table 64: Comparison across three types of readers by three devices in the video study
and follow-up interviews in terms of the 14 thematic categories ................................... 197
Table 65: Comparison across individual coding items from the video study and follow-up
interviews ........................................................................................................................ 198
Table 66: Comparison across the 14 thematic categories from the video study and followup interviews ................................................................................................................... 200
Table 67: Answers to the fourth research question: The design of interactivity ............ 208



List of Figures
Figure 1: Three approaches in reader-response criticism (derived from Bressler, 2003, p.
61) ..................................................................................................................................... 59
Figure 2: Use of reader-response criticism (adapted from Figure 3.5: The Inductive Logic
of Research in a Qualitative Study, Creswell, 2009, p. 63) .............................................. 61
Figure 3: Use of grounded theory and retroduction (adapted from Figure 3.5: The
Inductive Logic of Research in a Qualitative Study, Creswell, 2009, p. 63).................... 68
Figure 4: Relationships among variables that affect the nature of reading and annotation
behaviors ........................................................................................................................... 84
Figure 5: Participants in the second phase annotation study .......................................... 100
Figure 6: Annotations on a paper document ................................................................... 104
Figure 7: Annotations on a digital document .................................................................. 104
Figure 8: Notes in separate notepads on paper and in digital format.............................. 105
Figure 9: Participants in both the video study (the fourth phase) and follow-up interviews
(the fifth phase) ............................................................................................................... 127
Figure 10: Technology settings for the video study........................................................ 131
Figure 11: Frequency and distribution of current location (country) of residence affiliated
with the respondents’ institutions ................................................................................... 140
Figure 12: Frequency and distribution of English variations.......................................... 142
Figure 13: Frequency and distribution of gender ............................................................ 143
Figure 14: Frequency and distribution of age ................................................................. 144
Figure 15: Frequency and distribution of academic status ............................................. 145
Figure 16: Frequency and distribution of full-time status .............................................. 146



Figure 17: Frequency and distribution of major(s) ......................................................... 147
Figure 18: Frequency and distribution of annotation/note-taking while active reading . 148
Figure 19: Example of TX .............................................................................................. 168
Figure 20: Example of SL (1) ......................................................................................... 170
Figure 21: Example of SL (2) ......................................................................................... 170
Figure 22: Example of SL (3) ......................................................................................... 171
Figure 23: Example of HR (1) ........................................................................................ 171
Figure 24: Example of HR (2) ........................................................................................ 172
Figure 25: Examples of MN (1) ...................................................................................... 173
Figure 26: Example of MN (2) ....................................................................................... 173
Figure 27: Example of MN (3) ....................................................................................... 174
Figure 28: Example of EN (1) ........................................................................................ 174
Figure 29: Example of EN (2) ........................................................................................ 175
Figure 30: Example of AR (1) ........................................................................................ 176
Figure 31: Example of AR (2) ........................................................................................ 176
Figure 32: Example of AR (3) ........................................................................................ 176
Figure 33: Example of EV (1) ........................................................................................ 178
Figure 34: Example of EV (2) ........................................................................................ 178
Figure 35: Example of EV (3) ........................................................................................ 179
Figure 36: Example of LN (1) ........................................................................................ 180
Figure 37: Example of LN (2) ........................................................................................ 180
Figure 38: Example of LN (3) ........................................................................................ 180
Figure 39: Example of AD (1) ........................................................................................ 181



Figure 40: Example of AD (2) ........................................................................................ 182
Figure 41: Example of EX (1) ........................................................................................ 183
Figure 42: Example of EX (2) ........................................................................................ 183
Figure 43: Example of SH (1)......................................................................................... 184
Figure 44: Example of SH (2)......................................................................................... 184
Figure 45: Example of SH (3)......................................................................................... 184
Figure 46: Example of SH (4)......................................................................................... 184
Figure 47: Advanced coding: A relational map .............................................................. 190
Figure 48: Characteristics of heavy annotators/note-takers ............................................ 202
Figure 49: Characteristics of strong advocates of annotation ......................................... 203
Figure 50: Composite model of reader-text interaction .................................................. 209
Figure 51: Dynamics of a composite model of reader-text interaction .......................... 211
Figure 52: Summary of answers to the four research questions ..................................... 214



“I worry that the superficial way we read during the day is affecting us when we have to
read with more in-depth processing,” said Maryanne Wolf, a Tufts University cognitive
neuroscientist and the author of “Proust and the Squid: The Story and Science of the
Reading Brain.” (Rosenwald, 2014)

Chapter 1. Introduction
1.1 Research topic and motivation
The rate of acceptance of ebooks – books in digital formats – is growing rapidly
(Desilver, 2014; Milliot, 2008; Ramaiah, 2005; Springer, 2008). Yet studies show that for
active (serious) reading, people still prefer to read on paper and employ skimming
strategies when reading from a computer screen (Hillesund, 2010; Liu, 2005; Olsen et al.,
2013; Springer, 2008; Wexelbaum & Miltenoff, 2012). These studies imply that currently
available ebooks are optimized more for skimming than for active reading and thus do
not fully support the needs of people who want to use them for active reading. Of course,
skimming can be an important strategy in active reading – for example, for grasping the
overall structure of a text at the outset. However, reading devices that are optimized
primarily for skimming could hinder the in-depth engagement with text that is associated
with critical thinking. Thus there is a need for new insights into the design of ebook
devices that are optimized for active reading. This calls for investigation into the nature
of active reading itself.
Active reading is the purposeful reading of a skilled or expert reader; it requires
more active processes than other kinds of reading, such as leisure reading. This study



investigates the nature of one key aspect of active reading, reader-text interaction. The
study addresses three broad research questions: What is occurring between the reader and
text during active reading? What does each occurrence mean? And finally, how might the
findings of this study be translated into explicit, tangible design?
1.2 History, definitions, and perspectives on relevant terms
The key terms that are most directly related to the ultimate goals of this study are ebook,
hypertext, active reading, annotation(s), and interaction design. Some of these terms are
difficult to operationalize in practice. Therefore, definitions of each term, as well as its
history and different perspectives, theories, and principles that are associated with it, are
discussed in what follows to establish common understandings before proceeding to the
specifics of this study.
1.2.1 Ebooks
1.2.1.1 History
While the term ‘ebook’ is new, the concepts underlying it have historical antecedents.
The history of ebooks can be traced to the idea of the memex machine envisioned by
Vannevar Bush in his 1945 article As We May Think (Henke, 2003). Bush’s vision of the
memex as “a sort of mechanized private file and library” (Bush, 1945) was followed by
the idea of hypertext (or hypertext link), which is a term coined by Ted Nelson in the
early 1960s (Lambert, Woodford, Poole, & Moschovitis, 2005). Hypertext is discussed
further below.
In 1968, Alan Kay’s Dynabook was proposed as “the first prototype of a computer
hardware device for reading books online” (Henke, 2003, p. 22). Project Gutenberg,
initiated by Michael Hart at the University of Illinois in 1971, was an initiative designed



to produce etexts from a computer and make them replicable. This was referred to as
“Replicator Technology” (Hart, 1992). In the late 1980s, the idea of the World Wide Web,
“the all-time, ultimate e-book,” was proposed by Tim Berners-Lee (Lambert et al., 2005,
p. 85). Sony’s Data Discman, “the first handheld electronic book reader,” was released in
1990 (Lambert et al., 2005, p. 84). In 1998, the Rocket eBook, which resembles a paper
book in form and function, was released by Gemstar (Henke, 2003). Most recently, the
Amazon Kindle and the Sony reader launched a new generation of ebook devices that use
an epaper technology (Golovchinsky, 2008; Nikam & Rai, 2009).
1.2.1.2 Design principles
Some ebook designers/researchers (e.g., Golovchinsky, 2008; Marshall, Price,
Golovchinsky, & Schilit, 2001) argue that Alan Kay’s Dynabook was envisioned as an
ideal ebook device. The design principles that Kay (2000) proposed for Dynabook were
that it should enable children to read, write, draw, and play with ideas, access ideas in
other places, communicate with other children, etc. In other words, Kay envisioned
Dynabook as a dynamic medium that goes beyond static printed books to become an
interactive book.
The theories and concepts that inspired Kay (2002) in his user interface design
included Jean Piaget's theory of cognitive development, Seymour Papert’s learning
theory, and Jerome Bruner’s multiple mentality model. Papert’s argument in his work,
which was built on Piaget’s theory, was that children are able to learn even difficult
concepts (e.g., math) when knowledge is presented to them in a form (e.g., images) that is
consistent with their cognitive development stage (e.g., a visual stage). Bruner’s multiple
mentality model holds that human mentality consists of three separate modes of



representation: enactive, iconic, and symbolic. Putting Piaget, Papert, and Bruner’s
theories and concepts together, Kay (2002) came up with the idea,“[d]oing with images
makes symbols,” (p. 128) as a primary principle of user interface design. That is, people
should start by doing concrete things with images and move into making abstract
symbols through them (Kay, 2002). This principle was later concretized into the Graphic
User Interface (GUI).
Kay (2002) was also influenced by Herbert Marshall McLuhan’s book
Understanding Media (1964) with its famous quote, ‘The medium is the message.’ Kay
(2002) captured McLuhan’s concept in Dynabook in such a way that the computer is
neither a tool nor a vehicle, but a medium that shapes or changes “the thought patterns of
an entire civilization” (p. 125).
1.2.1.3 Definitions
The term ebook has multiple meanings in the literature. In practice, it has been used in
roughly four different ways.
First, some authors regard the ebook as a special type of text in a special format of
a digital medium. Feather and Sturges (1997) define ebook as “a text analogous to a book,
that is in digital form to be displayed on a computer screen” (p. 130). Hughes (2003)
defines ebook as “digital texts that are issued as individual works and designed to be
accessed by using special software for text navigation and ease of reading” (p. 984).
Other scholars consider ebook to be a subset of etext with a different purpose. Bellamy,
Burrow, Coburn, Loi, and Wilkins (2001) define etext as “a digital representation of a
written work that can include video, audio, text, and graphics and may facilitate
interaction by the reader, allowing the reader to directly question and contribute to the



content” (p. 125). Thus, Bellamy et al. (2001) define etext, which is designed for
“viewing and interaction” (p. 125) with an emphasis on a reader’s contribution, as a term
that encompasses an ebook which is designed only for viewing/reading.
Third, Anderson-Inman and Horney (1997) regard etext as a part/component of an
ebook by establishing four criteria that must be met for something to qualify as an ebook:
visually presented etext, sometimes with other media but only for enhancing etext, based
on the metaphor of the print book, and with software as a tool for organizing a theme.
Similarly, Vasileiou, Hartley, and Rowley (2009) argue that the ebook is defined by
incorporating the four features “media, content/file format, device and delivery” (p. 174).
Last, the term electronic book (or ebook) has multiple definitions in standard
dictionaries and in practice. The Oxford English Dictionary (2014) defines an ebook as
“[a] hand-held electronic device on which the text of a book can be read. Also: a book
whose text is available in an electronic format for reading on such a device or on a
computer screen; (occas.) a book whose text is available only or primarily on the
Internet.” The Merriam-Webster dictionary (2014) defines ebook as “a book composed in
or converted to digital format for display on a computer screen or handheld device.” In
practice, Wilson and Landoni (2001) state that electronic book is a term used to refer to
“hardware, software and content” (p. 2). Henke (2003) writes that the term ebook
includes two categories: “a hardware and software device used to read content and the
content itself” (p. 20).
In can be seen that the term ebook has no single clear meaning, which makes it
difficult for ebook designers/researchers to operationalize a definition for practical
application. For this reason, specific terms must be created to distinguish among the



different elements involved. In this study, therefore, four distinctive terms – etext, ebook
software, ebook hardware, and ebook device – are used to reconcile the conflicting
definitions of ebook available in the literature. Etext is defined as text in any digital
format. Ebook software, as opposed to ebook hardware, the physical component of a
device, is defined as a computer software program that facilitates reading on a digital
device, such as Adobe Acrobat Reader or the web-based software at NetLibrary. An
ebook device is defined as a reading appliance that includes the other three components:
etext, ebook software, and ebook hardware, for example a computer screen or the
Amazon Kindle.
1.2.2 Hypertext
1.2.2.1 Contexts
Kitzmann (2006) notes that hypertext has been used in four different contexts: 1) “literary
and artistic hypertext and hypermedia”; 2) “educational uses of hypertext and
hypermedia”; 3) “informational uses of hypertext technology”; and 4) “uses of hypertext
as a general platform for game play” (p. 33). In the first context, according to Kitzmann
(2006), hypertext is used for “purely creative purposes, such as in the creation of fiction
or poetry” (p. 33). The second context is education, with a vision that hypertext helps
students to be active actors in learning through “a dynamic two-way relationship” (p. 44).
In the third context discussed by Kitzmann, hypertext is used as a technology “to enhance
or create collaboration within the workplace” (p. 49). The last context in which hypertext
is used is computer game studies.



1.2.2.2 Definitions
The term hypertext was coined by Ted Nelson (McKnight, Dillon, & Richardson, 1996).
A simple definition of hypertext is more than text, which has nodes and links (McKnight
et al., 1996). Other definitions of hypertext can be derived from three different, but
complementary, viewpoints presented by Vannevar Bush, Doug Engelbart, and Ted
Nelson (Kitzmann, 2006; McKnight et al., 1996). First, Bush envisioned that the memex
device would enable all intellectual products to be linked to each other by utilizing the
principle of association, or human cognitive capability (McKnight et al., 1996). Second,
Engelbart’s Augment system focused more on augmenting or extending human cognitive
capabilities than on utilizing them (McKnight et al., 1996). Finally, Nelson’s Xanadu
system envisioned that a new document could be created, without redundancy, by linking
or bridging existing documents that are mutually exclusive (McKnight et al., 1996).
1.2.2.3 Electronic text vs. hypertext
There appears to be a consensus on the difference between the terms electronic text (or e
text) and hypertext. Namely, hypertext is regarded as a subset of etext. For example,
Dillon (2004) states that electronic text (or digital document) is a term that includes
“hypertext and non- hypertext” (p. 6). In a discussion on humanities computing,1 Willett
(2004, n.p.) classifies hypertext as one of four types of etexts: 1) “an electronic
transcription,” which includes two basic forms: “[a] transcription in the form of a
computer text file” and “a digital image of a physical page”; 2) “encoded text” with
encoding schemes (e.g., TEI); 3) unencoded text without encoding schema (e.g., Plain
Vanilla ASCII); and 4) “hypertext.”

1

Humanities computing is “concerned with the applications of computing to research and teaching within
subjects that are loosely defined as ‘the humanities’” (Hockey, 2004, Introduction section, para. 2).



In this study, hypertext is defined as a kind of etext, or etext with nodes and links.
The scope of hypertext is limited here to hypertext that is directly related to issues of
reading.
1.2.3 Interaction design
This study focuses on one particular aspect, the design of interactivity, because it is
especially relevant to reader-text interaction, in the sense that the design of dynamic
aspects (interactivity) has the potential to enhance reader-text interaction, both in terms of
the active involvement of readers and the contributions of the texts themselves. In order
to help operationalize the design of interactivity, the history, perspectives, and definitions
of interaction design are first introduced, followed by a definition of the design of
interactivity that is proposed for this study.
1.2.3.1 History
The term interaction design was coined by Bill Moggridge and Bill Verplank in the mid1980s and revitalized by Bruce “Tog” Tognazzini in 2003 (Cooper, Reimann, & Cronin,
2007). Saffer (2010) briefly summarizes the history of interaction design. Starting from
an early stage (1830s to 1940s) at which general users needed to adapt themselves to
machines whose usability was not in focus for engineers, it moved to the next stage
(1940s to 1960s) at which other field researchers, such as human factor engineers,
ergonomists, and cognitive scientists, started participating in interaction design. Finally, it
reached a stage (1960s to 1970s) at which engineers started creating more user-friendly
products, such as graphical user interfaces, email, the mouse, the laptop computer,
hyperlinks, virtual reality, and gaming. From the 1980s to the 1990s, the notion of
personal computers shifted from isolated to networked computing, and ubiquitous



computing emerged. In the late 1990s, computers/technology started to penetrate other
electronic appliances, such as cars and dishwashers. Today, the Internet has transformed
from a place where users passively read content to a place where users actively
participate in doing things.
1.2.3.2 Perspectives
Two different viewpoints can be identified as regards the terms interaction design and
user experience design.
First, Garrett (2003) and Saffer (2010) argue that interaction design is a subset of
the umbrella discipline of user experience design, which is concerned with all relevant
elements of user experience – information architecture, visual design, human factors,
industrial design, etc.
Second, Sharp, Rogers, and Preece (2007) observed that interaction design has
been used as a term that encompasses previously narrowly-focused terms such as “user
interface design, software design, user-centered design, product design, web design,
experience design, and interactive system design” (p. 9). According to the second
viewpoint, the purpose of interaction design is not to design users’ experience (Cooper et
al., 2007; Garrett, 2003; Sharp et al., 2007). Rather, the purpose of interaction design is to
design a product or a system to affect the user’s experience (Garrett, 2003; Sharp et al.,
2007). In other words, what should be designed (i.e., product, a system) and what should
be accomplished through design (i.e., human experience) are distinguished.
This is consistent with Unger and Chandler’s (2009) definition of user experience
as “[t]he creation and synchronization of the elements that affect users’ experience with a
particular company, with the intent of influencing their perceptions and behavior” (p. 3).



It is also consistent with Smith’s (2007) definition of interaction design as “shaping our
everyday life through digital artifacts – for work, for play, and for entertainment” (p. xi).
Additionally, this distinction between what should be designed and what should be
accomplished through design is related to three approaches to interaction design
introduced by Saffer (2010), which emphasize different aspects of design. Systems
Design is an approach concerned with issues on the system side. User-Centered Design
and Activity-Centered Design are concerned with issues on the human side (e.g., users’
goals, needs, preferences, activities, tasks).
1.2.3.3 Definitions
A review of the literature reveals that individual definitions of interaction design are not
comprehensive. Also, it is difficult for ebook designers/researchers to operationalize them
for use in practice because it is often unclear what components of an ebook device need
to be designed for what purpose. To operationalize a definition for practical application
and obtain a comprehensive definition, a broad range of definitions from the literature has
been synthesized in this study from three perspectives: kinds of products/system,
parts/aspects of products/system, and parts/aspects of user or human experience.
First, some researchers emphasize kinds of products/system in defining
interaction design. For example, Moggridge (2007) defines interaction design as “[t]he
design of everything that is both digital and interactive” (p. 660) by limiting
products/systems to technology-based products/systems. This is related to ‘the
Technology-Centered View,’ in which interaction design, Saffer (2010) argues, is
regarded as “mak[ing] technology useful, usable, and pleasurable to use” (p. 5).



Second, other researchers emphasize aspects/parts of products/systems in defining
interaction design. Garrett (2003) divides parts/aspects of design into four elements:
surface (visual design), skeleton (interface, navigation, and information design), structure
(interaction design and information architecture), and scope (content requirements).
Cooper et al. (2007) divide the parts/aspects of design into three elements – content,
form, and behavior – by arguing that interaction designers are interested in the design of
behavior, or “the design of interactivity, or form that changes and reacts to input over
time” (p. xxx). Cooper et al. are also interested in how content and form relate to
behavior. This is related to the Behaviorist View in which interaction design, according
to Saffer (2010), is regarded as defining “how products behave and provide feedback
based on what the people engaged with them are doing” (p. 5).
Last, other researchers emphasize different kinds/aspects of user or human
experience in defining interaction design. For example, Sharp et al. (2007) claim that
interaction design is “to support the way people communicate and interact in their
everyday and working lives” (p. 8) by emphasizing communication. This is related to ‘the
Social Interaction Design View,’ in which interaction design is about “facilitating
communication between humans” (Saffer, 2010, p. 5).
User or human experience has also been defined from different perspectives.
Tullis and Albert (2008) emphasize quantifiable, (indirectly or directly) observable user
experience, such as effectiveness, efficiency, satisfaction, behaviors, and attitudes.
McCarthy and Wright (2004) introduces four threads of human experience – the sensual,
the emotional, the compositional, and the spatio-temporal – from a pragmatist approach.
Ihde (1990) proposes four kinds of relations between human and technology – embodied,



hermeneutic, alterity, and background – from a phenomenological perspective. Wright
and McCarthy (2008) include “felt life, emotion, desire, fulfillment” (p. 644), as well as
“activities, practices, tasks” (p. 644) as components of user experience.
To incorporate a broad range of definitions (in interaction design and user/human
experience) and obtain a comprehensive definition, interaction design is defined as the
activities of defining attributes or properties of components in an ebook device to shape
or affect a reader’s measurable and unmeasurable reading experiences. The verb define is
used rather than design to eliminate the potential ambiguity of the term design, which
could also refer to technical or mechanical design in which programmers or engineers are
involved. In particular, this study focuses on the design of behavior (as compared to the
design of static content or form), or “the design of interactivity, or form that changes and
reacts to input over time” (Cooper et al., 2007, p. xxx), as an attribute or a property of
components in an ebook device. This is related to the Behaviorist View in which
interaction design, according to Saffer (2010), is regarded as “focusing on functionality
and feedback: how products behave and provide feedback based on what the people
engaged with them are doing” (p. 5).
1.2.4 Active reading
Active reading is a key concept of this study. In order to help collect meaningful data
about active reading in practice, in the following sections theoretical frameworks about
reading are first introduced, followed by perspectives on and definitions of active
reading. At the end, a definition of active reading is proposed for the purposes of this
study.



1.2.4.1 Perspectives/theories/models of reading
There is no consensus on a single definition of reading (Barnes, 1998). Rather, many
researchers and practitioners of reading argue that different perspectives/theories/models
of reading have their unique values in practice (Tracey & Morrow, 2006). In this study,
three representative perspectives on reading are reviewed.
According to behaviorism (1950s-1990s) and its focus on observable human
behavior as a result of external stimuli, reading is about the observable process of
recognizing letters and words. Goodman (1997) refers to this as the “Word Recognition
(WR) view” (p. 2). Tracey and Morrow (2006) argue that Skinner’s Operant
Conditioning Theory, which is developed from Pavlov and Watson’s Classical
Conditioning Theory and Thorndike’s Connectionism, affects the study of reading, in that
readers’ subskills, such as “phonics, vocabulary, and comprehension skills” (p. 40), can
be improved incrementally by direct instruction.
Viewed through a constructivist lens (1920s-present), reading is the observable or
unobservable process of knowledge (or meaning) construction by individuals’ voluntary,
active engagement (Tracey & Morrow, 2006). Various theories of reading – Dewey’s
Inquiry Learning, Bartlett’s Schema Theory, Rosenblatt’s Transactional/Reader Response
Theory, Psycholinguistic Theory/Whole Language Theory, Flavell and Brown’s
Metacognition, Engagement Theory, Sociolinguistic Theory of Reading, Socio-Cultural
Theory of Reading, Social Learning (or Cognitive) Theory and Critical Literacy Theory –
have been used to explain the process of individuals’ knowledge (or meaning)
construction and their active engagement from diverse (e.g., philosophical, cognitive,
emotional, social, and cultural) perspectives (Tracey & Morrow, 2006).



The perspectives of Information/Cognitive Processing in reading (1950s-present),
which can be traced back to the period of the late 1800s to early 1900s, were revived in
the early 1950s (Tracey & Morrow, 2006). According to these perspectives, reading is
regarded as unobservable mental/cognitive processes (Hiebert & Raphael, 1996).
Bottom-up models of reading (e.g., Gough’s Model & Automatic Information Processing
Model) – also known as “data driven” models of reading (Bruning, Schraw, Norby, &
Ronning, 2004, p. 262) – describe reading as a linear process from a lower level (e.g.,
word recognition) to a higher level of processing (e.g., comprehension) (Tracey &
Morrow, 2006). Conversely, top-down models of reading (e.g., Goodman’s Model) – also
known as “conceptually driven” models of reading (Bruning et al., 2004, p. 262) – regard
reading as a linear process from a higher level to a lower level (Bruning et al., 2004;
Tracey & Morrow, 2006). Interactive models of reading, such as Rumelhart’s Interactive
Model, Stanovich’s Interactive-Compensatory Model, and Kintsch’s ConstructionIntegration Model, describe reading as a simultaneous, interactive process involving both
lower and higher levels of processing (Bruning et al., 2004; Tracey & Morrow, 2006).
In this study, reader response theory as viewed through a constructive lens was
selected over other perspectives/theories/models as an appropriate theoretical framework
for the insight it provides regarding the interactive nature of active reading between the
reader and the text.
1.2.4.2 Perspectives on active reading
There seem to be two opposing viewpoints on active reading. According to Haussamen
(1995), active (purposeful/transforming/analytic/conversational) reading has been
regarded as a separate, distinct reading process from passive

 

(receptive/reactive/informational) reading. However, he argues that active reading and
passive reading are inseparable, not only in initial preliminary reading but also in
thoughtful re-reading. This is consistent with Adler and Van Doren’s (1972) argument
that no reading is completely passive. It implies that relative degrees or different kinds of
reading engagements should be emphasized in distinguishing active reading from passive
reading.
1.2.4.3 Definitions of active reading
In real-life practices, there is no clear distinction between passive and active reading
(Adler & Van Doren, 1972; Haussamen, 1995). However, researchers attempt to
distinguish between them definitionally. To operationalize currently available definitions
for use in practice (i.e., to use a refined definition, which is obtained by synthesizing
complementary definitions, in judging whether a reading practice is referring to active
reading or something else), three perspectives of process-focused definitions, outcomefocused definitions, and process- and outcome-focused definitions are introduced.
Some researchers emphasize the processes of reading, from a behavioral, a
constructive processing, or a cognitive perspective, in distinguishing active reading from
passive reading. For example, Murray (2006) defines active reading as “a term used to
emphasize the dynamic, opportunistic processes observed in non-recreational reading of
expository texts as done by experts and motivated readers” (p. 157). He elaborates that
active reading is “a set of high level reading, searching, problem solving, and
metacognitive skills used as readers proactively construct new knowledge” (p. 157).
Similarly, Flitterman-King (1988) defines an active reader as a person who has a reading
habit of “‘search[ing] into or rang[ing] over’ the literature ‘for the purpose of discovery’”

 

(p. 8). Harris and Hodges (1995) argue that active reading is “constructing meaning from
text by transforming and integrating textual information into existing networks of
knowledge and experience” (p. 4). Marshall et al. (2001) and Morris, Brush, and Meyers
(2007) define active reading narrowly as marking up and annotating documents by
focusing on writing as a part of active reading processes.
Others emphasize the outcomes of reading or the levels of outcomes in
distinguishing active reading from passive reading. For example, Bessey and Coffin
(1941) argue that active reading is “divided into three parts: Understanding the Thought,
Re-expressing the Thought, and Utilizing the Thought” (p. v). These authors also note
that “… the skilful reader will wish to go further than mere comprehension” (p. v).
Ingarden (1973) distinguishes active reading from “ordinary, purely passive (receptive)
reading” (p. 37) by arguing that passive readers stop comprehension at the level of the
sentence and do not arrive at a summary level of the whole text. Similarly, Best, Rowe,
Ozuru, and McNamara (2005) distinguish “deep comprehension” from “reading
comprehension” (p. 66) by using Kintsch’s Construction-Integration Model. They argue
that unlike reading comprehension, which is about constructing meanings from each
sentence in isolation, deep comprehension is about constructing meanings from the whole
text by filling in logical gaps between sentences (i.e., making inferences).
Last, to distinguish active reading from passive reading, Adler and Van Doren
(1972) emphasize two aspects of reading processes and outcomes by dividing reading
into four levels: Elementary Reading, in which child readers stop at the level of
recognizing individual words; Inspectional Reading, in which readers skim systematically
to obtain surface levels of content information within a short period of time; Analytical

 

reading, in which readers read actively and intensively for the sake of understanding
without time constraints; and Syntopical Reading, in which readers examine multiple
books to answer a particular question and further advance its understanding.
In summary, active reading has been regarded as a different reading practice from
passive reading in terms of reading processes and outcomes. Regardless of whether or not
active and passive processes are separable, to operationalize consistent use of the terms in
this study, active reading is defined as a skilled/expert reader’s purposeful/effortful
reading, in which, in order to go beyond the literal level of comprehension, s/he employs
more active processes during reading than when engaged in other kinds of reading such
as leisure reading. This synthesized definition is driven by synthesizing the above
process- and outcome-focused definitions using Sadoski’s three levels of comprehension.
Sadoski (2004) argues that the literary level of comprehension is the level of
understanding explicit meaning in the text; the inferential level of comprehension is the
level of understanding implicit meaning in the text; and the critical, applied, and
appreciative level of comprehension is the level of “finding personal relevance and
significance” (p. 72). More active processes are defined as reading processes in which
readers primarily seek deep comprehension of the writer’s intended meanings in order to
learn or acquire content knowledge, while spending little time memorizing for accurate
recall for tests or recitation, skimming to grasp main topics quickly, or scanning to find
target information. These processes are adapted from Carver’s (1992) five basic reading
processes of “learning,” “rauding,” “memorizing,” “skimming,” and “scanning” (p. 85).
The definition of active reading is derived from a wide range of sources in the literature

 

so as not to be confined to a narrowly-focused definition of active reading as simply a
reading practice that involves annotation.
1.2.5 Annotation(s)
1.2.5.1 History
The term annotations is closely related to the term marginalia in medieval illuminated
manuscripts. Marginalia are defined by the Oxford English Dictionary (2014) as
“[n]otes, commentary, and similar material written or printed in the margin of a book or
manuscript. Also (in extended use): notes, comments, etc., which are incidental or
additional to the main topic.”
Jackson (2001) argues that marginalia have evolved from impersonal and public
(“the Kingdom of Competition”) to personal and social (“the Kingdom of Sociability”)
and from there to personal and private (“the Kingdom of Subjectivity”) (p. 44). More
specifically, she claims that the characteristics of marginalia have evolved from
“impersonal contributions to scholarship” or “aggressive displays of disagreement” (p.
54) aimed to be shared with other scholars or students, to “typically critical (in the sense
of evaluative), personal, and designed to be shared” with close friends (p. 54), to
“predominantly a private affair, a matter of self-expression (p. 73). The invention of
printed indexes, commonplace books, footnotes, the mass production of books, and the
growth of public libraries, according to Jackson (2001), all contributed to the decline of
marginalia.
1.2.5.2 Definitions
Annotation is recognized as a well-known active reading strategy (Blachowicz & Ogle,
2008) and therefore important in this study. Annotation, as a singular form, is defined by

 

the Oxford English Dictionary (2014) as “[t]he action of annotating or making notes”
(n.p.). Annotations, as a plural form, is defined by the Oxford English Dictionary (2014)
as “note[s] added to anything written, by way of explanation or comment” (n.p.). In this
study, annotations include all additional marks other than the original text, such as notes
in page margins, highlights, underlines, and symbols.
Also, unlike as Jackson (2001) argues, annotation(s) are public in some cases
today. For example, annotation tools such as CoNoter and HyperNews have been
developed for collaborative commentary (Marshall, 1997). However, annotation in this
paper is limited mostly to annotation practices related to reading, not collaborative
commentary.
1.3 Reader-response criticism and three representative approaches
1.3.1 Reader-response criticism
Literary criticism is based on the assumption that the meaning of texts can only be
extracted “through the act of interpretation” (Klarer, 2004, p.76). Literary criticism is
interested in analysis, interpretation, and evaluation of literary texts, whereas literary
theory is concerned with the philosophical (or theoretical) assumptions and
methodologies of literary criticism (Bressler, 2003; Klarer, 2004). Different types of
literary criticism use different methodologies and make different philosophical
assumptions in the analysis, interpretation, and evaluation of literary texts. For example,
in analyzing and interpreting the meaning of literary texts and evaluating them,
formalism uses the text itself as the sole source, Marxism brings in social and historical
factors, and reader-response criticism focuses on readers’ responses to the text (Bressler,
2003; Castle, 2007).



One type of literary criticism that is most relevant to active reading is readerresponse criticism. This is because Louise Rosenblatt, who is referred to by Babin and
Harrison (1999) as “the originator of reader-response criticism” (p. 282), emphasized
“the need for active reading” (p. 282) in pedagogy. Also, she argued that the meaning of
text is constructed by readers’ active2 “self-corrective process” (Tyson, 2006, p. 173)
guided by text – with text as “the blueprint and stimulus” (Tyson, 2006, p. 173) – in the
course of reading (Bressler, 2003; Tyson, 2006). Reader-response criticism describes the
nature of the interaction between real or hypothetical readers3 and texts in the process of
reading (Bennett & Royle, 2004). A core tenet of reader-response criticism is that the
meaning of a text is constructed with the reader’s participation, so it emphasizes the
active role of individual readers, who bring their own “personal experience or private
emotions” (Bressler, 2003, p. 58) to the process of reading (Abrams & Harpham, 2005;
Bressler, 2003; Castle, 2007; Tyson, 2006). This assumption is opposed to New
Criticism4’s belief that readers’ experience is guided by the text itself, which is seen as
the most legitimate source for engaging literary meanings (Bressler, 2003; Castle, 2007).
1.3.2 Three representative approaches
One example of categorizing reader-response criticisms is Beach (1993)’s five-fold
taxonomy: textual, experiential, psychological, social, and cultural (Marshall, 2000). In

2

According to Tyson (2006), Louise Rosenblatt contrasts the term “aesthetic” mode, in which readers are
actively engaged in “the emotional subtleties of its language,” with the term “efferent” mode, in which
readers focus only on information in a passive way (p. 173).
3
Tyson (2006) argues that there are two kinds of readers in reader‐response criticism: “Readers” denote
“real people, and “the reader” represents “a hypothetical ideal reader” (p. 187). The ideal reader is “one
who explicitly and implicitly understands all the nuances, terminology, and structure of a text” (Bressler,
2003, p. 270).
4
New Criticism is a theory based on “the view that a work of art or a text is a concrete object that can be,
like any other concrete object, analyzed to discover its meaning independent of its author’s intention or the
emotional state and/or values of either author or reader” (Bressler, 2003, p. 276).



the present study, structuralism, phenomenology, and subjective criticism were selected;
this is another categorization of reader-response criticisms proposed by Bressler (2003)
and Mailloux (1982), among others. There are representative, distinctive groups among
many reader-response criticisms that employ their own theoretical and philosophical
assumptions and methodologies in approaching this common question and interest.
Subjective criticism, an example of reader-focused reader-response criticism, is
an approach that emphasizes the active role of readers in the course of meaning-making,
no matter what text is involved (Tyson, 2006). Subjective reader-response critics take the
position that readers’ “thoughts, beliefs, and experiences” (Bressler, 2003, p. 67) play an
important role in constructing the meaning of text, no matter what text is involved in this
meaning-making process. For example, Norman Holland (as cited in Bressler, 2003),
influenced by Freudian psychoanalysis, has stated that the meaning of text is shaped
differently by an unconscious “individualized identity theme that becomes the lens
through which we see the world” (p. 67), while David Bleich (as cited in Bressler, 2003)
has argued that the meaning of text is constructed collectively by the process of
negotiation among individuals in a group.
Structuralist criticism, an example of text-focused reader-response criticism, is an
approach that emphasizes the active role of text in the course of readers’ meaning-making
process. Structuralist reader-response critics argue that the readers’ prior knowledge of a
sign system (e.g., a road sign) plays a role in constructing textual meaning (Bressler,
2003). They believe that even though readers participate in the meaning-making process,
the text plays an important role in controlling their participation. For example, Gerald
Prince (as cited in Bressler, 2003) argues that three readers – “the real reader,” “the



virtual reader,” and “the ideal reader” (cf. Selden & Widdowson, 1993, p. 50) – can be
identified by analyzing signs in the text (p.64). Roland Barthes, the author of “The Death
of the Author,” believes that there are two kinds of texts (Allen, 2003; Cuddon, 1998;
Schmitz, 2007): “writerly” texts (scriptibles), which require readers’ participation in
meaning-making (i.e., the reader as producer), and “readerly” texts (lisibles), which do
not (i.e., the readers as consumer).
Phenomenological criticism, an example of transaction-focused reader-response
criticism, is an approach that emphasizes the active roles of both readers and text (i.e., the
two parties’ equal participation). Phenomenological reader-response critics believe that
the meaning of text can be constructed only when they have become conscious of and
accepted it through their interactions and transactions with texts, “filling in the gaps in
the text” (Bressler, 2003, p. 65). For example, Wolfgang Iser (as cited in Bressler, 2003)
has claimed that “determinate and indeterminate meanings” (Tyson, 2006, p.174) of text
are constructed as readers’ own horizons of expectations are guided and modified
throughout the process of reading. He also divided the term reader into “implied reader”
and “actual reader” (Selden & Widdowson, 1993, p. 55). According to Tyson (2006),
“determinate” meaning refers to “the facts of the text,” and “indeterminate” meaning
refers to “gaps” in the text (p. 174). Hans Robert Jauss (as cited in Bressler, 2003) also
argues that the meaning of text is constructed according to current readers’ own
consciously accepted horizons of expectation.
1.4 Research questions
To help address the need for new insights and ideas, this study was designed to
investigate the nature of active reading in depth by collecting a variety of behavioral and



non-behavioral data. In particular, this study focused on the nature of reader-text
interaction, one key aspect of active reading, taking into account the complexity of ebook
device design in relation to content, form, and medium in the context of active reading.
The broad questions guiding this research are: What is occurring between the reader and
text? What does each occurrence mean in the context of active reading? How can the
findings of this study be translated into explicit, tangible design?
The specific research questions were framed by three approaches to readerresponse criticism:
1. What types of reader interaction with text occur, as viewed in terms of the three
approaches of reader-response criticism?
2. What types of reader interaction with text occur beyond the three approaches of
reader-response criticism? In other words, what factors beyond the reader or/and
text play a role in active reading?
3. What kinds of reader intentions, needs, and desires underlie the types of reader
interaction with text identified in the answers to the first and the second research
questions?
4. How can readers’ intentions, needs, and desires, as identified in the findings from
the third research question, be translated into “the design of interactivity, or form
that changes and reacts to input over time” (Cooper et al., 2007, p. xxx) in ebook
devices that enhance readers’ interaction with text?
As discussed earlier in section 1.3.2, three approaches to reader-response criticism
are 1) subjective criticism, which emphasizes the active role of readers; 2) structuralist
criticism, which emphasizes the active role of text; and 3) phenomenological criticism,



which emphasizes the transactional or interactional roles of both readers and text. Further
details about how these three approaches are applied in this study are described in chapter
3, “Overarching Research Approaches.”
1.5 Outline of the study
Chapter 2 introduces a body of literature on adult expert readers’ active reading of text in
the three disciplines of HCI, education, and literary criticism and identifies gaps in the
literature. Chapter 3, “Overarching Research Approaches,” describe the methodological,
analytical, and quality-assurance approaches taken to answer the research questions.
Chapter 4, “Methodology,” discusses how this study was designed to include quantitative
and qualitative components and how data in both components were collected and
analyzed. Chapter 5, “Results,” reports both the quantitative and qualitative findings.
Chapter 6, “Discussion,” presents interpretations of the findings, and Chapter 7,
“Conclusion,” discusses contributions of the study, design implications, limitations of the
study, and suggestions for future research.

 

Chapter 2. Literature Review

2.1 Active reading in three disciplines
This section discusses a broad range of issues in active reading in three disciplines – HCI,
education, and literary criticism – in order to explore what aspects of active reading have
been studied and to identify the research gap that will be filled by this dissertation. Its
scope is limited to adult readers’ textual active reading. That is, children’s reading and
reading of multimodal content are excluded from this study.
2.1.1 Active reading in HCI
Active reading is a topic in the study of ereading (electronic/digital reading) device
design studies and annotation tool design. In order to discover ways to serve active
reading experiences, different aspects of ebook devices have been studied.
2.1.1.1 User research, design, and prototype
Schilit, Golovchinsky, and Price (1998) and Price, Schilit, and Golovchinsky (1998)
introduced a new pen-based tablet computer called XLibris (Active Reading Machine),
which was designed specifically to support active reading by maximizing the advantages
of both printed books and ebooks. Later, Marshall, Price, Golovchinsky, and Schilit
(2001) observed reading practices and contexts (e.g., mobility, link-based research,
annotation, organization, writing, collaboration) of law school students in a setting in
which serious reading and writing activities were required for an annual moot court
competition. This research engaged students in evaluating the use of XLibris in their

 

workplaces and invited them to propose design recommendations for the next version of
XLibris.
Similarly, Tashman and Edwards (2011a) introduced a new multitouch tabletop,
called LiquidText, to support active reading while attempting to overcome the limitations
of paper documents. Also, Tashman and Edwards (2011b) investigated knowledge
workers’ active reading practices and contexts associated with LiquidText and other
existing media. They reported a wide range of issues associated with the active reading
process and its practices, such as navigation, annotation, note-taking, retrieval, and sensemaking.
In contrast to earlier studies that dealt with a broad range of issues in higher level
active reading practices and contexts, Marshall (1997) investigated one particular issue,
annotation, by collecting and analyzing annotations in textbooks and identifying their
forms (e.g., underlines, arrows, notes) and their functions (e.g., aiding memory,
interpretation) in order to design better annotation tools. Later, Marshall and Brush (2002,
2004) compared personal annotations on paper with a group’s collaborative annotations
using a web tool in terms of types and frequency of annotation practices to gain insights
into the design of annotation tools that support a smooth transition between individual
and collaborative annotation(s).
Similarly, Hong, Piper, Weibel, Olberding, and Hollan (2012) used an overhead
camera to investigate one particular aspect of active reading, individual readers’ timewise behavioral movements of the body and artifacts at their own desks. Based on their
findings, the authors proposed design features (e.g., visual tracking, pointing, piling,

 

flipping, writing, annotating) that would help implement “feedback mechanisms that
support novel augmented active reading experiences” (p. 222).
2.1.1.2 Evaluation
Morris et al. (2007) compared four different media – paper, two monitors with a
keyboard and a mouse, two pen-enabled monitors with a stylus, and three tablet
computers with a stylus – to determine which medium better supports active reading
behaviors such as annotation, note-taking, navigation, spatial layout, composition, and
ergonomics. They proposed that to support active reading, media should be designed in a
way that combines the unique advantages of each type into a hybrid system.
Also, Golovchinsky (2008) compared software in two existing ebook devices, the
Kindle and the iLiad, to establish which ebook device better supports tasks involved in
active reading, including “annotation, quoting, comparing, information seeking, note
taking, sharing and mobility” (p. 24). He concluded that the iLiad was better than the
Kindle in terms of some criteria (e.g., annotation), but neither device supported the
quoting or comparing activities that are important active reading tasks.
To investigate how different annotation tools affect and provide support for
different aspects of active reading and propose design recommendations for better
computer-based annotation tools, Obendorf (2003) compared a “traditional paper-andpencil” tool and “two existing annotation tools for the World Wide Web” (p. 120) in
terms of number of annotations, annotation habits, preferences, problems, and quality of
summaries of documents. He found that participants who used paper produced higher
numbers of annotations and higher quality summaries of documents and concluded that

 

paper was a much better tool for active reading than the two computer-based annotation
tools.
Similarly, Zhao et al. (2014) collected a wide range of data including think-alouds,
experimental observations, and interviews to compare one task of active reading,
information revisitation, across three different media, paper, desktop, and paper-based
interactive system, from both quantitative (e.g., time for locating target information) and
qualitative (e.g., advantages and disadvantages of different media) perspectives.
In conclusion, active reading research in HCI has focused on user research, design,
and evaluation of active reading or ereading devices. Its emphasis lies more on behavioral
aspects (e.g., mobility, navigation, spatial layout, ergonomics) than on cognitive and
social aspects of active reading (e.g., information-seeking, cross-linking, collaboration).
2.1.2 Active reading in education
Terms associated with active reading in the education literature include active reading
strategies, reading comprehension strategies, active comprehension, strategic reading
comprehension, deep-level comprehension, and active engagement in comprehension.
The focus of active reading in education is mainly on instructional strategies or
interventions that promote students’ active non-recreational reading comprehension and
help students go beyond the literal level of comprehension.
2.1.2.1 Reader-focused interventions
A number of instructional strategies or interventions – including metacognitive skills;
Survey, Question, Read, Recite, Review (SQ3R); Known, Want-to-Know, Learned (KW-L); Directed Reading-Thinking Activity (DR-TA); anticipation guides, writing, and
collaborative strategic reading (Heilman et al., 2001) – have been developed to foster or

 

teach active reading and comprehension strategies. Many studies have examined the
effects of these instructional interventions on such processes as metacogntive awareness
and use of reading strategies and such outcomes as recall, answers to open-ended or
multiple-choice questions, essay writing, reading rate) in lab or classroom settings or in
digital environments.
Some researchers have focused on the effects of individual active reading
strategies on reading processes or outcomes. Frase and Schwartz (1975) studied the effect
of a question and answering strategy on recall of prose. Marino, Gould, and Hass (1985)
examined the effects of writing on recall of narrative text. Afflerbach (1990) investigated
the relationship between prior knowledge and reading strategies. McLain (1993)
attempted to understand the effect of ‘the KW-L strategy’ and ‘the Predicting/Evaluating
strategy’ on metacognitive awareness and reading achievement. Loxterman, Beck, and
McKeown (1994) examined the two factors of ‘think-aloud’ and ‘text coherence’ in terms
of recall and comprehension. The major findings of these studies were that overall active
reading strategies helped students obtain desirable outcomes.
Other studies have examined the effects of active reading programs on students’
reading processes or outcomes. O’Reilly, Best, and McNamara (2004) and O’Reilly,
Taylor, and McNamara (2006) investigated the effect on comprehension of a science text
of a reading intervention, Self-Explanation Reading Strategy Training (SERT), which is
designed to “train[ ] readers to use active reading strategies to self-explain difficult texts
more effectively” (McNamara, Levinstein, & Boonthum, 2004, p. 222). O’Reilly,
Sinclair, and McNamara (2004) examined the effects of two programs on comprehension:
SERT, the original version developed by McNamara, and Interactive Strategy Training



for Active Reading and Thinking (iSTART, n.d.), a web-based program derived from
SERT (McNamara et al., 2004). The major findings of studies about active reading
programs were that, overall, active reading programs were beneficial to students’ reading
processes and achievement.
2.1.2.2 Text-focused interventions
Text-focused strategies or interventions have been developed to foster students’ active
reading by helping them utilize features inherent in the text (e.g., text structures and
readability5) or that enhance the nature of text (e.g., hypertext) in the course of active
reading. Both empirical and analytical6 studies have examined the effects of these
instructional strategies on processes and outcomes on reading comprehension in labs,
classroom settings, and in digital environments.
Several researchers have investigated the effects of text characteristics on reading
processes or outcomes. Overall, well-organized and cohesive text affects reading in a
positive way. For example, Meyer and Freedle (1984) compared two types of discourse
in terms of recall: “the more organized discourse types of comparison, problem/solution,
and causation” versus “a collection of descriptions” (p. 121). They found that the
collection of descriptions was less effective than the other types in terms of learning and
memory. Similarly, Britton and Gülgz (1991) evaluated “cohesive” and “less cohesive”
texts in terms of free recall, reading rate, and comprehension as measured with multiple-


5

Readability, according to Heilman, Blair, and Rupley (2001), is “the approximate difficulty level of
written material” (p. 418). These authors argue that readability “depends on factors inherent in the text
(e.g., sentence structure, organizational pattern, physical presentation of the material, and vocabulary), the
reader (knowledge of text structures, interest in the subject, and prior knowledge of a topic), and the teacher
(the presentation)” (p. 421).
6
Analytical studies here refer to studies that are not empirically based, but rather are derived from theories
or/and analysis of empirical studies (e.g., Murray, 2006).



choice questions. They also concluded that cohesive text was better than less cohesive
text in terms of reading outcomes.
However, well-organized and cohesive text does not necessarily produce positive
reading outcomes. Other factors, such as reading skills and prior knowledge, affect
readers’ outcomes in different ways. For example, Liederholm et al. (2000) examined
how “easy” and “difficult” history texts with and without repairs in causal structure
affected less- and more-skilled readers’ comprehension. They concluded that moreskilled readers did not obtain benefits from easy texts with causal structure repairs.
Similarly, McNamara (2001) investigated the relationship between “high”- and “low”knowledge readers and “high”- and “low”-cohesive texts. She found that skillful readers
with high knowledge learn less from easy texts than from difficult texts.
Unlike previous studies of how to support active reading in printed books, Murray
(2006) discussed how to support active reading in “hyperbook,” an ebook, using
MetaLinks software, which has been developed to facilitate and scaffold “behavioral,
cognitive, and metacognitive active reading skills” (p. 156) by borrowing active reading
strategies that have been developed for printed books.
2.1.2.3 Engagement-focused interventions
Much research focuses mainly on cognitive aspects of reading engagement (Rueda,
MacGillivray, Monzó, & Arzubiaga, 2001). However, reading researchers have also
started to look at other aspects of reading engagement, including its motivational and
social aspects (Baker, Dreher, & Guthrie, 2000; Guthrie & Anderson, 1999; Rueda et al.,
2001). Guthrie and Anderson (1999) define reading engagement as “the joint functioning
of motivation, conceptual knowledge, strategies, and social interactions during literacy



activities” (p. 20). Rueda et al. (2001) broaden the scope of reading engagement by
connecting sociocultural factors (e.g., family/community) with reading engagement and
achievement. In this context, the purpose of instructional interventions is increase
students’ reading achievement by promoting their reading engagement (Baker et al.,
2000). They describe engaged readers as those who read frequently and widely “for
interest, enjoyment, and learning” (p. 2).
Several empirical studies have been focused on the factors that affect reading
engagement, reading motivation, reading activities, and reading achievement indirectly or
directly.
Guthrie, Schafer, Wang, and Afflerbach (1995) found that the interplay of all four
factors, instructional styles, social interaction, cognitive strategy use, and home literacy,
affects the amount and breadth of students’ reading activities, both indirectly or directly.
Similarly, Guthrie, Wigfield, Metsala, and Cox (1999) found that reading motivation is a
good predictor of reading amount, which is a good predictor of text comprehension.
Rueda et al. (2001) investigated the relationship between teacher- and studentdirected instructional styles and students’ engagement as shown, for example, in the use
of reading strategies, they found that there was no major difference between the two
styles in their relationship to students’ engagement. They also examined the relationship
between family cultures, represented by such factors as parental encouragement and
domestic workload, and students’ reading motivation and achievement. They found that
family cultures featuring a positive view of immigration and bilingualism, access to
knowledge about school, emotional support of children, and low childcare workload were
positively associated with students’ high reading motivation and reading achievement.



In conclusion, active reading research in education focuses on instructional
interventions and their effects on active reading processes and outcomes. Its emphases
are on a wide range of aspects of active reading including cognitive, emotional, social,
and cultural aspects, such as recall ability, motivation, social interaction, and home
literacy, but there has been little focus on behavioral aspects.
2.1.3 Active reading in literary criticism
A fundamental question posed from the perspective reader-response criticism is “what
occurs when a text and a reader interact or transact” (Bressler, 2003, p. 62). Many readerresponse researchers have analyzed hypothetical readers’ responses to literary texts,
while others have empirically studied real readers’ responses to such texts (Tyson, 2006).
For example, Booth (1961) and Iser (1978) conducted reader-response studies with
hypothetical readers (Miall, 2009), whereas Richards (1929), Bleich (1978), Fish (1980),
and Holland (1975) carried out empirical studies with real readers (Bortolussi & Dixon,
2003; Marshall, 2000).
There is a debate between the two parties in relation to the value of empirical
studies. On one hand, Culler argued against empirical studies, insisting that “the question
is not what actual readers happen to do but what an ideal reader must know implicitly in
order to read and interpret works in ways which we consider acceptable, in accordance
with the institution of literature” (1975, pp. 123-4; cf. 1981, p. 129), On the other hand,
Miall argued against purely theoretical, critical studies, asserting that “most literary
theorists lacked understanding of, or sympathy with, empirical methods” (1990, p. 323;
cf. 2006, pp. 11-22). Iser, in The Act of Reading: A Theory of Aesthetic Response (1978),



took a moderate position in this tension by attempting to establish “a framework for
mapping out and guiding empirical studies of reader reaction” (p. x).
One stream of reader-response criticism, which was derived from the work of
Richards (1929), was empirical (Marshall, 2000). The other stream of reader-response
criticism, which was derived from the work of Louise Rosenblatt (1938), was theoretical
and concerned literature education (Marshall, 2000). Her theory has subsequently been
cited in empirical investigations (Marshall, 2000; cf. Blake & Blake, 2002; Cooper, 1985;
Karolides, 2000; Many & Cox, 1992; Probst, 2004). This approach employs research
methods which, as Marshall (2000) has stated, are “largely derived from the social
sciences, shifting over time with changing research paradigms, borrowing early on from
psychometric models, and more recently from anthropology” (p. 389).
In this section, three empirical studies exemplifying these two streams of readerresponse criticism and the three representative approaches in section 1.3.2 are introduced.
Holland’s (1975) and Fish’s work (1980), which belong to reader-focused and
transaction-focused reader-response criticism, are introduced as representing the critical
tradition in studying response to literature, whereas Andringa’s work (1996), which
belongs to text-focused reader-response criticism, represents the empirical tradition,
borrowing research methods from the social sciences (Marshall, 2000). Andringa’s
research, therefore, supports critics who, like Fludernik (2009), argue that “reader
response findings should be cross-checked and validated” (p. 19).
2.1.3.1 Reader-focused reader-response criticism
As Selden and Widdowson (1993) point out, Holland, in 5 Readers Reading, (1975),
expressed concern about “the interplay between the reader’s identity theme and the text’s

 

unity” (p. 65). Marshall (2000) described Holland’s work as resembling “elaborately
detailed psychiatric case studies” (p. 388). Holland (1975) conducted in-depth interviews
with five individual students on a weekly basis, asking them to tell about their own
voluntary responses (e.g., feelings and thoughts) about stories and also to answer his
general and specific questions, such as “How do you feel about characters, events,
situations, or phrasings” and “Do you feel that Miss Emily took on some of her father’s
characteristics as she grew older?” (p. 44). He transcribed interviews along with his own
nuanced observations of “facial expression, gesture, stance, manner, and the like” (p. 45)
while students were sharing their responses. He analyzed students’ comments utilizing
psychoanalysic techniques to “reveal the dynamics of the ego” behind the comments (p.
45). He identified four principles of literary experience, which he called “the inner
dynamics of the reading experience,” (p. 113): 1) readers enjoy reading the text
depending on how similar they are to characters in the text; 2) readers accept characters
as filtered through their defense and adaptation mechanisms so as not to threaten their
identity; 3) after readers have finished such filtering processes, they project their
fantasies/wishes onto the text; and 4) readers’ fantasies/wishes are transformed into their
literary interpretation (cf. Winner, 1982, pp. 279-280). He called it DEFT standing for
“defense, expectation, fantasy, and transformation” (p. 402).
2.1.3.2 Text-focused reader-response criticism
Unlike other critics, Gerald Prince distinguished between reader and narratee in studying
novels (Selden & Widdowson, 1993). Andringa (1996)’s study, recommended by Prince
(2003) as an empirical study, is introduced in this section as representing text-focused
reader-response criticism. In order to understand whether the presentation of narrative

 

texts affect readers’ emotional involvement in characters and appreciation of stories,
Andringa designed two experiments with two short stories Borges’ Emma Zunz and
Chekhov’s Serious emotions. In her experiments, she prepared two versions of a short
story with and without the narrator’s direct commentary and asked participants, who
included both experienced and inexperienced readers of literary texts, to read them and
rate their emotional involvement in the characters and appreciation of the story on a 4point or 5-point scale in response to such questions as “How did you feel about Emma
and what she did?” “How did you like the story?” Based on statistical analyses, she
concluded that only readers’ appreciation of the stories was affected by the narrator’s
direct presence.
2.1.3.3 Transaction-focused reader-response criticism
As Selden and Widdowson (1993) point out, Fish, like Iser, was interested in a
transactional adjustment nature of reading, but Fish was concerned about “the
immediately local level of the sentence” (p. 58) or “read[ing] sentences word by word in
a temporal sequence” (p. 59). In order to argue for his theory that whether readers’
interpretations converge or diverge depends on whether they belong to the same or
different interpretive communities, Fish introduced his anecdotal empirical approach in
the chapter “How to Recognize a Poem When You See One” in the book Is There a Text
in This Class?: The Authority of Interpretive Communities (1980). As one anecdotal
example, Fish first showed a list of the surnames of five linguists correctly spelled and
one literary critic misspelled in addition to a question mark, arranged vertically to look
like a poem, to students of 17th century English religious poetry. Next, he told them that
it was a religious poem and asked them to interpret it. Fish described the progressive

 

development of students’ interpretations from regarding the list as “a hieroglyph,” (p.
324) to construing it as “an iconographic riddle” (p. 324), to “discern[ing] larger
structural patterns” (p. 325) and resolving contradictions. He concluded that students’
interpretations were possibly being made from the perspective of their interpretive
community, in which, as “members of a literary community they knew what a poem was”
(p. 332). At the end, he defended the trustworthiness of his experimental classroom study,
arguing that “I have duplicated this experiment any number of times at nine or ten
universities in three countries, and the results are always the same” (p. 327).
In summary, active reading research in literary criticism focuses on understanding
the nature of reader-text interaction. Its emphasis lies on interactional aspects of active
reading, for example, factors or mechanisms involved in readers’ reading experience or
interpretations of literary texts, rather than behavioral, cognitive, emotional, social, and
cultural aspects of active reading on which HCI and education have focused.
2.1.4 Conclusion
As summarized in Table 1, the emphases and therefore the strengths of active reading
research in the three disciplines included in this study are as follows: 1) in HCI, the
behavioral aspects of active reading (e.g., mobility, navigation, ergonomics); 2) in
education, the cognitive, emotional, social, and cultural aspects of active reading (e.g.,
recall, motivation, social interaction, home literacy); and 3) in literary criticism, the
interactional aspects of active reading (e.g., processes or factors involved in readers’
reading experiences or interpretations).
To obtain useful insights into the design of ebook devices that best serve active
reading, the aim of this dissertation research has to create a research design that

 

minimizes the gaps in HCI active reading research by utilizing the strengths of research
in education and literary criticism. Therefore, this dissertation study was designed to
investigate the nature of reader-text interaction in-depth, which is the weaknesses of
active reading research in HCI but the strength in literary criticism, from a wide range of
aspects, which is the strength of active reading research in education.
Table 1: Strengths of three disciplines in the study of active reading
Disciplines

Emphasis or Strength

HCI

Behavioral aspects of
active reading (rather
than cognitive and social
aspects of active reading)

Education

Cognitive, emotional,
social, and cultural
aspects of active reading

Dependent Variables/
Observed Phenomena
Mobility, link‐based research, annotation,
organization, writing, collaboration (Marshall et al.,
2001)
Navigation, annotation, note-taking, retrieval, sensemaking (Tashman & Edwards, 2011b)
Annotation, note‐taking, navigation, spatial layout,
composition, ergonomics (Morris et al., 2007)
Annotating, quoting, comparing,
information‐seeking, note‐taking and cross‐linking,
sharing, and mobility (Golovchinsky, 2008)
Behavioral movements of the body and artifacts
(Hong et al., 2012)
Annotation
(Marshall, 1997; Marshall & Brush, 2002, 2004;
Obendorf, 2003)
Information revisitation (Zhao et al., 2014)
Recall (Frase & Schwartz, 1975; Loxterman et al.,
1994; Marino et al., 1985)
Reading strategies (Afflerbach, 1990)
Metacognitive awareness and reading achievement
(McLain, 1993)
Reading comprehension (Loxterman et al., 1994;
O’Reilly et al., 2004, 2006)
Reading engagement, reading motivation, and
reading achievement (Rueda et al., 2001)
Amount and breadth of reading activities in terms of
instructional styles, social interaction, cognitive
strategy use, and home literacy (Guthrie et al., 1995)





 

Table 1: continued
Disciplines
Literary
criticism

Emphasis or Strength
Interactional aspects of
active reading

Dependent Variables/
Observed Phenomena
Four principles of literary experience (Holland,
1975)
Relationships between the presentation of literary
text and readers’ emotional involvement and
response (Andringa, 1996)
Interpretive communities as a factor that shapes
readers’ interpretations (Fish, 1980)

2.2 Methods of research on active reading
This section summarizes research methods used for the study of active reading in the
three disciplines of HCI, education, and literary criticism. This section is to address how
this dissertation study filled in a gap in research methods in studying active reading by
highlighting efforts and strategies to enhance the strengths of representative methods and
overcome limitations of them that the three disciplines have used to understand different
aspects of active reading.
2.2.1 Active reading in HCI
Two main methods, experiment and ethnography, have been used to answer different
kinds of research questions in the study of active reading in HCI. Two representative
studies of each method are discussed in detail below.
2.2.1.1 Lab-based experiments
The experimental method, the purpose of which is to “test the impact of a treatment (or
an intervention) on an outcome, controlling for all other factors that might influence that
outcomes” (Creswell, 2009, pp. 145 -146) and disclose causal relations (Lazar, Feng, &
Hochheiser, 2010), was used in the first study to answer questions about how specific



design features (software) and specific properties of hardware affect active reading
behaviors.
Morris et al. (2007) designed an experimental study to understand how four
different kinds of reading devices – paper; two monitors with a keyboard and a mouse;
two tablet computers with a stylus pen, a mouse and a keyboard; and three tablet
computers with a stylus pen – affect participants’ active reading behaviors. These
researchers brought 12 participants into a lab, held a tutorial session about how to use the
targeted design features (e.g., a highlighting tool), asked them to write a summary of a
news article to foster active reading, and collected quantitative and qualitative data,
including annotations and note-taking, navigation, special layout, composition, and
ergonomics. These data were collected through a think-aloud protocol, observations (with
pre-defined coding schema), and quantitative and qualitative questionnaires.
Morris et al. used only 12 participants in a controlled setting. Therefore, the
findings of their study cannot be generalized across different populations in real-world
settings. However, an attempt to overcome the artificiality of the experimental study
seems to have been made by selecting tasks familiar to participants in their workplaces.
Moreover, as triangulation is one strategy for maximizing the validity (a.k.a.
credibility) of qualitative findings (Creswell, 2009), Morris et al. seem to have attempted
to maximize validity by triangulating multiple sources of data using multiple methods.
For example, a think-aloud protocol is good for collecting data that are not easy to be
accessed by a third person. However, it relies heavily on participants’ verbal protocols
(Lazar, Feng, & Hochheiser, 2010). In order to reconfirm findings from the think-aloud
protocol, Morris et al. also used observations using pre-defined coding schemes drawn



from a similar study and a pilot study. Last, as mixed methods is an approach that utilizes
strengths of quantitative and qualitative research (Creswell, 2009), Morris et al. used both
quantitative (rankings of preferences for each setting on a scale of 1 to 4) and qualitative
(open-ended) questionnaires eliciting participants’ experience with each device.
2.2.1.2 Ethnography
Ethnography, which Creswell (2009) has described as “a way of studying a culturesharing group as well as the final, written product of that research” (p. 68) and well suited
for answering why, how, and what questions (Duke & Mallette, 2004), was used in the
second study to understand active reading practices and contexts in natural settings and
obtain insights into the interaction design of ebook devices.
Marshall et al. (2001) collected qualitative data in a law school as a natural setting
where active reading and its relevant tasks take place. The goal of their research was to
understand active reading practices and contexts. Throughout a three-month annual moot
court competition, they observed active reading tasks including reading and writing of
law school students as they prepared to participate, interviewed the students at their
workplaces such as the law library and dorm rooms, and analyzed their reading materials
with annotations. The researchers collected students’ comments by asking them to
interact with an ebook device that they designed for active reading, called XLibris, and
then conducted brief semi-structured interviews in their workplaces. The purpose of
conducting the semi-structured interviews in their workplaces was to obtain more situated
(i.e., more natural) data in authentic practices and contexts.
Marshall et al. attempted to arrive at a deep understanding of law students’
contexts and practices, which is not possible using an experimental study, by collecting



multiple data from multiple sources (e.g., observation, interviews, and artifacts) over a
long period of time. However, as a limitation of ethnographical research, data analysis
and interpretations rely heavily on the researchers’ subjective judgments (Babbie, 2007).
In an attempt to overcome this limitation, which Steinke (2004) described as “the risk of
randomness and arbitrariness” (p. 185), Marshall et al. conducted follow-up interviews
and applied findings of other similar studies to reconfirm their interpretations.
Marshall et al. also examined participants’ contexts and practices first in real
settings and tested later using follow-up interviews whether the features and functions of
their pre-existing device XLibris were consistent with their findings. As the authors
argued, it was good to obtain novel insights from participants with no influence from
their pre-existing device XLibris. However, because the participants did not use the
device in natural settings, the data were not well situated, suggesting that collecting these
data from participants after they had used the device in their own contexts would have
been preferable to collecting data with semi-structured interviews for maximizing
generalizability.
2.2.2 Active reading in education
Active reading studies in education typically aim to answer research questions about the
effects of instructional interventions on students’ active reading processes, outcomes, and
engagement. Therefore, many researchers use the experimental method, which is well
suited to “determine whether or not a given treatment caused a given effect” (Duke &
Mallette, 2004, p. 117) and requires “a deliberate attempt to administer a treatment in
order to observe the effects of that treatment” (p. 116).



2.2.2.1 Lab-based (true) experiments
Loxterman, Beck, and McKeown (1994) designed two experimental studies in order to
understand the effects of text coherence (a text-based intervention) and active
engagement/think-aloud (a reader-based intervention) on reading comprehension. In the
first experiment, the researchers established four experimental conditions: silent reading
(i.e., passive engagement) with less coherent text; silent reading with more coherent text;
thinking-aloud while reading (i.e., active engagement) with less coherent text; and
thinking-aloud while reading with more coherent text. The researchers assigned 22
students to one of the four conditions, using stratified random selection based on reading
comprehension test results. They asked each group to read less or more coherent text
passages silently or aloud, tested recall and asked open-ended questions, and analyzed the
data quantitatively and qualitatively. In the follow-up experiment, Loxterman’s group
employed the same procedures as in the first experiment, but this time they investigated
learning instead of recall by examining the effects of text coherence and active
engagement/think-aloud on delayed retention of information and on high- and low- levels
of reading comprehension.
Lexterman et al. used a highly controlled experimental study with a small number
of participants. Therefore, their findings cannot be generalized across different
populations in real contexts. However, the highly-controlled settings allowed the
researchers to have high confidence in confirming causal relationships between text
coherence and think-aloud protocols, the independent variables, and reading
comprehension and retention, the dependent variables.



Unlike quasi-experiments, which employ convenience sampling (Creswell, 2009),
Lexterman et al. study used random sampling, a characteristic of true experiments that
helps ensure that the results are not influenced by selective bias.
2.2.2.2 Classroom-based (quasi-) experiments or natural experiments
O’Reilly et al. (2006) conducted a quasi-experimental study with 465 students from 19
classrooms in three high schools, whom they divided into treatment (Self-Explanation
Reading Training or SERT) and control groups. They tested students’ prior knowledge
before at the beginning of the experiment, held a training session with the treatment
group, and compared the reading comprehension levels of the treatment (with SERT) and
the control (without SERT) groups.
O’Reilly et al. conducted a classroom-based natural experiment with a large
number of participants to overcome the limitations of lab-based experiments with a small
number of participants. Therefore, the findings of this study could be more confidently
generalized across different populations in real-world settings than could those of labbased experiments.
However, because this experiment did not take place in highly controlled settings,
it is hard to conclude that the study’s findings are causally related to the reading program
(SERT). In other words, a powerful advantage of true experiments (i.e., disclosing causal
relationships) can be easily weakened. Also, this quasi-experiment did not employ
random sampling. Therefore, it is possible to interpret the outcomes as having been
affected by the two groups’ unequal reading comprehension skills (i.e., an uncontrolled
factor).



2.2.3 Active reading in literary criticism
Klarer (2004) has argued that the purpose of active reading studies in literary criticism is
to understand “why, where, and when it [a text] is read” and “certain reading practices of
social, ethnic, or national groups,” in order to explain “the physiological aspect of the
actual reading process” and “certain mechanisms which are employed in the
transformation of the visual signs on paper into a coherent, meaningful text in the mind of
the reader” (p. 92).
Richards’ seminal empirical work (1929) and the recent empirical work of
Therman (2008) both employed document examination, a qualitative data collection
method used with not only historical documents but also documents written by living
writers (Potter, 1996). Also, both utilized a common two-step procedure of giving readers
a text-related task and regarding their performance as representing reader responses
(Bressler, 2003; Mailloux, 1982). However, they took different approaches in that the
earlier approach was more exploratory and the other more confirmatory, terms used
relatively because, as Gerring (2001) observed, “there are no purely confirmatory or
purely explanatory research designs” (p. 234). Confirmatory analysis techniques, which
are also used in qualitative research, are, Tashakkori and Teddlie (2003) point out,
conducted to “test hypotheses” and “increase the credibility of the results from the initial
study” (p. 363).
2.2.3.1 Document (essay) examination with a more exploratory approach
In Practical Criticism: A Study of Literary Judgment, Richards (1929) described
providing his students at Cambridge University with versions of poems that varied in
editorial changes, such as spelling and pronunciation. He asked the students to write



“their free responses to and evaluations of” each poem and collected their introspective
reports7 (as cited in Bressler, 2003, p. 59). Free responses, according to Richards, are
those in which students “comment freely in writing” without any information about the
authors provided by the researcher (p. 3). Richards interpreted these written reports in
two ways: by following “a train of thinking that seems to end where he [a participant]
ended,” but not tracing “what happened in his mind” (p. 6); and by contemplating “the
motives or mechanisms that have caused him [a participant] to say it” (p. 6), if it is
judged that s/he has not been honest in her or his responses. In discussing the findings of
the study, Richards reports on “the ways in which it [poetry] may be approached,
appreciated and judged” (p. 10) by connecting readers’ responses with characteristics of
the poetry or readers’ own thoughts and motives. For example, the meter and verse-form
of poetry are interpreted as causes of readers’ misunderstanding. Another finding is that
readers’ beliefs affect how they read religious poetry.
2.2.3.2 Document (questionnaire) examination with a more confirmatory approach
Unlike Richard’s study, which was more exploratory, Therman’s (2008) study was more
confirmatory. To justify her first argument that Holland, Bleich’s, Iser’s, and Fish’s
theories were based upon “implausible assumptions related to language” (p. 103) and her
second argument that readers’ different understandings of the same text are not
necessarily idiosyncratic, she collected written responses to three short stories from 27
undergraduate or graduate students using a questionnaire she devised. After collecting all
responses from all participants, she identified common themes that were shared by
several participants (e.g., “Coutts is afraid of Winifred”, p. 43), unique themes that were

7

The phrase “introspective reports” (p. 817) is taken from an article by Strang and Rogers (1965) that
discusses Richards’ method.



shared by a few participants, and exceptional themes that were expressed by only one
participant. Also, she identified participants’ explanations for their interpretations (e.g.,
“Coutts’ fear is related to the desire he feels for her”, p. 44) and their related passages in
the texts. From this evidence, she concluded that her two arguments were supported by
findings of her study.
The deep interpretation of participants’ writings in both studies provides useful
insights, illustrating one of the strengths of qualitative research. However, a limitation of
both studies is that data interpretation relies on a single author’s subjective interpretation.
Therefore, their trustworthiness can be questioned. However, in order to establish
trustworthiness, Richard and Therman used multiple sources of data from participants
and thick description of findings, as Creswell (2009) suggested. Also, in order to increase
trustworthiness, they documented all details of their procedures, as Yin (2003) suggested.
2.2.4 Conclusion
A review of the literature revealed that in order to answer a range of research questions
about active reading in the three disciplines, researchers in each discipline have made
efforts to enhance strengths or overcome limitations of particular research methods.
These are summarized in Table 2.



Table 2: Summary of research questions and methods in the three disciplines of active
reading research
Disciplines

HCI

Research
questions
How do specific
design features
(software) and
specific properties
of hardware affect
active reading
behaviors?
What are the
unique
characteristics of
active reading
practices and
contexts?

Education

Literary
criticism

Do instructional
interventions have
a positive impact
on students’
reading processes
and outcomes?

What kinds of
reader responses
exist?
How are those
reader responses
constructed?

Methods

Lab‐based
experiments;
Observations,
think‐aloud
protocols,
questionnaires
(Morris et al.,
2007)
Ethnography;
Observations
(Marshall et al.,
2001)

Lab‐based
experiments;
Recall, openended questions
(Loxterman et al.,
1994)
Classroom-based
experiments;
Reading
comprehension
(O’Reilly et al.,
2006)
Document
examination with a
more exploratory
approach;
Essay analysis/
interpretation
(Richards, 1929)
Document
examination with a
more confirmatory
approach;
Questionnaire
analysis/
interpretation
(Therman, 2008)



Data

Quantitative and
qualitative data
about active
reading
tasks/experience

Qualitative data
about active
reading practices

Efforts to enhance
strengths or
overcome
limitations
Selecting tasks
familiar to
participants in
their workplaces
and multiple
sources of data

Quantitative and
qualitative data
about active
reading outcomes

Follow-up
interviews and
borrowing
findings of other
similar studies to
reconfirm their
interpretations
Random sampling
instead of
convenience
sampling

Quantitative data
about active
reading outcomes

A large number of
participants in
real settings

Qualitative data
about nonbehavioral
interaction
between a reader
and literature

Multiple sources
of data and thick
description of
findings

Taken together, researchers’ strategies in the three disciplines can help ebook designers
and researchers collect rich data that will help them obtain useful insights into the design
of ebook devices that best serve active reading. Accordingly, as an overarching approach
of this dissertation study, a mixed-methods approach, was selected. These methods
included the following: document examination, which was used in literary criticism, to
investigate non-behavioral aspects of reader-text interactions; observation of participants
performing familiar tasks in real settings, which was used to overcome limitations of labbased research in HCI, to investigate behavioral aspects of reader-text interactions;
follow-up interviews and thick descriptions, which were employed in HCI and literary
criticism, to overcome limitations of qualitative research; and administration of an initial
survey involving a large sample to minimize limitations of an ethnographic study with a
relatively small number of participants in its primary phase.
2.3 Summary
This chapter addressed literature on active reading in the three complementary disciplines
of HCI, education, and literary criticism. The first part of the chapter introduced literature
to identify the emphasis or strength of active reading research in each discipline and a
research gap to be filled. The second part examined literature from a methodological
perspective to identify efforts and strategies to overcome the limitations of different kinds
of research methods employed in the three disciplines so that these could be utilized in
the present study.
Based on this literature review, this dissertation study was designed to investigate
in-depth the nature of reader-text interactions from a wide range of perspectives on active
reading (e.g., behavioral, cognitive, emotional, social, cultural), taking a mixed-method



approach. The aim of this research design is to investigate the phenomenon of reader-text
interaction holistically by “explor[ing] a situation from different perspectives” and
utilizing “multiple methods” (Kumar, 2010, p. 129). In keeping with Erlandson, Harris,
Skipper, and Allen’s (1993) metaphor that “by looking holistically at even a corner of the
cloth or at a piece taken from the middle of it, we can usually predict with great accuracy
the nature of the entire piece of cloth” (p. 11), the holistic approach taken in this study is
intended to further accurate understanding of reader-text interaction in ways that can best
promote ebook design that supports active reading.



Chapter 3. Overarching Research Approaches

3.1 Naturalistic inquiry (Constructivism)
This dissertation employed a mixed-methods design to investigate the mechanism of
reader-text interactions in depth by collecting diverse data.
A mixed-methods design can be implemented in different ways depending on the
overarching approach taken. This study followed a naturalistic inquiry approach, a
constructivist – as distinguished from a conventional scientific – paradigm. Each type of
inquiry is associated with a distinctive philosophical foundation, but not with particular
quantitative or qualitative methodologies. For example, Erlandson et al. (1993), in
alignment with Lincoln and Guba (1985), propose that scientific (conventional) is
associated with the premise of “a single objective reality, ascertainable through the five
senses and their extensions” (p. 11), and naturalistic (constructivist) inquiry is associated
with the acceptance of “multiple realities” (p. 11). However, they argue that any rigid
association of philosophical foundation with methodology, such as scientific inquiry with
quantitative methodologies and naturalistic inquiry with qualitative methodologies, is “in
error and unnecessarily confuses a very important issue” (p. 35). As Erlandson et al.
(1993) assert, this oversimplified distinction can produce the further misunderstanding
that naturalistic inquiry concerns “discovery” and conventional inquiry “verification,”
even though naturalistic inquiry is concerned with both discovery and verification.
This type of research design classification is different from another type of
“common” research design classification that foregrounds the quantitative-qualitative
distinction by associating each type of research design – quantitative, qualitative, and



mixed-methods – with a distinctive epistemology and particular research methodologies.
For example, Creswell (2009) asserts that quantitative designs are associated with
postpositivism, which assumes the existence of “the objective reality that exists ‘out
there’ in the world” (p. 7), qualitative designs with constructivism, which acknowledges
“subjective meanings” (p. 8), and mixed-methods with pragmatism, “emphasiz[ing] the
research problem” instead of methods (p. 10), and allowing for “multiple methods,
different worldviews, and different assumptions, as well as different forms of data
collection and analysis,” (p. 11). Also, he associates quantitative designs with surveys
and experiments; qualitative designs with phenomenology, grounded theory, and
ethnography; and mixed-methods designs with the combination of both quantitative and
qualitative designs.
Also, this type of research design classification is different from the other type of
research design classification that associates each type of research design, experimental,
naturalistic, and integrated, with a distinctive philosophical foundation and particular
research methodologies, but do not foreground the quantitative-qualitative distinction.
Rather than focus on numeric vs. non-numeric or text vs image data, they distinguish
between objective and subjective data, though these distinctions still associate
experimental-type research with what DePoy and Gitlin (2011) term “objective,
quantitative measurement” (p. 25) and naturalistic inquiry with “primarily … qualitative
methodologies” (p. 30). For example, DePoy and Gitlin propose that the “deductive,
predictive designs” (p. 25) of experimental-type research are associated with logical
positivism, which assumes the existence of “a single reality that can be discovered by
reducing it into its parts, a concept known as reductionism” (p. 25). The “pluralistic



perspectives” (p. 26) and “inductive and abductive reasoning” (p. 25) of naturalistic
inquiry are associated with holistic and humanistic philosophical traditions. And the
“relative and purposive” (p. 30) aims and “strategies from both experimental-type and
naturalistic inquiry traditions” (p. 34) are associated with the integrated and mixedmethods of pragmatism. Also, like Creswell (2009), DePoy and Gitlin propose that
scientific research is associated with different types of experimental designs; naturalistic
inquiry with phenomenology, ethnography, and grounded theory; and integrated and
mixed-methods with a combination of experimental-type research and naturalistic inquiry
methods.
In terms of utilizing both quantitative and qualitative methodologies, the
naturalistic inquiry design of this dissertation study resembles the mixed-methods designs
in the latter two classification types. However, the present design differs from these in
that it neither draws purposively on opposing philosophical foundations nor excludes the
use of a philosophical foundation. In other words, the present design is different from the
mixed-methods design in the two other classification types that follow pragmatism
according to two different viewpoints: one that pragmatism embraces “ontological
pluralism” (Tashakkori & Teddlie, 2010, p. 646); the other that pragmatism does not
require “a metaphysics or an epistemology” (Rorty, 1991, p. 22).



Table 3: Summary of three groups of researchers in terms of the flexibility of the
quantitative-qualitative distinction
Types of
research design
classification
First type
(Creswell,
2009, p. 17)

Second type
(DePoy &
Gitlin, 2011,
pp. 28-31)

Third type
(Lincoln &
Guba, 1985;
Erlandson et al.,
1993)

Research
Designs

Underlying
Philosophy

Quantitative

Postpositivism

Qualitative

Constructivism

Mixed methods

Pragmatism

Experimentaltype research
(“objective,
quantitative
measurement,” p.
25)
Naturalistic
inquiry
(“primarily on
qualitative
methodologies,”
p. 30)

Logistic
positivism

Integrated and
mixed-methods

Pragmatism

Scientific,
conventional
inquiry
Naturalistic
inquiry

The scientific
paradigm
(postpositivsm)
The naturalistic
paradigm
(constructivism)

Humanistic or
holistic

Research Methods
Surveys
Experiments
Phenomenology
Grounded theory Ethnography
Case study
Narrative
Sequential
Concurrent
Transformative
Non-experimental
Pre-experimental
Quasi-experimental
True experimental
Endogenous
Participatory action research
Critical theory
Phenomenology
Heuristic design
Ethnography
Narrative
Life history
Meta-analysis
Grounded theory
Semiotics
Sequential
Concurrent
Integrated
No clear distinction between
quantitative and qualitative
methods

In summary (Table 3), this study featured a naturalistic inquiry design, following
the third type of classification. It offers a flexible view in terms of the quantitative and
qualitative distinction between verification and discovery, and is governed by a



philosophical foundation, constructivism, as opposed to the first and second types of
classification, which take the view that pragmatism has either plural philosophical
foundations or none at all. In other words, this study integrates epistemologies espousing
multiple realities, subjective meanings, and holistic understandings into constructivism,
utilizing quantitative and qualitative methods to both verify and discover. For example,
quantitative survey data were collected to identify groups as a starting point that might be
meaningful for further data collection (discovery). As another example, numerical
characteristics of qualitative data were examined as a way to discover new insights
(discovery). The last example is that follow-up qualitative interviews were conducted not
only to reconfirm data from previous phases (verification) but also to gain new insights
(discovery).
3.2 Development as a way to integrate quantitative and qualitative components
To achieve a holistic understanding of reader-text interactions, the quantitative
components of this study served mainly “to obtain a quick picture of typical and atypical
cases and a map of where the outliers may be found in order to facilitate further in-depth
investigation” (Erlandson et al., 1993, p. 36), rather than to examine “the relationships
between and among variables” (Creswell, 2009, p. 145) and generalize findings, which
are typical verification purposes in quantitative research. This is consistent with
“development,” one of the five purposes of mixed methods which Greene, Caracelli, and
Graham (1989, p. 259) identified: “triangulation,” “complementa[tion],” “development,”
“initiation,” and “expansion.” The first purpose, triangulation, maximizes the validity or
credibility of findings by cross-checking using two methods. The second purpose,
complementation, uses a second method to elaborate or clarify findings obtained from an



initial method. The third purpose, development, uses findings from one method to help or
inform the design of a subsequent method. The fourth purpose, initiation, uncovers new
insights by comparing consistent and contradictory outcomes from two methods. The
fifth purpose, expansion, extends the scope of inquiry by investigating different
components (e.g., reading processes and outcomes) using different methods.
In short, this study employed mixed methods for the third purpose, development,
using quantitative research in the first phase to identify meaningful target groups to be
investigated in-depth in subsequent phases, using qualitative research. Specifically, this
design used a quantitative online survey method to situate subsequent qualitative data in
“a broader context” (p. 6) and to identify “representative cases” (Hesse-Biber, 2010, p.
6).
3.3 Methodological approach
Following Potter’s (1996) distinction that methodologies are “blueprints that prescribe”
(p. 50) how methods should be conducted, this section discusses methodological
approaches that guided the methods of the quantitative and qualitative components.
3.3.1 Quantitative components: Non-experimental approach
To achieve the purpose of this study, quantitative surveys that are appropriate to serve a
non-experimental objective were used to “measure characteristics of a population” and
“describe population parameters as well as to predict relationships among these
characteristics” (DePoy & Gitlin, 2011, p. 114), which is also consistent with the
overarching approach of naturalistic inquiry design selected for this study. This is based
on one type of classification in quantitative research in which quantitative research is



classified into types according to objectives. For example, Depoy and Gitlin (2011)
introduced four quantitative approaches: true-experimental, for “predict[ing] causal
relationships” p. 103); quasi-experimental, for “search[ing] for change over time” (p.
111); pre-experimental, for “answering a descriptive question” (p. 113), and nonexperimental, for “examin[ing] and quantify[ing] naturally occurring phenomena” (p.
115). This type of classification is different from another type of classification made by
many researchers, including Babbie (2007) and Creswell (2009), in which quantitative
research is classified into two categories, surveys and experiments.
In order to use the findings of an online survey in the first phase of this study as
an overview of a phenomenon to provide information for subsequent in-depth qualitative
research, the online survey was utilized quantitatively instead of qualitatively, and the
qualitative data obtained from the “other” option in the closed-ended questions were
treated holistically as an unknown item. This treatment was based on Kumar’s (2010)
argument that research can be determined to be quantitative or qualitative by restrictions
on “flexibility, structure, sequential order, depth and freedom that a researcher has” (p.
138), and so quantitative and qualitative research can employ the same methods of data
collection.
3.3.2 Qualitative components: Reader-response criticism
3.3.2.1 Application of reader-response criticism
The methodological approach to the qualitative components of this study was based on
reader-response criticism, a recent movement in literary scholarship that emphasizes the
active instead of the receptive role of readers (Bressler, 2003). This approach draws on
Potter’s (1996) classification of seven representative qualitative methodologies:



ethnography, ethnomethodology, reception study (a.k.a. reader response study),
ecological psychology, symbolic interactionism, cultural studies, and textual analysis.
Potter’s classification was selected over other types of classification in qualitative
methodologies, because it includes the category of reception study, a methodology
suitable for the present research. The interest of a reception study lies in “the context of
the interpretation rather than the texts themselves” (Potter, 1996, p. 54), which is
consistent with the focus of this study on participants’ intentions, needs, and desires
rather than text itself.
As mentioned earlier in section 1.4, this study explored participants’ responses to
text by drawing on three representative but distinct approaches in reader-response
criticism (Bressler, 2003; Mailloux, 1982):
•

Structuralist (text-focused) reader-response critics argue that the readers’ prior
knowledge of a sign system (e.g., a road sign) plays a role in constructing textual
meaning (Bressler, 2003). They believe that even though readers construct
meaning, the text plays an important role in controlling readers’ meaning-making
processes.

•

Subjective (reader-focused) reader-response critics take the position that readers’
“thoughts, beliefs, and experiences” (Bressler, 2003, p. 67) play an important role
in constructing the meaning of text, no matter what text is involved in this
meaning-making process.

•

Phenomenological (transaction-focused) reader-response critics believe that the
meaning of text can be constructed only when they have become conscious of and



accepted it through their interactions and transactions with texts, “filling in the
gaps in the text” (Bressler, 2003, p. 65).
These three approaches were selected rather than a single critical perspective
(e.g., Wolfgang Iser’s theory of aesthetic response shown in Figure 1), because individual
critics’ perspectives are too particular to literary texts (e.g., Gerald Prince's narratology)
to allow for a broad range of design insights and too critical or conceptual (e.g., Norman
Holland’s identity theory) to be operationalized into tangible designs. In other words,
these three approaches were selected because the combination of their conceptual levels
of guidance allowed for the collection of data that could provide a comprehensive, multidimensional view of reader interaction with a range of texts, with the potential to be
translated into explicit, tangible designs, although none of the approaches was developed
from a design perspective.

Norman Holland
David Bleich

Wolfgang Iser
Hans-Robert Jauss

Subjective Criticism

Phenomenology

Gerald Prince

Structuralism

Assumption: “Reader + Text = Meaning”

Figure 1: Three approaches in reader-response criticism (derived from Bressler,
2003, p. 61)
Hall (2001) has argued that reader-response has been used loosely from different
perspectives, and its oversimplification has rendered it “practically meaningless” (p. 44).



Also, researchers in various disciplines have utilized reader-response criticism in diverse
ways. For example, Benckhuysen (2010) analyzed biblical scholars’ interpretations of the
Hagar story to understand what leads readers to interpret the same text in different ways.
While Benckhuysen (2010) collected written interpretations as responses to text,
Lindstrom (2010), who was investigating the usefulness of a film-making project in
teaching literature, included films and journal entries as responses to text. In another
variation, Hickman (1981), investigating children’s responses to text, included such
nonverbal and spontaneous responses as “listening behaviors,” “contact with books,”
“acting on the impulse to share,” “oral responses,” “actions and drama,” “making things,”
and “writing” (p. 346). Similar to Hickman’s study, the focus of the present study is not
on readers’ textual interpretations per se, but rather on the nature of readers’ interactions
with text. Accordingly, it included a variety of cognitive and affective responses to texts
that were both behavioral and non-behavioral, such as underlining specific parts of text
and flipping through pages.
3.3.2.2 Role of reader-response criticism
In this study, the three categories of reader-response criticism served as a theoretical lens
that guided subsequent research processes in “identify[ing] the concepts and questions to
be included” in data collection, in “identify[ing] the major categories and items that need
to be coded” in data analysis, and in “explain[ing] the findings” of the study (Lazar,
Feng, & Hochheiser, 2010, p. 290). They were also continuously checked against
emerging data to determine how well they fit. In this way, reader-response criticism was
employed not to test theory, but as an overarching perspective that guided but did not
dictate the parameters of theory.



The approach taken in this study combines the perspectives of the first and third
of Creswell’s (2009) four groups of qualitative researchers: 1) those who use a particular
theory as a template to guide the design, procedures, and analysis of a study, a quasideductive approach; 2) those who use theory as a lens to address social issues, as in
feminist theory, critical theory, or racialized theory; 3) those who begin with data
collection and build theories at the end, a purely inductive approach; and 4) those who do
not use or produce explicit theory, but situate or utilize theory (or theoretical frameworks)
in different ways and at different stages of the research process, of whom
phenomenologists are prime examples (Corbin & Strauss, 2008; Creswell, 2009; Lazar,
Feng, & Hochheiser, 2010).

Pose generalizations or theories

Look for broad patterns, generalizations, or
theories from themes or categories
Analyze data to identify themes or categories

Gather information
(e.g., annotations, mouse-movement, interviews)

The three
categories
of
readerresponse
criticism

Establish research questions

Figure 2: Use of reader-response criticism (adapted from Figure 3.5: The Inductive
Logic of Research in a Qualitative Study, Creswell, 2009, p. 63)



In summary, utilizing Creswell’s categories but not staying within the boundaries of a
single one, this study adopted an inductive approach partly informed by a quasi-deductive
perspective, as shown in Figure 2 above.
Given that a purely inductive grounded theory approach was not sufficient to
operationalize the difficult concept of active reading, this strategy of combining a
grounded theory approach with the guidance of the three categories of reader response
criticism was useful throughout the whole research process. For example, participants
were asked to identify text properties they considered important or helpful while reading.
The theoretical perspective of text-focused reader-response criticism guided the
collection of such data. As another example, the theoretical perspective of reader-focused
reader-response criticism made it possible for the researcher to investigate how readers’
purposes for reading guided their interactions with texts by analyzing and identifying the
association between readers’ purposes for reading and their reasons for paying attention
to particular text segments. Finally, keeping in mind that other factors besides the reader
and the text might play a key role, the medium was identified as a key player affecting
reader-text interactions. For example, when readers used iPads they tended to limit their
interactions to texts that required low levels of engagement. A device likely to cause
eyestrain was not selected for active reading.
3.4 Analytical approach
3.4.1 Quantitative components: Frequency, cluster analysis, and logistical regression
For this study, descriptive and inferential data analyses were used based on Blaikie’s
(2003) argument that univariate descriptive analysis is for “represent[ing] the
characteristics” (p. 28); bivariate descriptive analysis for “establish[ing]… similarities or



differences” (p. 29) or “describ[ing] patterns or connections” (p. 29); explanatory
analysis for “address[ing]… ‘why’ questions” (p. 30); and inferential analysis for
“estimat[ing] the characteristics of or patterns in the population from which the sample
was drawn” (p. 32).
In order to answer the first research question (i.e., to identify characteristics of the
currently most common active reading practices with regard to annotation behaviors and
characteristics of common physical environments for active reading), frequency and
cluster analysis were applied as descriptive statistical analysis to questionnaire responses.
Cluster analysis was employed for “grouping objects of similar kind into respective
categories” by “discover[ing] structures in data without explaining why they exist” (Hill
& Lewicki, 2005, p. 115). For example, such analysis is conducted when biologists group
“the different species of animals before a meaningful description of the differences
between animals is possible” (Hill & Lewicki, 2005, p. 115). Cluster analysis was
selected over other similar statistical techniques, such as factor analysis and discriminant
analysis, for the following reasons. Factor analysis would not reflect ‘real world’
phenomena well in terms of multiple items (e.g., a group of people who have similar
patterns in using multiple reading devices) by reducing data “from many variables into a
reduced set of variables or composite variables (Zikmund & Babin, 2007, p. 610).
Discriminant analysis, which is for grouping clusters as compared to known groups
(Norušis, 2012), was not possible for this study without known groups. Two-step
clustering, a combination of hierarchical and k-means clustering, was used over either
hierarchical clustering or k-means clustering alone. K-means, although it is generally
better than hierarchical methods in that “it is less affected by outliers and the presence of



irrelevant clustering variables” (Mooi & Sarstedt, 2011, p. 259), requires researchers to
specify the optimum number of clusters (Mooi & Sarstedt, 2011). As one way to
overcome this problem, it is common for researchers to use hierarchical techniques first
to identify the optimum number of clusters and then use these to apply k-means
techniques (Burns & Burns, 2008, Mooi & Sarstedt, 2011, Norušis, 2012). Thus, the twostep procedure that Burns and Burns (2008) suggested was applied as follows: 1) The
Ward’s method was used to get some sense of the possible number of clusters and the
way they might merge as seen from the dendrogram; 2) then the clustering was rerun
with only a chosen optimum number in which to place all the cases (k-means clustering)
(p. 557).
To answer the second question (i.e., to identify factors that distinguish groups of
people who share similar active reading practices with regard to annotation behaviors),
binary logistic regression (BLR) in SPSS 20 was applied as inferential statistical analysis
to questionnaire responses. BLR was used as appropriate for a statistical analysis in
which 1) future outcomes as dependent/criterion variables) are to be predicted from past
data independent/predictor variables, which is applicable for any kind of regression; 2)
criterion variables in logistic regression are categorical as compared with those in linear
and multiple regression, which are continuous; and 3) the number of categories of
criterion variables in BLR is two as compared with multinomial logistic regression for
criterion variables with more than two categories (Field, 2009). Also, BLR is appropriate
for a statistical analysis in which subjects are to be grouped “based on values of a set of
predictor variables” in terms of a criterion variable (SPSS, 2004, p. 13). In short, BLR
was used to help determine what predictor variables significantly predicted criterion



variables, which ultimately were used in identifying a target group of participants for
subsequent qualitative phases.
3.4.2 Qualitative components: Grounded theory (abduction) and retroduction
3.4.2.1 Grounded theory and constructivist grounded theory
Among Potter’s (1996) 20 representative qualitative methods8 of analysis, grounded
theory, initiated by Barney Glaser and Anselm Strauss (Charmaz, 2006; Corbin & Strauss,
2008; Stern & Porr, 2011), was selected as the primary analytical method for this study
because of its focus on building theory, which makes it different from other qualitative
methodologies (Corbin & Strauss, 2008). Utilizing grounded theory to develop “theories
from research grounded in data rather than deducing testable hypotheses from existing
theories” (Charmaz, 2006, p. 4), this study built a new version of reader-response
criticism that fits old (paper) and new (digital) media, thereby furthering understanding of
the nature of reader-text interaction in the digital age.
Charmaz’s version of constructivist grounded theory was selected over other
versions because its philosophical assumptions are consistent with the overarching
approach of naturalistic inquiry. Unlike Glaser and Strauss’s original version of
systematic or objectivist grounded theory that “embrac[es] the study of a single process
or core category” (p. 65), Charmaz’s constructivist grounded theory emphasizes “diverse
local worlds, multiple realities, and the complexities of particular worlds, views, and
actions” (Creswell, 2007, p. 65). Also, unlike Glaser and Strauss’s grounded theory,

8

The 20 representative methods of analysis Potter (1996, pp 134-158) introduced are semiotics/semiology,
discourse analysis, narrative analysis, genre analysis, dialogic analysis, historical analysis, Marxist analysis,
feminist analysis, psychoanalytical analysis, postmodern analysis, myth analysis, hypothesis testing,
grounded theory, triangulation, maximizing comparisons, sensitized concepts, thick description, analytical
induction, negative case analysis, and retroduction.



Charmaz’s constructivist grounded theory methods emphasize “the researcher and
research participants’ respective positions and subjectivities, situated knowledge.” In
short, while Charmaz’s constructivist version of grounded theory follows the “coding,
memo-writing, and sampling for theory development, and comparative methods” of
classical grounded theory (Charmaz, 2006, p.9), it does not follow its underlying
epistemological approach of and positivistic assumptions, which Wertz el al. (2011) have
identified as “(1) an external reality, (2) an objective, authoritative observer, (3) a quest
for generalizations, and (4) a treatment of data as given without acknowledging the
participants’ and researcher’s roles in shaping these data” (p. 168).
3.4.2.2 Constructivist grounded theory (abduction) and retroduction
To extend an original reader-response criticism to new media without creating a new,
entirely data-driven theory, Turow’s (1984) retroduction was combined with grounded
theory as part of the theoretical framework. Turow described retroduction as

the activity of deductively applying ideas from certain bodies of
knowledge and emerging frameworks to case studies and then
inducing from findings of the case studies the extent to which (and the
manner in which) the bodies of knowledge and emerging frameworks
should be altered. (p. 71)

Although grounded theory and retroduction may seem incompatible because
grounded theory is viewed as only inductive, and retroduction has a deductive
component, Corbin and Strauss (2008) argued in their 1967 book, The Discovery of



Grounded Theory, that Glaser and Strauss’s emphasis on inductive reasoning is easily
misunderstood to mean that grounded theory is purely inductive. Rather, they point out
that grounded theory is inductive in the sense that “findings are derived from data” (p.
326), but it also has deductive aspects in the sense that “the concepts and the linking
statements are interpretative, that is, constructed by the analyst from data” (p. 326). They
also call this process abductive reasoning, “a type of reasoning that begins by examining
data and after scrutiny of these data, entertains all possible explanations for the observed
data, and then forms hypotheses to confirm or disconfirm until the researcher has arrived
at the most plausible interpretation of the observed data” (p. 186) (Charmaz, 2006). More
importantly, Locke (2001) pointed out that even though the classic version of grounded
theory emphasized developing a new theory from data, Strauss (1973) argued
convincingly that grounded theory can be used to extend theory by “extending and
refining its existing theoretical categories and relationships” (p. 103). Therefore,
grounded theory and retroduction, although different in that grounded theory begins with
data inductively while retroduction begins with existing knowledge deductively, are not
contradictory.
In summary, this study combined grounded theory with retroduction by beginning
retroductively with research questions that were informed by the three categories of
reader-response criticism (Figure 3). At the same time, the researcher was open to new
concepts that might emerge from the data, utilizing a grounded theory approach by
feeding back raw data that did not fit current reader-response criticism to create new
categories and revise old categories and thus expand the theory rather than letting it
control the inquiry. This approach was taken to avoid excluding important concepts that



were not currently included in the theory but were still meaningful in understanding
readers’ interaction with text.

Pose generalizations or theories

Look for broad patterns, generalizations, or
theories from themes or categories

Analyze data to identify themes or categories

The three
categories
of
readerresponse
criticism

Expanded
categories
of readerresponse
criticism

Gather information
(e.g., annotations, mouse-movement, interviews)

Establish research questions

Figure 3: Use of grounded theory and retroduction (adapted from Figure 3.5: The
Inductive Logic of Research in a Qualitative Study, Creswell, 2009, p. 63)
3.4.2.3 Coding and building a theory
Among various ways to utilize the common features of grounded theory – “coding,
memo-writing, and sampling for theory development, and comparative methods”
(Charmaz, 2006, p. 9) – this study followed Stern and Porr’s nine steps (Table 4) by
utilizing substantive coding, including open and selective coding, and theoretical coding.
Substantive and theoretical coding are two representative types of coding in classical
grounded theory (Holton, 2010).



Table 4: Steps of data analysis (taken from Table 5.1: Steps of Analysis, Stern & Porr,
2011, pp. 62-63)
Steps
1. Substantive
coding
1.1 Open
coding
1.2 Constant
comparison

1.3 Memoing
1.4 Selective
coding
1.5 Memoing
1.6 Constant
comparison

2. Theoretical
coding

2.1 Constant
comparison
2.2 Sorting
memos
2.3 Writing
the report

Techniques
Conduct open coding, constant comparison and memoing followed by selective
coding, memoing, and constant comparison procedures.
Fracture transcript (if your data source is an interview) into data segments.
Use codes to assign labels to data segments.
Group labeled codes into conceptual categories.
Compare labeled coded with each other, and with emerging conceptual
categories.
Compare labeled codes and emerging conceptual categories with newer labeled
codes of new incoming data.
Code interview two. Compare labeled codes from interview two with labeled
codes and conceptual categories you found in interview one.
Code interview three. Compare labeled codes from interview three with labeled
codes and conceptual categories you found in interview one and two.
Continue to compare labeled codes and conceptual categories with all new
incoming data.
Record all ideas, hunches and queries that arise during 1.1 Open coding.
Identify the recurring problem, issue or concern (i.e., the basic social
psychological problem).
This problem or concern becomes the core variable.
Record all ideas, hunches and queries that arise during coding for the core
variable.
Review and select your substantive codes (i.e., labeled codes and conceptual
categories) that seem related to the core variable.
After analyzing new data (using 1.1 Open coding), compare these new
substantive codes with your existing codes and conceptual categories (those
linked to your core variable).
Is an overarching process emerging (i.e., the basic social psychological process)
that accounts for all the conceptual categories associated with the core variable?
Identify this basic social psychological process that resolves the core problem.
Conduct theoretical coding, constant comparison and memo sorting procedures.
Implement theoretical sampling to expand conceptual categories.
Use coding families to expand conceptual categories and to determine how
substantive codes relate to one another. For example, how one conceptual
category is a condition of another or a consequence; how some labeled codes
are properties of conceptual categories; how some conceptual categories are
actually dimensions of another conceptual category; how some labels codes
don’t fit and should be excluded.
Analyze new data, beginning with 1. Substantive Coding.
Compare your existing conceptual categories, their properties, dimensions,
consequences, conditions and so forth, with your new substantive codes.
Sort your memos to assist with saturation of conceptual categories and to give
you visual insight into further theoretical coding and the theoretical structure
and layout of your conceptual categories.
Expect to find-tune your analysis as you write up your report.

 

However, the terms “open,” “selective,” and “theoretical” coding in grounded theory
were replaced by “initial,” “intermediate,” and “advanced” coding as independent from a
particular theorist’s approach in order to avoid potential misunderstanding in labeling.
Table 5 below illustrates correspondences between the terms used in this study and terms
used for coding by Glaser and Strauss (1967), Glaser (1978), Strauss and Corbin (1990,
1998), and Charmaz (2006).
Table 5: Three representative phases of coding (taken from Table 7.1 Phases of coding,
Birks & Mills, 2011, p. 116)
Glaser and Strauss
(1967)
Glaser (1978)
Strauss and Corbin
(1990; 1998)
Charmaz (2006)

Initial coding
Coding and
comparing incidents
Open coding
Open coding

Intermediate coding
Integrating categories
and properties
Selective coding
Axial coding

Advanced coding
Delimiting the theory
Theoretical coding
Selective coding

Initial coding

Focused coding

Theoretical coding

In brief, throughout the four phases of qualitative data collection and analysis,
tentative thematic categories about reader-text interaction in active reading were created
by utilizing the earlier steps of intermediate coding. At the same time, the previously
identified tentative thematic categories were refined by adding new thematic categories
or/and sub-categories or by correcting pre-defined thematic categories. As a consistent
comparison strategy, data collection and analysis were conducted simultaneously by
continuously comparing individual participants’ data. At the end, utilizing advanced
coding, the relationships among all data that were collected, interpreted, and aggregated
in previous phases were identified to propose a composite model of reader-text
interaction. Additional data were collected from later participants by asking them
questions that were related to thematic categories that had emerged from data with earlier



participants (i.e., theoretical sampling) to “saturate categories under development” (Birks
& Mills, 2011, p. 10).
For the second and the third phases of the annotation study and follow-up
interviews, MS Word was used to free the researcher from pre-defined features of
computer-assisted data analysis software. Also, to take advantage of computer-assisted
data analysis software that helps “organize and record thoughts about and reactions to
data as well as […] access and review” (Morgan & Guevara, 2008, p. 103), the researcher
used a qualitative research analysis software tool, HyperRESEARCH
(http://www.researchware.com), which supports diverse modes of data including “text,
photographs, audio, and video” (Merriam, 2009, p. 198).
3.5 Quality assurance criteria
3.5.1 Quantitative components: Content validity, reliability, and other practical criteria
Two representative quality criteria for evaluating the findings of quantitative research are
validity and reliability. Pitney and Parker (2009) define internal validity as “whether an
instrument takes the intended measurement,” external validity (generalizability) as “how
the findings of one study can be applied to other participants or settings,” and reliability
as “the consistency of measures [...] regardless of the number of repetitions or the amount
of rest between trials” (p. 62).
Along with strategies to maximize content validity and reliability and minimize
practical problems with interface design and technical aspects at the design stage of the
questionnaire, other additional strategies were applied at the evaluation stage. Also, they
were applied throughout the pilot study with faculty and students to test the initial version
of the completed questionnaire (Appendix A.1). Also, before, during, and after the pilot



study feedback was collected from research committee members and a consultant at the
Center for Survey Research at Indiana University Bloomington. Further details are as
follows.
3.5.1.1 Strategies at the design stage
First, definitions of academic reading and active reading were provided at the beginning
to ensure that all respondents interpreted these terms in the same way (Fowler, 1995).
Second, in the final section of the questionnaire, respondents were asked to indicate the
variety of English they considered their native language (e.g., American English) to make
sure that all respondents belonged to the intended group of native speakers of English.
Third, questions were organized by topic to lighten participants’ cognitive burden
(Dillman, Smyth, & Christian, 2009), even though some researchers suggest randomly
organizing questions to avoid unintended order effects (Saris & Gallhofer, 2007). Fourth,
important topic-related questions were followed by easy and general questions (e.g.,
academic status, majors) to promote better cooperation and elicit better answers from
respondents (Dillman et al., 2009), even though some researchers suggest that questions
should be arranged from easy and general to important topic-related questions to
familiarize participants with the format and prepare them to answer important topicrelated questions (Saris & Gallhofer, 2007). Fifth, the first set and the second set of
questions about general reading practices and academic reading practices were placed
before questions about the more difficult concept of active reading practices, following
Dillman et al.’s (2009) advice to “help to set the framework so that the rest of the
questions will be relatively easy to answer and will not require a lot of effort from
potential respondents” (p. 158). Last, demographic information was placed at the end of



the questionnaire in order to avoid respondents’ losing motivation to proceed further
when they encounter “a routine form” at the beginning of the questionnaire (Babbie,
2007, p. 256).
3.5.1.2 Strategies at the evaluation stage
Strategies used in three main question-evaluation methods, including “Focus group
discussion,” “Intensive individual interviews,” and “Field pretesting” (Fowler, 1995, p.
104), were employed to assess validity, reliability, and practical aspects of the
questionnaire.

Content validity
To ensure the initial questionnaire’s content validity, “the degree to which each question
links to the [researcher’s] objectives” (Thomas, 2004, p. 81), the pilot study included
individual interviews conducted in person with four students who were recruited through
an email (Appendix B.1) sent to an electronic mailing list (slis-studentsl@listserv.indiana.edu) of all master’s students in the School of Library and Information
Science (changed to the Department of Information and Library Science in July 1, 2013)
at Indiana University Bloomington. Also, six faculty members at Indiana University
Bloomington, four from the School of Library and Information Science, one from the
School of Informatics and Computing, and one from the Center for Survey Research,
completed the questionnaire and answered the questions for the pilot study in response to
an email invitation (Appendix B.2).



Questions posed in these evaluations were derived from the following suggestions
by Thomas (2004) and Fowler (1995) for evaluating the content validity of and survey
questions in a questionnaire:
Thomas (2004, p. 81):
•
•

•

Does the question clearly link to the objective as intended?
Together, do all the questions linked to an objective provide thorough coverage of
the topic?
- Are there questions that overlap each other and therefore provide
essentially the same information?
- Are there topics that should be included that were not?
As a whole, to what extent will the questionnaire yield the data required?

Fowler (1995, p. 112):
1. Ask respondents to paraphrase their understanding of the question.
2. Ask respondents to define terms.
3. Ask respondents for any uncertainties or confusions they had about
what the appropriate answer was.
4. Ask respondents how confident they are that they can give an accurate
answer.
5. If the question called for a numerical figure, ask respondents how they
arrived at the number; if a question calls for a rating task, ask respondents
about the process they went through to decide on the answer.

Also, in order not to miss important variables of active reading practices during
individual interviews, open-ended questions that encouraged thinking beyond established
parameters were asked, such as “Think about your own active reading practices! In this
questionnaire, are there questions I [the researcher] need to include to collect data about
important aspects of your active reading practices?” This strategy takes advantage of a
similar focus group method that was used at the survey design stage “to help define the
topic and the research questions” (Fowler, 1995, p. 105).



The respondents’ comments to these questions were analyzed and used to add
more options to answers, as necessary (Appendix D.1), minimize redundant information
in instructions, questions, and answers (Appendix D.2), and maximize the clarity and
conciseness of instructions, questions, and answers (Appendix D.3).

Reliability
Test-retest, which is one of two ways (test-retest and internal consistency) for evaluating
the reliability of a questionnaire (Thomas, 2004), was conducted. Four students, recruited
with the email invitation in Appendix B.1 sent to the student lists mentioned above, were
asked to complete the initial questionnaire via email twice with an interval of seven to ten
days, and their answers for the two administrations were compared. Pearson’s correlation
coefficients were tested using SPSS 20 to examine if two (pre- and post-) answers within
each participant and across the four participants were reasonably consistent. After testing
reliability within each participant (Appendix D.4), it was concluded that because all r
values for the four participants (r=.933, r=.930, r=.879, and r=.840) were much higher
than .50, which indicates strong correlations according to Cohen (1988) ’s proposal that r
= ± .50 is strong, r = ± .30 is moderate, and r = ± .10 is weak, the test-retest reliability for
the instrument was very high.
Across the participants (Appendix D.5) it was concluded that because r values for
39 questions were higher than .50 (in strong), r values for six questions were higher than
.30 (in moderate), and r values for four questions were higher than .10 (in weak), the testretest reliability for the instrument was relatively high.
In addition, because there were only four participants, the six questions with



moderate correlations and the four questions with weak correlations were closely
examined by comparing pre- and post-values case by case while the questionnaire was
being revised for the larger survey. In Table 6 below, which shows the questions about
usage or activity frequency with moderate correlations, Q1_3 refers to Reading for
course papers, Q1_5 refers to Reading to prepare lectures, Q10_4 refers to Skimming,
Q30_1 refers to Print book/article, Q30_2 refers to Scrollable web page, and Q37_2
refers to Ereader.

Table 6: Comparison between pre and post data: Moderate correlations
Q1_3 Q1_3 Q1_5 Q1_5 Q10_4 Q10_4 Q30_1 Q30_1 Q30_2 Q30_2 Q37_2 Q37_2
_pre _post _pre _post _pre _post _pre _post _pre _post _pre _post
Usage or 5
6
1
1
3
5
5
5
4
5
1
2
activity
3
3
1
4
5
5
5
4
5
4
1
1
fre5
4
2
1
3
4
5
5
3
3
1
1
quency
4
7
1
1
3
5
4
5
4
5
5
1

In conclusion, the test-retest reliability for moderate correlations was considered good for
three reasons: 1) one point up or down is not a big difference with continuous variables
on a 5-point scale (Never, Rarely, Sometimes, Quite Often, Very Often) or 7-point scale
(Never, Less than Once a Month, Once a Month, 2-3 Times a Month, Once a Week, 2-3
Times a Week, Daily); 2) serious changes in point values occurred with only one
participant for each question (i.e., 4 to 7 in Q1_2; 1 to 4 in Q1_5; and 5 to 1 in Q37_2),
rather than all four participants, which might imply that this participant was more prone
to changing perceptions over a short period time; and 3) the test-retest reliability within
each participant was overall very high. However, because three participants changed their
values on the scales one (or two) up (or down) in Q10_4 about skimming, the researcher



kept in mind either that skimming might be a practice that generally varies day by day, or
that Q10_4 has a reliability problem.
In Table 7 below, which shows questions about usage or activity frequency with
weak correlations, Q10_5 refers to Scanning, Q24_3 refers to No annotation, but notetaking on paper, Q24_6 refers to Both annotation and note-taking in digital formats, and
Q35_3 refers to Office.

Table 7: Comparison between pre and post data: Weak correlations

Usage or
activity
frequency

Q10_5
_pre
2
5
4
4

Q10_5
_post
5
5
4
5

Q24_3
_pre
2
2
5
3

Q24_3
_post
3
2
3
1

Q24_6
_pre
2
1
1
3

Q24_6
_post
2
1
1
1

Q35_3
_pre
1
5
1
1

Q35_3
_post
2
3
4
2

Like the test-retest reliability for the questions with moderate correlations, the
test-retest reliability for the questions with weak correlations was considered good for
three reasons: 1) one point up or down is not a big difference with continuous variables
on a 5-point or a 7-point scale; 2) serious changes in point values occurred with only one
participant for each question (i.e., 2 to 5 in Q10_5 and 3 to 1 in Q24_6), which might
imply that one participant’s perceptions changed significantly within a short period time;
and 3) the test-retest reliability within each participant was overall very high. However,
because two or more participants changed their values on the scales two (or three) up (or
down) for Q24_3, referring to note-taking only on paper, and for Q35_3, referring to
reading at the office, the researcher kept in mind either that note-taking only on paper and
reading at the office might be practices that in general vary day by day, or that Q24_3 and
Q35_3 have reliability problems.



Other practical (interface design and technical) criteria
To minimize practical problems that could occur throughout participation in an online
questionnaire, email interviews were conducted with faculty members and student
participants. The six faculty members mentioned above, who completed the
questionnaire, answered three questions via email: How long did it take you to complete
the questionnaire? Were there any interface design elements that did not make sense to
you? Did you encounter any technical problems? Also, the four students who participated
in the reliability check were also asked via email to answer these three questions.
The respondents’ answers (Appendix D.6) to the question of how long it would
take to complete the questionnaire were used to provide instructional information at the
beginning of the questionnaire. The respondents’ comments about the question of
whether there were any interface design elements that did not make sense (Appendix D.7)
were used to fix critical problems in the interface design (presentation). Responses to the
question of whether participants encountered any technical problems (Appendix D.8)
were used to modify technical issues of the questionnaire.
3.5.2 Qualitative components: Trustworthiness
In agreement with Steinke (2004), who argued that quality criteria for qualitative research
should be formulated to avoid “the risk of randomness and arbitrariness” (p. 185), this
researcher did not formulate quality criteria independently, but selected the three criteria
of credibility, transferability, and dependability, which “are now standard” in qualitative
research (Pitney & Parker, 2009, p. 62), over the two criteria of validity and reliability,
which could connote the positivistic assumptions of an objective reality and causal



relationships. Merriam (2009) defined credibility as “how research findings match
reality” (p. 213), transferability as “the extent to which the findings of one study can be
applied to other situations” (p. 223), and dependability (consistency) as “whether the
results are consistent with the data collected” (p. 221).
This choice is consistent with the position of the second group of qualitative
researchers in Steinke (2004)’s three different positions in terms of measuring and
ensuring criteria for trustworthiness, an umbrella term that is equivalent to validity and
reliability in quantitative research (Pitney & Parker, 2009). In Steinke’s typology, one
group has established qualitative criteria (e.g., confirmability, dependability/auditability,
credibility/authenticity, and transferability/fittingness) equivalent to those used in
quantitative research (e.g., objectivity, reliability, internal validity, and external validity);
the second group has established quality criteria for qualitative research that are
independent from those used in quantitative research (e.g., communicative validation,
triangulation, validation of the interview-situation, and authenticity); and the last group
has rejected establishing quality criteria for qualitative research based on such underlying
philosophical foundations associated with qualitative research as social constructivism
and postmodernism.
In order to enhance credibility of the qualitative components, this study employed
four strategies that qualitative researchers have commonly proposed (Merriam, 2009):
triangulation, member checks (response validation), adequate engagement, and
researcher’s position (reflexivity). At the design stage, a strategy of triangulation was
employed by utilizing three research methods (annotation analysis, distant observation,
and follow-up interviews) and collecting data from multiple participants. Also, follow-up



interviews were conducted with participants as a strategy of member checks (response
validation). At the implementation stage, data collection was continued until the
emerging findings were saturated (i.e., until no new findings/categories appeared) as a
strategy of adequate engagement. Also, the researcher reported “assumptions,
experiences, worldview, and theoretical orientation to the study” (Merriam, 2009, p. 219)
as a strategy of researcher’s reflexivity to clarify how findings were determined. Last,
there is a debate over whether or not inter-rater reliability is required in qualitative
research (Armstrong, Gosling, Weinman, & Marteau, 1997). Inter-rater reliability was
not checked in this study, but follow-up interviews with participants helped correct any
misinterpretations on the part of the researcher.
In order to enhance transferability in qualitative components, which is not about
statistical or probabilistic generalization, two strategies, rich, thick description and
typical sampling, which qualitative researchers have commonly proposed (Merriam,
2009), were employed. At the design stage, use of a survey as a tool that helps select “a
typical or modal sample” was a strategy for maximizing transferability (Merriam, 2009,
p. 228). At the implementation stage, details of “the setting and participants of the
study… [and] the findings with adequate evidence presented in the form of quotes from
participant interviews, field notes, and documents” (p. 227) were reported as a strategy of
rich, thick description, so that other researchers may judge the similarity between this
study and their research.
In order to enhance dependability (consistency), which Merriam (2009) states, “is
not whether findings will be found again but whether the results are consistent with the
data collected” (p. 221), three strategies commonly proposed by qualitative researchers,



the audit trail, triangulation, and reflexivity (Merriam, 2009),were employed. The two
strategies of triangulation and reflexivity were used in the same way as for enhancing
credibility. The strategy of the audit trail was applied by keeping a journal and recording
memos about “how data were collected, how categories were derived, and how decisions
were made throughout the inquiry” (Merriam, 2009, p. 223).



Chapter 4. Methodology
4.1 Quantitative components
4.1.1 Instrumental (online questionnaire) design
The design steps of the online survey were based on Saris and Gallhofer’s (2007) eight
steps of survey design: select a topic, select the most important variables, select a data
collection method, translate the concepts into questions (operationalization), test the
quality of the questionnaire, formulate the final questionnaire, select population and
sample design, and decide about the fieldwork. A description of each step follows.
4.1.1.1 Step 1. Choice of topic
As mentioned in chapter 3, an online survey was administered to identify a purposive,
meaningful target group(s) for the subsequent qualitative component, the primary study,
which involved collecting naturalistic data on reader-text interaction in the context of
active reading. In other words, the online survey was not intended to test hypotheses but
to identify cases to be investigated in depth following a naturalistic inquiry approach. The
main criterion for defining purposive, meaningful target group(s) for this qualitative
component was derived from literature indicating that annotation (i.e., writing while
reading) is very closely related to active reading (Blachowicz & Ogle, 2008), so this
online survey was designed to identify distinctive groups of people who shared similar
active reading practices with regard to annotation/note-taking behaviors. This was judged
to be a valuable resource for understanding active reading processes in later qualitative
phases of the research. Of equal importance, this approach enabled the researcher to
avoid making artificial interventions in the later phases, such as encouraging or requiring



participants to produce rich annotations, which would violate the principle of naturalistic
inquiry.
Saris and Gallhofer (2007) state that there are two types of survey research: a
descriptive study, which is designed to identify “the distribution of responses” (p. 4) of
participants; and an explanatory study, which is designed to “determine … reasons” (p. 4)
that underlie a target phenomenon. The survey used in the present study served a
descriptive purpose, in that it was designed to identify the distribution of the currently
most common active reading practices with regard to annotation/note-taking behaviors,
along with the characteristics of common physical environments for active reading. The
survey also served an explanatory purpose in that was designed to identify factors that
distinguish groups of people who share similar active reading practices with regard to
annotation/note-taking behaviors. These two purposes correspond to the two main
research questions for the survey.
The objective of the first question was to understand the nature and context of
active reading, which is based on the assumption that subjects and contexts are
interrelated and was important in the naturalistic inquiry approach. The objective of the
second question was to determine unique characteristics of distinctive groups of people
who share similar active reading practices with regard to annotation behaviors.
4.1.1.2 Step 2. Choice of most important variables
In order to answer the first research question, two key variables relating to active reading
and annotation behaviors were identified:
Variable #1:

Type of active reading in terms of annotation (writing) habits
(= Annotation Frequency)



Variable #2:

Type of annotation in terms of location (on or off documents) and
medium (paper vs. digital formats)
(=Annotation Type)

Also, two variables of places and tools commonly used by participants for active
reading were included to identify common physical characteristics of active reading
environments. The purpose of this was to duplicate similar environments in the lab where
participants would be brought for the fourth phase.
Variable #3:
Variable #4:

Place for active reading
Tools for active reading

The first step to answer the second research question was to identify potential
variables that affect annotation behaviors. The positive effects on reading outcomes of
annotating and note-taking while reading, such as enhanced recall, have been studied
(Flippo & Caverly, 2009). However, little research seems to have addressed the question
of characteristics of readers in terms of their annotation behaviors. Therefore, key
variables for the second research question were borrowed from a subset of two important
sets of variables affecting the nature of reading that have been identified in reading
assessment research (Alderson, 2000), i.e., reader and text variables. This decision was
based on the assumption that some variables that affect the nature of reading processes
and outcomes will also affect annotation behaviors/note-taking (Figure 4).
Reading processes
and outcomes

Variables that
affect the nature
of reading
Annotation/
note-taking
behaviors

Figure 4: Relationships among variables that affect the nature of reading and
annotation behaviors



Examples of reader variables are prior knowledge (e.g., subject-matter
knowledge), skills and abilities (e.g., analyzing skills), reading purposes, motivation and
interest, and emotional state, as well as stable characteristics (e.g., gender, intelligence,
processing capacity of memory, span and speed of eye movement). Examples of text
variables are text topic and content (e.g., degree of abstraction, quantity of information),
text type and genre (e.g., the way text is organized, such as expository), text organization
(e.g., coherence), linguistic variables (e.g., syntax), text readability, typographical
features, graphic information, and the medium of text presentation (Alderson, 2000).
Reader and text variables that are stable over time, including gender, common
format (software), and common device (hardware), were selected for the second research
question. Other stable reader variables, including reading skills, intelligence, and
memory, were excluded on the assumption that participants in this study (master’s
students and above), having high levels of education would have similarly high levels of
reading skills and ability, intelligence, and memory. Information about variables that
change over time, including prior knowledge, reading purposes, motivation and interest,
and text readability, was collected using the Information Sheet (Appendix M) in the
fourth phase, to which participants brought their own documents and devices.
Variable #5:
Variable #6:
Variable #7:

Gender
Most common format (software)
Most common device (hardware)

Additionally, age, academic status, and academic major(s) were included as stable reader
variables that might affect active reading practices with regard to annotation behaviors.
Variable #8: Age
Variable #9: Academic status
Variable #10: Major(s)



The variables used in the questionnaire are summarized in Table 8.

Table 8: Summary of variables used in the questionnaire
Kinds of Variables9
Criterion/Outcome/Dependent
Variables

Predictor/Explanatory/Independent
Variables

Names of Variables
Variable #1. Type of active
reading in terms of writing
(annotation) habits
Variable #2. Type of
annotation in terms of the
location (on or off
documents) and the medium
(paper vs. digital formats)
Variable #3. Place for active
reading
Variable #4. Tools for active
reading
Variable #5. Gender
Variable #6. Format
(software)
Variable #7. Device
(hardware)
Variable #8. Age
Variable #9. Academic
status’
Variable #10. Major(s)

Short Names of
Variables
Annotation Frequency
Annotation Type

Place
Tool
Gender
Format
Device
Age
Degree
Major

4.1.1.3 Step 3. Choice of data collection method
A web survey was used in this study, which was appropriate for “very specific
populations such as college students and certain professionals” (Dillman et al., 2009, p.
44), because it would “reach very many people with relatively low costs” (Saris &
Gallhofer, 2007, p. 156). Reaching many participants was very important for this study
because its purpose was to collect diverse data from a variety of readers.


9

The corresponding variable names in experimental and non-experimental research designs are from Vogt
(2005).



There are disadvantages to a self-administered survey, such as low rates of
response, over other methods that require a surveyor’s presence (Saris & Gallhofer,
2007). However, in this case the surveyor’s absence could be expected to have no major
negative impact on the quality of responses because the topic of this study was neither
complex nor sensitive (Saris & Gallhofer, 2007).
4.1.1.4 Step 4. Operationalization
Operationalization is “the translation of the concepts into the questions” (Saris &
Gallhofer, 2007, p. 6). Given the two major research questions in Step 1, three important
concepts were 1) “most common active reading practices with regard to annotation/notetaking behaviors,” 2) “most common types of annotation behaviors,” and 3) “factors that
determine distinctive groups of people who share similar active reading practices with
regard to annotation behaviors.”
The first group of questions was created by translating the concept of “most
common active reading practices with regard to annotation (writing) behaviors” into a
key question using Variable#1, Type of active reading:

Indicate on the scale how often you engage in active reading practices
involving writing (i.e., annotation or/and note-taking):
Never

Rarely

Sometimes

Quite Often

Very Often

Comments (if any):

The second group of questions was created by translating the concept of “most
common annotation behaviors” into a key question using Variable #2, Type of annotation
in terms of a location (on or off documents) and a medium (paper vs. digital formats):



Indicate how often you do each annotation or/and note-taking practice below:
Never Rarely Sometimes Quite Very
Often Often
Annotation on paper
Annotation on digital
formats
No annotation, but notetaking on paper
No annotation, but notetaking in digital formats
Both annotation and notetaking on paper
Both annotation and notetaking in digital formats
Other (Please specify):

The third group of questions was created by translating the concept of “factors
that determine distinctive groups of people who share similar active reading practices
with regard to annotation behaviors” into six key questions using Variable #5, Gender;
Variable #6, Most common format (software); Variable #7, Most common device
(hardware); Variable #8, Age; Variable #9, Academic status; and Variable #10, Major(s):

What is your gender?
1) Female
2) Male
3) Other



Indicate how often you employ each format below for active reading:


Never

Rarely

Sometimes

Quite
Often

Very
Often

Print book/article
Scrollable web page
PDF file read online
PDF file printed out
Documents
specifically
formatted for
ereading devices
Other (Please
specify):

Indicate how often you employ each device below for active reading:
Never

Rarely

Paper
Desktop computer
Laptop computer
Amazon Kindle
Barnes & Noble’s
Nook
Sony Ereader
Apple iPad
Smart Phone
Other (Please specify):



Sometimes

Quite
Often

Very
Often

What is your age?
1) 19 and Under
2) 20-29
3) 30-39
4) 40-49
5) 50-59
6) 60 and Older

What is your current academic status?
1) Master’s student
2) Doctoral student
3) Post-doc
4) Faculty
5) Other (Please specify): _____________
What are your major(s) or research emphases (field(s) of study)?
_____________
Besides these three key concepts in the two major research questions, another key
concept was “common physical characteristics of active reading environments,” which
generated a practical research question about physical environments for active reading.
The last group of questions was created by translating the concept of “common physical
characteristics of active reading environments” into two key questions using Variable #3,
Place for active reading and Variable #4, Tools for active reading:
Indicate how often you read at each place below for active reading:


Never

Rarely

Library
Home
Office
Café or restaurant
Transportation (e.g., bus)
Other (Please Specify):



Sometimes

Quite
Often

Very
Often

Indicate how often you use each tool below for active reading:
Never

Rarely

Sometimes

Quite
Often

Very
Often

Computer
Ereader (e.g., Amazon
Kindle)
Printer
Pen/Pencil,
Paper/Notepad
Highlighter pen
Other (Please specify):

4.1.1.5 Step 5. Test of quality of the questionnaire
As mentioned in section 3.5 Quality assurance criteria, several strategies were conducted
before the pilot study (at the design stage), during the pilot study (at the evaluation stage),
and after the pilot study in order to maximize the quality of the initial questionnaire.
Along with all these efforts, the initial version of the questionnaire (Appendix A.1) was
revised and finalized for the larger study (Appendix A.2).
4.1.1.6 Step 6. Formulation of the final questionnaire
The online questionnaire was designed using Qualtrics (www.qualtrics.com), which is an
online survey administration tool that facilitates the design of web-based questionnaires.
To minimize unintended order effects (Dillman et al., 2009), a page-by-page construction
was selected rather than a one-screen construction that would enable respondents to
review all questions and answer them in any order, although the latter is better for
respondents to review relevant information easily and quickly (Corbin & Strauss, 2008).
In order to minimize measurement error while still minimizing nonresponse error,
Request Response was selected over Force Response (Dillman et al., 2009) because the



latter may encourage respondents to select random, dishonest answers, instead of
accurate answers to escape an error. Also, the option ‘Other’ for further descriptions and
elaborations was included so as not to force respondents to select one answer that was
inaccurate rather than insert an accurate answer that the survey did not anticipate.
Providing the option of ‘Other’ might thus capture important data that are otherwise
excluded by a pre-defined list of response options. However, Force Response was
selected over Request Response for questions eliciting basic information, such as
demographic information, and for straightforward questions, such as respondents’ chosen
pseudonyms and made-up email addresses, so as not to omit critical information.
Following Dillman et al.’s (2009) advice to clearly differentiate one kind of
question from another kind by giving visual cues, round radio buttons were used for
single-answer questions and square check boxes for multiple-answer questions. Also, as
Dillman et al. advise, to assign each respondent a unique ID, the respondent was asked to
voluntarily provide full name and email address at the end of the questionnaire. This
measure was taken to minimize the problem of identifying multiple responses from one
person who used changing IP addresses, which can arise when data are collected
anonymously instead of with individuals’ contact information.
4.1.1.7 Step 7. Choice of population and sample design and Step 8. Decisions about the
fieldwork
The target population for the main study comprised graduate and post-doctoral students
and faculty whose native language was English. This population was considered to be
expert readers and more likely than other populations to be involved in active reading
associated with teaching and research.



To gather questionnaire data, an email invitation (Appendix B.3), along with the
link to the questionnaire, was sent to the PHD-DESIGN, jESSE, and MEDIAIU-L
electronic mailing lists. PHD-DESIGN, a world-wide (electronic) mailing list for doctoral
students and faculty members in design disciplines, was chosen because its subscribers
are people in academia, who are a subset of the target population of this study and who
are likely to be interested in its topic (i.e., active reading practices and ebook design). The
jESSE electronic mailing list, which is a world-wide electronic mailing list for
professionals in library and information science, was chosen for similar reasons, as well
as on the assumption that because almost every institution has a library, many
information professionals including librarians have connections with campus-wide
electronic mailing lists, subscribe to jESSE, and are interested in ebook design and thus
might be willing to participate in the survey. The MEDIAIU-L electronic mailing list,
whose subscribers are people who are interested in media at Indiana University, was
chosen particularly to recruit volunteers who would be able to be physically present for
the fourth and fifth video phases of this study.
Additionally, to attract participants from a wider diversity of disciplines and who
would be able to be physically present for the video phases of the study and follow-up
interviews, the second recruitment email (Appendix B.4) was sent to the directors of
graduate studies, the associate deans for graduate program, and graduate secretaries
whose schools or departments offered both master’s and doctoral programs at Indiana
University Bloomington. Ten schools and 37 departments, which were accessible from
http://www.iub.edu/academic/majors/by-school.shtml as of March 22, 2012, were
contacted (Appendix B.5).



In order to increase response rates, follow-up reminders (Appendix C.1) were sent
via email to the electronic mailing lists one or two times after the first distribution of the
questionnaire (Dillman et al., 2009). Also, participants were asked to repost the link to
the questionnaire to any campus-wide electronic mailing lists in their institutions or any
other appropriate (electronic) mailing lists as a snowball sampling technique, which is a
purposive sampling method that helped the researcher reach appropriate participants for
the study.
4.1.2 Data cleaning and analysis

As of September 17, 2012, 676 surveys had been collected. From this group, 165
incomplete cases were eliminated, consisting of 88 surveys that stopped at the very early
stage about general and academic reading practices, 68 surveys that stopped right before
the questions about active reading, and 9 cases that stopped after a question about one
dependent variable, the heaviness of annotations. In short, the majority of incomplete
cases had no meaningful data about active reading practices and so could have no
meaningful impact on key results of this study. As a second step, 33 non-qualified cases
were eliminated; these included 23 respondents who were non-native speakers of English
and 10 respondents who were not master’s, doctoral, or postdoctoral students or faculty.
Third, text-based answers to open-ended questions of academic status/degree,
country, city, and school name were standardized. For example, “I’m a librarian working
on a PhD part-time” was coded as doctoral student and other. “Orange County, NC” was
coded as USA. School names were standardized based on the Directory of Institutes
Offering Accredited Master’s Programs at the American Library Association (ALA)



website (Appendix C.2), the website of each department, school, or university (if not
available from the ALA website), and the Indiana University Bloomington website
(Appendix B.5). As the fourth step, majors were coded as 1 to 60 based on the
Classification of Instructional Programs at the National Center for Education Statistics
website (Appendix C.3), 61 as dual, and 62 as unknown. As the fifth step, full-time status
was coded as 1 and part-time status was coded as 2, and other (e.g., on leave, retired) was
coded as 3. Finally, cases with multiple degree statuses (e.g., doctoral student and faculty,
post-doc and faculty) were re-coded as Other. After the first round of cleaning, 478 cases
were left; these were used for descriptive analysis.
To run cluster analysis and binary logistic regression using SPSS 20, 42 cases
from groups with only a few cases or with missing values were eliminated, including 3
cases from postdoc participants, 3 cases from participants whose gender was not
identified, and 36 cases with missing values, including 16 missing values for Types of
annotation in terms of medium and location, 5 missing values for Format, 4 missing
values for Device, 4 missing values for Place, 4 missing values for Tool, and 3 missing
values for Major(s). Also, 35 cases with majors that had fewer than 10 cases were recoded by combining them with cases in related categories with a larger number of cases:
Seven cases in the category of “Architecture and Related Services” were combined with
cases in the category of “Visual and Performing Arts”; 2 cases in the category of “Area,
Ethnic, Cultural, Gender, and Group Studies” were combined with cases in the category
of “Communication, Journalism, and Related Programs”; 3 cases in the category of
“English Language and Literature/Letters” were combined with cases in the category of



“Foreign Languages, Literatures, and Linguistics”; 6 cases in the category of “Philosophy
and Religious Studies,” 1 case in the category of “Public Administration and Social
Service Profession,” and 2 cases in the category of “Business, Management, Marketing,
and Related Support Services” were combined with cases in the category of “Social
Sciences”; and 2 cases in the category of “Computer and Information Sciences and
Support Services,” 5 cases in the category of “Engineering,” 1 case in the category of
“Biological and Biomedical Sciences,” 1 case in the category of “Psychology,” and 1
case in the category of “Health Professions and Related Programs” were combined to
create a new category of “Hard Science.” As a result of the second round of cleaning, a
total of 436 cases remained; these were used for cluster analysis and binary logistic
regression using SPSS 20.
After cleaning the data, frequency, cluster analysis, and binary logistic regression
were run using SPSS 20.
4.2 Qualitative components
After a target population had been identified from the findings of the quantitative survey,
the qualitative components were conducted to answer the research questions in section
1.2. This section discusses procedures and settings as an overview of the qualitative
components, how the qualitative data were collected using the three major types of
qualitative research methods “document examination, interview, and observation”
(Potter, 1996, p. 95), and how the data were analyzed.



4.2.1 Procedures and settings
To employ a naturalistic inquiry approach toward understanding the target phenomenon
of reader-text interaction holistically, qualitative data were collected from multiple
participants utilizing multiple methods. Following the first phase, the quantitative
component, the main study consisted of four phases of the qualitative components: an
annotation study (document examination), follow-up interviews after the annotation
study, a video study in a lab simulation (distant observation), and follow-up interviews
after the video study.
Annotations in the second phase were collected from documents that had been
read by survey respondents in real-world settings. Follow-up interviews in the third phase
took place in real-world settings, at the researcher’s office, or in a public lobby at times
of the participants’ choosing. Follow-up interviews in the fifth phase took place in the lab
setting right after observations while participants’ memories were still fresh.
Observations in the fourth phase were conducted by bringing participants to a designated
“naturalistic laboratory” (Hoffman & Militello, 2008, p. 380). “Naturalistic laboratory” is
a concept proposed by researchers who have attempted to go beyond a simple dichotomy
between artificial and natural settings by creating a laboratory “in which participants have
experiences similar to those had in the human ecology,” as distinguished from an
artificial laboratory, “in which participants have experiences with little or no reference to
the human ecology;” from a natural laboratory, which Jackson (2007) has described as
“research conducted in a human ecology that has been partly machined to conduct
research;” and from a field laboratory, in which “research methods from ethnography or
methods adapted from the artificial laboratory are used in the human ecology or in a



nonlaboratory-designed environment” (p. 380). “Naturalistic laboratory” was selected
because it would be too challenging for one researcher to collect diverse concurrentlyoccurring data from participants’ real-world settings within a limited amount of time as
well to control data quality and quantity in a naturalistic setting. Also, participants
brought their own documents and devices, instead of the researcher’s designated
materials and devices, to the lab. To reduce interruptions during participants’ naturalistic
silent reading, I chose not to use a think-aloud protocol, which is a method that has been
used to elicit non-behavioral data in reading research. To reduce participants’ awareness
of being observed, they were video-recorded so that non-participant observation could
take place outside of the lab.
4.2.2 Phase 2: Annotation study (document examination)
This section, the first phase of the qualitative component, discusses how annotations in
text and page margins and notes in separate notepads, as outcomes of a well-known
active reading strategy (Blachowicz & Ogle, 2008), were collected and analyzed. The
primary purpose of this phase was to investigate an aspect of reader-text interaction in
active reading. The secondary purpose was to create questions for follow-up interviews in
the third phase, which would elicit participants’ conscious and unconscious intentions
behind their annotations.
4.2.2.1 Data collection
Examination of annotations in documents and notes in notepads, defined as “any
preserved recording of a person’s thoughts, actions, or creations” (Potter, 1996, p. 95),
was a major source of evidence for understanding an aspect of reader-text interaction in
active reading. Unlike observations that “allow us to see overt behavior,” this approach



allowed collection of non-behavioral data such as “the inner meaning of everyday events”
(Merriam, 2009, p. 142).
As the first step, a recruitment message (Appendix F) was emailed to 259
participants from the first online survey phase who had either agreed to participate or
were indecisive as to whether to participate in the annotation study. They were asked to
forward via email representative samples of their documents in any format (software) and
device (hardware), and their notes or/and annotations on these materials, as well as
contextual information (e.g., when, where, why they annotated). In order to make sure
that their reading samples were representative of their active reading, participants were
asked to articulate their rationales for selecting these particular reading samples.
Forty-nine participants provided their documents, including annotations and/or
reading notes on paper or in digital formats in person or via email, post mail, or campus
mail. Thirty participants were excluded from the annotation study for the following
reasons: One made annotations to give editorial comments on somebody else’s writing,
which is inconsistent with the definition of annotations in this study; three provided no
annotations or reading notes that could be analyzed; one provided annotations that were
too illegible to analyzed; four provided reading notes that comprised annotated
bibliographies or summaries that were too short to be useful products of active reading;
five provided reading notes without their associated documents that could not be
analyzed accurately in a context-sensitive way; one was hearing disabled, a condition
beyond the scope of this study; two provided outdated annotations or reading notes that
were too old to fall within the scope of this study; one provided annotations that were
made for mixed purposes (i.e., pleasure and work); one provided annotations or reading



notes but did not agree to participate in follow-up interviews; and eleven were faculty or
master’s students who were identified from the first phase as less likely to be heavy
annotators/note-takers and/or strong advocates of annotation.
As a result, 19 Ph.D. students were selected who had been identified from the first
phase of the online survey as likely to be heavy annotators/note-takers and/or strong
advocates of annotation, representing groups who made diverse kinds of annotations
using diverse formats and tools, as represented in Figure 5 (see sections 5.1.3 and 6.1 for
further details):

Ph.D.
1

4
2

Tool lovers
(with paper
tools and a
computer)

3

D
Digital
lovers
(with paper
and digital
formats)

1. A group of Ph.D. students who use
diverse paper tools as well as a
computer frequently
2. A group of Ph.D. students who use
digital and paper formats,
3. A group of Ph.D. students who use
diverse tools and diverse formats, and
4. A group of Ph.D. students who use
neither diverse formats nor diverse
tools

Figure 5: Participants in the second phase annotation study

4.2.2.2 Data analysis
As the first step of data analysis, the 19 participants were ranked (see Table 9) from the
one with the most diverse and heaviest annotations to the one with the least diverse and
lightest annotations, indicated first by the diversity of annotations (i.e., the average
number of annotation types, underlines, highlights, notes in page margins, and symbols,
across the total number of documents provided by each participant) and then by the



density of annotations, represented by the average percentage of total text pages that had
annotations, that is, pages with annotations divided by the total number of text pages.
For example, the second-ranked participant provided four documents, three of which
included three types of annotation (highlights, symbols, and notes in page margins) and
one of which included four types of annotation (highlights, underlines, symbols, and
notes in page margins). Thus, the average number of annotation types was 3.25 = (3 + 3 +
4 + 3)/4. Also, 85% (34 out of 40 pages), 100% (4 out of 4 pages), 77% (20 out of 26
pages), and 91% (10 out of 11 pages) were annotated in four individual documents. Thus,
the average percentage of the total page number with annotations was 84%.
Second, each participant’s documents were ranked from the one having the
heaviest and most diverse annotations to the one having the least heavy and diverse
annotations, first by the diversity of annotations and then by the heaviness of annotations
or the amount of notes. This two-step sorting process enabled the researcher to first
analyze the heaviest and most diverse annotations/notes and so to come up with insightful
questions at earlier stages of the research, before subsequent analyses within a participant
and across participants, which helped elicit many diverse conscious and unconscious
intentions behind annotations, even from participants who did not make heavy and
diverse annotations.



102

F

F

F

7

8

9

F

4

M

F

3

6

M

2

F

M

1

5

Gender

#

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Degree
program

Modern US History – cultural
history, history of consumption,
social history, history of gender
and sexuality
Anthropology - Archaeology in
Social Context
Religious Studies - American
Religion

Modern American/European
History
Second language acquisition,
sociolinguistics, phonetics,
statistics
Information Science information search behavior and
information design
U.S. History / Urban
Environmental History
Literacy, Culture and Language
Education (minor in Media &
Research)
Design, democracy, indigenous
knowledge and socio-technical
systems

Concentration(s)



Religious Studies

Anthropology

Design, Development,
Environment and
Material; Development
Policy and Practice
History

Education

History

Information

Second Language
Studies

History

Major(s)/
School or department
name(s)

Table 9: The 19 participants for the annotation study and the order of analysis

Desktop/
ON
Desktop/
ON

Desktop/
ON

Desktop/
ON

Paper/
ON
Desktop/
ON

Paper/
ON

Paper/
ON
Desktop/
ON

(ON: on documents/ OFF:
in separate notepads)

Reading device(s)/
Location of annotations

3.00

3.00

3.00

3.00

3.00

3.00

3.00

3.25

4.00

Diversity
of
annotations

71

77

80

83

88

90

100

84

82

Density of
annotations

103

Gender

M

F

F

F

M

F

F

F

F

F

#

10

11

12

13

14

15

16

17

18

19

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D. &
Faculty

Master’s &
Ph.D.
Ph.D.

Ph.D.

Ph.D.

Ph.D.

Degree
program

Table 9: continued

Archives and records
management
Gender Studies - Gendered
Technology and Media Use
Information
Science/Information
behavior/time pressure and
emotion

Knowledge Management

M.S. Industrial Engineering &
Ph.D. Engineering Education
Cognitive Psychology and
Cognitive Science
Cataloguing, mental models of
information and information
systems

Epistemology, Philosophy of
Logic
Design (specifically
communication design)
Informatics

Concentration(s)



Information School
(iSchool)

Psychological and Brain
Sciences
Information and Social
Sciences, School of (this
is where I am a faculty
member). Faculty of IT
(different university, this
is where I am a doctoral
student)
Education Faculty,
School of Information
Studies
Information and Library
Science
Gender Studies

Engineering Education

Information

Design

Philosophy

Major(s)/
School or department
name(s)

Unknown/OFF
(Digital)

Unknown/OFF
(Digital)
Paper/ OFF (Digital)

Unknown/OFF
(Digital)

Desktop/
ON
Paper & Desktop/
ON
Desktop/
ON
Desktop/
ON
Desktop/
ON
Unknown/
OFF (Paper)

(ON: on documents/ OFF:
in separate notepads)

Reading device(s)/
Location of annotations

0.88

0.91

1.00

1.00

1.00

1.00

1.00

2.00

2.33

3.00

Diversity
of
annotations

13

5

5

9

24

33

41

49

22

65

Density of
annotations

Third, all individual instances of annotations on documents (symbol, underline,
highlight, memo), as shown in Figures 6 and 7 below, were scanned from the first page to
the last page to identify common themes of recurring patterns (e.g., colors of highlights,
underlines, and notes; locations of highlights, underlines, and notes; types of symbols;
contents of notes).


Figure 6: Annotations on a paper document


Figure 7: Annotations on a digital document



Similarly, all individual instances (e.g., symbol, underline, highlight, memo) of notes in
separate notepads on paper or in digital formats, as shown in Figure 8 below, were
scanned while continuously referring back to the text they corresponded to in the original
documents to identify common themes of recurring patterns (e.g., types of symbols,
contents of notes, locations of notes).


Figure 8: Notes in separate notepads on paper and in digital format

Fourth, after identifying common themes, all annotations and notes were closely
examined instance by instance to identify the annotator’s intention(s), needs, or desires
behind each instance (reasons for annotation or note-taking) and to create questions for
follow-up interviews in the subsequent phase, as exemplified in Table 10 below. All
instances were analyzed in all documents of the first two participants (six and four
documents respectively) who were ranked as making the heaviest and most diverse



annotations/notes. For the remaining 17 participants, all instances in their subsets of
documents (two or three or in one case one document) were analyzed only until new
reasons did not emerge, indicating that data saturation had been reached.

Table 10: Example of initial coding (1)
Instances
Color of highlights

Yellow vs. green

Location
(Page #)
Multiple pages

Color of notes and
underlines
Symbols

Blue vs. green

Multiple pages

Star(s)

Multiple pages

Vertical lines vs. curly
bracket

p. 1, p. 3 vs. pp.
5-7

Jules David Prown

p. 1

Material culture is

p. 1

Highlights

Title

p. 1

Notes in page
margins

Artifacts as historical
evidence

p. 3

Location of notes

Cover page vs. margin on
the top

Underlines



Questions for follow-up
interviews
What are the differences
between yellow and
green?
What are the differences
between blue and green?
Are three stars for the
most important text? If
so, from what perspective
are they important? From
your own research or
from the author’s
viewpoint?
What are the differences
between vertical lines and
curly brackets?
Why did you underline
the author’s name?
Do you always underline
a definition?
Why did you highlight a
title? What are the
differences between
underlines and
highlights?
Is this memo about a
short summary? If so,
what is it for? Is it for
grasping a key idea
quickly later?
Does the location of notes
matter? For example, do
you write a big idea about
the entire text in the cover
page?

Fifth, coding items signifying reasons for annotating were continuously revised or
refined through constant comparison within a participant and across participants. For
example, “to evaluate the author’s argument” was first identified as a reason but was
found to be not specific enough to differentiate one instance from another. Therefore, it
was broken down into more specific levels: “the clarity of the author’s argument,” “the
validity of the author’s argument,” and “the robustness of evidence for the author’s
argument.” As another example, “to make text about a historical interpretation or reinterpretation stand out” was first identified as one reason, with the assumption that
readers underline text based on their purposes for reading non-contextually, without
taking into account the global idea of a whole paragraph. However, it was re-identified as
“to make a historic or historical change or shift stand out” by re-directing a perspective of
the analysis with the addition of the assumption that readers underline text contextually,
taking into account the global idea of a whole paragraph, no matter what their purposes
for reading might be. These revisions or refinements continued until the “reason” coding
items were stabilized with no inconsistencies in level of specificity or direction of
analysis and with no further reasons being added.
Last, in order to compose questions for follow-up interviews in the subsequent
phase, all common thematic categories of intentions, needs, or desires across individuals
were identified by eliminating redundancies, as shown in Table 11 below.



Table 11: Example of initial coding (2)
Instances
Color of highlights

Yellow only

Location
(Page #)
Multiple pages

Color of notes and
underlines
Symbols

Blue, green, red

p. 25

Star(s)

Multiple pages

Underlines

Arrow
gender, class, ...

Multiple pages
p. 24

three case studies
Title
aim
Raw materials for info.
About ...
e.g., my Mathers exhibit or
the ...
Future text to consult and/or
assign?
Cover page

p. 24
Front page
p. 24
p. 25

Highlights
Notes in page
margins

Location of notes

p. 28
p. 43

Questions for followup interviews
Why did you use
yellow only?
How about red?
Degrees of
importance
Anchoring
A list of parallel
words or concepts
Numeral word
Title
Text organization
Summary by
paraphrasing
Link to prior or
relevant knowledge
Future reference
Key ideas of the
entire text

Toward the end of the analysis, annotation analysis was carried out for each
participant using a codebook featuring a letter/numeric system (e.g., LN(1)0710),
developed from the common thematic categories of intentions, needs, or desires derived
from the follow-up interviews after the maximum levels of saturation had been reached.
An example of the intermediate codebook is shown in Table 12 below.



10

LN stands for linking as one reason for annotating; 1 stands for examining and developing content
carefully and critically as one purpose for annotating; 07 stands for a specific external resource to be linked
with



Table 12: Example of intermediate coding
Types of
instances
Highlights

Purpose
0) To examine and develop
content carefully and
critically
1) To grasp the author’s
intentions and grasp the
author’s key points quickly

2) To react to provoking
text items and find them
later quickly

3) To seek the reader’s
target information items
(background knowledge)
and find them later quickly

Reason(s) for annotating
(Intention(s), needs, or desires)
LN(1)07: Link with an external resource
LN(1)08: Link with prior knowledge
LN(1)09: Link with practical examples
AD(1)03: Disagreement
SL(2)01: The author’s key argument or idea
(of a section)
SL(2)02: The author’s key argument or idea
about the entire text
SH(2)04: Summary by paraphrasing
TX(3)03: List
TX(3)04: Numeral word(s)
TX(3)06: Key terms that are defined
TX(3)07: Definition or definitional
TX(3)17: Practical (real-life) examples
SL(3)10: Future quotation



4.2.3 Phase 3: First follow-up interviews

The third phase of the study involved interviews, which Merriam (2009) characterized as
“necessary when we cannot observe behavior, feelings, or how people interpret the world
around them” (p. 88); it was designed to overcome the limitations of document
examination in the second phase and increase “the span of inferential reasoning”
(Marshall & Rossman, 2011, p. 162). In other words, follow-up interviews were
conducted to go beyond the researcher’s inferential reasoning from documents by
obtaining information directly from participants.
The primary purpose of the first follow-up interview was to obtain participants’
confirmation of the researcher’s interpretations of their use of annotations and notes in
the second phase and additional information that might not have been available during

 

the researcher’s investigation of documents. The secondary purpose of the follow-up
interview was to create a coding scheme by identifying recurring patterns in annotations
and notes and other contextual information participants reported that was relevant to their
annotations and notes (e.g., flipping through pages). The purpose of the coding scheme
was to enable the first three participants, who were assigned to check the adequacy of the
codebook, to code instances of their own annotations and notes and the researcher to
create questions for follow-up interviews after participants’ reading in the fourth phase
(the video study), while avoiding use of intrusive research methods such as a think-aloud
protocol during silent reading. The other secondary purpose of the interviews was to help
participants, who would also participate in the video study and follow-up interviews,
become familiar with the process of eliciting and voicing their own thoughts in
preparation for the fourth and the fifth phases.
4.2.3.1 Data collection
Eighteen of the 19 Ph.D. students in the annotation study (phase 2) were recruited by
email (Appendix G.1 or Appendix G.2) to participate in follow-up interviews (see Table
13 below).



111

M

F

6

7




F

F

3

5

M

2

F

M

1

4

Gender

#

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Degree
program

Modern US History – cultural
history, history of consumption,
social history, history of gender
and sexuality

U.S. History / Urban
Environmental History
Literacy, Culture and Language
Education (minor in Media &
Research)
Design, democracy, indigenous
knowledge and socio-technical
systems

Modern American/European
History
Second language acquisition,
sociolinguistics, phonetics,
statistics
Information Science - information
search behavior and information
design

Concentration(s)





Design, Development,
Environment and
Material; Development
Policy and Practice
History

Education

History

Information

Second Language Studies

History

Major(s)/
School or department
name(s)

Table 13: The 18 participants for the first follow-up interviews

Desktop/
ON

Desktop/
ON

Paper/
ON
Desktop/
ON

Paper/
ON

Reading
device(s)/
Location of
annotations
(ON: on
documents; OFF in
separate notepads)
Paper/
ON
Desktop/
ON

Email

Voice
Skype

Skype &
Phone
In person

Email

In person

In person

Mode of
interview

Email (with
pictures of the
participant’s
place)

The participant’s
place

Email (with
pictures of the
participant’s
place)
The participant’s
place
A public lobby

The researcher’s
office
The researcher’s
office

Interview location

112

F

F

F

M

11

12

13

14

F

9

M

F

8

10

Gender

#

Master’s
& Ph.D.
Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Degree
program

Table 13: continued

M.S. Industrial Engineering &
Ph.D. Engineering Education
Cognitive Psychology and
Cognitive Science

Informatics

Design (specifically
communication design)

Epistemology, Philosophy of
Logic

Religious Studies - American
Religion

Anthropology - Archaeology in
Social Context

Concentration(s)

Psychological and Brain
Sciences

Engineering Education

Information

Design

Philosophy

Religious Studies

Anthropology

Major(s)/
School or department
name(s)

Desktop/
ON
Desktop/
ON
Desktop/
ON

Paper & Desktop/
ON

Desktop/
ON

Desktop/
ON

Reading
device(s)/
Location of
annotations
(ON: on
documents; OFF in
separate notepads)
Desktop/
ON

Video
Skype
Video
Skype
Email

Email

Email

Email

Email

Mode of
interview

Email (with
pictures of the
participant’s
place)
Email (with
pictures of the
participant’s
place)
Email (with
pictures of the
participant’s
place)
Email (with
pictures of the
participant’s
place)
The participant’s
place
The participant’s
place
Email (with
pictures of the
participant’s
place)

Interview location

113

F

F

F

17

18

F

15

16

Gender

#

Ph.D.

Ph.D.

Ph.D.

Ph.D. &
Faculty

Degree
program

Table 13: continued


Information Science/Information
behavior/time pressure and
emotion

Gender Studies - Gendered
Technology and Media Use

Knowledge Management

Cataloguing, mental models of
information and information
systems

Concentration(s)



Information School
(iSchool)

Gender Studies

Information and Social
Sciences, School of (this
is where I am a faculty
member). Faculty of IT
(different university, this
is where I am a doctoral
student)
Education Faculty,
School of Information
Studies

Major(s)/
School or department
name(s)

Unknown/OFF
(Digital)

Paper/ OFF
(Digital)

Unknown/OFF
(Digital)

Reading
device(s)/
Location of
annotations
(ON: on
documents; OFF in
separate notepads)
Unknown/OFF
(Paper)

Email

Email

Email

Email

Mode of
interview

Email (with
pictures of the
participant’s
place)
Email (with
pictures of the
participant’s
place)
Email (with
pictures of the
participant’s
place)

Email (with
pictures of the
participant’s
place)

Interview location

Individual in-depth, face-to-face interviews were conducted with some participants in the
researcher’s office or at a public place of the participant’s choosing. The latter especially
for participants who did not read at one designated place or did not want to be
interviewed in their own places. Others were interviewed by Skype or email in their own
places, which allowed collection of naturalistic data in context and provided the
interviewees with easy access to additional documents when needed. Interviews took
about an hour and were voice recorded along with note-taking by the researcher. To
minimize the negative effects of voice recording (Denscombe, 2010), participants were
reminded that the data would be kept confidential before interviews.
In order to address a broad range of questions by gathering descriptive,
explanatory, and interpretative information, Rubin and Rubin’s (2005) two types of
classifications of interviews were selected over types of classification governed by
specific philosophical or disciplinary orientations (Fontana & Prokos, 2007; King &
Horrocks, 2010; Kvale & Brinkmann, 2009; Marshall & Rossman, 2011; Merriam, 2009;
Patton, 2001). These researchers have introduced different types of interviews from
different perspectives, including structure (e.g., structured, semistructured, unstructured),
philosophical orientation (e.g., neo-positive, constructivist, postmodern), disciplinary
orientation (e.g., ethnographic, phenomenological, focus group), and types of questions
(e.g., factual, conceptual, narrative, discursive).
Rubin and Rubin (2005)’s first type of classification divides interviews by
“breadth of focus (narrow to broad) and subject of focus (meaning to description)” (p. 5).
Among the nine types of interviews (Table 14) in this classification, elaborated case



studies, whose purpose is “to find out what happened, why, and what it means” (p. 6),
was selected as consistent with the purpose of this study.
Table 14: Rubin and Rubin’s first type of interview classification (taken from Table 1.1:
The variety of qualitative interviews, Rubin & Rubin, 2005, p. 5)
Narrowly-focused
scope
Concept classification

Focused mainly on
meanings and
frameworks
In-Between

Exit interview

Focused mainly on
events and processes

Investigating
interviewing

In-Between
Theory elaboration
Oral histories
Organizational culture
Action research
Evaluation research

Broadly-focused
scope
Ethnographic
interpretation
Life history
Elaborated case
studies

Rubin and Rubin (2005)’s second type of classification divides interviews
according to “how the overall research projects are carried out” (p. 9). For this study,
topical interviews, which are designed to “explore what, when, how, why, or with what
consequences something happened” and “work out a coherent explanation by piecing
together what different people have said” (p. 11), were selected over the second type in
this classification, cultural interviews.
In order to gather interview data guided by elaborated case studies and topical
interviews, the researcher primarily posed the first three of Patton’s (2001) six general
question types, “behaviors, opinions, feelings, knowledge, sensory data, and
demographics” (p. 351). Behavior questions elicit “behaviors, experiences, actions, and
activities that would have been observable” (pp. 349-350). Opinion questions probe “the
cognitive and interpretive processes of people [by] ask[ing] about opinions, judgments,
and values” (p. 350). Feeling questions elicit “feeling responses of people to their
experiences and thoughts” (p. 350).



The interviews were semi-structured, the middle position in the continuum of
interview structure. As Merriam (2009) notes, semi-structured interviews are “guided by
a list of questions or issues to be explored, and neither the exact wording nor the order of
the questions is determined ahead of time” (p. 90). Therefore, the preliminary questions
(Appendix H.1) were drawn from the findings of the second phase of the annotation
study, not to guide the order of the interview but as a reminder to cover specific points.
Other questions were triggered by the participant’s responses to questions in the natural
flow of conversation. In order to minimize “a bias or an assumption that the researcher is
making” (Merriam, 2009, p. 99) due to leading questions, participants’ own explanations
of individual annotations and notes preceded the questions that were prepared from the
second phase. More importantly, in order to follow the methodological approach of
constructivist grounded theory as described by Fontana and Prokos (2007), the
interviewer was “an active participant” (p. 57) who was mindful of “the necessity of
situating data from interviews in their social context” (p. 57), rather than “an unbiased
observer” (p. 58) who “gather[s] existing data from respondents” (p. 57).
At first, recruitment emails without interview questions (Appendix H.1) were sent
prior to the interviews to elicit participants’ preferred interview options (in-person, email,
or Skype). Later, however, as the same data converged across participants without
suggesting new thematic categories, data saturation was deemed to be reached, so
subsequent recruitment emails (Appendix H.2) included more directive interview
questions in order to guide participants’ answers in ways to reconfirm the researcher’s
interpretations of previous data and obtain new insights. Also, follow-up emails were
sent, if necessary, to clarify unclear comments, posing such questions as, “You said that



you rarely take notes on the pages of a book. Is it because you have been taught
(culturally) that it is not a good habit?” Follow-up emails were also sent to obtain and ask
questions about photos that showed contextual information about participants’ reading
places (e.g., home, office), such as “Is a blue sticky note on your laptop related to your
active reading? Is there any object in any photo that is related to active reading?”
There are no definite rules for the order of questions (Merriam, 2009). However,
ordering questions from those that elicit “relatively neutral, descriptive information” to
those calling for “perceptions, opinions, values, emotions” is recommended (p. 103).
Therefore, questions moved from contextual (e.g., When, where, and why do you read
books or articles?) and behavioral (e.g., What are you doing while reading?) to reflective
aspects (e.g., What does this specific underline mean to you?), the latter to prompt the
participant to share thoughts that might not easily be accessible to others but were very
useful for understanding deeper levels of mental processes closely associated with active
reading (Appendix H.1, Appendix H.2).
4.2.3.2 Data analysis
As mentioned in the earlier discussion of constant comparison in grounded theory,
analysis of the annotation data was followed by analysis of follow-up interview data, one
participant at a time, according to the schedule in Table 15. However, if participants
being interviewed by email delayed responding, the researcher moved onto annotation
analysis or follow-up interviews with next available participant so as to maintain
momentum in data collection and analysis.



118

F

F

F

M

7

8

9

10

F

4

M

F

3

6

M

2

F

M

1

5

Gender

#

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Degree
program

Modern US History – cultural
history, history of consumption,
social history, history of gender and
sexuality
Anthropology - Archaeology in
Social Context
Religious Studies - American
Religion
Epistemology, Philosophy of Logic

Literacy, Culture and Language
Education (minor in Media &
Research)
Design, democracy, indigenous
knowledge and socio-technical
systems

Information Science - information
search behavior and information
design
U.S. History / Urban Environmental
History

Second language acquisition,
sociolinguistics, phonetics, statistics

Modern American/European History

Concentration(s)

Table 15: Schedule for participation in the third phase

Philosophy

Religious Studies

Anthropology

Design, Development,
Environment and
Material; Development
Policy and Practice
History

Education

History

Information

Second Language Studies

Major(s)/
School or department
name(s)
History

4/12/13

3/27/13

3/17/13

3/8/13

1/7/13 (eliciting
preferred
interview option)
2/12/13 (eliciting
preferred
interview option)
2/18/13

Invitation email
(after annotation
analysis) by
7/6/12 (eliciting
preferred
interview option)
8/30/12 (eliciting
preferred
interview option)
1/3/13

4/18/13

4/8/13

5/25/13

3/29/13

3/29/13

2/18/13

1/14/13

1/7/13

9/27/12

7/17/12

Interview or
email reply by

Email

Email

Email

Email

Voice Skype

In person

Skype &
Phone

Email

In person

In person

Mode of
interview

119

F

F

18

19

F

15

F

M

14

17

F
F

12
13

F

F

11

16

Gender

#

Ph.D.

Ph.D.

Ph.D.

Ph.D.

Ph.D. &
Faculty

Ph.D.
Master
& Ph.D.
Ph.D.

Ph.D.

Degree
program

Table 15: continued

Gender Studies - Gendered
Technology and Media Use
Information Science/Information
behavior/time pressure and emotion

Archives and records management

Knowledge Management

Design (specifically communication
design)
Informatics
M.S. Industrial Engineering & Ph.D.
Engineering Education
Cognitive Psychology and Cognitive
Science
Cataloguing, mental models of
information and information systems

Concentration(s)




Information School
(iSchool)

Psychological and Brain
Sciences
Information and Social
Sciences, School of (this is
where I am a faculty
member). Faculty of IT
(different university, this
is where I am a doctoral
student)
Education Faculty, School
of Information Studies
Information and Library
Science
Gender Studies

Information
Engineering Education

Major(s)/
School or department
name(s)
Design

6/22/13

6/18/13

6/3/13

6/3/13

7/2/13

5/22/13

5/15/13
5/20/13

Invitation email
(after annotation
analysis) by
4/23/13

6/26/13

7/10/13

Not received

7/11/13

7/22/13

5/27/13

5/24/13
5/28/13

5/8/13

Interview or
email reply by

Email

Email

Email

Email

Email

Email

Video Skype
Video Skype

Email

Mode of
interview

Following is a summary of how the codebook was developed. The first codebook
was built by highlighting key phrases or sentences in the first participant’s written
interview scripts, assigning them individual codes (initial coding) and grouping them into
emerging themes (intermediate coding). For example, one thematic category, “I want to
prioritize a part of a text hierarchically and indicate the degree of importance,” was
created based on the following interview excerpt:

...I have to go back and read all of this now because I have not
prioritized within that, um, and that’s when I started, especially … my
senior year and my first few years of graduate school, that’s when I
started going and adding extra layers beyond the highlighting, so you
know, I talked about how all of my annotation style was hierarchically
based according to color, with a yellow highlighter,...

This thematic category evolved and was finalized by developing sub-categories
(individual coding items), as shown in Table 16 below.



Table 16: Example of intermediate coding
Thematic category
I want to prioritize a
part of a text
hierarchically and
indicate the degree of
importance:

Coding
Number
HR01

Coding
Item
Extremely

HR02

Most

HR03

Moderately

HR04

Least

HR05

Seemingly

Description
The author’s extremely important arguments
or ideas or what I must look at later without
fail (e.g., multiple indications such as stars
and underlining)
The author’s most important arguments or
ideas, or what I must look at later (e.g., three
stars)
The author’s moderately important
arguments or ideas, or what I might look at
later (e.g., two stars)
The author’s least important arguments or
ideas, or what I could look at later (e.g., one
star)
The author’s seemingly unimportant
arguments or ideas, but I am not sure; I
might or might not look at them later (e.g., a
curly bracket)

Additionally, if any coding items that were not confirmed directly by follow-interviews
had examples from the annotation analysis, these were added as coding items to be
considered by upcoming participants who might agree with them (e.g., text structure
matters to some in reading, but not to other readers) or to stimulate upcoming participants
who might have been reading unconsciously without thinking about their reading
processes and annotation activities. This strategy was based on the finding that many
participants, except for a few who had been reading with their own systematic (predefined) ways of annotating or note-taking, were reading unconsciously without thinking
about the meta-levels of their reading and annotation activities.
Ultimately, there were four kinds of coding items: 1) coding items that were
created by the researcher solely from follow-up interviews with participants; 2) coding
items that were created by the researcher and confirmed by follow-up interviews with
participants; 3) coding items that were created by the researcher in association with



particular annotation examples, but that were not confirmed by follow-up interviews with
participants due to lack of interview time; and 4) coding items that were created by the
researcher based on her insights or inferences from multiple sources such as annotation
examples, follow-up interviews, and the researcher’s personal experience.
The codebook was continuously revised by refining each new version that had
been developed from the previous codebook. Refinements to make coding items and their
descriptions consistent within a codebook were made by adjusting writing styles, word
choices, and levels of specificity; correcting coded information; moving coding items
from one thematic category to the other; removing redundant coding items under
different thematic categories; adjusting levels of thematic categories (from a coding item
to a coding thematic category); or creating new coding thematic categories. For example,
“Judgment/Evaluation: Further articulation,” which was a coding item in one thematic
category, was revised to form a new thematic category, “Elaboration,” comparable to an
existing thematic category, “Shortened,” by combining coding items in other thematic
categories.
After the iterative analysis processes of the annotation study and follow-up
interviews were completed, 14 thematic categories were identified as the reader’s
intentions, needs, or desires for static written forms of annotations or notes, as shown in
Table 17 below.



123

Key
player(s)
Text
(passive or
reactive
reading)
Reader
(purposeful
reading)
Both reader
and text
(negotiating
reading)

EN
AR
EV
LN
AD

7
8
9
10

4

6

HR

3

MN

SL

2

To seek the reader’s
target information or
knowledge
To grasp the author’s key
ideas

5

TG

1

To react to text passively

Coding
initial
TX

#

Purpose(s)

Descriptions

The reader wants to articulate implicit content
or elaborate concise content by [doing an
activity].
The reader wants to evaluate the original text
from [a perspective].
The reader wants to link [between one element
and another element].
The reader wants to add [a comment] in
response to the author’s argument.

The reader wants to enhance recall by [doing an
activity].

The reader wants to differentiate parts of a text
selectively and make [each of them] stand out.
The reader wants to prioritize a part of a text
hierarchically and indicate [the degree of
importance] or the relationship between items of
importance.
The reader wants to externalize or monitor
thinking by [doing an activity].

The reader wants to tag [a comment] for the
entire text.

The reader wants to make [a property or an
element] of text stand out (whether or not it
represents the author’s key ideas).

Table 17: Intermediate coding: Static annotations/notes

EV05: The quality (strength of
reasoning) of the author’s argument
LN07: Between information or
knowledge in different locations
AD01: My emotional reactions with
or without reasons for them

TG01: Target information or
knowledge that the reader wants to
or needs to focus on while reading
SL05: The author’s summary of a
section
HR01: The author’s extremely
important arguments or ideas (or
what the reader must look at later
without fail)
MN03: Writing out the steps or
processes of the reader’s thinking
from the initial thoughts to the final
conclusion
EN01: Re-writing key information
or knowledge about the entire text in
one place
AR02: Writing out abbreviations

TX07: Numeral words (e.g., three,
fourth)

Example of coding items

124

Medium

Key
player(s)

Purpose(s)

To maximize current
and/or future reading
experience

Table 17: continued

CT

12
13
MD

SH

11

14

Coding
initial
EX

#



The reader wants to shorten the original text or
his/her own notes by [doing an activity].
The reader wants to categorize the entire text
and assign it to [a category]
The reader wants to deploy [a property or an
element] of the medium.

The reader wants to extend ideas in the original
text by introducing [a comment].

Descriptions

MD06: The portability of documents
(e.g., paper instead of a digital copy)

CT02: A favorite article

EX01: The reader’s own
recommendation(s) for the author’s
argument
SH03: Numbering (e.g., 1,2,3)

Example of coding items

Based on the researcher’s own experience and the first follow-up interviews, nine
thematic categories were identified as the reader’s intentions, needs, or desires for
dynamic movements, as shown in Table 18 below.

Table 18: Intermediate coding: Dynamic movements
#
1

Coding initial
FLIP

Descriptions
The reader wants to flip through multiple
pages in order to [achieve a goal].

2

PROGRESS

3

FORWARD

4

LAST

5

BACKWARD

The reader wants to check the progress bar
in order to [achieve a goal].
The reader wants to move forward (or
scroll down) from one page to another in
order to [achieve a goal].
The reader wants to move forward (or
scroll down) to the last page in order to
[achieve a goal].
The reader wants to move backward (or
scroll up) from one page to another in
order to [achieve a goal].

6

FIRST

7

TOC

8

BACKFOR

9

ZOOM

The reader wants to move backward (or
scroll up) to the first page in order to
[achieve a goal].
The reader wants to move backward (or
scroll up) to the table of contents (TOC) in
order to [achieve a goal].
The reader wants to move back and forth
(or scroll up and down) across multiple
pages in order to [achieve a goal].
The reader wants to zoom in and out in
order to [achieve a goal].



Example of coding items
FLIP01: Check the number
(or percentage) of the
remaining pages
PROGRESS01: Check where
the reader is currently at
FOR01: Scan upcoming,
relevant text (e.g., 1st step,
2nd step)
LAST01: Scan the conclusion
section
BACK03: Examine
consistencies across colors,
forms, or hierarchical levels of
importance of annotations
FIRST01: Put a summary on
the first page
TOC01: Figure out the
relationship(s) between one
section and another or
between one section and the
entire text
BACKFOR01: Examine the
logical flow
ZOOM01: Figure out the
relationship(s) between one
section and another or
between one section and the
entire text

Also, based on the researcher’s own experience and the first follow-up interviews, five
thematic categories were identified as the reader’s intentions, needs, or desires for other
external activities (beyond one document or one application), as shown in Table 19.

Table 19: Intermediate coding: Other external activities
#
1

Coding
initial
WEB

2

APP

3

PRINT

4

PAD

5

MONITOR

Descriptions

Example of coding items

The reader wants to open a web page in order to
[achieve a goal].
The reader wants to use additional applications
or software in order to [achieve a goal].
The reader wants to print out a document in
order to [achieve a goal].
The reader wants to use a separate notepad in
order to [achieve a goal].

WEB01: Look up a
dictionary
APP02: Find information,
knowledge, or resources
PRINT02: Prevent eye
strain
PAD01: Write down further
action that the reader wants
to undertake as a reminder
MONITOR02: Facilitate
multi-tasking

The reader wants to utilize additional monitor(s)
in order to [achieve a goal].

The finalized codebook (Appendix I) that was prepared after the annotation study
and follow-up interviews, including 14 thematic categories for static written
annotations/notes, nine thematic categories for dynamic movements, and five thematic
categories for other external activities, was used for the subsequent phases of the video
study (distant observation) and follow-up interviews.
4.2.4 Phase 4: Video study (distant observation)
Merriam (2009) has pointed out that personal documents are a good source of data in
terms of knowing about “a person’s attitudes, beliefs, and view of the world,” but they
are not a good source of data in terms of knowing “what actually may have occurred” (p.
143). Rather, Merriam states, observations are suitable for collecting real-time firsthand
data of occurring events/phenomena and data of which participants may not be aware.



4.2.4.1 Data collection
To narrow down the scope of participants in this phase of the video study, Ph.D. students
who used paper and digital formats and paper and digital tools, as one subset of
participants in the previous two phases, were selected, as shown Figure 9 below.

Ph.D.

Tool lovers
(with paper
tools and a
computer)

Digital lovers
(with paper
and digital
formats)

Figure 9: Participants in both the video study (the fourth phase) and follow-up
interviews (the fifth phase)
As the first step, a recruitment mail (Appendix J.1) was sent to nine Ph.D.
students who had participated in the second and third phases and so were already familiar
with having the intentions behind their annotations or notes in separate notepads elicited.
To recruit more participants from diverse majors, another recruitment email (Appendix
J.2) was sent to IUB campus-wide (electronic) mailing lists whose subscribers were
groups of people who might be interested in ebook and reading. These included ILSPHD-L@indiana.edu, whose subscribers were Ph.D. students in the Department of
Information and Library Science; mediaiu-l@list.indiana.edu; whose subscribers were
anyone interested in media; rkcsi_phd_students-l@list.indiana.edu, whose subscribers
were Ph.D. students interested in social informatics; and cognoscente@indiana.edu;



whose subscribers were anyone interested in cognitive science. To reach as many Ph.D.
students with diverse majors as possible, a third recruitment email (Appendix J.3) was
sent to directors, associate deans, or secretaries in IUB schools and departments with
Ph.D. programs as of September 5, 2013 (Appendix J.4).
Twenty-one of the 45 participants who responded to a recruitment email
expressing interest in participating were selected according to the following criteria: prior
use of diverse reading devices for academic reading, preference for an iPad or a laptop as
a reading device (a minority, as most participants’ preferred device was paper), and a
representation of different departments or schools. The selection was based on a desire to
recruit participants who met the criteria for the video phase of the study and to increase
the diversity of devices and majors. The 21 participants for the video study are described
in Table 20.



129

9/16/13

9/17/13
9/17/13

11/11/13
11/11/13
11/12/13

11/15/13

11/18/13
11/19/13
11/19/13

11/20/13

11/22/13

11/22/13
11/25/13

12/2/13

12/2/13
12/3/13

1 (pilot study)

2 (pilot study)
3 (pilot study)

4
5
6

7

8
9
10

11

12

13
14

15

16
17



Date

#

Psychology (Cognitive
neuroscience)
Psychology (Social)
Education (Literacy, Culture,
Language Ed)
Linguistics, Second language
studies
Art History
Religious Studies

Biology
History
Education (Human development,
Counseling & Ed. Psychology)
Sociology

English

Philosophy
Microbiology
Vision Science

Information Science
History

Information Science

Major

Table 20: Participants for the video study




Print/Printouts, Laptop
Books, paper, laptop

Laptop

My laptop, iPad and printed
articles/books
Macbook, paper (when no electronic
copy is available)
Laptop
Paper copies

My iPad and on paper
Laptop/ desktop (for newspaper
articles & images), bound books for
dissertation and courses
Paper books, laptop, Sony Ereader
A laptop, a Kindle, paper
Paper, a laptop, a 23 inch monitor, a
Google Nexus tablet
Paper books, printouts, Kindle Fire,
laptop
Paper, laptop
Paper
Laptop, paper

Books, laptop (Adobe), iPad
(iAnnotate), and personal computer

Reading devices for academic reading

Paper
Paper or laptop

Laptop

Laptop
iPad (iAnnotate)

Paper (scan and save in digital
form)
Laptop (Papers2) and Evernote

Paper and Kindle (for free stuff, a
part of PDF, a rent)
Paper
Paper
Laptop

Preferred reading device
(paper, laptop, iPad)
Laptop or desktop (during the
business day) or a tie between
iPad and laptop (at night)
Paper for ease of annotation
Computer (for long articles, short
OnCourse article), books
(ownership)
Paper
Paper
Paper

130

12/6/13

12/9/13
12/10/13

12/16/13

19
20

21

Date

18

#

Table 20: continued

Education (Counseling
Psychology)

Psychology
Hispanic linguistics

Mass communications,
Journalism

Major



iMac, iPhone

Laptop, iPad
Paper, laptop, desktop computer, iPad,
iPhone

Laptop, paper

Reading devices for academic reading

cf. iPad (in the past)
iPad (journal articles)

Preferred reading device
(paper, laptop, iPad)
Printed books, hard-copies of
journal articles, notecards with
pen
iPad
Laptop (at home) or desktop
computer (on campus)

An email (Appendix K) was sent to the selected 21 participants to finalize their
schedules using a Doodle online poll. For identification, each participant was assigned a
number using a random number generator (http://www.random.org) to protect his or her
privacy.
Observations were conducted in a designated lab in the Collaboration
Technologies unit of University Information Technology Services (UITS) at Indiana
University Bloomington. In order to minimize the observer’s effect on a participant’s
reading behaviors, the participant and the researcher were in two separate rooms for the
observation session, which was conducted using teleconferencing technology (CISCO
C20, H323 protocol) with video cameras without the observer being present inside the
lab. The two rooms were connected using teleconferencing technology, as shown in
Figure 10 below.
Teleconferencing Technology


Room A:
The participant’s room
1st camera
(Web cam)

Room B: The researcher’s room
TV monitor
Monitor for
documents

2nd camera
(Document
camera)

Monitor for
movements

Speakerphone


Camcorder
(A back-up
plan)

3rd camera
(Camcorder)

Figure 10: Technology settings for the video study



In the participant’s room, the first web cam was for capturing the participant’s
movements. The second document camera on the ceiling was for zooming in on a paper
or digital document that a participant brought and capturing its movements, including the
participant’s annotation activities. The third stand-alone camcorder was an Apple iPhone
with no connection to teleconferencing technology for capturing a participant’s activities
from an angle different from that of the first web cam, as backup. The reading behaviors
and related activities of each participant during reader-text interaction (e.g., pageflipping, mouse movement, annotating) were recorded for about an hour per session in
the web server. In the researcher’s room, two monitors displayed the participant’s
enlarged documents and real time movements using teleconferencing technology, which
were also recorded them using an Apple iPad camcorder as backup for cases when web
recordings were not available before follow-up interviews due to heavy traffic delays or
failed due to malfunction of the teleconferencing technology.
For an observation session, participants were asked to bring their own documents
and preferred reading devices of paper, a laptop computer, and Apple iPad, along with
any other artifacts they were accustomed to using in natural settings. Also, participants
were asked to bring their own supplementary tools (e.g., highlighters, Apple iPad) or
inform the researcher in advance of anything not portable, such as a printer, that they
could not bring to the lab.
To make the participant feel as comfortable as possible, all technology equipment
in the setting was introduced when the researcher first greeted him/her at the beginning of
a session. Next, the whole procedure, including all steps of the observation study
(Appendix L), was briefly introduced to the participant. Third, to make sure that the



participants read actively, they were informed in advance that they would be asked what
their texts were about and how they read to achieve their purposes. Finally, participants
were informed that they would be signaled to stop reading after an hour by the researcher
knocking on the door or contacting them over a speakerphone.
For this study, onlooker (non-participant) observation, with no involvement in
participants’ activities, was conducted but from an insider’s (the participant’s)
perspective, and in an unstructured way, without a pre-defined coding scheme, such as
one based on a theory or other research, which determines items to be observed. This
approach was selected among different types of observation which various researchers
(Angrosino, 2008; Gillham, 2008; Merriam, 2009; Patton, 2001) have introduced from
different perspectives such as structure (structured, semi-structured, or. unstructured),
observer’s involvement (participant, onlooker, or both), perspectives (insider’s vs.
outsider’s view), effect of the observer (overt vs. covert), duration (short vs. long), and
scope (narrow vs. broad).
In this type of study, factors such as purpose of the study and conceptual
framework determine what to observe (Merriam, 2009). In order to achieve the purpose
of this study (i.e., to understand reader-text interaction from the perspective of the three
categories of reader-response criticism), the three most relevant aspects of Merriam’s
(2009) six representative elements11 to be observed were the physical setting, activities
and interactions, along with subtle factors such as nonverbal communication, and the
observer’s own behavior (pp. 120-121). As Lincoln and Guba (1985) advised, nonverbal


11

Merriam’s (2009) six representative elememts to be observed includes the physical setting, the
participants, activities and interactions, converation, and suble factors (pp. 120-121).



communication was used “in a supplementary fashion to flag items of information that
require more detailed attention later” (p. 276).
4.2.4.2 Data analysis
While participants were reading, the researcher simultaneously analyzed intentions,
needs, or desires behind all annotations/notes (e.g., colors, locations, notes in page
margins) and movements observable on two screens through which the participant’s
room was being broadcast live using teleconferencing technology (e.g., scrolling up and
down, visiting a website, looking up a dictionary item, writing notes in separate
notepads). The researcher recorded both the intentions, needs, or desires that were based
on the codebook and those that were not, the latter being the researcher’s own new
speculations for follow-up interviews in the observation notes (Appendix O). In order to
be able to play back and check each instance with the participants later, time stamps were
recorded along with annotations/notes and movements.
4.2.5 Phase 5: Second follow-up interviews
Through observations, it is possible to collect data of which participants are not aware.
However, without additional follow-up interviews, there is a risk of observer bias in data
collection and interpretation, subjective interpretations, and data incompleteness (Kumar,
2010) or in Steinke’s (2004) terms “the risk of randomness and arbitrariness” (p. 185).
Therefore, as with the follow-up interviews in the third phase, follow-up interviews in
this phase were used to reconfirm the researcher’s interpretations of participants’ readingrelated activities as documented in video clips, documents including annotations, and
newly-created coding items, as well as to gain new information directly from participants
from their own perspectives.



4.2.5.1 Data collection
To minimize memory decay, individual semi-structured, in-depth interviews took place in
the lab right after each participant’s observation session ended. To check the adequacy of
the codebook, the first three participants were asked to code their annotations (Appendix
N) by themselves, using the prepared codebook (Appendix I) and creating any needed
codes that were not included in the existing scheme. The rest of the participants were not
asked to code their annotations by themselves but were guided by the researcher, who
was already familiar with the codebook, to obtain as much information as possible within
a limited amount of time. These face-to-face interviews took about an hour and were
video recorded to capture both the voice interviews and their associated documents while
the researcher also took notes. Before each interview, preliminary questions (Appendix
P) were drawn from the codebooks of the first three participants, the findings from earlier
video clips, and documents that had annotations, not to guide the order of the interview
but as a reminder to cover specific points. To gather additional data from participants’
own perspectives, other questions were asked that were triggered by participants’
responses to questions in a natural conversational flow.
Questions derived from one participant were used with the next participant as a
theoretical sampling technique in grounded theory, described by Bryant & Charmaz
(2007) as “aim[ing] to develop the properties of his or her [the researcher’s] developing
categories or theory, not to sample randomly selected populations or to sample
representative distributions of a particular population” (p. 611), and in that way questions
evolved from being open-ended to stimulate a participant’s response to being directive to
confirm the researcher’s interpretations.



4.2.5.2 Data analysis
First, the researcher played back video-taped interview clips about annotations/notes,
movements, and active reading practices and coded them with a key phrase indicating the
type of annotation (e.g., medium_software_easy_to_switch_between_tools) using
HyperRESEARCH. This initial coding was done without referring back to the old
codebook that was prepared after the annotation analysis and follow-up interviews in
phases 2 and 3 (Appendix I), so as not to be influenced by it or hindered in coming up
with new items.
Second, the initially coded items were re-coded as a part of intermediate coding
by grouping individual items, moving from the first to last again, by assigning a code
number in the old codebook (Appendix I) to each coded item, creating new items and
adding them to the old codebook, revising coded items, and recategorizing some coded
items. This was to incorporate code items in this fifth phase into the old codebook.
Third, thematic categories and items in the new codebook (Appendix Q.1,
Appendix Q.2, and Appendix Q.3) were compared to those in the old codebook
(Appendix I) to check which thematic categories or items from the old codebook were
omitted and which new items were added in the new codebook. The omitted and new
thematic categories are summarized in Table 21 below (see Appendix Q.1, Appendix
Q.2, and Appendix Q.3 for newly added items in each thematic category).



Table 21: Summary of thematic categories in the old codebook (after the annotation study
and follow-up interviews) and the new codebook (after the observation study and its
follow-up interviews)
Static annotations/notes
Thematic
Thematic
categories
categories
in the old
in the new
codebook
codebook
TX
TX
TG
TG
SL
SL
HR
HR
MN
MN
EN
EN
AR
AR
EV
EV
LN
LN
AD
AD
EX
EX
SH
SH
CT
MD
MD
N=14

N=13

Dynamic movements
Thematic
Thematic
categories
categories in
in the old
the new
codebook
codebook
FLIP
FLIP
PROGRESS
FOR
FOR
LAST
LAST
BACK
BACK
FIRST
FIRST
TOC
TOC
BACKFOR
BACKFOR
ZOOMINOUT ZOOMINOUT
ZOOMIN
ZOOMOUT
JUMP
ROTATE
BOOK
HAND
N=9
N=14

Other external activities
Thematic
Thematic
categories
categories
in the old
in the old
codebook
codebook
WEB
WEB
APP
APP
PRINT
PRINT
PAD
PAD
MONITOR
DEVICE

N=5

N=5

As a fourth step, the intentions behind items in dynamic movements and in other
external activities (Appendix Q.2 & Appendix Q.3) were re-coded using coding items for
static (written) annotations/notes in both codebooks. This was to aggregate codebooks in
three categories (i.e., static annotations, dynamic movements, and other external
activities) into one final codebook by combining common intentions across them.
Additionally, items or thematic categories were newly created and coded if no item or
thematic category was found from the two previous codebooks (see Appendix R for more
details). The final codebook (Appendix R) was created by aggregating the items in the
new codebook for static annotations/notes (Appendix Q.1) and the newly-coded items in

 

dynamic movements and in other external activities. The final codebook contained 14
thematic categories (Table 22).

Table 22: Thematic categories in the old, the new, and the final codebook
Thematic categories
in the old codebook
only for static
annotations/notes
(after the annotation study and
follow-up interviews)
TX
TG
SL
HR
MN
EN
AR
EV
LN
AD

Thematic categories
in the new codebook
only for static
annotations/notes
(after the video study and
follow-up interviews)
TX
TG
SL
HR
MN
EN
AR
EV
LN
AD

Thematic categories
in the final codebook
(aggregating coding items in
the three categories)

EX
SH
CT
MD
N=14

EX
SH

TX
TG
SL
HR
MN
EN
AR
EV
LN
AD
RV (NEW)
EX
SH

MD
N=13

MD
N=14

As a fifth step, relationships among all items in the 14 thematic categories of the
final codebook were identified, re-grouped, and re-organized based on meaningful,
emerging themes (time-wise, depth of engagement, ultimate reasons, and goals) as
advanced coding to create a composite model of reader-text interaction about active
reading.
As a sixth step, to understand the core characteristics of active reading, the most
common coding items and thematic categories were identified by counting the number of
occurrences of all coding items from the video study and follow-up interviews.

 

Last, the 14 thematic categories, the purpose(s), the major(s), the amount of prior
knowledge, the degree of interest, and the level of readability (taken from the Information
Sheet in Appendix M) were compared across three different types of participants who
used three different reading devices (iPad, laptop, paper) in the video study to examine
the potential effect (or relationship) of media in active reading.


 

Chapter 5. Results
5.1 Quantitative components
5.1.1 Demographic information about the survey respondents (descriptive statistics)
The frequencies of seven demographic characteristics of the survey respondents were
examined, including the country of residence affiliated with the respondents’ current
institutions, their variety of English, their gender, their age, their degree program and
full- or part-time status, and their major(s). As shown in Figure 11 and Table 23 below,
more than 90% of the respondents were from the USA, and most others were from other
English speaking countries: Canada, Australia, UK, and New Zealand.

Figure 11: Frequency and distribution of current location (country) of residence affiliated
with the respondents’ institutions



Table 23: Frequency and distribution of current location (country) of residence affiliated
with the respondents’ institutions
Frequency Percent
Australia
Canada
New Zealand
New Zealand and Australia (as multiple current
locations of residence)
South Korea
Thailand
UK
Unknown
USA
USA and Germany
USA and Japan
Total

10
17
1

Valid Cumulative
Percent Percent
2.1
2.1
2.1
3.6
3.6
5.6
.2
.2
5.9

1

.2

.2

6.1

1
1
9
4
432
1
1
478

.2
.2
1.9
.8
90.4
.2
.2
100.0

.2
.2
1.9
.8
90.4
.2
.2
100.0

6.3
6.5
8.4
9.2
99.6
99.8
100.0

More than 90% of the respondents were American English speakers, while others were
Canadian, Australian, British, Indian, and South African English speakers, as shown in
Figure 12 and Table 24 below.



Figure 12: Frequency and distribution of English variations



Table 24: Frequency and distribution of English variations
Frequency Percent Valid Percent Cumulative Percent
American
435
91.0
91.0
91.0
Australian
9
1.9
1.9
92.9
British
6
1.3
1.3
94.1
Canadian
19
4.0
4.0
98.1
Indian
2
.4
.4
98.5
South African
1
.2
.2
98.7
Other (Please specify):
6
1.3
1.3
100.0
Total
478 100.0
100.0

The number of female respondents was about three times greater than the number of male
respondents, as shown in Figure 13 and Table 25.



Figure 13: Frequency and distribution of gender



Table 25: Frequency and distribution of gender
Frequency Percent Valid Percent Cumulative Percent
Female
Male
Other (e.g., LGBT)
Total

356
119
3
478

74.5
24.9
.6
100.0

74.5
24.9
.6
100.0

74.5
99.4
100.0

More than 60% of the respondents were in their twenties or thirties, as shown in Figure
14 and Table 26. Also, people in their forties, fifties, and sixties were reasonably well
represented at 77, 44, and 35 respondents, respectively.



Figure 14: Frequency and distribution of age



Table 26: Frequency and distribution of age
Frequency Percent Valid Percent Cumulative Percent
20 - 29
176
36.8
36.8
36.8
30 - 39
146
30.5
30.5
67.4
40 - 49
77
16.1
16.1
83.5
50 - 59
44
9.2
9.2
92.7
60 and Older
35
7.3
7.3
100.0
Total
478 100.0
100.0

More than 70% of the respondents were students, and about 20% were faculty, as shown
in Figure 15 and Table 27 below.



Figure 15: Frequency and distribution of academic status



Table 27: Frequency and distribution of academic status
Frequency
MA
207
PhD
144
PostDoc
3
Faculty
93
Other
31
Total
478

Degree
Percent Valid Percent Cumulative Percent
43.3
43.3
43.3
30.1
30.1
73.4
.6
.6
74.1
19.5
19.5
93.5
6.5
6.5
100.0
100.0
100.0

Figure 16 and Table 28 show that the number of full-time faculty or students was higher
than the number of part-time faculty or students.



Figure 16: Frequency and distribution of full-time status



Table 28: Frequency and distribution of full-time status
Full-Time
Part-Time
Other (e.g., multiple statuses)
Total

Frequency Percent Valid Percent Cumulative Percent
279
58.4
58.4
58.4
195
40.8
40.8
99.2
4
.8
.8
100.0
478 100.0
100.0

Library science, with more than 50% of the participants, had the highest representation
by far. Social science, with just over 7%, was next, followed by the others. This
distribution is shown in Figure 17 and Table 29 below.





Figure 17: Frequency and distribution of major(s)
Table 29: Frequency and distribution of major(s)

4. Architecture & Related Services
5. Area, Ethnic, Cultural, Gender, and Group Studies
9. Communication, Journalism, and Related Programs
11. Computer and Information Sciences and Support
Services
13. Education
14. Engineering
16. Foreign Languages, Literatures, and Linguistics
23. English Language and Literature/Letters
25. Library Science
26. Biological and Biomedical Sciences
30. Multi/Interdisciplinary studies
38. Philosophy and Religious Studies
42. Psychology
44. Public Administration and Social Service Professions
45.Social Sciences
50. Visual and Performing Arts
51. Health Professions and Related Programs
52. Business, Management, Marketing, and Related
Support Services
54. History
61. Dual (or multiple) Majors from different, separate
departments/schools
62. Unknown
Total

 

Frequency

Percent

Valid
Cumulative
Percent
Percent
1.5
1.5
.4
1.9
2.9
4.8

7
2
14

1.5
.4
2.9

3

.6

.6

5.4

26
6
11
3
274
1
18
6
6
1
34
15
1

5.4
1.3
2.3
.6
57.3
.2
3.8
1.3
1.3
.2
7.1
3.1
.2

5.4
1.3
2.3
.6
57.3
.2
3.8
1.3
1.3
.2
7.1
3.1
.2

10.9
12.1
14.4
15.1
72.4
72.6
76.4
77.6
78.9
79.1
86.2
89.3
89.5

2

.4

.4

90.0

23

4.8

4.8

94.8

19

4.0

4.0

98.7

6
478

1.3
100.0

1.3
100.0

100.0

5.1.2 Characteristics of active reading practices (cluster analysis)
Frequency and cluster analyses were conducted using SPSS 20 to identify groups of
participants who shared similar behaviors in terms of frequency and types of annotations,
formats, devices, places, and tools.
5.1.2.1 Annotation/Note-taking frequency (Variable #1): Light vs. heavy annotators/notetakers
As shown in Figure 18 and Table 30 below, more than 70% of the survey respondents
reported that they write (i.e., make annotations or take notes) quite often or very often
while reading.


Figure 18: Frequency and distribution of annotation/note-taking while active reading

 

Table 30: Frequency and distribution of annotation/note-taking while active reading
Frequency Percent Valid Percent Cumulative Percent
Never
1
.2
.2
.2
Rarely
28
6.4
6.4
6.7
Sometimes
70
16.1
16.1
22.7
Quite Often
147
33.7
33.7
56.4
Very Often
190
43.6
43.6
100.0
Total
436 100.0
100.0

For the purpose of further analysis (binary logistic regression), participants were divided
into two groups: 1) Light Annotators/Note-Takers, comprising 99 participants who
reported “Never,” “Rarely,” or “Sometimes,” and 2) Heavy Annotators/Note-Takers,
comprising 337 participants who reported “Quite Often” or “Very Often.”
5.1.2.2 Annotation type (Variable #2): Weak vs. strong advocates of annotation
To identify the optimal number of clusters for Variable #2, hierarchical cluster analysis
was done as a first step. A clear demarcation point (substantial change in heterogeneity)
was found between two and three clusters, as shown in Tables 31 and 32 below. Thus,
two was selected as the optimal number of clusters to represent the cluster solution for
Variable #2.

Table 31: Agglomeration schedule for variable#2 annotation type
Stage
1
...
429
430
431
432
433
434
435

Cluster Combined Coefficients Stage Cluster First Appears Next Stage
Cluster 1 Cluster 2
Cluster 1
Cluster 2
157
434
.000
0
0
85
1
2
6
6
1
2
1

11
8
14
19
6
5
2

1865.788
2020.553
2207.612
2416.726
2756.394
3174.160
4157.060

421
428
422
431
429
430
433



 

416
423
426
407
432
427
434

433
434
432
433
435
435
0

Table 32: Re-formed agglomeration table for variable #2 annotation type
No.
of
clusters

Agglomeration
last step

Coefficients
this step

Change

2

4157.060

3174.160

982.90

3

3174.160

2756.394

417.766

4

2756.394

2416.726

339.668

5

2416.726

2207.612

209.114

6

2207.612

2020.553

187.059

7

2020.553

1865.788

154.765

565.134
78.098
130.554
22.055
32.294

As the next step, to identify characteristics of each cluster, k-means cluster analysis was
performed with the optimal number using SPSS 20. It was found that cluster 1 (Weak
Advocates of Annotation) was characterized as a group of people who sometimes make
annotations on paper documents or take notes on a separate digital notepad, and cluster 2
(Strong Advocates of Annotation) was characterized as a group of people who frequently
annotate directly on paper or digital documents or frequently annotate directly on paper
documents in addition to writing notes on a separate paper notepad. This is shown in
Tables 33 and 34.

Table 33: Number of cases in each cluster for variable #2 annotation type
# of cases (participants)
1
231
Cluster
2
205
Valid
436
Missing
0



Table 34: Final cluster centers for variable #2 annotation type
Cluster
1 2
Annotation on paper
3 4
Annotation in digital formats
2 4
No annotation, but note-taking in digital formats
3 3
No annotation, but note-taking on paper
2 3
Both annotation and note-taking on paper
2 4
Both annotation and note-taking in digital formats 2 3

Additionally, it was found from k-means cluster analysis that because the significance
levels for all variables were small (see Table 35 below), all variables contributed to the
separation of the clusters. “Both annotation and note-taking in digital formats,” the F
value of which was largest, contributed most to the separation of the clusters, and “No
annotation, but note-taking in digital formats,” the F value of which was smallest,
contributed least to the separation of the clusters. In conclusion, it is warranted to say that
the two clusters are reasonably different from each other in terms of the six types of
annotation. In particular, the biggest difference between the two clusters is in terms of
one type of annotation, “Both annotation and note-taking in digital formats.”

Table 35: ANOVA table for variable #2 annotation type
ANOVA

Annotation on paper
Annotation in digital formats
No annotation, but note-taking in digital formats
No annotation, but note-taking on paper
Both annotation and note-taking on paper
Both annotation and note-taking in digital
formats

Cluster
Error
F
Sig.
Mean
df Mean df
Square
Square
105.801
1 1.226 434 86.322 .000
299.161
1 1.077 434 277.767 .000
58.770
1 1.284 434 45.778 .000
99.303
1 1.278 434 77.680 .000
222.754
1 1.188 434 187.560 .000
318.472

1

.982 434 324.430 .000

Note: The F tests should be used only for descriptive purposes because the clusters have been chosen to
maximize the differences among cases in different clusters. The observed significance levels are not
corrected for this and thus cannot be interpreted as tests of the hypothesis that the cluster means are equal.



5.1.2.3 Format (Variable #6): Digital vs. paper lovers
To identify the optimal number of clusters for Variable #6, hierarchical cluster analysis
was first performed. As shown in Tables 36 and 37, it was found that a clear demarcation
point occurred between two and three clusters, between three and four clusters, and
between four and five clusters. Two was chosen as the optimal number of clusters to
represent the cluster solution for Variable #6.
Table 36: Agglomeration schedule for variable #6 format
Stage
1
.....
429
430
431
432
433
434
435

Cluster Combined Coefficients Stage Cluster First Appears Next Stage
Cluster 1 Cluster 2
Cluster 1
Cluster 2
363
436
.000
0
0
40
24
2
14
1
2
1
1

32
6
24
17
8
14
2

1279.787
1392.347
1519.792
1648.410
1909.112
2301.673
2818.706

418
422
425
419
430
432
434

411
421
429
428
427
431
433

431
433
434
434
435
435
0

Table 37: Re-formed agglomeration table for variable #6 format
No.
of
clusters

Agglomeration
last step

Coefficients
this step

Change

2

2818.706

2301.673

517.033

3

2301.673

1909.112

392.561

4

1909.112

1648.410

260.702

5

1648.410

1519.792

128.618

6

1519.792

1392.347

127.445

7

1392.347

1279.787

112.55

124.472
131.859
132.084
1.173
14.895






As the next step, to identify characteristics of each cluster, k-means cluster analysis was
performed with the optimal number using SPSS 20. It was found that cluster 1 (Digital
Lovers) was characterized as a group of people who used both paper (book/journal) and
digital formats (webpage and PDF online) frequently, and cluster 2 (Paper Lovers) was
characterized as a group of people who used paper formats (book, journal, and PDF on
paper) frequently. This is shown in Tables 38 and 39.
Table 38: Number of cases in each cluster for variable #6 format
# of cases (participants)
1
235
Cluster
2
201
Valid
436
Missing
0

Table 39: Final cluster centers for variable #6 format
Cluster
1 2
Print (Paper) book/journal
4 4
Scrollable webpage
4 3
PDF file read online
5 3
PDF file printed out
3 4
Documents specifically formatted for ereading devices 3 2

Additionally, it was found from k-means cluster analysis that because the significance
levels for all variables were small, as shown in Table 40 below, all variables contributed
to the separation of the clusters. “Scrollable webpage,” whose F value was largest,
contributed most to the separation of the clusters, and “Print (paper) book/journal,”
whose F value was smallest, contributed the least. In conclusion, the two clusters that are
identified from cluster analysis can be said to be reasonably different from each other in
terms of the five types of format, with the largest difference contributed by the format
“Scrollable webpage.”



Table 40: ANOVA table for variable #6 format

Print (paper) book/journal
Scrollable webpage
PDF file read online
PDF file printed out
Documents specifically formatted
for eReading devices

ANOVA
Cluster
Mean
df
Square
7.997 1
246.820 1
206.664 1
32.319 1
126.926

Error
Mean
Square
1.047
.618
.701
1.314

434
434
434
434

7.635
399.227
294.645
24.589

.006
.000
.000
.000

1.383

434

91.768

.000

1

F

Sig.

df

Note: The F tests should be used only for descriptive purposes because the clusters have been chosen to
maximize the differences among cases in different clusters. The observed significance levels are not
corrected for this and thus cannot be interpreted as tests of the hypothesis that the cluster means are equal.


5.1.2.4 Device (Variable #7): Multi, stationary, mobile, vs. tablet players
To identify the optimal number of clusters for Variable #7, hierarchical cluster analysis
was first conducted. As shown in Tables 41 and 42, a clear demarcation point was found
between four and five clusters, so four was chosen as the optimal number of clusters to
represent the cluster solution for Variable #7.
Table 41: Agglomeration schedule for variable #7 device
Stage
1
.....
429
430
431
432
433
434
435

Cluster Combined Coefficients Stage Cluster First Appears Next Stage
Cluster 1 Cluster 2
Cluster 1
Cluster 2
281
435
.000
0
0
189
7
1
7
1
7
1
1

8
27
13
2
28
7
6

2160.561
2291.285
2438.935
2631.244
2997.536
3439.890
4021.856

412
425
429
430
431
432
434










422
421
417
423
428
433
427

431
432
433
434
434
435
0

Table 42: Re-formed agglomeration table for variable #7 device
No.
of
clusters

Agglomeration
last step

Coefficients
this step

Change

2

4021.856

3439.89

581.966

3

3439.89

2997.536

442.354

4

2997.536

2631.244

366.292

5

2631.244

2438.935

192.309

6

2438.935

2291.285

147.65

7

2291.285

2160.561

130.724

139.612
76.062
173.983
44.659
16.926



To identify characteristics of each cluster, k-means cluster analysis was conducted with
the optimal number using SPSS 20. Cluster 1 (Multi Players) was characterized as a
group of people who used paper and desktop/laptop frequently and sometimes used
Amazon Kindle and Phone; cluster 2 (Stationary Players) was characterized as a group of
people who used paper, laptop, and desktop frequently; cluster 3 (Mobile Players) was
characterized as a group of people who used paper and laptop frequently; and cluster 4
(Tablet Players) was characterized by a group of people who used paper, laptop, and iPad
frequently. These are shown in Tables 43 and 44.

Table 43: Number of cases in each cluster for variable #7 device
1
2
Cluster
3
4
Valid
Missing

# of cases (participants)
66
165
141
64
436
0



Table 44: Final cluster centers for variable #7 device
1
Paper
5
Desktop computer
4
Laptop/Netbook computer 5
Amazon Kindle
3
Barnes & Noble Nook
1
Sony Ereader
1
Apple iPad
1
Smart Phone
3

Cluster
2 3 4
4 4 4
4 2 3
4 4 4
1 1 1
1 1 1
1 1 1
1 1 4
1 1 3

Additionally, it was found from k-means cluster analysis that because the significance
levels for “Barnes & Noble Nook” and “Sony Ereader” were large, as shown in Table 45
below, neither contributed to the separation of the clusters. “Apple iPad,” whose F value
was largest, contributed most to the separation of the clusters, and “Paper,” whose F
value was smallest, contributed least to the separation of the clusters. It can be said that
the four clusters are reasonably different from each other in terms of the eight types of
device, with “Apple iPad” contributing the most to the difference.

Table 45: ANOVA table for variable #7 device

Paper
Desktop computer
Laptop/Netbook computer
Amazon Kindle
Barnes & Noble Nook
Sony Ereader
Apple iPad
Smart Phone

ANOVA
Cluster
Error
Mean Square df Mean Square
2.395
3
.808
184.899
3
.858
8.949
3
1.297
34.393
3
1.038
.116
3
.512
.103
3
.094
190.677
3
.281
97.180
3
.819

F
df
432
432
432
432
432
432
432
432

2.962
215.514
6.901
33.127
.227
1.089
677.861
118.640

Sig.
.032
.000
.000
.000
.877
.353
.000
.000

Note: The F tests should be used only for descriptive purposes because the clusters have been chosen to
maximize the differences among cases in different clusters. The observed significance levels are not
corrected for this and thus cannot be interpreted as tests of the hypothesis that the cluster means are equal.



5.1.2.5 Place (Variable #3): Public vs. private readers
To identify the optimal number of clusters for Variable #3, hierarchical cluster analysis
was first performed. As shown in Tables 46 and 47, a clear demarcation point was found
between two and three clusters, so two was chosen as the optimal number of clusters to
represent the cluster solution for Variable #3.
Table 46: Agglomeration schedule for variable #3 place
Stage
1
.....
429
430
431
432
433
434
435

Cluster Combined Coefficients Stage Cluster First Appears Next Stage
Cluster 1 Cluster 2
Cluster 1
Cluster 2
128
434
.000
0
0
99
17
9
6
1
6
1
1

27
66
23
4
9
6
17

1664.468
1788.037
1915.045
2048.751
2296.077
2693.337
3401.167

425
422
427
423
431
432
434

428
418
415
426
430
433
429

435
433
433
434
434
435
0



Table 47: Re-formed agglomeration table for variable #3 place
No.
of
clusters

Agglomeration
last step

Coefficients
this step

Change

2

3401.167

2693.337

707.83

3

2693.337

2296.077

397.26

4

2296.077

2048.751

247.326

5

2048.751

1915.045

133.706

6

1915.045

1788.037

127.008

7

1788.037

1664.468

123.569

310.57
149.934
113.62
6.698
3.439



Next, to identify characteristics of each cluster, k-means cluster analysis was conducted
with the optimal number using SPSS 20. It was found that cluster 1 (Public Readers) was

 

characterized as a group of people who read at home and in the office frequently and
sometimes at other places as well, and cluster 2 (Private Readers) was characterized as a
group of people who read at home frequently. This is shown in Tables 48 and 49.
Table 48: Number of cases in each cluster for variable #3 place
1
Cluster
2
Valid
Missing

# of cases (participants)
271
165
436
0

Table 49: Final cluster centers for variable #3 place
Cluster
1 2
Carrel
2 2
Commons 2 2
Home
5 5
Office
5 2
Cafe
3 2
Bus
2 2

Additionally, the k-means cluster analysis showed that because the significance levels for
“Library (Information Commons)” and “Home” were large, as shown in Table 50 below,
neither contributed to the separation of the clusters. “Office,” the F value of which was
largest, contributed most to the separation of the clusters, and “Transportation,” whose F
value was smallest, contributed least. In conclusion, it is can be said that the two clusters
that are identified from cluster analysis are reasonably different from each other in terms
of the six types of place with “Office” contributing the most to the difference.

 

Table 50: ANOVA table for variable #3 place

Library (Carrel)
Library (Information
Commons)
Home
Office
Cafe or restaurant
Transportation (e.g., bus)

ANOVA
Cluster
Error
Mean Square df Mean Square
18.375
1
1.108

F

Sig.

df
434

16.585

.000

2.863

1

1.185

434

2.417

.121

.660
763.061
12.743
10.154

1
1
1
1

.460
.496
1.456
1.271

434
434
434
434

1.434
1539.391
8.754
7.987

.232
.000
.003
.005

Note: The F tests should be used only for descriptive purposes because the clusters have been chosen to
maximize the differences among cases in different clusters. The observed significance levels are not
corrected for this and thus cannot be interpreted as tests of the hypothesis that the cluster means are equal.

5.1.2.6 Tool (Variable #4): Tool, music, vs. reading lovers
To identify the optimal number of clusters for Variable#4, hierarchical cluster analysis
was first performed. As shown in Tables 51 and 52, a clear demarcation point was found
between three and four clusters, so three was chosen as the optimal number of clusters to
represent the cluster solution for Variable #4.
Table 51: Agglomeration schedule for variable #4 tool
Stage
1
.....
429
430
431
432
433
434
435

Cluster Combined Coefficients Stage Cluster First Appears Next Stage
Cluster 1 Cluster 2
Cluster 1
Cluster 2
360
430
.000
0
0
141
1
1
6
11
2
2
1

12
22
25
13
11
6
2

2567.605
2762.274
2964.463
3182.388
3444.705
4067.731
4716.929

423
429
424
421
428
433
430








 

406
419
427
416
432
431
434

430
435
434
433
434
435
0



Table 52: Re-formed agglomeration table for variable #4 tool
No.
of
clusters

Agglomeration
last step

Coefficients
this step

Change

2

4716.929

4067.731

649.192
26.166

3

4067.731

3444.705

623.026

4

3444.705

3182.388

262.317

5

3182.388

2964.463

217.925

6

2964.463

2762.274

202.189

7

2762.274

2567.605

195.669

360.709
44.392
15.736
6.52

Next, to identify characteristics of each cluster, k-means cluster analysis was conducted
with the optimal number using SPSS 20. As shown in Tables 53 and 54 below, cluster 1
(Tool Lovers) was characterized as a group of people who used diverse paper tools as
well as a computer frequently; cluster 2 (Music Lovers) was characterized as a group of
people who used a paper tool (pen/pencil) as well as a computer frequently and while
listening to music frequently; and cluster 3 (Reading Lovers) was characterized as a
group of people who used only a computer frequently.
Table 53: Number of cases in each cluster for variable #4 tool
# of cases (participants)
1
171
Cluster 2
107
3
158
Valid
436
Missing
0



Table 54: Final cluster centers for variable #4 tool
Cluster
1 2 3
Computer
4 4 4
Ereader
1 3 2
Computer Printer
4 3 2
Pen/Pencil, Paper/Notepad 5 4 3
(Physical) Highlighter Pen 4 3 2
Music Player
2 4 2
TV
2 3 1

Additionally, the k-means cluster analysis showed that because the significance levels for
all variables were small, as shown in Table 55 below, all variables contributed to the
separation of the clusters. “(Physical) highlighter pen,” the F value of which was largest,
contributed most to the separation of the clusters, and “Computer,” the F value of which
was smallest, contributed least. In conclusion, the three clusters can be said to be
reasonably different from each other in terms of the seven types of tool, with “(Physical)
highlighter pen” contributing the most to the difference.
Table 55: ANOVA table for variable #4 tool

Computer
Ereader
Computer Printer
Pen/Pencil, Paper/Notepad
(Physical) highlighter pen
Music Player
TV

ANOVA
Cluster
Error
Mean Square df Mean Square
3.948
2
.908
120.693
2
1.451
148.335
2
1.049
60.442
2
.899
181.421
2
1.147
172.778
2
1.125
45.449
2
.929

F
df
433
433
433
433
433
433
433

4.348
83.203
141.434
67.223
158.152
153.579
48.925

Sig.
.014
.000
.000
.000
.000
.000
.000

Note: The F tests should be used only for descriptive purposes because the clusters have been chosen to
maximize the differences among cases in different clusters. The observed significance levels are not
corrected for this and thus cannot be interpreted as tests of the hypothesis that the cluster means are equal.



5.1.3 Factors predicting the frequency and the type of annotation (binary logistic
regression)
To identify which independent variables (Format, Device, Place, Tool, Degree, Major,
Gender, and Age) would help predict the two dependent variables Annotation Frequency
and Annotation Type (the second research question), binary logistic regression was
performed using SPSS 20.
5.1.3.1 Annotation frequency: Characteristics of heavy or light annotators/note-takers
As a first step, crosstabs with the Pearson chi-square test were run for all eight
independent variables to identify those that were good candidates for follow-up binary
logistic regression with Annotation Frequency (p < 0.05, or chi-square values > critical
values for chi-square at degrees of freedom and an alpha level of 0.05) and sufficient
cases (at least 5) in each cell. As a result, the two independent variables Tool and Degree
were selected. Minimizing the number of variables for follow-up binary logistic
regression through selection was based on the assumption that “the resultant model is
more likely to be numerically stable, and is more easily adopted for use” (Hosmer,
Lemeshow, & Sturdivant, 2013, p. 90) (see Appendix E.1 for further details).
As the next step, binary logistic regression was conducted using SPSS 20 to check
if the two independent variables, Tool and Degree, were good indicators in terms of
predicting Annotation Frequency (Heavy vs. Light Annotators/Note-takers). Because
logistic regression does not require three major statistical assumptions of normality,
homoscedasticity, and linearity (Spicer, 2005), these assumptions were not tested.
Following Leech, Barrett, and Morgan’s (2011) recommendation, “If the researcher has
no prior ideas about which variables will create the best prediction equation and has a



reasonably small set of predictors, then simultaneous regression is the best method to
use” (p. 106), both Tool and Degree were entered simultaneously instead of
hierarchically.
As shown in Table 56 (see Appendix E.2 for all SPSS outputs), Tool and Degree
were significant predictors (sig < 0.001) of people’s characteristics in terms of frequency
of annotation. Given the values of the Exp (B), or the relative odds (odds ratio), Reading
lovers were 0.244 times as likely to be heavy annotators/note-takers as Tool lovers. In
other words, people who used diverse paper tools as well as a computer frequently (Tool
lovers) were more likely to belong to the group of people who are heavy annotators/notetakers than people who frequently used a computer only (Reading lovers).

Table 56: Findings of binary logistic regression with Annotation Frequency
B
Step 1

a

Q10Tool(0): Tool lovers
Q10Tool(1): Music lovers
Q10Tool(2): Reading lovers
Q12Degree(0): PhD
Q12Degree(1): MA
Q12Degree(2): Faculty
Q12Degree(3): Other
Constant

S.E.

-.388
-1.411

.345
.297

-1.648
-1.219
-.641
3.064

.351
.406
.635
.373

Wald
df Sig. Exp(B)
25.832 2 .000
1.263 1 .261
.679
22.592 1 .000
.244
23.337 3 .000
22.043 1 .000
.193
9.006 1 .003
.295
1.020 1 .313
.527
67.435 1 .000 21.422

a. Variable(s) entered on step 1: Q10Tool, Q12Degree.

Also, given the values of the Exp (B), or the relative odds (odds ratio), master’s
students were 0.193 times as likely and faculty 0.295 times as likely to be heavy
annotators/note-takers as Ph.D. students. In other words, Ph.D. students are more likely to
be heavy annotators/note-takers than either master’s students or faculty.



5.1.3.2 Annotation type: Characteristics of strong or weak advocates of annotation
As with Annotation Frequency, crosstabs with the Pearson chi-square test were as a first
step run for all eight independent variables to identify those that were good candidates for
follow-up binary logistic regression with Annotation Type. As a result, the five
independent variables Format, Device, Place, Tool and Degree were selected. As the next
step, binary logistic regression was run using SPSS 20 to check if the five independent
variables were good indicators of Annotation Type (Weak vs. Strong Advocates of
Annotation).
As shown in Table 57 below (see Appendix E.3 for further details), Format, Tool
and Degree were found to be significant predictors (sig < 0.05) of people’s characteristics
in terms of type of annotation. Given the values of the Exp (B), or the relative odds (odds
ratio), Paper lovers were 0.482 times as likely to be strong advocates of annotation as
Digital lovers. In other words, people who used both paper book/journal and digital
formats (webpage and PDF online) frequently (Digital Lovers) were more likely to be
strong advocates of annotation than people who used only paper formats (book, journal,
and PDF on paper) frequently (Paper Lovers).



Table 57: Findings of binary logistic regression with Annotation Type
Step 1

a

Q7Format(1): Paper lovers
Q8Device(0): Multi players
Q8Device(1): Stationary players
Q8Device(2): Mobile players
Q8Device(3): Tablet players
Q9Place(1): Private readers
Q10Tool(0): Tool lovers
Q10Tool(1): Music lovers
Q10Tool(2): Reading lovers
Q12Degree(0): Ph.D.
Q12Degree(1): MA
Q12Degree(2): Faculty
Q12Degree(3): Other
Constant

B
-.730

S.E.
.231

.121
-.294
.454
-.262

.324
.352
.384
.232

.302
-1.018

.282
.251

-1.197
-.849
-.341
1.276

.255
.319
.456
.367

Wald
df Sig. Exp(B)
9.971 1 .002
.482
5.029 3 .170
.139 1 .709 1.128
.698 1 .404
.745
1.402 1 .236 1.575
1.276 1 .259
.769
25.758 2 .000
1.146 1 .284 1.352
16.489 1 .000
.361
23.141 3 .000
21.967 1 .000
.302
7.098 1 .008
.428
.559 1 .455
.711
12.122 1 .000 3.583

a. Variable(s) entered on step 1: Q7Format, Q8Device, Q9Place, Q10Tool, Q12Degree.

Also, given the values of the Exp (B), or the relative odds (odds ratio), Reading
lovers were 0.361 times as likely to strong advocates of annotation as Tool lovers. In
other words, people who used diverse paper tools as well as a computer frequently (Tool
lovers) were more likely to belong to the group of people who were strong advocates of
annotation than people who used only a computer frequently (Reading lovers).
Last, given the values of the Exp (B), or the relative odds (odds ratio), master’s
students were 0.302 times as likely and faculty 0.428 times as likely to be strong
advocates of annotation as Ph.D. students. In other words, Ph.D. students were more
likely to belong to the group of strong advocates of annotation than were master’s
students or faculty.



5.2 Qualitative components
5.2.1 Fourteen thematic categories of reader-text interaction in active reading (as a result
of initial and intermediate coding)
Throughout the iterative revision and refinement processes of data collection and analysis
in the four phases of qualitative components, 14 thematic categories were identified to
characterize the nature of reader-text interaction in active reading for the subset of users
who were most likely to be heavy annotators/note-takers and/or strong advocates of
annotation: 21 Ph.D. students who used diverse formats and tools. These are summarized
in Table 58 and described in the sections that follow.

Table 58: Fourteen themes that explain the nature of reader-text interaction in active
reading
Extended categories
of
of reader-text
interaction
Text-focused

Intentions, needs, or desires
(14 thematic categories)
1

TX

Reader-focused

2

TG

Transaction-focused

3

SL

4

HR

5

MN

6

EN

7

AR

8

EV

9
10

LN
AD

The reader wants to make [a particular property or element
of a text] stand out (whether or not it represents the
author’s key ideas).
The reader wants to tag [particular information or
knowledge] for the entire text.
The reader wants to differentiate [a particular part of a text]
selectively and make it stand out.
The reader wants to prioritize [a part of a text]
hierarchically and indicate the degree of importance or the
relationship between or among importances.
The reader wants to externalize or monitor thinking by
[doing a particular activity].
The reader wants to enhance recall and/or quick retrieval
by [doing a particular activity].
The reader wants to articulate implicit content or elaborate
concise content by [doing a particular activity].
The reader wants to evaluate the original text [from a
particular perspective].
The reader wants to link between [particular elements].
The reader wants to add [a particular comment] in response
to the author’s argument.



Table 58: continued
Extended categories
of
of reader-text
interaction

Medium-focused

Intentions, needs, or desires
(14 thematic categories)
11

RV

12

EX

13

SH

14

MD

The reader wants to revise annotations/notes by [doing a
particular activity].
The reader wants to extend ideas in the original text by
[doing a particular activity].
The reader wants to shorten the original text or the reader’s
own notes by [doing a particular activity].
The reader wants to deploy [a particular property or
element] of the medium.

5.2.1.1 The first (text-focused) category of reader-response criticism
In the text-focused category of reader-response criticism, the reader’s prior knowledge
about a sign system plays a role in constructing textual meaning. A sign system in this
study was construed as participants’ prior knowledge about text properties or elements
that they had learned they needed to pay attention to through their past experiences with
general and discipline-specific academic reading. Therefore, the first category includes
one theme (TX) in which a text (i.e., participants’ prior knowledge about text properties
or elements) guides participants’ active reading without them transacting reflectively with
the text, such as evaluating the author’s argument.

1) TX: Text
The first theme represents the reader’s desire to make a particular property or element of
a text (e.g., numerical words, definitions, terminology, criteria, data sources) stand out,
whether or not it represents the author’s key ideas. For example, one reader made a list of
five elements stand out by underlining them, as shown in Figure 19.

 


Figure 19: Example of TX
5.2.1.2 The second (reader-focused) category of reader-response criticism
The reader-focused category of reader-response criticism asserts that readers’ “thoughts,
beliefs, and experiences” (Bressler, 2003, p. 67) play an important role in constructing
the meaning of text, no matter what text is involved. In this study, readers’ thoughts,
beliefs, and experiences were construed as participants’ target information or knowledge
they established before they started reading (i.e., without interaction with the text).
Therefore, this second category includes one theme (TG) in which participants have
targeted information or knowledge that guides their attention and active reading, without
such interactions with the text as deriving new insights from the author’s argument.

2) TG: Tag
The second theme represents the reader’s desire to tag particular information or
knowledge throughout the text either mentally or in written form, generally before

 

reading. For example, one interviewee wrote a reference citation in APA style on the top
margin right above an article title in the first page and reported “... this was already there
before I started (reading), but that’s how I should cite this,” indicating prior intention to
identify articles for citation. In answer to whether he made annotations before reading,
another participant reported that he started reading keeping in mind that he needed to pay
attention to Amazon’s Mechanical Turk as a data collection method he planned to use for
his dissertation.
5.2.1.3 The third (transaction-focused) category of reader-response criticism
The transaction-focused category of reader-response criticism is based on the idea that
the meaning of text can be constructed only when readers have become conscious of and
accepted its meaning through their interactions and transactions with texts. In this study,
this category was restated as “when readers elicit the author’s knowledge or produce new
knowledge through their familiarity with text and processes of examination, critical
thinking, and reflection.” This third category includes 11 themes: MN (Monitor), EN
(Enhance), and SH (Shorten), which represent participants’ activities of eliciting the
author’s knowledge through their familiarity with text and processes of examination; and
SL (Select), HR (order Hierarchically or Prioritize), AR (Articulate), EV (Evaluate), LN
(Link), AD (Add), RV (Revise), and EX (Extend), which represent participants’ activities
of producing new knowledge through critical thinking and reflection.

3) SL: Select
The third theme represents the reader’s desire to differentiate a particular part of a text
selectively and make it stand out. Select was applied to two kinds of content: 1) key

 

terms, key arguments, and background knowledge from the author’s perspective; and 2)
interesting, inspiring, disagreeing, and unclear parts of a text from the reader’s
perspective. Figure 20 shows one example in which a participant has selected the author’s
important information and made it stand out by highlighting it and adding a comment and
stars to it.


Figure 20: Example of SL (1)
Figure 21 below is an example in which a participant makes a point of the author’s with
which s/he agrees stand out by highlighting it and adding a comment.


Figure 21: Example of SL (2)

Similarly, another participant reported in follow-up interviews, “A checkmark means it’s
a great point/idea or that I completely agree with it.”

 

Figure 22 below is an example in which a participant makes textual content s/he
wants to use in the future stand out by highlighting it and adding a comment.



Figure 22: Example of SL (3)
4) HR: Order Hierarchically or Prioritize
The fourth theme represents the reader’s desire to prioritize a part of a text hierarchically
and indicate its degree of importance or relationships among degrees of importance.
Importance was considered from two perspectives: the author’s and the reader’s. For
example, one participant used one star, two stars, and three stars for least, moderately,
and extremely important statements in Figure 23 below.


Figure 23: Example of HR (1)

 

In follow-up interviews, one interviewee reported, “If I highlight it in yellow, it means
worthy of another look in the future. If I highlight on top of that in green, it means that
it’s a um, you know, fairly important idea. Any concepts or key passages or phrases that
get highlighted in blue, means that that is a critical term or concept that I need to pay
major attention to, and um, in a similar way, I found myself putting stars next to things in
the margin.”
As a further step, some participants used an arrow to connect important
statements and indicate relationships between them, such as a topic-and-details
relationship (Figure 24) or a higher-and-deeper-explanation relationship.


Figure 24: Example of HR (2)

5) MN: Monitor
The fifth theme represents the reader’s desire to externalize or monitor thinking by doing
particular tasks. For example, one participant reported that she wrote notes “to record my
own process of comprehending the text.” Other participants added multiple circles to a
particular word or a note in the margin as evidence of externalizing their processes of
thinking (Figure 25).

 

Figure 25: Examples of MN (1)

As another example (Figure 26), a participant enclosed one word with asterisks as
evidence of monitoring his own thinking processes, reporting via email “I use single
asterisks enclosing an expression to emphasize it. It’s the equivalent of putting it in
boldface type I suppose. => EMPHASIZE (MONITOR THINKING).”


Figure 26: Example of MN (2)

Another participant wrote “ha” (Figure 27), explaining, “No, I just thought what
he wrote was funny. I take notes almost ‘automatically’ now, so sometimes I just write
whatever I’m thinking without considering whether it’s really helpful.”

 


Figure 27: Example of MN (3)

6) EN: Enhance
The sixth theme represents the reader’s desire to enhance recall or quick retrieval by rewriting or reviewing important information or knowledge from the author’s perspective
such as key terms and ideas and information or knowledge that the reader found
interesting or important or did not know or understand.
For example, a participant wrote a key term in the margin that was taken from a
paragraph to retrieve an important idea quickly later, as shown in Figure 28 below.


Figure 28: Example of EN (1)

In Figure 29, another participant wrote all ideas in a separate notepad by flipping through
the first to the last page after reading as an aid to enhance recall and retrieve important
information later.

 


Figure 29: Example of EN (2)

7) AR: Articulate
The seventh theme represents a reader’s desire to articulate implicit content or elaborate
concise content by such means as adding lines to a graph; translating an image, a graph,
or a formula into a written description; making ambiguous expressions unambiguous;
identifying information or explanations that were omitted by the author; and identifying a
rationale underlying the author’s arguments.
For example, a participant wrote the year 1992 to clarify “recent” in the phrase
“recent conferences on design” (Figure 30) and translated the German word
“Weltanschauung” into English (Figure 31).

 


Figure 30: Example of AR (1)





Figure 31: Example of AR (2)
Another participant unpacked the meaning of a graph into written statements (Figure 32).


Figure 32: Example of AR (3)

 

Other participant expressed his desire to make ambiguous terms unambiguous, reporting:




 #            #   

 !  

    !#    ! #!!!!

  
 ! #     

  !# # 

                      

     !   

    

 

     

   

     $ % "  
 #         
     "

8) EV: Evaluate
The eighth theme represents the reader’s desire to evaluate the original text from different
perspectives such as the correctness of English usage, style, and composition; the validity
of the author’s argument; discrepancies with the reader’s prior knowledge; and the
quality of the research design, data analysis, and interpretation. Figures 33-35 below are
examples of participants’ addition of evaluative comments to the author’s research
questions, reasoning processes, and graphs, respectively.






Figure 33: Example of EV (1)



Figure 34: Example of EV (2)







Figure 35: Example of EV (3)

9) LN: Link
The ninth theme represents the reader’s desire to link a part of a text with diverse
elements such as related information on a distant page within one document, related
sources or prior knowledge beyond one document, and the reader’s personal research.
For example, one participant added a comment of “See ex. below” to link
knowledge on one page with that on another page (Figure 36).






Figure 36: Example of LN (1)
Another participant wrote a note in a separate notepad by linking her prior
knowledge (“PRUDENCE TRAP”) with her current reading (Figure 37).


Figure 37: Example of LN (2)

Also, one participant related an external source to her current reading (Figure 38),
reporting, “Kenneth Foote, um, is an author that we had read for another day’s
assignment, so F-O-O-T-E – that’s the author’s last name. It’s kind of a cross-reference to
remind my students about it and to remind myself of that...”


Figure 38: Example of LN (3)


 

Another participant reported in her follow-up interview, “the most important thing
to me is how does it relate to the bigger questions I’m researching and the other data that
I’m coming across.”
Last, it was found from observation that many participants flipped back and forth
or scrolled up and down to link knowledge in different locations or between current texts
and external resources (e.g., websites, lecture notes).

10) AD: Add
The tenth theme represents the reader’s desire to add his or her comments to the author’s
arguments, such as justification for disagreement, questions that need to be posed to the
author or colleagues, notes about definitions of concepts, and reminders for future
reading. For example, one participant reported, “That note is associated with the vertical
line, which points out a quote from Socrates. It is a note of agreement, as I agree with his
words and “not too far off” reminds me that it can be applicable today still” (Figure 39).


Figure 39: Example of AD (1)
As another example, one participant wrote her disagreement with the author’s
arguments, along with page number and justification for the criticism, in a separate
notepad as shown in Figure 40 below.

 


Figure 40: Example of AD (2)

11) RV: Revise
The eleventh theme represents the reader’s desire to revise previous annotations by
actions such as deleting or changing them. This was identified as one reason why
participants scrolled up and down or flipped back and forth: to revise their annotations
based on their adjusted or corrected understanding as they continued to read. For example,
one participant reported, “I read ahead and then something I noticed earlier or comments
I made earlier became wrong based on that new information that I have read and so I
need to go back and forth to revise previous annotations and things like that.”

12) EX: Extend
The twelfth theme represents the reader’s desire to extend ideas in the original text by
adding ideas such as the reader’s own recommendations related to the author’s argument,
additional interpretations or solutions that the author missed, and questions or statements
inspired by the author’s argument.
For example, one participant showed his desire to expand knowledge by reporting,
“In other cases, I ‘engage deeply’ with the text by either criticizing it or expanding on it.
See for example my long anchored note on page 28” (Figure 41).

 


Figure 41: Example of EX (1)

Another participant proposed a new idea for a future study that was derived from a point
the author had missed in Figure 42 below:


Figure 42: Example of EX (2)

13) SH: Shorten
The thirteenth theme represents the reader’s desire to shorten the original text or the
reader’s own notes by such means as using or creating an abbreviation (Figure 43),
transforming a word into a symbol (Figure 44), writing down indexing terms (Figure 45),
and summarizing a paragraph (Figure 46).

 


Figure 43: Example of SH (1)



Figure 44: Example of SH (2)



Figure 45: Example of SH (3)


Figure 46: Example of SH (4)







5.2.1.4 The fourth (medium-focused) category of reader response theory
14) MD: Deploy the Medium
The fourteenth theme represents the reader’s desire to deploy properties or elements of
the medium such as hardware properties (e.g., prevention of eye-strain, suitability of use
for daily transportation), software properties (e.g., zoomability, capability for checking
the remaining pages), psychological properties (e.g., ease and comfort of use stemming
from personal long-term habits), socio-economic aspects (e.g., the price of reading
devices), cultural aspects (e.g., ownership of books), and environmental aspects (e.g.,
controllability of distraction).
For example, one participant emphasized the importance of hardware properties,
reporting, “Resolution is very important with reading. Crisp characters that uhm it’s not
too insolated and crisp pixilated. It has to be in color. A lot of the documents have charts
and images which I need to understand. ... They’re plastic and they seem a little bit more
durable.”
One participant criticized a particular aspect of one software feature, reporting, “I
put my notes, my thoughts in a sticky note and whenever I read now, I switch over to
using the typewriter function a lot, so I don’t have to click through…it’s just one extra
step to like click on that and see what I…uhm…notated, and so…” and “It’s just easier to
see my overall, like give more overall picture of what the different points were that I was
trying to uhm…take away or understand or remember from what I wanted to say about
that article.”
As an example relating to socio-economic aspects, one participant from South
Africa reported that “in South Africa, it’s quite expensive to go online for some people.

 

Uh…often we have uh a criteria called CAPS, and where people only have contracts, say
10 megabytes or 10 gigabytes per month, uh and so unlike in America, [where] you can
download as much you want, but in South Africa, you have to be quite careful,” and
“You know in South Africa, electronic equipment is very expensive.”
5.2.1.5 Summary
Through the iterative and refinement processes of data collection and analysis in the four
qualitative phases (the annotation study, the first follow-up interviews, the video study,
and the second follow-up interviews), this study identified the 14 thematic categories
shown in Table 58, which represent the intentions, needs, and desires of Ph.D. students
who used diverse formats and tools – the active readers surveyed in this study who were
most likely to be heavy annotators/note-takers and/or strong advocates of annotation.
5.2.2 Relationships among the fourteen themes of reader-text interaction in active reading
(as a result of advanced coding)
Considering the relationships among individual coding items in the 14 thematic
categories, one overarching theme that emerges is that particular items in some themes
are time-sensitive (i.e., tasks that can only be done before, during, or after reading). These
are summarized in Table 59.

 

Table 59: Grouping the 14 thematic categories as time-wise processes of active reading
(based on the final codebook in Appendix R)
Types
of reader-text
interaction
Text-focused
Reader-focused
Transactionfocused

Intentions,
needs, and
desires
(the 14 thematic
categories)
TX
TG
SL

Code # of
tasks done
before
active
reading
01

Code # of tasks done
during active reading

03,04,14,18
05, ..., 36.3

01,03
00.1
02.1, ..., 12.2
08, ..., 11
27
29
27.1
31.1, 31.2, 31.3
01, ...., 06.2
01.1, ..., 04.1
01,02,03

HR
MN
EN

01, ..., 01.5
1.6, ..., 03

AR
EV
LN

4.1, ..., 8.4
01, ..., 15.1
02, ..., 07.1
07,08,09
15,16
10, ..., 14
03, ..., 05.3
01,02
01, ..., 07.1
01,02
02.1, ..., 08
10, ..., 41

AD
RV
EX
SH
Mediumfocused

MD

Code # of
tasks done
after active
reading

01, ..., 09.5
61, …, 65

46, ..., 58

For example, some participants wrote the author’s name and the year of publication and
citation information on the first page before reading, reporting that they were “to fit my
filing system” and “already there before I started (reading),” which is consistent with
TX01 and TG03. Thus, TX01 and TG03 were assigned as coding items that needed to be
done before reading. As another example, a participant engages in reflective activity after





reading, reporting “I re-read my notes and cross-reference them (to a limited extent) ... I
often highlight my own notes as I go, or add more questions,” which is consistent with
EN01.7. Thus, EN01.7 was assigned as an item that needed to be done after reading.
The other major emergent theme was that the depth of engagement varied from
low, involving a literal level of comprehension; to medium, involving an inferential level
of comprehension; to high, involving critical, applied, or appreciative levels of
comprehension (Sadoski, 2004), as summarized in Table 60 below.
For example, LN02 was designated as low engagement, because it is about
linking between a table and its relevant text, which involves a literal level of
comprehension. LN07 was designated as medium, because it is about linking between
information or knowledge in two different locations or across multiple locations, which
requires an inferential level of comprehension. LN10 was designated as high, because it
is about linking between the current text and prior knowledge, which requires an applied
level of comprehension.





Table 60: Grouping the 14 thematic categories in terms of the depth of engagements of
active reading
Types
of readertext
interaction
Textfocused
Readerfocused
Transactionfocused

Intentions,
needs, or desires
(the 14 thematic
categories)
TX

Depth
of
engagement
Low

Code # of
tasks done
before active
reading
01

TG

Low

01,03

SL

Low

MN
EN
AR
EV
LN

Mediumfocused

Medium
High
Medium
Low
High
Medium
High
Low
Medium

AD
RV
EX
SH

High
High
High
High
Low

MD

N/A

Code # of
tasks done
after active
reading

00.1
02.1, ..., 12.2
08, ..., 11
27
29
27.1
31.1, 31.2,
31.3
01, ...., 06.2
01.1, ..., 04.1
07,08,09

Medium
High
HR

Code # of
tasks done
during active
reading
03,04,14,18
05, ..., 36.3

01, ..., 01.5
1.6, ...,03

01,..., 09.5

4.1, ..., 8.4
01, ..., 15.1
02, ..., 07.1
07,08,09
15,16
10, ..., 14
03, ..., 05.3
01,02
01, ..., 07.1
01,02
02.1, ..., 08
10, ..., 41

46, ..., 65

Based on these observations, the individual coding items in the 14 thematic
categories were horizontally re-arranged according to the time-wise processes of active
reading, including before reading, during reading, and after reading, and were vertically
re-arranged based on the depth of engagement in active reading, including low, medium,
and high levels of comprehension. This is represented in Figure 47 below.







)" ""

&#
#!"

190




-0###!"
!!(#&##!#









''

.










,
/

!#%
 !"
!#' '
! !#%%
 !"






















,
.

,
-



!










,
0












,
2









,
2














,
2





,
2








,
3








#!%
 !"
!#
%
 !"




)

,
2












,
4













)

,
4










,
4

,
5



















)

,
5













,













)"

,




Figure 47: Advanced coding: A relational map

6#%'!6%!'6"('6$#$!'6#'"6"
6 !($"'6&#($"' 6!"#($"' 6 $($"
















,
1



,
0



$!!









,













.















-












-

#!
















.

























As shown in Goals and Reasons in Figure 47, a further level of horizontal relationship
that scaled down from the time-wise grouping of the individual coding items in the 14
thematic categories was identified by re-grouping the coding items in the categories
based on the 12 ultimate reasons for reader-text interaction, including annotation,
movements, and other activities (Table 61). This was based on an emerging theme in
participants’ responses to questions about their ultimate reasons in reader-text interaction
(for example questions, see 5. General information about your reasons for [or your
ultimate goals of] annotating and/or note-taking in Appendix H.2). For example, because
all coding items in EN (ENhance) had the ultimate goal, 11. To think through the
author’s key ideas and the reader’s reflections and utilize them later, they were grouped
together.



192
High
Low
Medium
High
High
High
High
Low

EV
LN



Medium

MN

AD
RV
EX
SH

Low
Medium

SL
AR

Transactionfocused

Low

Low

TX

MD

Mediumfocused

Low

Low

Depth
of
engagement

Text-focused

TX

Intentions,
needs, and
desires
(the 14
thematic
categories)
TG

Text-focused

Reader-focused

Extended
categories
of reader-text
interaction

01, ...,
09.5
61, …,
65

01

Code #
of tasks
done
before
active
reading
01,03

Table 61: Ultimate reasons for reader-text interaction

01, ..., 15.1
02, ..., 07.1
07,08,09
10, ..., 14
03, ..., 05.3
01,02
01, ..., 07.1
01,02

07,08,09

00.1
4.1, ..., 8.4

03,04,14,1
8

Code # of
tasks done
during
active
reading



Code # of
tasks done
after
active
reading

7. To minimize time-consuming tasks while reading

3. To take note of properties or elements of a text that
spontaneously elicit attention (whether or not they represent
the author’s key ideas)
4. To make content clearer (e.g., make implicit content
explicit, make complicated content simpler, elaborate
concise content)
5. To be more aware of thinking (or metacognitive)
processes
6. To examine and develop content carefully and critically

1. To keep track of particular target information or
knowledge
2. To familiarize oneself with bibliographic information
and/or find it quickly later
12. To maximize current and future reading experience

Ultimate reasons

193

Mediumfocused

Mediumfocused
Transactionfocused

Text-focused
Transactionfocused

Extended
categories
of reader-text
interaction

High
Low

Low

EN

MD

Low
Low
Medium
Low

Low
Low
Low

SH
TX
SL

SL
SL
LN
MD

Medium

Low

Depth
of
engagement

HR

Intentions,
needs, and
desires
(the 14
thematic
categories)
SL

Table 61: continued
Code #
of tasks
done
before
active
reading

27
29
15,16
10, ..., 41

02.1,
...,12.2
01, ....,
06.2
02.1, ..., 08
05, ..., 36.3
08, ..., 11

Code # of
tasks done
during
active
reading



01, ...,
01.5
1.6, ..., 03
46, ..., 58

Code # of
tasks done
after
active
reading

12. To maximize current and future reading experience

11. To think through the author’s key ideas and the reader’s
reflections and utilize them later

12. To maximize current and future reading experience

9. To quickly retrieve information or knowledge that is not
necessarily the author’s key points but that I find important,
useful, or interesting
10. To undertake further action later such as doublechecking, further researching, and further discussion

8. To grasp the author’s key points quickly for later
retrieval (without re-reading the entire text)

Ultimate reasons

I also identified another higher level of horizontal relationship scaled up from the
reason-wise grouping of individual coding items in the 14 thematic categories by regrouping them based on the higher goals of reader-text interaction (Table 62). This level
is based on an emergent theme in participants’ responses to one question about whether
an individual reader-text interaction was for current reading, future reading, or both in the
follow-up questions. For example, for one participant, reader-text interactions were
mostly for future reading, whereas for another participant, all reader-text interactions
were for both current and future reading.
Table 62: Goals and ultimate reasons for reader-text interaction
Ultimate reasons
1. To keep track of particular target information or
knowledge
2. To familiarize oneself with bibliographic information
and/or find it quickly later
12. To maximize current and future reading experience
3. To take note of properties or elements of a text that
spontaneously elicit attention (whether or not they
represent the author’s key ideas)
4. To make content clearer (e.g., make implicit content
explicit, make complicated content simpler, elaborate
concise content)
5. To be more aware of thinking (or metacognitive)
processes
6. To examine and develop content carefully and critically
7. To minimize time-consuming tasks while reading
8. To grasp the author’s key points quickly for later
retrieval (without re-reading the entire text)
9. To quickly retrieve information or knowledge that is not
necessarily the author’s key points but that I find
important, useful, or interesting
10. To undertake further action later such as doublechecking, further researching, and further discussion
12. To maximize current and future reading experience
11. To think through the author’s key ideas and the
reader’s reflections and utilize them later
12. To maximize current and future reading experience

 

Goals
I. To seek target information or
knowledge (current and future)

II. To enhance current (moment-tomoment) reading processes or
experiences or to engage deeply
with content cognitively and/or
emotionally

III. To enhance future reading
processes or experiences

IV. To re-examine and organize text
(current and future)

Last, as described in section 5.2.1, the four categories that were extended from the
three categories that were derived from reader-response criticism (reader-focused, textfocused, and transaction-focused) were designated as R for reader-focused, T for textfocused, RT for transaction-focused, and M for medium-focused.
As an important reminder, the grouping and arrangement of coding items in the
relational map in Figure 47 could vary depending on diverse factors such as individuals’
preferences, behaviors, and situations. As one example in relation to individuals’
preferences, Table 63 shows that there was no difference across the three types of readers
who had different preferences for devices in terms of the amount of prior knowledge,
degree of interest, or level of readability. However, with the exception of the common
purpose of writing a manuscript, the iPad and laptop (or paper) readers differed in term of
purpose(s) for active reading.
Table 63: Comparison across three types of readers by three devices in the video study
and follow-up interviews in terms of purpose(s), major(s), amount of prior knowledge,
degree of interest, and level of readability
Device

Purpose(s)

iPad
(3
participants)

Class preparation,
final exam, writing a
manuscript

Education,
psychology

Laptop
(8
participants)

Dissertation,
teaching, project
proposal, response
paper for class,
writing a manuscript
Dissertation
(prospectus,
qualifying paper and
exams, proposal),
discussion group for
class, seminar paper,
lab work, prelims

Education, history,
information
science, linguistics,
psychology,
religious studies
Art history,
biology, English,
history, information
science, journalism,
microbiology,
philosophy,
sociology, vision
science

Paper
(10
participants)

Major(s)

 

Amount of
prior
knowledge
Little,
moderate

Degree of
interest

Level of
readability

Somewhat,
a lot

Easy,
difficult

Little,
moderate,
much

Somewhat,
a lot

Easy,
moderate,
difficult

Little,
moderate,
much

Somewhat,
a lot

Easy,
moderate,
difficult

One example in relation to individuals’ behaviors was TX05, which is about
highlighting or enumerating an entire list of parallel words. TX05 was assigned as
relevant for future reading experience, but TX05 could be assigned as relevant for current
or both current and future reading experiences, depending on the intentions behind
individuals’ behaviors. As an example in relation to individuals’ situations, TG03, which
is about tagging a reference citation for the entire text, was assigned as something to be
done before reading, but TG03 could be assigned as something to be done during or after
reading, depending on when a reader decided this would be a useful annotation.
5.2.3 Numerical characteristics of qualitative components
5.2.3.1 Comparison across the three types of readers by three devices in the video study
and follow-up interviews in terms of the 14 thematic categories
As shown in Table 64, there was little difference between laptop and paper readers in
terms of the 14 thematic categories. Some difference between the two groups was found
in the five thematic categories of AD (Add), AR (Articulate), EN (Enhance), EV
(Evaluate), and SH (Shorten), in that paper readers were higher than laptop readers in
AR, EN, and SH, whereas laptop readers were higher than paper readers in AD and EV.
However, there was a notable difference between iPad and laptop (and paper) readers, in
that thematic categories that require higher levels of engagement (AD, EV, EX, RV) were
not found among the iPad readers.

 

Table 64: Comparison across three types of readers by three devices in the video study
and follow-up interviews in terms of the 14 thematic categories
Device
AD

Thematic categories
(Numbers represent the total occurrence of coding items in the final codebook)
AR EN EV EX HR LN MN RV SH SL TG TX MD

TTL

0

3

5

0

0

33

23

0

0

6

65

0

29

68

232

0

1

2

0

0

14

10

0

0

3

28

0

13

29

100%

Laptop
(8
participants)

66

12

13

99

47

4

149

2

11

20

118

2

22

129

694

10

2

2

14

7

1

21

0

2

3

17

0

3

19

100%

Paper
(10
participants)

29

41

37

16

41

18

93

6

2

62

114

1

36

107

603

5

7

6

3

7

3

15

1

0

10

19

0

6

18

100%

iPad
(3
participants)

5.2.3.2 Comparison across the individual coding items from the video study and followup interviews
Based on a substantial decrease in occurrence between LN10 and MD49 (The
seamlessness of transitions from reading to a database/filing system) in Table 65, the
seven most common coding items (types of reader-text interaction) were: AD03 (Add the
reader’s disagreement with or without justification for it), LN07 (Link between relevant
information or knowledge across multiple locations), SH04 (Note the author’s key words
or phrases that trigger recall of the content of a paragraph, a chapter, or the entire text),
LN09 (Link between the original text with its relevant external sources), SL04 (Select the
author’s key argument or idea about the entire text), EV03 (Evaluate the validity of the
author’s argument), and LN10 (Link between the original text with its relevant prior
knowledge). In relation to the medium, the most common coding item (type of readertext interaction) was MD49 (the seamlessness of transitions from reading to a

 

database/filing system), followed by MD29.3 (the capability to scan and find information
with speed) and MD15 (the capability to annotate or take notes easily and quickly).

Table 65: Comparison across individual coding items from the video study and follow-up
interviews
Coding items (Types of reader-text interaction)
AD03
LN07, SH04
LN09
SL04
EV03
LN10
MD49
EN01
EX05, SL21
LN13
AR04.1
HR6.2
SL06
MD29.3, SL29
EV02
SL31.1
MD15, TX09
EX01, EX01.2, EX06
AD05.1, SH06, SL25.1
TX01, TX05
MD46
AR08.1, MD47, SL17
LN03, TX08
LN08, LN16, MD29
EV12, HR01, LN08, RV02, SL13
LN04, MD17.1
EV15.1, MD31, MD31.2, SL25.2
AR05, MD09.2, SL24
EV01, HR03, HR04, LN05.1, MD20, MD26.1, SL09.1, SL25.5, SL27.1
HR02, LN02, MD03.1, MD10, MD12.1, MD12.2, MD14.1, MD20.2,
MD38, MN03, SL02.2
EN01.5, EV11.1, MD09, MD24, MD29.4, MD34.1, SL03, SL11, SL11.2,
SL12, SL19, SL19.1, SL25.4, TX32.1
AR08.2, EN01.4, MD03, MD09.1, MD11, MD21, MD37, MD41.1,
MD63, RV01, SH01, SL09, SL12.1, SL14, SL27









Occurrence
77
64
61
57
53
52
37
36
30
29
28
26
25
24
23
22
20
18
16
15
14
13
12
11
10
9
8
7
6
5

%
5.04
4.19
3.99
3.73
3.47
3.40
2.42
2.35
1.96
1.90
1.83
1.70
1.64
1.57
1.50
1.44
1.31
1.18
1.05
0.98
0.92
0.85
0.78
0.72
0.65
0.59
0.52
0.46
0.39
0.33

4

0.26

3

0.20

Table 65: continued
Coding items (Types of reader-text interaction)
AR08.3, AR08.4, EN01.1, EN02, EN02.2, EV11.3, EV14, HR6.1,
LN07.1, MD3.2, MD03.3, MD06, MD07, MD08, MD09.4, MD12,
MD15.1, MD17, MD20.1, MD23.1, MD27.1, MD32, MD52, MD57.2,
MD58, MD64.1, MD64.3, MN01, SH03, SL08, SL10, SL12.2, SL16,
SL25, TG01, TX04, TX14, TX16
AD05.2, AD05.3, AR04.2, EN01.2, EN01.3, EN01.6, EN02.1, EN02.2,
EN03, EV07, EV10.1, EV11.2, EV11.4, EV12.1, EV12.2, EV13, EX01.1,
EX01.3, EX02, EX07.1, LN11, LN13.1, LN15, MD01, MD02, MD03.2,
MD05, MD06.1, MD08.1, MD09.3, MD09.5, MD10.1, MD12.3, MD15.2,
MD19, MD23, MD29.1, MD29.2, MD30.1, MD31.1, MD33.1, MD35.1,
MD40, MD50, MD50.1, MD50.2, MD50.3, MD54, MD55, MD55.1,
MD56.1, MD57.1, MD61, MD62, MD64, MD64.2, MN02, SH02,
SH02.1, SH08, SL00.1, SL00.2, SL02.1, SL08.1, SL11.1, SL13.1,
SL16.1, SL18, SL25.3, SL25.6, SL31.2, SL31.3, TG03, TX03, TX04.1,
TX04.2, TX06, TX07, TX10, TX11, TX13.1, TX13.2, TX18, TX19.1,
TX20, TX36.1, TX36.2, TX36.3
Grand Total

Occurrence
2

%
0.13

1

0.07

1529

100


5.2.3.3 Comparison across the 14 thematic categories and their individual coding items
from the video study and follow-up interviews
The most common thematic category was MD (Deploy the medium), followed by SL
(Select) and LN (Link), based on a substantial decrease in occurrence between LN (Link)
and EV (Evaluate) in Table 66.





Table 66: Comparison across the 14 thematic categories from the video study and followup interviews
14 thematic categories
MD
SL
LN
EV
AD
EX
SH
TX
AR
EN
HR
RV
MN
TG
Total

Occurrence
304
297
265
115
95
88
88
87
56
55
55
13
8
3
1529

%
20
19
17
8
6
6
6
6
4
4
4
1
1
0
100



Chapter 6. Discussion
6.1 Quantitative components
6.1.1 Demographic information about the survey respondents
Demographic characteristics of the participants in the first phase of the study, the online
survey, indicated that a majority were U.S. female master’s or Ph.D. students in library
science in their twenties or thirties. This is a reflection of the fact that the online
questionnaire was distributed to particular English-language electronic mailing lists, the
subscribers of which were considered likely to be interested in the topic of this study.
Active reading and ebook design appear to be more attractive topics to U.S. female
master’s or Ph.D. students in library science in their twenties or thirties than other
population groups who participated in the survey (native speakers of English in master’s
or Ph.D. programs or post-doc or faculty positions).
6.1.2 Characteristics of active reading practices
With regard to annotation behaviors, a majority of the participants were heavy annotators
and/or note-takers, which shows that writing while reading is a very common practice
among U.S. graduate students and faculty. About half of the participants were strong
annotators, indicating that writing directly on documents is a common practice among
graduate students and faculty. Moreover, about half of the participants favored paper
formats (book and printed PDF files), which shows that paper formats are still popular
among graduate students and faculty, but not as dominant as in the past. A majority of
participants favored paper, a desktop computer, or a laptop computer for active reading,
which suggests that more recently-introduced reading devices such as ebook readers,



tablet computers, and smart phones are not yet popular for active reading among graduate
students and faculty. At the same time, a majority of participants were open to active
reading in diverse places, including home, office, and cafe, indicating that graduate
students and faculty do not necessarily require quiet places for active reading. A majority
of participants used paper-related tools (e.g., pen, notepad) as well as computers while
reading. This suggests that while some tasks (e.g., annotating, making memos as
reminders, searching) were integral to graduate students and faculty’s active reading,
those tasks were better accomplished using separate platforms (e.g., reading on paper
while note-taking in a digital notepad, reading digitally while note-taking in a paper
notepad).
6.1.3 Factors predicting the frequency and type of annotation
As illustrated schematically in Figure 48, heavy annotators/note-takers were likely to be
Ph.D. students, frequent users of diverse paper tools in addition to a computer, or both.

Ph.D.
students

Tool lovers
(paper tools
and a
computer)

Figure 48: Characteristics of heavy annotators/note-takers

Not surprisingly, writing while reading was a more common strategy among
Ph.D. students, who, as novice scholars, need to employ diverse strategies in reading
difficult texts. Also, it was not surprising that writing while reading was a more common



practice among frequent users of a computer together with diverse paper tools, since use
of multiple tools could trigger more writing than use of only one tool such as a computer
only.
Strong advocates of annotation were likely to be Ph.D. students, frequent users of
both paper (book) and digital formats (Web pages and PDF online), and/or frequent users
of diverse paper tools as well as a computer, as shown in Figure 49 below.

Ph.D.
students

Tool lovers
(paper tools
and a
computer)

Digital lovers
(paper and
digital
formats)

Figure 49: Characteristics of strong advocates of annotation
It is not so surprising that annotating on documents that could help reading text line by
line, preventing loss of context, was a more common strategy among Ph.D. students who
need to read difficult text closely. Also, it is not surprising that annotating on documents
was a more common practice among frequent users of a computer and diverse paper tools
that are usually used for writing on documents, rather than on separate notepads.
However, it was somewhat surprising that annotating on both paper and digital
documents was a more common strategy among frequent users of diverse formats, in the
sense that paper reading produces more annotations than digital reading (Liu, 2005). At



the same time, it was not surprising, in the sense that annotating on digital documents is
common and easy in the digital age.
6.2 Qualitative components
6.2.1 Types of reader-text interaction in terms of the three approaches of reader-response
criticism
The first research question asked what types of reader interaction with text occur, as
viewed in terms of the three approaches of reader-response criticism. Coding items in 13
thematic categories (TX, TG, SL, HR, MN, EN, AR, EV, LN, AD, RV, EX, and SH)
belong to the three approaches of text-focused, reader-focused, and transaction-focused in
the original reader-response criticism. TX, TG, SL, HR, MN, EN, AR, EV, LN, AD, RV,
EX, and SH consist of 23, 2, 41, 10, 3, 11, 7, 15, 15, 4, 2, 8, and 7 coding items,
respectively, each of which represents a different type of reader-text interaction. For
example, TX06, which is one of the 23 coding items in TX, represents one type of textfocused reader-text interaction where readers make italicized key terms stand out.
From participants’ most frequently mentioned coding items (types of reader-text
interaction), it appears that for them active reading was mainly about selecting and
extracting the author’s key information or knowledge (SL04, SH04), linking the original
text with relevant information or knowledge across different locations, external sources,
and prior knowledge (LN07, LN09, LN10), adding disagreement with the author’s
argument (AD03), and evaluating the validity of the author’s argument (EV03).



6.2.2 Types of reader-text interaction beyond the three approaches of reader-response
criticism
The second research question asked what types of reader interaction with text occur
beyond the three approaches of reader-response criticism. Eighty-one individual coding
items in one thematic category of MD belong to one newly-added medium-focused
approach of reader-response criticism. In this approach, the medium plays a key role in
the way that readers look into properties or elements of the medium first to decide how to
deploy them in their follow-up interaction with text. For example, MD01, which is one of
the 81 coding items in MD, represents one type of medium-focused reader-text
interaction where readers look into one property of eyestrain first to decide if they will
use digital devices to read text in their particular contexts where eyestrain is a key
consideration personally and situationally, for example when people have severe
computer vision problems or when people need to read for a long period of time.
From participants’ most frequently mentioned coding items in relation to the
medium, it appears that indirect issues that go beyond reading-related tasks, such as the
expandability of the medium (MD49 smooth transitions from reading to a database/filing
system), are quite important in the context of active reading, even more important than
directly reading-related issues, such as the capability to scan and find information quickly
(MD29.3) and the capability to annotate or take notes easily and quickly (MD15).
6.2.3 Readers’ intentions, needs, and desires underlying different types of reader-text
interaction
The third research question asked what kinds of reader intentions, needs, and desires
underlie the types of reader interaction with text identified in answers to the first and the



second research questions. The 14 thematic categories of TX, TG, SL, HR, MN, EN, AR,
EV, LN, AD, RV, EX, SH, and MD, which were derived from all the individual coding
items as Ph.D. students’ answers to the first two research questions, represent different
types of intentions, needs, and desires underlying different types of reader-text
interaction.
From participants’ most frequently mentioned thematic categories it can be
inferred that the medium was a highly important factor in the context of active reading,
indeed more important than any other reader-focused, text-focused, or transactionfocused factors, including SL (Select) and LN (Link), which were identified as the most
common categories along with MD (Deploy the media).
Given that AD (Add) and EV (Evaluate), which require higher levels of
engagement, were more common practices for laptop readers than for paper readers, in
can be assumed that a laptop is as important and appropriate a device as paper in the
context of active reading. However, because iPad readers did not engage much in AD
(Add), EV (Evaluate), EX (Extend), and RV (Revise), which are higher levels of
engagement, it can be inferred that an iPad is not yet an appropriate device for active
reading, which is also consistent with a finding of the online survey.
6.2.4 Translating findings into the design of interactivity: A composition model of readertext interaction
The fourth research question asked how readers’ intentions, needs, and desires, as
identified in the findings from the third research question, can be translated into “the
design of interactivity, or form that changes and reacts to input over time” (Cooper et al.,
2007, p. xxx). This expression refers to the design of interactive behaviors of software



and hardware, as opposed to the design of static form by graphic designers, in ebook
devices.
One purpose of this study was to find ways to enhance readers’ interaction with
text in ebook devices. Interactivity was operationalized as text form that changes and
reacts to readers’ input over time. To be aligned with the design of interactivity, which is
behavioral, implications for the design of interactivity were generated by transforming
non-behavioral verbs (e.g., externalize, enhance, evaluate) in the 14 thematic categories
into behavioral verbs (e.g., add, isolate), as shown Table 67.
For example, ‘add a new layer of information or knowledge (e.g., meta-cognitive
info)’ in MN (Monitor) was transformed into an implication for the design of interactivity
by changing the non-behavioral verb externalize to the behavioral verb add.



Table 67: Answers to the fourth research question: The design of interactivity

TX
TG
SL
HR
MN
EN
AR
EV
LN
AD
RV
EX
SH
MD

Intentions, needs, and desires
(14 thematic categories)
The reader wants to make [a particular property or
element of a text] stand out (whether or not it
represents the author’s key ideas).
The reader wants to tag [particular information or
knowledge] for the entire text.
The reader wants to differentiate [a particular part
of a text] selectively and make it stand out.
The reader wants to prioritize [a part of a text]
hierarchically and indicate the degree of importance
or the relationship between or among importances.
The reader wants to externalize or monitor thinking
by [doing a particular activity].
The reader wants to enhance recall and/or quick
retrieval by [doing a particular activity].
The reader wants to articulate implicit content or
elaborate concise content by [doing a particular
activity].
The reader wants to evaluate the original text [from
a particular perspective].
The reader wants to link between [particular
elements].
The reader wants to add [a particular comment] in
response to the author’s argument.
The reader wants to revise annotations/notes by
[doing a particular activity].
The reader wants to extend ideas in the original text
by [doing a particular activity].
The reader wants to shorten the original text or the
reader’s own notes by [doing a particular activity].
The reader wants to deploy [a particular property or
element] of the medium.



The design of interactivity
Isolate segments and foreground
them
Tag a new layer of information or
knowledge (e.g., bibliographic info)
for the entire text
Isolate segments and foreground
them
Isolate segments and arrange them
hierarchically
Add a new layer of information or
knowledge (e.g., meta-cognitive
info)
Isolate segments and foreground
them
Add a new layer of information or
knowledge (e.g., articulation)
Add a new layer of information or
knowledge (e.g., evaluation)
Isolate segments and link between
them
Add a new layer of information or
knowledge (e.g., responses)
Add or detach a new layer of
information or knowledge
Add a new layer of information or
knowledge (e.g., insights)
Isolate segments and add a new
layer of information or knowledge
(e.g., summary)
Manipulate reading environments
(e.g., properties of media and
surroundings)

Aggregating individual types of interactivity design in the 14 thematic categories
(Table 67) allows us to redefine active reading. First, active reading involves readers’
three-dimensional activities of re-arranging the original text hierarchically (according to
levels of importance) and horizontally (isolating, foregrounding, or linking) and redesigning it by tagging or adding, manipulating reading environments selectively
(properties of media & surroundings). I propose this as a composite model of reader-text
interaction, as represented schematically in Figure 50.
Isolate and foreground
Projected segments

Detach

Most important
segments
Linking

Thoughts, insights

The original text
Arrange

Important segments


Less important
segments

Tag

Add

External resources

Manipulate

Figure 50: Composite model of reader-text interaction
These activities are three-dimensional in the sense that they are carried out in a space that
has length, breadth, and depth; they include linking between segments across different
locations in all directions, foregrounding important segments projecting hidden important
segments aligned with non-important segments, and arranging important segments
hierarchically according to three or more levels of importance. Especially importantly,



the addition of depth adds great benefit to this composition model of reader-text
interaction in terms of recognizing and comparing different text segments at different
levels of importance (e.g., very important, least important) and for different types of
purposes (e.g., for lab meetings, for qualifying exams, for further investigation). These
activities are quite critical for key features of active reading, such as arranging text
segments according to different levels of importance and linking text segments at
multiple locations.
Second, active reading involves dynamic activities of selecting various types of
reader-text interaction at one of three levels of engagement that change over time
strategically at three different stages of reading. These dynamic activities are to achieve
diverse goals for various reasons for interaction, as represented schematically in Figure
51. For example, writing target information that needs to be attended to while reading
(TG01), which requires a low level of reader engagement, was chosen by readers who
prefer to do it before reading to help keep track of that particular information or
knowledge. In short, active reading is dynamic, in the sense that the reader’s level of
engagement and types of reader-text interaction change over time before, during, and
after reading.



Isolate and foreground

Isolate and foreground
Add

Link
Tag

Manipulate

Before reading

During reading

After reading

Figure 51: Dynamics of a composite model of reader-text interaction
The association between individual types of reader-text interaction and their
corresponding reasons, goals, and stages varies depending on factors such as individuals’
preferences, behaviors, and situations. As one example, readers who have a preference
for iPads had a tendency to select particular sets of reader-text interaction that require low
and medium levels of engagement, whereas readers who have a preference for laptops or
paper had a tendency to select all 14 types of reader-text interaction that require low,
medium, and high levels of engagement.
As another example, readers with a preference for iPads had a tendency to use
their iPads for simple, short-term projects such as class preparation and exams. In
contrast, readers with a preference for laptops or paper had a tendency to use their laptops



or paper for complex, long-term projects such as dissertation-related work, as well as for
simpler, short-terms projects.
The other examples were associated with TX05, which concerns highlighting or
enumerating an entire list of parallel words, and TG03, which is about tagging a reference
citation for the entire text. TX05 was assigned as relevant for future reading experience,
but TX05 could be assigned as relevant for current or both current and future reading
experiences, depending on the intentions behind individuals’ behaviors. TG03 was
assigned in the analysis as something to be done before reading, but TG03 could be
assigned as something to be done during or after reading, depending on individuals’
situations, such as when they decided it would be a useful annotation.
6.3 Summary
As findings of this multi-phase user study, individual types of reader-text interactions,
such as “linking with implicitly or explicitly relevant contents at distant locations” and
“extending the author’s ideas by adding the reader’s own recommendation,” were
grouped into 14 emergent themes. These were coded as actions, for example, Select,
Articulate, Monitor, Evaluate, Link, Add, Revise, Extend, Shorten, Prioritize
hierarchically, and Enhance.
To achieve the ultimate goal of the study, which was to obtain insights to inform
the design of ebooks for people who want to use them for active reading, the 14 themes
were translated into themes in relation to the design of interactivity by transforming nonbehavioral verbs in the codes for the 14 themes into behavioral verbs, for example,
Isolate and foreground, Detach, and Arrange hierarchically. This translated taxonomy
describes an overall mechanism of how active readers interact with texts spatially as they



create a new text by re-arranging or redesigning the original text horizontally and
hierarchically, supporting the conclusion that active reading involves three-dimensional
activities on the part of readers.
Additionally, relationships among individual types of reader-text interaction were
identified in relation to three levels of engagement (high, medium, or low) and three
stages of active reading (before, during, or after reading). This construction describes an
overall mechanism of how active readers interact with texts temporally, supporting the
conclusion that active reading involves readers in a dynamic process of strategically
selecting various types of reader-text interaction in terms of changing levels of
engagement at different stages of reading. In brief, throughout the active reading process,
readers’ interactions with text change to achieve diverse goals.
A summary of answers to the four research questions is summarized in Figure 52
as below (see Table 62 for details of goals and ultimate reasons):



X
X
X

Isolate segments and foreground them

X

10

Isolate segments and foreground them

Isolate segments and add a new layer

Isolate segments and link between them
Add a new layer

M
D
E
N
M
D
T
X
S
H
H
R
S
L
L
N

A
D

R
V

E
X

Add a new layer

S
H

X
X
X

Add or detach a new layer

X

X

8

Add a new layer

X
X
X

Isolate segments and add a new layer

X

Isolate segments and foreground them

E
V
M
N
A
R

X
X

5

Add a new layer

X

Manipulate reading environments

X

Isolate segments and foreground them

T
X

Tag a new layer

T
G

M
D

T
X

S
L

X
X

Isolate segments and foreground them

R3

Intentions,
needs, and
desires

The design of
interactivity
(The design of
behavior)
R4

R1-R4

Goals
Reasons
Coding

Engagement
levels

H
M
L

1

I

2

Isolate segments and foreground them

X

3

4

Add a new layer

1
2
Before
Stages
Research
questions

Figure 52: Summary of answers to the four research questions

II

6

7

During reading

Isolate segments and arrange them
hierarchically

X

III

9

Isolate segments and foreground them

L
N

1
1
X
1
2
X

Isolate segments and link between them

S
L

Manipulate reading environments

S
L

X
X
X

12

Isolate segments and foreground them

IV

After

Manipulate reading environments

Advanced

Intermediate

214

Deploy a property or element of the medium (e.g., MD46 seamless transition between reading and
writing)
Enhance recall or quick retrieval by re-writing information or knowledge (e.g., EN01.1 key terms)
Deploy a property of element of the medium (e.g., MD29 search capability)
Link a part of a text with diverse elements (e.g., LN15 the author’s contact information)
Differentiate a part of a text (e.g., SL29 new information) selectively and make it stand out
Differentiate a part of a text (e.g., SL28 abstract) selectively and make it stand out
Make a property or element of a text (e.g., TX05 parallel words or concepts) stand out
Shorten the original text or the reader’s own notes (e.g., SJ06 summarize)
Prioritize a part of a text hierarchically (e.g., HR01 extremely important)
Differentiate a part of a text (e.g., SL02.1 key terms) selectively and make it stand out
Shorten the original text or the reader’s own notes (e.g., SH01 use an abbreviation)
Extend the authors’ ideas by adding an idea (e.g., EX01 recommendations)
Revise a previous annotation (e.g., RV01 delete)
Add a comment to the author’s arguments (e.g., AD03 justification for disagreement)
Link a part of a text with diverse elements (e.g., LN07 related information across distant pages)
Evaluate the original text from a perspective (e.g., EV12 the quality of research design)
Monitor thinking by doing a task (e.g., MN01 multiple circling)
Articulate implicit content or elaborate concise content (e.g., AR8.4 hidden rationale)
Differentiate a part of a text (e.g., SL00.1 key conjunction) selectively and make it stand out
Make a property or element of a text (e.g., TX03 title or subtitle) stand out
Deploy a property of element of the medium (e.g., MD01 eye-strain)
Make a property or element of a text (e.g., TX01 bibliographic information) stand out

R1 & R2

Types of readertext interaction

Tag information or knowledge (e.g., TG03 reference citation) for the entire text

Initial

215

Chapter 7. Conclusion
7.1 Summary
This study was designed to shed light on the common practices and essential nature of
reader-text interaction for readers using diverse devices in the context of active reading.
A secondary goal was to obtain useful insights for the design of ebook devices that best
support reader-text interaction in active reading. The study was initially motivated by the
researcher’s perspective that the design of ebook devices should focus on ways that
readers interact with text, rather than on the properties of media and their mediating
effects, thereby helping readers focus on active reading itself. This perspective was
consistent with one key conclusion of this study, namely, that negative effects of the
medium (e.g., the absence of annotation capability) should be minimized, but it was
inconsistent with another key conclusion, that positive effects of the medium (e.g., the
expandability of the medium) should be maximized in ebook device design. In short,
ideally, ebook devices for use by active readers should correct deficiencies in current
designs while fully exploiting the affordances of digital capabilities.
The results of the multi-methods analysis showed that for heavy annotators/notetakers and strong advocates of annotating documents, active reading involves a complex
interplay of dynamic, three-dimensional mental and physical activities. These activities
include rearranging the original text hierarchically to distinguish levels of importance and
rearranging it horizontally by isolating, foregrounding, or linking segments; re-designing
the text by tagging or adding to it; and manipulating reading environments, including
properties of both media and physical surroundings. These activities vary according to
readers’ strategies and purposes in selecting appropriate types of reader-text interaction,



which requires one of three different levels of engagement, to achieve diverse goals over
time before, during, and after reading. They also vary according to readers’ personal and
situational factors.
7.2 Design implications
To be aligned with the nature of active reading, ebook devices should be designed in a
way that supports such individual dynamic, three-dimensional mental and physical
activities. These have not been fully supported by previous static, two-dimensional text
designs. Furthermore, the devices should react appropriately to different types of readertext interaction that require different levels of engagement for different reasons to achieve
diverse goals at different stages of active reading.
Additionally, because active reading is sometimes very personal and situational,
the adaptability of ebook technology should be a key consideration in its design. For
example, to support or promote individualizing activities, ereading technology could
employ adaptive technology that helps isolate a segment (e.g., the reader’s target
information, the author’s key ideas or key words, the reader’s own comments) using
automatic detection (e.g., machine-learning algorithms derived from the reader’s habitual
behavior or based on the reader’s habitual behavioral analyzed using natural language
processing tools such as sentiment analysis) or the reader’s manual input. As another
example, ereading technology that supports adding activities could employ adaptive
technology that stimulates the reader to develop new ideas automatically, perhaps by
suggesting relevant knowledge or making suggestions based on analysis of data about the
reader’s habits or based on the reader’s own input. Adaptive technology might also be
designed to help the reader manipulate properties of media and surroundings



automatically according to automatic data input from outside (e.g., the amount of light) or
from the reader’s own settings on the device. The important activity of linking can be
supported by adaptive technology that isolates related contents, automatically (using
automatic text analysis algorithms) or based on the reader’s own input.
A majority of participants in this study were open to diverse places for active
reading, including home, office, and cafe. Therefore, portability and data synchronization
across different platforms should also be key considerations in the design of devices for
active reading.
Toward this end, one product of the current study is a codebook of reader-text
interactions (Appendix R), which can be translated into design features that enhance
active reading in cognitive, behavioral, emotional, social, socio-economical, and cultural
ways (cf. Figure 47). As an example of a cognitive enhancement, LN02, which is about
linking between the original text and its relevant table, can be translated into a design
feature that enables this operation simply by hovering over the table. As an example of a
behavioral enhancement, MD38, which is the capability to anchor, can be translated
directly into a design feature that helps readers attach annotations easily and quickly to
their relevant text segments. MD03.1 (Holding experience), MD03.2 (Codex book form
factors), and MD09.1 (Tactile, tangible, or touchable experience), as examples of
affective considerations, can be translated into design features that provide the same look
and feel as paper books. The capability to share (MD58), as an example of a social aspect
of active reading, can be translated into a design feature that enables readers to
communicate with other readers or with authors. As an example of socio-economical
concerns, the price of reading devices (MD61) should be taken into account in selecting



software and hardware designs. As an example of cultural aspects, MD62, the ownership
of books, can be translated into design features that help organize the mix of kinds of
texts (e.g., owned, borrowed, paper, digital, edition) in readers’ own databases. This can
help them make a decision about buying a personal copy on which to write and thereby
avoid the culturally prohibited act of writing on borrowed books.
7.3 Metaphors for active reading
In order to support such three-dimensional and dynamic activities of active reading
holistically, it will be necessary for ebook researchers and designers to come up with new
metaphors. Well-conceived metaphors could provide a compact yet powerful way to
represent complex structures or processes of active reading. To conceptualize active
reading in a way that might stimulate innovative thinking about ebook device designs, the
metaphor of building an original structure by assembling Lego blocks is proposed as
analogous to readers’ dynamic, three-dimensional activities of creating a new form of
text through re-arranging text segments hierarchically and horizontally and re-designing
them by adding new text segments in new ways that make sense to readers in their
particular contexts. Another metaphor that captures this dynamic process is navigating a
new city and creating a map, which evokes the reader’s exploration and navigation of
new texts while creating a record that will be useful in future explorations and
navigations of the same or different texts. This is similar to how travelers who are
navigating new cities select meaningful landmarks and signs at different levels of
importance (e.g., a tall building or spire as a major orienting landmark in comparison to a
small shop that designates a street or neighborhood). A third metaphor for active reading
is redesigning the interior of a house, which involves changes at different levels



according to different types of criteria (e.g., accessibility or use of space). At one level,
redesign might involve simply changing wall colors and installing new furniture or
decorative items, but at a deeper level, it could involve structural changes such as adding
or removing walls or even extending overall square footage or raising or lowering
ceilings. All such renovations are consistent with readers’ re-arranging existing text
segments and re-designing a text by adding new text segments.
7.4 Theoretical, methodological, and practical contributions
This study developed a composite model of reader-text interaction in the context of
ebook user research and design by adding a medium-focused approach of reader-response
criticism to the three existing approaches. As a theoretical contribution, the composite
model of reader-text interaction adds a novel theoretical perspective to traditional reading
theories (cf. Tracey & Morrow, 2006), one that explains the spatial and temporal
dynamics of active reading in terms of both behavioral and non-behavioral aspects. The
composite model of reader-text interaction may provide a useful framework for
understanding new ereading phenomena in academic environments, not only for ebook
researchers and practitioners, but also for reading experts and teachers.
Moreover, future ebook design research may benefit from the novel methodology
used in this study, which was designed to collect a wide range of quasi-naturalistic data,
as well as from the researcher’s attempts to understand both behavioral and nonbehavioral aspects of active reading as a holistic process. Either experimental or
ethnographic methodologies have been commonly used, which limits researchers’ ability
to gain in-between insights by combining some advantages of each of the two

 

methodologies. This newly developed methodology may facilitate the advancement of
more diverse types of in-between methodologies.
This study makes a further methodological contribution by combining grounded
theory with a theoretical framework, thus maximizing the advantages of both a datadriven and a theory-driven approach and introducing a new analytical method. A new
theory of the emerging phenomenon of ereading was established through grounded
theory, whereas important aspects of active reading, a concept difficult to operationalize
in practice, were captured by applying the theoretical framework of reader-response
criticism. Specifically, the three existing approaches provided a theoretical framework
that helped the researcher identify and collect similar types of reader-text interaction to
those types in identified in the theoretical works from empirical data in real-world
settings. For example, the researcher asked participants to tell her about important text
properties they paid attention to while reading. Without the researcher’s theoretical
knowledge of text-focused reader-text interaction, she would not have been able to
collect such text-focused types of empirical data. Additionally, this study proposed a new
way of transforming and applying a theoretical framework in one discipline (literary
criticism) to another totally different discipline (design), thereby making a contribution to
interdisciplinary research.
Also, schools, libraries, and other agencies with an interest in understanding the
potential of ebook devices as primary or secondary (text)books may benefit from the
findings of this study in their selection or design of ebook devices appropriate for use in
academic environments. For example, the core types of active reading activities –
selecting and extracting the author’s key information or knowledge; linking the original



text with relevant information or knowledge across different locations, external sources,
and prior knowledge; adding disagreement with the author’s argument; and evaluating
the validity of the author’s argument – can be used as an evaluative toolkit in selecting an
appropriate ereading technology in academic settings by judging if a particular ereading
technology has design features that support or facilitate the core types of active reading
activities. As another evaluative toolkit, the 14 thematic categories in the composite
model of reader-text interaction can be used to judge if a particular ereading technology
has design features that support or facilitate important thematic categories, such as EV
(evaluating), LN (linking), AD (adding), RV (revising), EX (extending), HR (ordering
hierarchically), SL (selecting), and EN (enhancing), which require a high level of reader
engagement.
Finally, educators who mentor graduate students developing as researchers may
take pedagogical advantage of the findings of this study. It is no exaggeration to state that
the literature review is a critical step in any scholarly undertaking, because if the
literature review is not well done at the beginning, the foundation of the inquiry will have
cracks, such as overlooked meaningful research gaps or neglected studies that belong to
established knowledge; thus the inquiry itself may fail to make a significant contribution
to new knowledge or advance existing knowledge. Therefore, it is also important that
educators emphasize the importance of active reading and the critical thinking it entails to
the construction of a strong literature review. Furthermore, when educators emphasize the
importance of the relationship between active reading and good literature reviews, they
should also emphasize the importance of students’ choice of reading device by
encouraging them to question whether a device has design features that facilitate active



reading, including those that are associated with individual types of reader-text
interaction in the final codebook and the 14 theoretical categories. For example, do the
devices have design features that support a seamless transition from reading to a database
system? Do their devices help them link activities within and beyond their current
reading material? And so forth.
7.5 Limitations and directions for future research
This study utilized the three higher levels of reader-response criticism, which provided
insights that were not confined to individual critics’ particular viewpoints. However, this
approach might miss in-depth nuanced levels of design insights guided by individual
critics’ particular viewpoints. For example, analyzing reader-text interaction from the
perspectives of Gerald Prince’s three readers – “the real reader,” “the virtual reader,” and
“the ideal reader” – could yield different insights that could inform ebook design
specialized for English majors who are interested in differences among the three types of
readers (e.g., ebook designs that help separate one layer of text from another according to
the ideal reader’s and the real readers’ perspectives). For further refined insights and
design implications, therefore, it could be useful to engage with individual critics’ unique
viewpoints in future research.
Another goal for future research is to increase trustworthiness and diverse insights
by involving multiple researchers from different backgrounds in coding, rather than a
sole researcher, which was a limitation of the present study. Also, the relational coding
map (Figure 47), which presents my extension of reader-response criticism, was neither
confirmed by participants or reading experts nor tested empirically in this study.
Therefore, additional confirmation of the findings of the relational coding map with



follow-up interviews with participants or reading experts or empirical observation is
needed. Methodological triangulation might be another direction for increasing
trustworthiness. Multiple methods could be combined, including oral think-alouds, oral
discussion responses, journal writing, extended essay writing, responding to texts using
art work and hypermedia, questionnaires/surveys, rating scales, and the media
ethnography methods introduced by Beach (2004).
The scope of this study was confined to a particular set of readers (i.e., one group
of Ph.D. students) and a particular set of contexts (i.e., academic settings). Therefore,
future research might expand the scope of readers and contexts. For example, how do the
reading behaviors and practices differ among readers at different scholarly levels, e.g.,
professors vs. graduate students? How do their active reading behaviors and practices
change over time? How are active reading practices in academic settings different from
practices in other settings (e.g., occupational settings where knowledge workers, such as
doctors and lawyers, need other types of active reading)? These are questions for future
research.
Furthermore, while this study involved data collection methods that were as
naturalistic as possible, it was not an ethnographic study conducted in real-life settings. In
order to overcome this limitation, ethnographic research utilizing knowledge from this
study and advanced technology (e.g., non-intrusive eye movement tracking technology)
would help extend understanding of active reading greatly. For example, when
participants were brought to a lab for a short period time, they were not involved in
common distractions, such as answering a phone or switching between websites
including Facebook. Also, it was not possible to identify any issues in relation to mobility



such as switching between devices according to different locations (e.g., at home and on
the bus), behaviors that could be captured in an ethnographic study in natural settings.
Besides issues related to mobility and device switching, another aspect that could be
investigated in naturalistic research is the relationships among key players in a reader’s
daily life, including people, objects, and contexts.
Also, in order to expand the scope of the present study, which focused only on
text-based documents, future research should address diverse types of documents,
including multimodal documents. This is important because of the increasing
incorporation of multimodal content (which has always been available in paper
documents in the form of graphic illustrations) into digital reading devices, including in
the form of audio and video. How readers interact with multimodal content is a largely
unexplored area in need of study.
Finally, one of the interesting findings of this study was that iPads were not yet
considered suitable for active reading by a majority of the participants in the study,
whereas laptop computers have become as important as paper in the context of active
reading. This implies that reading devices have been influencing the nature of active
reading, while readers have accommodated themselves to the medium over time, with or
without sacrificing the quality of active reading. In order to investigate this interactional
or bidirectional relationship, further studies are needed that examine what properties of
readers – individual preferences for devices, generational memberships, majors, genders,
duration of use for media, etc. – and what properties of devices enable readers to
accommodate (or hinder them from accommodating) to the medium.



References
Abrams, M. H., & Harpham, G. G. (2005). A glossary of literary terms (8th ed.). Boston,
MA: Thomson/Wadsworth.
Adler, M. J., & Van Doren, C. C. (1972). How to read a book. New York: Touchstone.
Afflerbach, P. P. (1990). The influence of prior knowledge on expert readers’ main idea
construction strategies. Reading Research Quarterly, 25(1), 31-46.
Alderson, J. C. (2000). Assessing reading (Cambridge language assessment). Cambridge,
UK: Cambridge University Press.
Allen, G. (2003). Roland Barthes. London, New York: Routledge.
Anderson-Inman, L., & Horney, M. (1997). Electronic books for secondary students.
Journal of Adolescent & Adult Literacy, 40(6), 486-491.
Andringa, E. (1996). Effects of 'narrative distance' on readers’ emotional involvement
and response. Poetics, 23(6), 431–452.
Angrosino, M. (2008). Doing ethnographic and observational research. Thousand Oaks,
CA: Sage.
Armstrong, D., Gosling, A., Weinman, J., & Marteau, T. (1997). The place of inter-rater
reliability in qualitative research: An empirical study. Sociology, 31(3), 597-606.
Babbie, E. R. (2007). The practice of social research (11th ed.). Belmont: Wadsworth
Publishing.
Babin, E. & Harrison, K. (1999). Contemporary composition studies: A guide to theorists
and terms. Westport: Greenwood Press.
Baker, L., Dreher, M. J., & Guthrie, J. T. (2000). Engaging young readers: Promoting
achievement and motivation. New York: Guilford Press.
Barnes, L. A. (1998). Reading types, strategies, attitudes and habits: An investigation of
reading behaviors and perceptions in one whole language community college
reading classroom (Doctoral dissertation). University of Pennsylvania, Philadelphia,
PA.
Beach, R. (1993). A teacher’s introduction to reader response theories. Urbana, IL:
National Council of Teachers of English.



Beach, R. (2004). Researching response to literature and the media. In A. Goodwyn & A.
W. Stables (Eds.), Learning to read critically in language and literacy (pp. 123-149).
London: Sage Publications.
Bellamy, C., Burrow, P., Coburn, M., Loi, D., & Wilkins, L. (2001). Creating a viable etext market. In B. Cope & D. Mason (Eds.), Creator to consumer in a digital age:
Australian book production in transition (pp. 123-148). Altona, Australia: Common
Ground Publishing.
Benckhuysen, A. J. (2010). Actualizing Hagar’s story: The interchange between the
reader and the text in the interpretation of Genesis 16 and 21. (Doctoral
dissertation). University of St. Michael’s College (Canada).
Bennett, A., & Royle, N. (2004). An introduction to literature, criticism and theory (3rd
ed.). Harlow, England: Pearson Longman.
Bessey, M. A., & Coffin, I. P. (1941). Active reading. NewYork: Appleton-Century.
Best, R. M., Rowe, M., Ozuru, Y., & McNamara, D. S. (2005). Deep-level
comprehension of science texts: The role of the reader and the text. Topics in
Language Disorders, 25(1), 65-83.
Birks, M., & Mills, J. (2011). Grounded theory: A practical guide. Thousand Oaks, CA:
Sage.
Blachowicz, C. L. Z., & Ogle, D. (2008). Reading comprehension: Strategies for
independent learners (2nd ed.). New York: Guilford Press.
Blaikie, N. (2003). Analyzing quantitative data: From description to explanation.
London: Sage.
Blake, B. E., & Blake, R. W. (2002). Literacy and learning: A reference handbook. Santa
Barbara: ABC-CLIO.
Bleich, D. (1978). Subjective criticism. Baltimore, London: The Johns Hopkins
University Press.
Booth, W. (1961). The rhetoric of fiction. Chicago, IL: University of Chicago Press.
Bortolussi, M., & Dixon, P. (2003). Psychonarratology: Foundations for the empirical
study of literary response. New York: Cambridge University Press.
Bressler, C. E. (2003). Literary criticism:An introduction to theory and practice (3rd ed.).
Upper Saddle River, NJ: Pearson Prentice Hall.



Britton, B. K., & Gülgöz, S. (1991). Using Kintsch’s computational model to improve
instructional text: Effects of repairing inference calls on recall and cognitive
structures. Journal of Educational Psychology, 83(3), 329-345.
Bruning, R. H., Schraw, G. J., Norby, M. M., & Ronning, R. R. (2004). Cognitive
psychology and instruction (4th ed.). Upper Saddle River, NJ:
Pearson/Merrill/Prentice Hall.
Bryant, A. & Charmaz, K. (Eds.) (2007). The SAGE handbook of grounded theory.
Thousand Oaks, CA: Sage.
Burns, R. B., & Burns, R. A. (2008). Business research methods and statistics using
SPSS. London: Sage.
Bush, V. (1945, July). As we may think. The Atlantic Monthly. Retrieved December 5,
2014, from http://www.theatlantic.com/doc/194507/bush
Carver, R. P. (1992). Reading rate: Theory, research, and practical implications. Journal
of Reading, 36(2), 84-95.
Castle, G. (2007). The Blackwell guide to literary theory. Malden, MA; Oxford:
Blackwell Publishers.
Charmaz, K. (2006). Constructing grounded theory: A practical guide through
qualitative analysis. London: Sage.
Cohen, B. H. (1998). Explaining psychological statistics. Hoboken, NJ: John Wiley and
Sons.
Cooper, C. R. (Eds.). (1985). Researching response to literature and the teaching of
literature: Points of departure. Norwood, NJ: Ablex Publishing Corporation.
Cooper, A., Reimann, R., & Cronin, D. (2007). About face 3: The essentials of
interaction design (3rd ed.). Hoboken, NJ: Wiley.
Corbin, J. M., & Strauss, A. L. (2008). Basics of qualitative research: Techniques and
procedures for developing grounded theory (3rd ed.). Los Angeles: SAGE.
Creswell, J. W. (2007). Qualitative inquiry and research design: Choosing among five
approaches (2nd ed.). Thousand Oaks, CA: Sage.
Creswell, J. W. (2009). Research design: Qualitative, quantitative, and mixed methods
approaches (3rd ed.). Thousand Oaks, CA: Sage.
Cuddon, J. (1998). The Penguin dictionary of literary terms and literary theory (4th ed.).
London [u.a.]: Penguin Books.



Culler, J. (1975). Structuralist poetics. London: Routledge & Kegan Paul.
Culler. J. (1981). The pursuit of signs. London: Routledge & Kegan Paul.
DePoy, E., & Gitlin, L. N. (2011). Introduction to research: Understanding and applying
multiple strategies (4th ed.). St. Louis: Elsevier Mosby.
Denscombe, M. (2010). The good research guide: For small-scale social research
projects (4th ed.). Berkshire: Open University Press.
DeSilver, D. (2014). Overall book readership stable, but e-books becoming more popular.
Retrieved September 8, 2014 from http://www.pewresearch.org/facttank/2014/01/21/overall-book-readership-stable-but-e-books-becoming-morepopular/
Dillman, D. A., Smyth, J. D., & Christian, L. M. (2009). Internet, mail, and mixed-mode
surveys: The tailored design method (3rd ed.). Hoboken, NJ: Wiley.
Dillon, A. (2004). Designing usable electronic text (2nd ed.). Boca Raton, FL: CRC Press.
Duke, N. K., & Mallette, M. H. (2004). Literacy research methodologies. New York:
Guilford Press.
Erlandson, D. A., Harris, P. E. L., Skipper, B. L., & Allen, S. D. (1993). Doing
naturalistic inquiry: A guide to methods. Newbury Park, CA: Sage Publications, Inc.
Feather, J., & Sturges, P. (1997). International encyclopedia of information and library
science. London: Routledge.
Field, A. P. (2009). Discovering statistics using SPSS (3rd ed.). Thousand Oaks, CA:
Sage.
Fish, S. (1980). Is there a text in this class?: The authority of interpretive communities.
Cambridge, MA: Harvard University Press.
Flippo, R. F., & Caverly, D. C. (2009). Handbook of college reading and study strategy
research (2nd ed.). New York: Taylor & Francis.
Flitterman-King, S. (1988). The role of the response journal in active reading. Quarterly
of the National Writing Project and the Center for the Study of Writing, 10(3), 4-11.
Fludernik, M. (2009). An introduction to narratology. New York: Routledge.
Fontana, A., & Prokos, A. H. (2007). The interview: From formal to postmodern. Walnut
Creek, CA: Left Coast Press.



Fowler, F. J. (1995). Improving survey questions: Design and evaluation (Applied Social
Research Methods). Thousand Oaks, CA: Sage.
Frase, L. T., & Schwartz, B. J. (1975). Effect of question production and answering on
prose recall. Journal of Educational Psychology, 67(5), 628-635.
Garrett, J. J. (2003). The elements of user experience: User-centered design for the Web.
New York: Peachpit Press.
Gerring, J. (2001). Social science methodology: A critical framework (1st ed.). New
York: Cambridge University Press.
Gillham, B. (2008). Observation techniques: Structured to unstructured. London:
Continuum.
Glaser, B. G. (1978). Theoretical sensitivity: Advances in the methodology of grounded
theory. Mill Valley, CA: Sociology Press.
Glaser, B. G., & Strauss, A. L. (1967). The discovery of grounded theory: Strategies for
qualitative research. New York: Aldine.
Golovchinsky, G. (2008). Reading in the office. Proceeding of the 2008 ACM workshop
on Research advances in large digital book repositories - BooksOnline’08. New
York: ACM Press.
Goodman, K. S. (1997). The reading process. In V. Edwards & D. Corson (Eds.),
Encyclopedia of language and education. Vol. 2, Literacy (pp. 1-8). Dordrecht, The
Netherlands: Kluwer Academic.
Greene, J. C., Caracelli, V. J., & Graham, W. F. (1989). Toward a conceptual framework
for mixed-method evaluation designs. Educational Evaluation and Policy Analysis,
11(3), 255-274.
Guthrie, J. T., & Anderson, E. (1999). Engagement in reading: Processes of motivated,
strategic, knowledgeable, social readers. In J. T. Guthrie & D. E. Alvermann (Eds.),
Engaged reading: Processes, practices, and policy implications (pp. 17-45). New
York: Teachers College Press.
Guthrie, J. T., Schafer, W., Wang, Y. Y., & Afflerbach, P. (1995). Relationships of
instruction to amount of reading: An exploration of social, cognitive, and
instructional connections. Reading Research Quarterly, 30(1), 8-25.
Guthrie, J. T., Wigfield, A., Metsala, J. L., & Cox, K. E. (1999). Motivational and
cognitive predictors of text comprehension and reading amount. Scientific Studies of
Reading, 3(3), 231-256.

 

Hall, D. E. (2001). Literary and cultural theory: From basic principles to advanced
applications. Boston, MA: Houghton Mifflin Company.
Harris, T. L., & Hodges, R. E. (1995). The literacy dictionary: The vocabulary of reading
and writing. Newark, DE: International Reading Association.
Hart, M. (1992). History and philosophy of Project Gutenberg. Retrieved December 5,
2014, from http://www.gutenberg.org/about/history
Haussamen, B. (1995). The passive-reading fallacy. Journal of Reading, 38(5), 378-381.
Heilman, A. W., Blair, T. R., & Rupley, W. H. (2001). Principles and practices of
teaching reading (10th ed.). Englewood Cliffs, NJ: Prentice Hall.
Henke, H. (2003). An empirical design for ebooks (1st ed.). Niwot, CO: Chartula Press.
Hesse-Biber, S. N. (2010). Mixed methods research: Merging theory with practice. New
York: The Guilford Press.
Hickman, J. (1981). A new perspective on response to literature: Research in an
elementary school setting. Research in the Teaching of English, 15(4), 343-354.
Hiebert, E. H., & Raphael, T. E. (1996). Psychological perspectives on literacy and
extensions to educational practice. In D. Berliner & R. C. Calfee (Eds.), Handbook
of educational psychology (pp. 550-602). New York: Simon & Schuster Macmillan.
Hill, T., & Lewicki, P. (2005). Statistics: Methods and applications (A comprehensive
references for science, industry, and data mining). Tulsa: StatSoft.
Hillesund, T. (2010). Digital reading spaces: How expert readers handle books, the Web
and electronic paper. First Monday, 15(4-5). Retrieved September 8, 2014 from
http://firstmonday.org/htbin/cgiwrap/bin/ojs/index.php/fm/article/view/2762/2504
Hoffman, R. R., & Militello, L. G. (2008). Perspectives on cognitive task analysis:
Historical origins and modern communities of practice (Expertise: Research and
Applications Series). New York: Psychology Press.
Holland, N. (1975). 5 readers reading. New Haven, CT: Yale University Press.
Holton, J. A. (2010). The coding process and its challenges. In A. Bryant & K. Charmaz
(Eds.), The SAGE handbook of grounded theory (pp. 265-289). Thousand Oaks:
Sage.



Hong, M., Piper, A. M., Weibel, N., Olberding, S., & Hollan, J. (2012). Microanalysis of
active reading behavior to inform design of interactive desktop workspaces. In
Proceedings of the 2012 ACM International Conference on Interactive Tabletops
and Surfaces (pp. 215–224). New York: ACM Press.
Hosmer, D. W., Lemeshow, S., & Sturdivant, R. X. (2013). Applied logistic regression
(3rd ed.). Hoboken, NJ: Wiley.
Hughes, C. A. (2003). E-books. In M. A. Drake (Ed.), Encyclopedia of library and
information science (2nd ed., pp. 948-949). New York: Marcel Dekker.
Ihde, D. (1990). Technology and the lifeworld: From garden to earth. Bloomington, IN:
Indiana University Press.
Ingarden, R. (1973). Cognition of the literary work of art. Evanston, IL: Northwestern
University Press.
Iser, W. (1978). The act of reading. London: Routledge & Kegan Paul.
iSTART (n.d.). Interactive Strategy Trainer for Active Reading and Thinking. Available
at http://csep.psyc.memphis.edu/istart/front.htm
Jackson, H. (2001). Marginalia: Readers writing in books. New Haven, CT: Yale
University Press.
Jackson, S. L. (2007). Research methods: A modular approach. Belmont, CA:
Wadsworth Publishing.
Karolides, N. J. (Ed.). (2000). Reader response in secondary and college classrooms (2nd
ed.). Mahwah, NJ: Lawrence Erlbaum Associates.
Kay, A. (2000). Review: Dynabooks: Past, present, and future. The Library Quarterly,
70(3), 385-395.
Kay, A. (2002). User interface: A personal view. In R. Packer & K. Jordan (Eds.),
Multimedia: From Wagner to virtual reality (Expanded ed., pp. 121-131). New
York: Norton.
King, N., & Horrocks, C. (2010). Interviews in qualitative research. Thousand Oaks:
Sage.
Kitzmann, A. (2006). Hypertext handbook: The straight story. New York: Peter Lang.
Klarer, M. (2004). An introduction to literary studies (2nd ed.). New York: Routledge.



Kumar, R. (2010). Research methodology: A step-by-step guide for beginners (3rd ed.).
London: Sage.
Kvale, S., & Brinkmann, S. (2009). Interviews: Learning the craft of qualitative research
interviewing. Thousand Oaks, CA: Sage.
Lambert, L., Woodford, C., Poole, H., & Moschovitis, C. J. P. (Eds). (2005). E-books (pp.
83-89). In The internet: A historical encyclopedia. Santa Barbara, CA: ABC-CLIO.
Lazar, J., Feng, J. H., & Hochheiser, H. (2010). Research methods in human-computer
interaction. West Sussex, U.K.: Wiley.
Leech, N. L., Barrett, K. C., & Morgan, G. A. (2011). IBM SPSS for intermediate
statistics: Use and interpretation (4th ed.). New York: Routledge.
Liederholm, T., Everson, M. G., Broek, P. V. D., Mischinski, M., Crittenden, A., &
Samuels, J. (2000). Effects of causal text revisions on more- and less-skilled
readers’ comprehension of easy and difficult texts. Cognition and Instruction, 18(4),
525-556
Lincoln, Y. S., & Guba, E. G. (1985). Naturalistic inquiry. Beverly Hills: Sage.
Lindstrom, B. G. (2010). Beyond reader response theory: Brigham Young UniversityHawai’i student film adaptations of previously published short stories. (Doctoral
dissertation). University of Hawai’i at Manoa.
Liu, Z. (2005). Reading behavior in the digital environment: Changes in reading behavior
over the past ten years. Journal of Documentation, 61(6), 700-712.
Locke, K. (2001). Grounded theory in management research. Thousand Oaks, CA: Sage.
Loxterman, J. A., Beck, I. L., & McKeown, M. G. (1994). The effects of thinking aloud
during reading on students’ comprehension of more or less coherent text. Reading
Research Quarterly, 29(4), 353-367.
Mailloux, S. (1982). Interpretive conventions: The reader in the study of American fiction.
Ithaca, NY: Cornell University Press.
Many, J., & Cox, C. (Eds.). (1992). Reader stance and literary understanding. Norwood,
NJ: Ablex Publishing Corporation.
Marino, J. L., Gould, S. M., & Haas, L. W. (1985). The effects of writing as a prereading
activity on delayed recall of narrative text. The Elementary School Journal, 86(2),
199-205.



Marshall, C. C. (1997). Annotation: From paper books to the digital library. In
Proceedings of the second ACM international conference on Digital libraries - DL
97 (pp. 131-140). New York: ACM Press.
Marshall, J. (2000). Research on response to literature. In M. L. Kamil, P. B. Mosenthal,
P. D. Pearson, & R. Barr (Eds.), Handbook of reading research Vol. III (pp. 381–
402). Mahwah, NJ: Lawrence Erlbaum Associates.
Marshall, C. C., & Brush, A. J. B. (2002). From personal to shared annotations. CHI ‘02
extended abstracts on Human factors in computing systems - CHI ‘02. New York:
ACM Press.
Marshall, C. C., & Brush, A. J. B. (2004). Exploring the relationship between personal
and public annotations. In Proceedings of the 2004 joint ACM/IEEE conference on
Digital libraries - JCDL ‘04. New York: ACM Press.
Marshall, C. C., Price, M. N., Golovchinsky, G., & Schilit, B. N. (2001). Designing ebooks for legal research. In Proceedings of the first ACM/IEEE-CS joint conference
on Digital libraries - JCDL ‘01 (pp. 41-48). New York: ACM Press.
Marshall, C., & Rossman, G. B. (2011). Designing qualitative research (5th ed.).
Thousand Oaks, CA: Sage.
McCarthy, J., & Wright, P. (2004). Technology as experience. Cambridge, MA: The MIT
Press.
McKnight, C., Dillon, A., & Richardson, J. (1996). User centred design of
hypertext/hypermedia for education. In D. Jonassen (Ed.), Handbook of research on
educational communications and technology (pp. 622-633). New York: Macmillan.
McLain, K. V. M. (1993). Effects of two comprehension monitoring strategies on the
metacognitive awareness and reading achievement of third and fifth grade students
[Revised.]. Retrieved September 8, 2014, from http://eric.ed.gov/?id=ED364840
McNamara, D. S. (2001). Reading both high-coherence and low-coherence texts: Effects
of text sequence and prior knowledge. Canadian Journal of Experimental
Psychology, 55(1), 51-62.
McNamara, D. S., Levinstein, I. B., & Boonthum, C. (2004). iSTART: Interactive
strategy training for active reading and thinking. Behavior Research Methods,
Instruments, & Computers, 36(2), 222-233.
Merriam, S. B. (2009). Qualitative research: A guide to design and implementation. San
Francisco: John Wiley & Sons.



Meyer, B. J. F., & Freedle, R. O. (1984). Effects of discourse type on recall. American
Educational Research Journal, 21(1), 121-143.
Milliot, J. (2008). Report finds growing acceptance of digital books. Publishers Weekly,
255(7), 6.
Miall, D. S. (1990). Readers’ responses to narrative: Evaluating, relating, anticipating.
Poetics, 19, 323–339.
Miall, D. S. (2006). Literary reading: Empirical and theoretical studies. New York: Peter
Lang.
Moggridge, B. (2007). Designing interactions. Cambridge, MA: The MIT Press.
Mooi, E., & Sarstedt, M. (2011). A concise guide to market research: The process, data,
and methods using IBM SPSS statistics. New York: Springer.
Morgan, D. L. & Guevara, H. (2008). Computer-assisted data analysis. In The Sage
Encyclopedia of Qualitative Research Methods. (Vol. 2, pp. 103-109). Thousand
Oaks: Sage.
Morris, M. R., Brush, A. J. B., & Meyers, B. R. (2007). Reading revisited: Evaluating the
usability of digital display surfaces for active reading tasks. Second Annual IEEE
International Workshop on Horizontal Interactive Human-Computer Systems
(TABLETOP’07) (pp. 79-86). IEEE.
Murray, T. (2006). Hyperbook features supporting active reading skills. In Z. Ma (Ed.),
Web-based intelligent e-learning systems: Technologies and applications. Hershey,
PA: Information Science Publishing.
Nikam, K., & Rai, A. S. (2009). Open e-books: The changing paradigm. International
Journal of Library and Information Science, 1(1), 006-011.
Norušis J., M. (2012). Cluster analysis. In IBM SPSS Statistics 19 Statistical Procedures
Companion (pp. 375–404). Upper Saddle River, NJ: Prentice-Hall.
Obendorf, H. (2003). Simplifying annotation support for real-world-settings. In
Proceedings of the fourteenth ACM conference on Hypertext and hypermedia HYPERTEXT’03. New York: ACM Press.
Olsen, A. N., Kleivset, B., & Langseth, H. (2013). E-book readers in higher education:
Student reading preference and other data from surveys at the University of
Agder. SAGE Open, 3(2), 1-8.



O’Reilly, T., Best, R., & McNamara, D. S. (2004). Self-explanation reading training:
Effects for low-knowledge readers. In K. Forbus, D. Gentner, & T. Regier (Eds.),
(pp. 1053-1058). Presented at the 26th Annual Meeting of the Cognitive Science
Society, Mahwah, NJ: Erlbaum.
O’Reilly, T., Sinclair, G., & McNamara, D. S. (2004). Reading strategy training:
Automated verses live. Proceedings of the 26th Annual Cognitive Science Society,
1059-1064.
O’Reilly, T., Taylor, R. S., & McNamara, D. S. (2006). Classroom based reading strategy
training: Self-explanation vs. reading control (pp. 1887-1892). Presented at the 28th
Annual Conference of the Cognitive Science Society.
Patton, M. Q. (2001). Qualitative research and evaluation methods (3rd ed.). Thousand
Oaks, CA: Sage.
Pitney, W., & Parker, J. (2009). Qualitative research in physical activity and the health
professions. Champaign, IL: Human Kinetics.
Potter, W. J. (1996). An analysis of thinking and research about qualitative methods.
Mahwah, NJ: Routledge.
Price, M. N., Schilit, B. N., & Golovchinsky, G. (1998). XLibris: The active reading
machine. CHI 98 conference summary on Human factors in computing systems CHI ‘98 (pp. 22-23). New York, New York, USA: ACM Press.
Prince, G. (2003). Surveying narratology. In T. Kindt & H.-H. Müller (Eds.), What is
narratology?: Questions and answers regarding the status of a theory (pp. 1–16).
Berlin: Walter de Gruyter.
Probst, R. E. (2004). Response and analysis: Teaching literature in secondary school.
(2nd ed.). Portsmouth, NH: Heinemann.
Ramaiah, C. K. (2005). An overview of electronic books: A bibliography. The Electronic
Library, 23(1), 17-44.
Richards, I. A. (1929). Practical criticism: A study of literary judgment. New York:
Harcourt Brace & Company.
Rorty, R. (1991). Objectivity, relativism, and truth. Cambridge University Press.
Rosenblatt, L. (1938). Literature as exploration. New York: Modern Language
Association.



Rosenwald, M. S. (2014, April 6). Serious reading takes a hit from online scanning and
skimming researchers say. The Washington Post, Retrieved September 8, 2014, from
http://www.washingtonpost.com/local/serious-reading-takes-a-hit-from-onlinescanning-and-skimming-researchers-say/2014/04/06/088028d2-b5d2-11e3-b89920667de76985_story.html
Rubin, H. J., & Rubin, I. (2005). Qualitative interviewing: The art of hearing data (2nd
ed.). Thousand Oaks, CA: SAGE.
Rueda, R., MacGillivray, L., Monzó, L., & Arzubiaga, A. (2001). Engaged reading: A
multilevel approach to considering sociocultural factors with diverse learners. In D.
M. Mclnerney & S. Van Etten (Eds.), Research on sociocultural influences on
motivation and learning (Vol. 1, pp. 231-264). Greenwich, CT: Information Age
Pub.
Sadoski, M. (2004). Conceptual foundations of teaching reading. New York: Guilford
Press.
Saffer, D. (2010). Designing for interaction: Creating innovative applications and
devices (2nd ed.). Berkeley, CA; New Riders.
Saris, W. E., & Gallhofer, I. N. (2007). Design, evaluation, and analysis of
questionnaires for survey research. Hoboken, NJ: Wiley-Interscience.
Schilit, B. N., Golovchinsky, G., & Price, M. N. (1998). Beyond paper: Supporting active
reading with free form digital ink annotations. In Proceedings of the SIGCHI
conference on Human factors in computing systems - CHI ‘98 (pp. 249-256). New
York: ACM Press.
Schmitz, T. A. (2007). Modern literary theory and ancient texts: An introduction.
Oxford: Blackwell Publishing.
Selden, R. & Widdowson, P. (1993). A reader's guide to contemporary literary theory
(3rd ed.). Lexington: The University Press of Kentucky.
Sharp, H., Rogers, Y., & Preece, J. (2007). Interaction design: Beyond human-computer
interaction (2nd ed.). Hoboken, NJ: Wiley.
Smith, G. C. (2007). What is interaction design? In B. Moggridge (Ed.), Designing
interactions (pp. vii – xix). Cambridge, MA: MIT Press.
Spicer, J. (2005). Making sense of multivariate data analysis. Sage. Thousand Oaks, CA:
Sage.



Springer. (2008). Ebooks - The end user perspective (White Paper). Computer. Retrieved
September 8, 2014, from
http://www.springer.com/cda/content/document/cda_downloaddocument/eBooks++t
he+End+User+Experience?SGWID=0-0-45-608298-0
SPSS. (2004). SPSS regression models 13.0. Chicago: SPSS Inc.
Steinke, I. (2004). Quality criteria in qualitative research. In U. Flick, E. von Kardorff, &
I. Steinke (Eds.), A companion to qualitative research (pp. 184-190). Thousand
Oaks, CA: Sage.
Stern, P. N., & Porr, C. J. (2011). Essentials of accessible grounded theory. Walnut
Creek, CA: Left Coast Press.
Strauss, A. L. (1973). Discovering new theory from previous theory. In T. Shibutani (Ed.),
Human nature and collective behavior: Papers in honor of Herbert Blumer (pp. 4653). Englewood Cliffs, NJ: Prentice Hall.
Strauss, A. L., & Corbin, J. M. (1990). Basics of qualitative research: Grounded theory
procedures and techniques. Newbury Park, CA: Sage.
Strauss, A. L., & Corbin, J. M. (1998). Basics of qualitative research: Techniques and
procedures for developing grounded theory (2nd ed.). Thousand Oaks, CA: Sage.
Strang, R., & Rogers, C. (1965). How do students read a short story? The English Journal,
54(9), 819-829.
Tashakkori, A., & Teddlie, C. B. (Eds.). (2003). Handbook of mixed methods in social
and behavioral research. Thousand Oaks, CA: Sage.
Tashakkori, A., & Teddlie, C. B. (Eds.). (2010). SAGE handbook of mixed methods in
social and behavioral research (2nd ed.). Thousand Oaks, CA: Sage.
Tashman, C. S., & Edwards, W. K. (2011a). LiquidText: A flexible, multitouch
environment to support active reading. In Proceedings of the 2011Annual
Conference on Human Factors in Computing Systems - CHI ‘11 (pp. 3285-3294).
New York: ACM Press.
Tashman, C. S., & Edwards, W. K. (2011b). Active reading and its discontents: The
situations, problems and ideas of readers. In Proceedings of the 2011Annual
Conference on Human Factors in Computing Systems - CHI ‘11 (pp. 2927-2936).
New York, New York, USA: ACM Press.
Therman, C. (2008). Readers' responses versus reader-response theories: Am empirical
study. Saarbrücken, Germany: VDM Verlag Dr. Müller.



Thomas, S. J. (2004). Using web and paper questionnaires for data-based decision
making: From design to interpretation of the results. Thousand Oaks, CA: Corwin
Press.
Tracey, D. H., & Morrow, L. M. (2006). Lenses on reading: An introduction to theories
and models. New York: Guilford Press.
Tullis, T., & Albert, W. (2008). Measuring the user experience: Collecting, analyzing,
and presenting usability metrics. Amsterdam: Morgan Kaufmann.
Turow, J. (1984). Media industries: The production of news and entertainment. New
York: Longman.
Tyson, L. (2006). Critical theory today: A user-friendly guide (2nd ed.). New York:
Routledge.
Unger, R., & Chandler, C. (2009). A project guide to UX design: For user experience
designers in the field or in the making. Berkeley, CA: New Riders.
Vasileiou, M., Hartley, R., & Rowley, J. (2009). An overview of the e-book marketplace.
Online Information Review, 33(1), 173-192.
Vogt, P. W. (2005). Dictionary of statistics & methodology: A nontechnical guide for the
social sciences (3rd ed.). Thousand Oaks, CA: Sage.
Wertz, F. J., Charmaz, K., McMullen, L. M., Josselson, R., Anderson, R., & McSpadden,
E. (2011). Five ways of doing qualitative analysis: Phenomenological psychology,
grounded theory, discourse Analysis, narrative research, and intuitive inquiry. New
York: Guilford Press.
Wexelbaum, R., & Miltenoff, P. (2012). Challenges to e-reader adoption in academic
libraries. The Reference Librarian, 53(3), 270–283.
Willett, P. (2004). Electronic texts: Audiences and purposes. In S. Schreibman, R. G.
Siemens, & J. Unsworth (Eds.), A companion to digital humanities. Malden, MA:
Blackwell Publication. Retrieved from
http://www.blackwellreference.com/subscriber/book?id=g9781405103213_9781405
103213
Wilson, R., & Landoni, M. (2001). Evaluating electronic textbooks: A methodology. In P.
Constantopoulos & I. T. Sølvberg (Eds.), Research and Advanced Technology for
Digital Libraries (Vol. 2163, pp. 1-12). Berlin, Heidelberg: Springer Berlin
Heidelberg.
Winner, E. (1982). Invented worlds: The psychology of the artcs. Cambridge, MA:
Harvard University Press.



Wright, P., & McCarthy, J. (2008). Empathy and experience in HCI. In Proceeding of the
twenty-sixth annual CHI conference on Human factors in computing systems - CHI
‘08 (pp. 637-646). New York: ACM Press.
Yin, R. K. (2003). Case study research: Design and methods (2nd ed.). Thousand Oaks,
CA: Sage.
Zhao, Y., Qin, Y., Liu, Y., Liu, S., Zhang, T., & Shi, Y. (2014). QOOK: Enhancing
information revisitation for active reading with a paper book. In Proceedings of the
8th International Conference on Tangible, Embedded and Embodied Interaction (pp.
125–132). New York: ACM Press.
Zikmund, W., & Babin, B. (2007). Exploring marketing research (9th ed.). Mason, OH:
Thomson/South-Western.

 

Appendices
Appendix A.1: Online questionnaire for the pilot study














Appendix A.2: Online questionnaire for the larger study
Active Reading Practices

Active Reading Practices in Academic Settings
The primary purpose of this survey is to gather information about active reading practices (with and without digital
reading devices) in academic settings such as teaching, coursework, and research. Participants should be native
speakers of English who are currently master's students, doctoral students, post-docs, or faculty.
This survey is part of doctoral dissertation research being conducted in the School of Library and Information Science
at Indiana University, Bloomington, IN, USA. The findings of the survey will be anonymized, aggregated, and analyzed
as part of the dissertation research and later publication. The researcher plans to use the data to obtain insights to
inform the design of ebook devices, or ereaders, that facilitate active reading. (Active reading is defined on the next
page). The summary results of this survey will be made available to you upon request if you provide your email address
at the end of the survey.
All questions in this survey are related to general and academic reading activities and do not require sensitive data to
answer them. All responses will be stored in a password-protected personal computer that can be accessed only by the
investigator, HyunSeung Koh. If you have any questions or concerns, please feel free to contact me, HyunSeung Koh,
at hskoh@indiana.edu or the Human Subjects Office at Indiana University at irb@iu.edu (the IRB approved
study#1106006158).
Please begin by clicking the 'Agree' button if you agree to participate in the survey outlined above.

I. General Reading Practices
This section is designed to help me understand your current, common, general reading practices and help you understand
academic reading, which is a subset of general reading.
General reading is reading related to two kinds of reading practices: academic reading (e.g., reading journal articles
for teaching, coursework, or research) and non-academic reading (e.g., reading novels or product reviews for pleasure,
out of curiosity, or for non-academic work).

1. Indicate how often you read each kind of reading material below in general reading:
Less
2-3
than
Once Once Times Once
a
a
a
a
Never Month Month Month Week
Academic Journal or Conference Proceedings
Newspaper or News website
Magazine
Novel
Blog
Other (Please specify):

2. Indicate how often you do general reading for each purpose below:
Less
2-3
than
Once Once Times Once
a
a
a
a
Never Month Month Month Week
Reading for academic purposes such as teaching, coursework, and research
Reading for (non-academic) work
Reading for pleasure or to satisfy personal curiosity
Reading to seek information for a specific practical purpose
Other (Please specify):



II. Academic Reading Practices
This section is designed to help me understand your current, common, academic reading practices and help you
understand active reading, which is a subset of academic reading.

Academic reading is reading in which readers employ one or more of the following processes in academic
settings such as teaching, coursework, or research:
Deeper comprehending (to understand the writer's intended meanings as completely as possible)
Learning (to acquire content knowledge)
Memorizing (for accurate recall, e.g., for later tests)
Skimming (to grasp the main topic quickly)
Scanning (to find target information)

1. Indicate how often you do academic reading for each purpose below:
(Note: Select 'Never' if an item is 'not applicable' to you.)
Less
than
2-3
Once Once Times Once
a
a
a
a
Never Month Month Month Week
Reading for class participation (as a student)
Reading for quizzes/tests (as a student)
Reading for course papers (as a student)
Reading for group work (as a student)
Reading for work you are preparing for presentation or publication
Reading to prepare lectures
Reading and commenting to give feedback on other people's writing
Other (Please specify):

2. Indicate how often you employ each reading process below in academic reading:
Quite
Never Rarely Sometimes Often
Deeper comprehending (to understand the writer's intended meanings as completely as possible)
Learning (to acquire content knowledge)
Memorizing (for accurate recall, e.g., for later tests)
Skimming (to grasp the main topic quickly)
Scanning (to find target information)
Other (Please specify):

III. Active Reading Practices (1)
This section is designed to help me understand your current, common, active reading practices with regard to annotation*
and note-taking**.

Active reading, as a subset of academic reading, is reading in which readers employ the two processes of
'deep comprehending' and 'learning' most of the time, while spending little time memorizing, skimming***,
or scanning, in order to go beyond the literal level or sentence level of comprehension.

* Annotation means the action of underlining, highlighting, adding symbols, and/or making notes for oneself in the text
and/or in the page margins. It is different from commenting to give feedback on other people's writing.



** Note-taking (or copying and pasting) means taking notes in separate notepads.
*** Skimming most of time but still engaging with some parts of texts actively is not considered active reading in this
survey.
1. Indicate on the scale below how often you engage in active reading practices involving writing (i.e., annotations and/or
note-taking):
Never

Rarely

Sometimes

Quite Often

Very Often

Comments (if any):

2. Indicate how often you do each annotation and/or note-taking practice below in active reading:
Quite
Never Rarely Sometimes Often
Annotation on paper
Annotation in digital formats
No annotation, but note-taking on paper
No annotation, but note-taking in digital formats
Both annotation and note-taking on paper
Both annotation and note-taking in digital formats
Other (Please specify):

IV. Active Reading Practices (2)
This section is designed to understand your current, common, active reading practices with regard to formats and devices.

Same as above, active reading, as a subset of academic reading, is reading in which readers employ the
two processes of 'deep comprehending' and 'learning' most of the time, while spending little time
memorizing, skimming, or scanning, in order to go beyond the literal level or sentence level of
comprehension.

1. Indicate how often you employ each format below for active reading:
Quite
Never Rarely Sometimes Often
Print (Paper) book/journal
Scrollable web page
PDF file read online
PDF file printed out
Documents specifically formated for ereading devices
Other (Please specify):

2. Indicate how often you employ each primary device below for active reading:
Quite
Never Rarely Sometimes Often
Paper
Desktop computer
Laptop/Netbook computer



Amazon Kindle
Barnes & Noble Nook
Sony Ereader
Apple iPad
Smart Phone
Other (Please specify):

V. Active Reading Practices (3)
This section is designed to understand your current, common, active reading practices with regard to reading locations
and tools/devices (in addition to your primary reading device).

Same as above, active reading, as a subset of academic reading, is reading in which readers employ the
two processes of 'deep comprehending' and 'learning' most of the time, while spending little time
memorizing, skimming, or scanning, in order to go beyond the literal level or sentence level of
comprehension.

1. Indicate how often you read at each place below for active reading:
Quite
Never Rarely Sometimes Often
Library (Carrel)
Library (Information Commons)
Home
Office
Cafe or restaurant
Transportation (e.g., bus)
Other (Please specify):

2. Indicate how often you use each tool or device (in addition to your primary reading device) below during active reading:
Quite
Never Rarely Sometimes Often
Computer
Ereader (e.g., Amazon Kindle, iPad)
Computer Printer
Pen/Pencil, Paper/Notepad
(Physical) highlighter Pen
Music Player
TV
Other (Please specify):

VI. Active Reading Practices (4)
Do you have any other comments that you wish to share about your active reading practices?

 

VII. Academic Information
1. What is your current academic status?
Master's student
Doctoral student
Post-doc
Faculty
Other (Please specify):

2. Are you a full-time student or faculty member?
Yes, Full-time student
Yes, Full-time faculty member
No, Not a full time student or faculty member (Please specify your status):

3. What are your major(s) or research emphases (field(s) of study)?

4. What is the name of your department or school? (e.g., School of Education, Department of English)

5. In what city (and state if in the U.S.) is the institution located that you are currently affiliated with?

6. In what country is the institution located that you are currently affiliated with?

VIII. Demographic Information
1. What is your gender?
Female
Male
Other
2. What is your age?
19 and Under
20 - 29
30 - 39
40 - 49
50 - 59
60 and Older



3. What variety of English do you speak natively?
American
Australian
British
Canadian
Indian
South African
Other (Please specify):

IX. Additional Important Information
This section is designed to collect additional information that is important for this study.
1. Would it be okay for me to contact you for further clarification of your answers to questions in this questionnaire?
Yes
No
2. Would you be willing to participate in the next phase of the study (i.e., I will collect and analyze representative samples of
your reading materials and/or notepads including annotations and notes)?
Yes
No
Maybe
3. Do you want to receive the summary results of the survey via email?
Yes
No
4. Please leave your name and an email address where I can reach you.
(Choose a pseudonym and an email address that doesn't show your real name if you are concerned about your privacy.)
Last Name:
First Name:
Email address:

If you can help me by reposting the link to this survey to any campus-wide listservs in your institution, or if you have any
advice on how I can access any campus-wide listservs in your institutions, please email me at hskoh@indiana.edu. It would
be truly appreciated.



Appendix B.1: Invitation/recruitment email message for the pilot study with student
participants
Dear All
I am HyunSeung Koh, a doctoral student in SLIS. I have designed a very short web-based
questionnaire as part of my dissertation research to gather information about current
reading practices in academic settings and non-academic settings.
In order to improve the quality of the current version of the questionnaire before the
larger study, I want to conduct a small pilot study with 15 - 20 people as follows:
•I will ask 5 people in person whether the instructions, questions, and answers are clear
enough to be understood and whether important aspects of reading practices and
behaviors have been omitted;
•I will ask 10-15 people via email to complete the questionnaire and give me answers to
three questions (How long did it take you to complete it? Were there any interface design
elements that did not make sense to you? Did you encounter any technical problems?).
Also, I will ask the same 10-15 people via email to complete the same questionnaire after
an interval of about a week to compare answers between the two administrations in order
to test the reliability of the questionnaire as a research instrument.
If you are a native speaker of English and interested in participating in either phase of the
pilot study described above, please kindly contact me at hskoh@indiana.edu. As a token
of gratitude, I will give a $10 Starbucks gift card to each participant in the individual
interviews and a $5 Starbucks gift card of to each participant who completes the
questionnaire twice and provides answers to my questions.
Thank you very much!
Best regards,
HyunSeung Koh



Appendix B.2: Invitation/recruitment email message (including the link to the online
questionnaire) for the pilot study with faculty members

Dear Dr. _________________
Thanks a lot for coming to my proposal defense!
As soon as I get the final approval from IRB, I am planning to proceed a pilot study with
SLIS students (please refer to the file attached for details). Meantime, I was told that it
would be also a good idea for me to proceed a pilot study with faculty members.
When you have some spare time, can you proceed the “short” questionnaire at
https://iucsr.qualtrics.com/SE/?SID=SV_eG0Rro7VGcI58Mc and let me know your
answers to the following questions?:
1) Are the instructions, questions, and answers are clear enough to be understood?
2) Are there important aspects of reading practices and behaviors that have been omitted?
3) How long did it take you to complete it?
4) Were there any interface design elements that did not make sense to you?
5) Did you encounter any technical problems?
Thanks in advance!
Best regards HyunSeung Koh



Appendix B.3: Invitation/recruitment email message (including the link to the online
questionnaire) for the larger study

Dear ___________ subscribers,
I am HyunSeung Koh, a doctoral candidate in the School of Library and Information
Science at Indiana University, Bloomington. I designed a very short web-based survey
questionnaire as part of my dissertation to gather information about current active
reading practices in academic settings.
If you are currently a master’s student, a doctoral student, a post-doc, or a faculty
member whose native language is English, please kindly click the link at
https://iucsr.qualtrics.com/SE/?SID=SV_eG0Rro7VGcI58Mc and answer the questions
in the questionnaire. It will take only 10 or 15 minutes to complete.
Also, if you can help me by reposting the link to this questionnaire to any campus-wide
listservs in your institution, or if you have any advice on how I can access any campuswide listservs in your institutions, I would truly appreciate if you could email me at
hskoh@indiana.edu.
Thank you very much in advance!
Best regards,
HyunSeung Koh
Doctoral candidate
School of Library and Information Science
Indiana University
Bloomington, IN, USA
P.S. Apologies for duplicate posting if you have already received or keep receiving the
link to the questionnaire via other sources.



Appendix B.4: Second invitation/recruitment email message (including the link to the
online questionnaire)
Re: Dissertation Survey> Current active reading practices in academic settings
Dear Dr. _________________
I am HyunSeung Koh, a doctoral candidate in the School of Library and Information
Science at Indiana University, Bloomington. I have been conducting my doctoral
dissertation survey regarding reading practices. From my first distribution to two
international listservs and one IU campus-wide listserv, I found that I need to attract
people from a wider diversity of disciplines to obtain more meaningful data.
Can you help me by posting the following message on listservs to which master’s and
doctoral students, post-docs, and/or faculty members in your department or school
subscribe? Or can you help me by forwarding this email to others who might be able to
post the message on listservs to which master’s and doctoral students, post-docs, and/or
faculty members in your department or school subscribe?
Thank you in advance!
Best regards,
HyunSeung Koh
hskoh@indiana.edu
Doctoral candidate
School of Library and Information Science
Indiana University
Bloomington, IN, USA
-----------------------------------------------------------------Dear subscribers
I am HyunSeung Koh, a doctoral candidate in the School of Library and Information
Science at Indiana University, Bloomington. I designed a very short web-based survey as
part of my dissertation to gather information about current active reading practices in
academic settings.
If you are currently a master’s student, a doctoral student, a post-doc, or a faculty
member whose native language is English, please kindly click the link below and answer
the questions in the survey. It will take only 10 or 15 minutes to complete.



https://iucsr.qualtrics.com/SE/?SID=SV_1z9ym3ona9PzfUM
Also, if you can help me by reposting the link to this survey to any campus-wide or
international listservs in your discipline(s), or if you have any advice on how I can access
any campus-wide or international listservs in your discipline(s), I would truly appreciate
if you could email me at hskoh@indiana.edu.
Thank you very much in advance!
Best regards,
HyunSeung Koh
Doctoral candidate
School of Library and Information Science
Indiana University
Bloomington, IN, USA
P.S. Apologies for duplicate posting if you have already received or keep receiving the
link to the questionnaire via other sources.



Appendix B.5: List of 10 schools and 37 departments that offered both master’s and
doctoral programs at Indiana University Bloomington as of March 22, 2012

10 schools:
• College of Arts and Sciences
• Jacobs School of Music
• Kelley School of Business
• Maurer School of Law
• School of Education
• School of Health, Physical Education, and Recreation
• School of Informatics and Computing
• School of Journalism
• School of Optometry
• School of Public and Environmental Affairs
37 departments in the College of Arts and Sciences:
• African American and African Diaspora Studies
• Anthropology
• Astronomy
• Biochemistry
• Molecular and Cellular
• Biology
• Central Eurasian Studies
• Chemistry
• Classical Studies
• Communication and Culture
• Comparative Literature
• Criminal Justice
• East Asian Languages and Cultures
• Economics
• English
• Folklore and Ethnomusicology
• French and Italian
• Geography
• Geological Sciences
• Germanic Studies
• History
• History and Philosophy of Science
• History of Art
• Linguistics
• Mathematics
• Near Eastern Languages and Cultures
• Philosophy



•
•
•
•
•
•
•
•
•
•

Physics
Political Sciences
Psychological and Brian Sciences
Religious Studies
Second Languages Studies
Slavic Languages and Literatures
Sociology
Speech and Hearing Sciences
Telecommunications
Theatre and Drama

Source: http://www.iub.edu/academic/majors/by-school.shtml



Appendix C.1: Reminder email message

Dear ________________ subscribers,
This is a reminder for those who have not had a chance to participate in my survey
questionnaire (https://iucsr.qualtrics.com/SE/?SID=SV_1z9ym3ona9PzfUM) yet but still
want to participate in it to help my dissertation research.
To those who have already completed the survey, I want to express my gratitude.
Again, please contact me at hskoh@indiana.edu if you have any questions or
concerns.
Best regards,
HyunSeung Koh
Doctoral candidate
School of Library and Information Science
Indiana University
Bloomington, IN, USA

 

Appendix C.2: List of ALA-accredited programs (from Table of Contents in the
Directory of Institutes Offering Accredited Master’s Programs, March 1, 2012)

UNITED STATES
ALABAMA
University of Alabama 6
ARIZONA
University of Arizona 7
CALIFORNIA
University of California, Los Angeles 8
San Jose State University 9
COLORADO
University of Denver 10
CONNECTICUT
Southern Connecticut State University 11
DISTRICT OF COLUMBIA
The Catholic University of America 12
FLORIDA
Florida State University 13
University of South Florida 14
GEORGIA
Valdosta State University 15
HAWAII
University of Hawaii 16
ILLINOIS
Dominican University 17
University of Illinois, Urbana–Champaign 18
INDIANA
Indiana University 19
IOWA
University of Iowa 20
KANSAS
Emporia State University 21
KENTUCKY
University of Kentucky 22
LOUISIANA
Louisiana State University 23
MARYLAND
University of Maryland 24
MASSACHUSETTS
Simmons College 25
MICHIGAN
University of Michigan 26



Wayne State University 27
MINNESOTA
St. Catherine University 28
MISSISSIPPI
University of Southern Mississippi 29
MISSOURI
University of Missouri 30
NEW JERSEY
Rutgers, The State University of New Jersey 31
NEW YORK
University at Albany, State University of New York 32
University at Buffalo, State University of New York 33
Long Island University 34
Pratt Institute 35
Queens College 36
St. John’s University 37
Syracuse University 38
NORTH CAROLINA
North Carolina Central University 39
University of North Carolina at Chapel Hill 40
University of North Carolina at Greensboro 41
OHIO
Kent State University 42
OKLAHOMA
University of Oklahoma 43
PENNSYLVANIA
Clarion University of Pennsylvania 44
Drexel University 45
University of Pittsburgh 46
PUERTO RICO
University of Puerto Rico 47
RHODE ISLAND
University of Rhode Island 48
SOUTH CAROLINA
University of South Carolina 49
TENNESSEE
University of Tennessee 50
TEXAS
University of North Texas 51
University of Texas at Austin 52
Texas Woman’s University 53
WASHINGTON
University of Washington 54
WISCONSIN
University of Wisconsin–Madison 55
University of Wisconsin–Milwaukee 56



CANADA
ALBERTA
University of Alberta 57
BRITISH COLUMBIA
University of British Columbia 58
NOVA SCOTIA
Dalhousie University 59
ONTARIO
University of Toronto 60
University of Western Ontario 61
QUEBEC
McGill University 62
Université de Montreal 63
Source:
http://www.ala.org/accreditedprograms/sites/ala.org.accreditedprograms/files/content/dire
ctory/pdf/LIS%20DIR_current.pdf



Appendix C.3: List of major codes (from Classification of Instructional Programs, 2010,
at the National Center for Education Statistics website)

01) AGRICULTURE, AGRICULTURE OPERATIONS, AND RELATED SCIENCES.
03) NATURAL RESOURCES AND CONSERVATION.
04) ARCHITECTURE AND RELATED SERVICES.
05) AREA, ETHNIC, CULTURAL, GENDER, AND GROUP STUDIES.
09) COMMUNICATION, JOURNALISM, AND RELATED PROGRAMS.
10) COMMUNICATIONS TECHNOLOGIES/TECHNICIANS AND SUPPORT
SERVICES.
11) COMPUTER AND INFORMATION SCIENCES AND SUPPORT SERVICES.
12) PERSONAL AND CULINARY SERVICES.
13) EDUCATION.
14) ENGINEERING.
15) ENGINEERING TECHNOLOGIES AND ENGINEERING-RELATED FIELDS.
16) FOREIGN LANGUAGES, LITERATURES, AND LINGUISTICS.
19) FAMILY AND CONSUMER SCIENCES/HUMAN SCIENCES.
22) LEGAL PROFESSIONS AND STUDIES.
23) ENGLISH LANGUAGE AND LITERATURE/LETTERS.
24) LIBERAL ARTS AND SCIENCES, GENERAL STUDIES AND HUMANITIES.
25) LIBRARY SCIENCE.
26) BIOLOGICAL AND BIOMEDICAL SCIENCES.
27) MATHEMATICS AND STATISTICS.
28) MILITARY SCIENCE, LEADERSHIP AND OPERATIONAL ART.
29) MILITARY TECHNOLOGIES AND APPLIED SCIENCES.
30) MULTI/INTERDISCIPLINARY STUDIES.
31) PARKS, RECREATION, LEISURE, AND FITNESS STUDIES.
32) BASIC SKILLS AND DEVELOPMENTAL/REMEDIAL EDUCATION.
33) CITIZENSHIP ACTIVITIES.
34) HEALTH-RELATED KNOWLEDGE AND SKILLS.
35) INTERPERSONAL AND SOCIAL SKILLS.
36) LEISURE AND RECREATIONAL ACTIVITIES.
37) PERSONAL AWARENESS AND SELF-IMPROVEMENT.
38) PHILOSOPHY AND RELIGIOUS STUDIES.
39) THEOLOGY AND RELIGIOUS VOCATIONS.
40) PHYSICAL SCIENCES.
41) SCIENCE TECHNOLOGIES/TECHNICIANS.
42) PSYCHOLOGY.
43) HOMELAND SECURITY, LAW ENFORCEMENT, FIREFIGHTING AND
RELATED PROTECTIVE SERVICES.
44) PUBLIC ADMINISTRATION AND SOCIAL SERVICE PROFESSIONS.
45) SOCIAL SCIENCES.
46) CONSTRUCTION TRADES.
47) MECHANIC AND REPAIR TECHNOLOGIES/TECHNICIANS.
48) PRECISION PRODUCTION.



49) TRANSPORTATION AND MATERIALS MOVING.
50) VISUAL AND PERFORMING ARTS.
51) HEALTH PROFESSIONS AND RELATED PROGRAMS.
52) BUSINESS, MANAGEMENT, MARKETING, AND RELATED SUPPORT
SERVICES.
53) HIGH SCHOOL/SECONDARY DIPLOMAS AND CERTIFICATES.
54) HISTORY.
60) RESIDENCY PROGRAMS.
Source: http://nces.ed.gov/ipeds/cipcode/browse.aspx?y=55




Appendix D.1: Content validity in the initial questionnaire: Omission

Stage
Before
(the
pilot
study)

Mode
of
interview
Email

Before

Email

Before

Email

Before

Email

During
During
During

In-person
In-person
In-person

During
During
During

In-person
In-person
In-person

After

Email

After

Email

After

Email

After

Email

Comments
(Note: Quoted directly from email interviews and quoted indirectly based
on in-person interviews)
[S]hould one of the choices be: Reading to satisfy personal curiosity (or
some such)? All of your choices are instrumental, but some people read
academic works for intrinsic reasons, e.g., to gain knowledge for its own
sake. You could even add a choice “Reading for pleasure,’ which you
wouldn’t expect people to select for (1), but you would expect it to be
selected for (2).
This survey has the virtues of being fairly brief and easy to answer. I
wonder, though, if it will gather all the information you want. I’ve made
comments to suggest ways to collect more nuanced info (mainly by
including more options for some questions) and to make the English sounds
more native-like
I suggest adding a page towards the end (e.g., before asking about academic
information) with: “Do you have any other comments that you wish to
share about your active reading?” (with a box to input comments)
Include ‘office’ as an option here and in (2). Also, how about ‘café or
restaurant’?
Flash cards and flags are tools for reading.
A sofa is one for reading.
Active reading is rather based on the purpose of reading (goal-oriented)
rather than the type of documents. For example, English students will read
novels not for pleasure.
Music, a bottle of water, a computer, and paper are tools for reading.
How about a netbook computer for a reading device?
A couch, a cup of tea, highlighter pens, TV shows, a computer, and the Star
Trek are tools for reading.
should have “n/a” as an option (since, e.g., for professors, the first three
options are not relevant).
Another possible category to add: reading and commenting on other
people’s writing. [Professors and editors do this a lot.]
In the demographics at the end, you ask for city and country but not state.
Do you need that (for US participants)?
Could there be an option such as “Reading for group work,” since many
students work in groups in many classes. Also, you should expect a lot of
“Never” responses from students who do not prepare lectures or publish.
Students may do reading in “Information Commons”



Appendix D.2: Content validity in the initial questionnaire: Redundancy

Stage
Before
(the
pilot
study)
Before

Mode
of
interview
Email

Comments
(Note: Quoted directly from email interviews and quoted indirectly based
on in-person interviews)
The questionnaire feels like the same questions are asked repeatedly. I
often had to re-read questions to be sure they were different

Email

Before
Before
Before

Email
Email
Email

Before
Before
After

Email
Email
Email

During
After

In-person
Email

This [during most recent years...] isn’t really necessary unless you want
to contact those who were once eligible but no longer are.
This [for Study Information Sheet] isn’t needed.
This isn’t really needed. No one will do it twice.
Since you just provided these definitions, and they are rather self-evident
from the labels themselves, I don’t think it’s necessary to include them
again. In fact, including them makes the text harder to read and process.
Redundant; omit.
sentence is redundant and adds no information; omit.
In the main part of the survey, there is a persistent definition at the top of
each page where the use of a comma in part of the long list of adjectives
(but not with subsequent items in the list) seemed odd.
The repeated definition of active reading seems rather confusing.
Do you need the explanations for deeper comprehending, learning, etc.
both in the question and above?



Appendix D.3: Content validity in the initial questionnaire: Clarity and conciseness

Stage
Before
(the
pilot
study)
Before
Before

Mode
of
interview
Email

Comments
(Note: Quoted directly from email interviews and quoted indirectly based
on in-person interviews)
You could tell the respondents that the questions refer to reading on
computers and on paper. I first thought it was for computers only.

Email
Email

Before

Email

This [besides devices where texts are present] isn’t clear.
This [Reading for publication] could be misinterpreted to mean ‘reading
publications (books, etc.), whereas I think your intention is ‘reading for
work you are preparing for publication’.
It’s not clear why this is added; omit or reword to clarify. You seem to be
presupposing that availability alone determines what is most common,
where in question 2, there is the assumption that people might prefer to
behave differently. To make the contrast without the first assumption
(which seems problematic to me), I suggest:

Before

Email

Before

Email

Before

Email

Before

Email

Before

Email

During

Inperson
Inperson

During
During

Inperson

1. Which of the following categories best describes your most common
actual active reading practices in relation to writing?
I find these options confusing; I cannot relate them clearly to any formats I
use. Better might be more familiar categories such as:
• print book/article
• scrollable web page
• pdf file read online
• pdf file printed out
• documents specially formatted for e-reading devices
shouldn’t this and the next list include Ereader? It makes this question
overlap partially with the one about devices, but overlap in survey design
is often desirable (it gives you slightly different perspectives on the same
phenomena).
This sentence [The findings of the survey ...] is too long and a bit
confusing.
I didn’t see it possibly because the definitions are so long that I likely
didn’t read the intro carefully. You have to assume that most respondents
won’t read the introductions and definitions. If might help if the definition
followed directly after the first sentence.
That’s a tough question. The last book/article would get better answers but
they might want to report their tendency. I think it might differ by format
– paper, web, etc. [Writing while reading]
How about verbal discussion? How about re-reading?
Each section (Academic, Active, etc.) is separated, but it seems that a
subject easily forgets the context for each question. How about adding “in
the context of academic reading practices” at the end of each question.
What does Printer mean? Printouts?



During

After

Inperson
Inperson
Inperson
Inperson
Inperson
Inperson
Inperson
Inperson
Email

After

Email

After

Email

After

Email

After

Email

After
After
After

Email
Email
Email

After

Email

After

Email

After

Email

During
During
During
During
During
During
During

What does Academic article mean?
A highlighter pen could be a highlighter pen in PDF.
It might be helpful to add what is not active reading.
Quite Often and Very Often seem confusing.
An interval between 2-3 Times a Week and Daily is too large? How about
adding 4-5 times a week?
Are both written and oral engagement related to active reading?
The current definition of active reading could be also for non-academic
reading.
It might be helpful to add a typical example of active reading practices.
The category of “Reading for pleasure” seems to overlap with “Reading to
satisfy personal curiosity” - is there a theoretical or empirical reason for
separating them? Also, if there are going to be non-academic participants,
there might be a need for a category “Reading for work”
For annotation, does writing in a text only take place in the margins? Are
you excluding the act of writing in the text (I do this when reading papers
online)?
It is not clear to me how the category of “tool” differs from “device” on
the previous page - they seem to overlap considerably. Also, a pen and
pencil are different types of tools than paper and notepad. And why
wouldn’t Ipad be listed here since it is a device from the previous page.
Someone in the School of Ed might be in IST and be confused about
which affiliation they should include here. What level of affiliation do you
want and is this the best question to ask to get at it? Do you want to know
if these people are in residence at their schools? If you have DE students,
they may live far away from their schools.
The category of news is most problematic to me as it is a type of content,
not a format. Newspaper would be more in line with the other categories.
Pleasure and personal curiosity seem to be non-exclusive categories.
How is print article different from pdf file printed out?
My answer would be different here if the definition of annotation included
inserting comments into (other writers’) documents.
My problem in responding to your questions is that I did a fair amount of
annotating but little of it as part of active reading. And, my goal in the
academic reading the articles was mostly of the
non-active kind but I was also looking for areas that required active
reading.
Many Americans struggle to respond with double negatives. Are you a full
time student or faculty member? Yes, student; Yes, faculty; no, not a full
time student or faculty member.
Unfortunately, response sets [Never to Very Often or Never to Daily] are a
little vague. Your test/retest indicates the scales are somewhat reliable.
That’s about as good as it gets.



After

Email

After
After

Email
Email

After

Email

After

Email

After

Email

After

Email

After

Email

After

Email

After

Email

I like to use time frames, e.g., in the past year. Ideally, it would be a
shorter time frame because that’s what is remembered most accurately.
But, you will have fewer “positive” responses if you use a short time
frame. [Overall vs. most recent tendency]
I think it [Adding habitually] might be more confusing.
I’m not currently taking or teaching classes, so my academic reading is
really rare and mostly medical or computer science related – both personal
topics.
I do remember that the use of “survey” and “questionnaire” for the same
thing seemed unnecessary.
I didn’t answer the question about reading to prepare for class discussion
or for quizzes. I do that, but it’s part of class preparation more generally,
not just for these activities.
On the first few questions I missed “Never” for “Other” because I didn’t
have anything to report.
Students and faculty probably do these (the first three items) for different
purposes - doctoral students may read course papers both to write for their
courses and to read for courses they teach.
“Academic article” is at a different level of granularity than the rest of the
options. Perhaps it should be “Academic Journal”
Should the scale used in the questions on this page (III) reflect the same
time divisions as on the previous page instead of the vague terms used
here? (same on IV.)
Also, in the error page that won’t let you advance until you answer, the
wording should be: “Please select at least one choice.”)

 

Appendix D.4: Test-retest reliability within a participant for the pilot study

Sm_pre

Correlations
Sm_pre Sm_post Fr_pre Fr_post St_pre St_post Gu_pre Gu_post
1
.933** .596**
.560** .646**
.714**
.643**
.664**

Pearson
Correlation
Sig. (2.000
.000
tailed)
N
49
49
49
Sm_post Pearson
.933**
1 .569**
Correlation
Sig. (2.000
.000
tailed)
N
49
50
50
**
**
Fr_pre Pearson
.596
.569
1
Correlation
Sig. (2.000
.000
tailed)
N
49
50
50
Fr_post Pearson
.560**
.540** .930**
Correlation
Sig. (2.000
.000
.000
tailed)
N
49
50
50
St_pre
Pearson
.646**
.640** .555**
Correlation
Sig. (2.000
.000
.000
tailed)
N
49
50
50
St_post Pearson
.714**
.702** .672**
Correlation
Sig. (2.000
.000
.000
tailed)
N
49
50
50
Gu_pre Pearson
.643**
.663** .524**
Correlation
Sig. (2.000
.000
.000
tailed)
N
49
50
50
Gu_post Pearson
.664**
.735** .501**
Correlation
Sig. (2.000
.000
.000
tailed)
N
49
50
50
**. Correlation is significant at the 0.01 level (2-tailed).





.000

.000

.000

.000

.000

49
.540**

49
.640**

49
.702**

49
.663**

49
.735**

.000

.000

.000

.000

.000

50
.930**

50
.555**

50
.672**

50
.524**

50
.501**

.000

.000

.000

.000

.000

50
1

50
.608**

50
.649**

50
.511**

50
.473**

.000

.000

.000

.001

50
1

50
.879**

50
.478**

50
.469**

.000

.000

.001

50
1

50
.516**

50
.545**

.000

.000

50
1

50
.840**

50
.608**
.000
50
.649**

50
.879**

.000

.000

50
.511**

50
.478**

50
.516**

.000

.000

.000

50
.473**

50
.469**

50
.545**

50
.840**

.001

.001

.000

.000

50

50

50

50

.000
50
1

50

Appendix D.5: Test-retest reliability for each of the 50 questions for the pilot study
A group of questions with a strong
relationship (r = .50)

Correlations

Correlations

Q44_5_post

1

.938

Pearson Correlation

Q44_1_pre

Q44_1_post

1

.688

N

4

4

.312

Pearson Correlation

.938

1

Sig. (2-tailed)

.062

Pearson Correlation
Q44_1_pre

Q44_5_pre

Sig. (2-tailed)
N
Pearson Correlation

Q44_1_post Sig. (2-tailed)

4

4

.688

1

Q44_5_pre

Q44_5_post

Sig. (2-tailed)

.062

N

4

4

Q45_1_pre

Q45_1_post

1

.905

.312
Correlations

N

4

4

Correlations
Q44_2_post

1

.899

N

.101

Pearson Correlation
Q44_2_pre

Pearson Correlation

Q44_2_pre

Sig. (2-tailed)
N
Pearson Correlation

Q44_2_post Sig. (2-tailed)

4

4

.899

1

Q45_1_pre

Q45_1_post

Sig. (2-tailed)

.095
4

4

Pearson Correlation

.905

1

Sig. (2-tailed)

.095

N

4

4

Q45_2_pre

Q45_2_post

1

.728

.101
Correlations

N

4

4

Correlations
Q44_3_pre

Q44_3_post

1

.966

Pearson Correlation
Q44_3_pre

Pearson Correlation

Sig. (2-tailed)

Q45_2_pre

*

Pearson Correlation

4

4

*

1

.966

Q44_3_post Sig. (2-tailed)

.272

N

.034

N

Sig. (2-tailed)

Q45_2_post

4

4

Pearson Correlation

.728

1

Sig. (2-tailed)

.272

N

4

4

.034

N

4

Correlations

4

Q45_3_pre

*. Correlation is significant at the 0.05 level (2-tailed).
Pearson Correlation

Q45_3_post
a

.

a

.

Correlations
Q45_3_pre

Pearson Correlation
Q44_4_pre

Q44_4_pre

Q44_4_post

1

.915

Sig. (2-tailed)

Pearson Correlation

.

N

4

4

Pearson Correlation

.

a

.

a

.085
Q45_3_post

N

Sig. (2-tailed)

4

4

.915

1

Sig. (2-tailed)

.

N

4

4

a. Cannot be computed because at least one of the variables is constant.
Q44_4_post Sig. (2-tailed)
N

.085
4

4





Correlations

Correlations
Q21_pre

Q21_post

1

**

Pearson Correlation
Q21_pre

Q21_post

1.000

Sig. (2-tailed)

Q24_5_pre

4

4

N

Pearson Correlation

**

1

.000

N

Q24_5_post

4

1

.718

Sig. (2-tailed)

N

Sig. (2-tailed)

Q24_5_post

Pearson Correlation

.000

1.000

Q24_5_pre

4

.282
4

4

Pearson Correlation

.718

1

Sig. (2-tailed)

.282

N

4

4

Q30_3_pre

Q30_3_post

1

.782

**. Correlation is significant at the 0.01 level (2-tailed).
Correlations
Correlations
Q24_1_pre

Q24_1_post

1

.522

Pearson Correlation
Q24_1_pre

Sig. (2-tailed)

Pearson Correlation
Q30_3_pre

.478

N
Pearson Correlation
Q24_1_post Sig. (2-tailed)

4

4

.522

1

.218

N

Q30_3_post

.478

N

Sig. (2-tailed)
4

4

Pearson Correlation

.782

1

Sig. (2-tailed)

.218

N

4

4

4

Q30_4_pre

Q30_4_post

1

.927

4
Correlations

Correlations
Q24_2_pre
Pearson Correlation
Q24_2_pre

Q24_2_post

1

1.000

Sig. (2-tailed)

Pearson Correlation

**

Q30_4_pre

.000

N
Pearson Correlation

4

4

**

1

1.000

Q24_2_post Sig. (2-tailed)

.073

N

Q30_4_post

.000

N

Sig. (2-tailed)
4

4

Pearson Correlation

.927

1

Sig. (2-tailed)

.073

N

4

4

4

Q30_5_pre

Q30_5_post

1

.739

4
Correlations

**. Correlation is significant at the 0.01 level (2-tailed).

Pearson Correlation

Correlations

Pearson Correlation
Q24_4_pre

Q24_4_pre

Q24_4_post

1

.577

Sig. (2-tailed)
N
Pearson Correlation

Q24_4_post Sig. (2-tailed)
N

Q30_5_pre

N

.423
4

4

.577

1

Sig. (2-tailed)

Q30_5_post

.261
4

4

Pearson Correlation

.739

1

Sig. (2-tailed)

.261

N

4

4

.423
4

4





Correlations

Correlations

Q45_4_pre

Q45_4_post

1

.870

Pearson Correlation
Q45_4_pre

Sig. (2-tailed)

Q1_4_pre
Pearson Correlation

.130

N

4

Pearson Correlation

4

.870

Q45_4_post Sig. (2-tailed)

Q1_4_pre

1

.130

N

Q1_4_post

4

4

Q1_4_post

1

1.000

Sig. (2-tailed)

**

.000

N

4

4

Pearson Correlation

**

1

1.000

Sig. (2-tailed)

.000

N

4

4

**. Correlation is significant at the 0.01 level (2-tailed).
Correlations
Q14_pre
a

Pearson Correlation
Q14_pre

Correlations

Q14_post
a

.

.

Sig. (2-tailed)

Q14_post

4

4

Pearson Correlation

a

a

.

Sig. (2-tailed)

.

N

4

Q10_1_pre

.

Pearson Correlation

Q10_1_post

4

4

4

Pearson Correlation

.833

1

Sig. (2-tailed)

.167

N

Q1_1_post
1

.910

Sig. (2-tailed)

4

4

Q10_2_pre

Q10_2_post

1

.577

Pearson Correlation

.090

N

Q10_2_pre

Sig. (2-tailed)

.423

4

4

N

4

4

Pearson Correlation

.910

1

Pearson Correlation

.577

1

Sig. (2-tailed)

.090

Sig. (2-tailed)

.423

N

Q10_2_post

4

4

N

Correlations

Pearson Correlation

Q1_2_pre

Q1_2_post

1

.979

*

Pearson Correlation

.021

Q10_3_pre

4

Q10_3_pre

Q10_3_post

1

.913

Sig. (2-tailed)

4

4

N

*

1

Pearson Correlation

.979

Sig. (2-tailed)

.021

N

4

Correlations

Sig. (2-tailed)
N

Q1_2_post

.167

Correlations

Q1_1_pre

Q1_2_pre

.833

Sig. (2-tailed)

Correlations

Q1_1_post

1

N

a. Cannot be computed because at least one of the variables is constant.

Q1_1_pre

Q10_1_post

Pearson Correlation

.

N

Q10_1_pre

4

Q10_3_post
4

.087
4

4

Pearson Correlation

.913

1

Sig. (2-tailed)

.087

N

4

4

*. Correlation is significant at the 0.05 level (2-tailed).





Correlations
Correlations
Q32_1_pre

Q32_1_post
Q32_5_pre
a

Pearson Correlation

.

a

Pearson Correlation
Q32_1_pre

Sig. (2-tailed)

a

.

.

.
Q32_5_pre

Q32_1_post

Q32_5

a

.

N

4

4

Pearson Correlation

.

a

.

Sig. (2-tailed)

.

N

4

Sig. (2-tailed)

.

N

4

4

Pearson Correlation

.

a

.

a

Q32_5

Sig. (2-tailed)

.

N

4

a

4
4

a. Cannot be computed because at least one of the variables is constant.
a. Cannot be computed because at least one of the variables is constant.
Correlations
Correlations
Q32_2_pre

Q32_2_post
Q32_6_pre

Pearson Correlation

1.000

a

Pearson Correlation
Q32_2_pre

Q32_6_post

**

1

Sig. (2-tailed)

a

.

.

.000
Q32_6_pre

N
Pearson Correlation

4

4

**

1

1.000

Q32_2_post Sig. (2-tailed)

Sig. (2-tailed)

.

N

4

4

Pearson Correlation

a

.

a

.

.000
Q32_6_post

N

4

Sig. (2-tailed)

.

N

4

4
4

**. Correlation is significant at the 0.01 level (2-tailed).
a. Cannot be computed because at least one of the variables is constant.
Correlations
Correlations
Q32_3_pre

Q32_3_post

1

.577

Q32_7_pre
Pearson Correlation

a

Pearson Correlation
Q32_3_pre

Sig. (2-tailed)

Q32_7_post
a

.

.

.423
Q32_7_pre

N
Pearson Correlation
Q32_3_post Sig. (2-tailed)

4

4

.577

1

Sig. (2-tailed)

.

N

4

4

Pearson Correlation

a

.

a

.

.423
Q32_7_post

N

4

Sig. (2-tailed)

.

N

4

4
4

a. Cannot be computed because at least one of the variables is constant.
Correlations

Pearson Correlation
Q32_4_pre

Q32_4_pre

Q32_4_post

1

**

Sig. (2-tailed)

1.000

4

4

Pearson Correlation

**

1

N

Pearson Correlation

.000

N

Q32_4_post Sig. (2-tailed)

Correlations

1.000

Q35_1_pre

4

Q35_1_post

4

1

.688
.312

4

4

Pearson Correlation

.688

1

Sig. (2-tailed)

.312

N

**. Correlation is significant at the 0.01 level (2-tailed).

Q35_1_post

Sig. (2-tailed)
N

.000

Q35_1_pre

4

4





Correlations

Correlations
Q35_2_pre

Pearson Correlation
Q35_2_pre

Q35_2_post
a

a

.

.

Sig. (2-tailed)

Q35_2_post

Q37_3_pre

Q37_3_post

1

.943

Pearson Correlation

.

Q37_3_pre

Sig. (2-tailed)

.057

N

4

4

N

4

4

Pearson Correlation

.

a

1

Pearson Correlation

.943

1

Sig. (2-tailed)

.057

Sig. (2-tailed)

.

N

4

Q37_3_post
4

N

4

4

Q37_4_pre

Q37_4_post

1

.899

a. Cannot be computed because at least one of the variables is constant.
Correlations
Correlations
Q35_4_pre

Q35_4_post

1

.816

Pearson Correlation
Q35_4_pre

Sig. (2-tailed)

Pearson Correlation
Q37_4_pre

.184

N
Pearson Correlation
Q35_4_post Sig. (2-tailed)

4

4

.816

1

.101

N

Q37_4_post

.184

N

Sig. (2-tailed)
4

4

Pearson Correlation

.899

1

Sig. (2-tailed)

.101

N

4

4

4

Q37_5_pre

Q37_5_post

1

.899

4
Correlations

Correlations
Q35_5_pre
Pearson Correlation
Q35_5_pre

Q35_5_post

1

1.000

Sig. (2-tailed)

Pearson Correlation

**

Q37_5_pre

.000

N

4

4

Pearson Correlation

**

1

1.000

Q35_5_post Sig. (2-tailed)

Q37_5_post

4

Q37_1_pre

1

1.000

.101
4

4

Correlations

**

N

4

4

Pearson Correlation

**

1

N

Sig. (2-tailed)

A group of questions with a moderate
relationship (r = .30)

Pearson Correlation

.000

1.000

1

Q37_1_post

Sig. (2-tailed)

Q37_1_post Sig. (2-tailed)

4

.899

4

Correlations

Pearson Correlation

4

Pearson Correlation

N

**. Correlation is significant at the 0.01 level (2-tailed).

Q37_1_pre

.101

N

.000

N

Sig. (2-tailed)

Q1_5_pre

4

Pearson Correlation
Q1_5_post

4

Sig. (2-tailed)
N

**. Correlation is significant at the 0.01 level (2-tailed).

Q1_5_post

1

-.333

Sig. (2-tailed)
N

.000

Q1_5_pre

.667
4

4

-.333

1

.667
4

4





Correlations

Correlations

Q30_1_pre

Q30_1_post

1

-.333

Pearson Correlation
Q30_1_pre

Sig. (2-tailed)

Pearson Correlation
Q30_1_post Sig. (2-tailed)

Q37_2_pre

4

4

N

1

Pearson Correlation

.667

Q37_2_post

4

4

Q30_2_pre

Q30_2_post

1

.426

Q30_2_pre

Sig. (2-tailed)

Pearson Correlation
Q30_2_post Sig. (2-tailed)

4

4

.426

1

1

.667
4

4

Correlations
Q10_5_pre

Q10_5_post

1

-.132

Pearson Correlation
Sig. (2-tailed)

.868

N

4

Pearson Correlation
Q10_5_post

Correlations
Q1_3_pre

4



Q10_5_pre

4

4
-.333

A group of questions with a weak
relationship (r = .10)

.574

N

.667

Sig. (2-tailed)

.574

N

-.333

N

Correlations

Pearson Correlation

1

Sig. (2-tailed)

-.333

N

Q37_2_post

Pearson Correlation

.667

N

Q37_2_pre

Sig. (2-tailed)

4
1

.868

N

Q1_3_post

4
-.132

4

4

Q24_3_pre

Q24_3_post

1

.246


Pearson Correlation
Q1_3_pre

1

.381

Sig. (2-tailed)

Correlations

.619

N

4

4

Pearson Correlation

.381

1

Sig. (2-tailed)

.619

Pearson Correlation
Q24_3_pre

Q1_3_post

Sig. (2-tailed)

.754

N
N

4

4



Q24_3_post

4

4

Pearson Correlation

.246

1

Sig. (2-tailed)

.754

Correlations
N

Pearson Correlation
Q10_4_pre

Q10_4_pre

Q10_4_post

1

.333

Sig. (2-tailed)
N
Pearson Correlation

Q10_4_post Sig. (2-tailed)
N

4

4
1

Pearson Correlation
Q24_6_pre

.667
4

4

Q24_6_pre

Q24_6_post

1

.174

Correlations

.667

.333

4



Sig. (2-tailed)
N

4








Q24_6_post

4

4

Pearson Correlation

.174

1

Sig. (2-tailed)

.826

N




.826

4

4



Correlations
Q35_3_pre

Q35_3_post

1

.174

Pearson Correlation
Q35_3_pre

Sig. (2-tailed)

.826

N
Pearson Correlation
Q35_3_post Sig. (2-tailed)

4

4

.174

1

.826

N

4

4




A question with an unknown relationship
with a missing value
Correlations
Q32_8_pre
Pearson Correlation
Q32_8_pre

Q32_8_post



Q32_8_post

1

a

.

Sig. (2-tailed)

.

N

3

3

Pearson Correlation

a

.

.

Sig. (2-tailed)

.

N

3

a

4

a. Cannot be computed because at least one of the variables is constant.


Note: The questions that elicited the SPSS output comment “Cannot be computed
because at least one of the variables is constant,” signifying that all pre- and post-values
across participants were the same, were grouped into questions with a strong correlation.
One question with a missing value was excluded from analysis.



Appendix D.6: Duration of survey for the pilot study

Stage
After (the
pilot study)
After
After
After
After

Mode
of
interview
Email
Email
Email
Email
Email

Comments
(Note: Quoted directly from email interviews and quoted indirectly
based on in-person interviews)
I believe it took me around 30 minutes (I had a bit of
environmental distraction in the middle).
15 minutes
10 minutes
The questionnaire took about 10-15 minutes to complete.
It took me about 12 minutes to complete the survey.



Appendix D.7: Interface design (presentation) of the initial online questionnaire

Stage
After (the
pilot study)

Mode
of
interview
Email

After

Email

After

Email

After

Email

After

Email

After

Email

After

Email

After

Email

After
After

Email
Email

After

Email

Comments
(Note: Quoted directly from email interviews and quoted indirectly
based on in-person interviews)
Every time I went to click one of the circles for an answer, the
background would turn into a dark gray square around the choices.
That wasn’t much of a problem – every time I clicked a circle, I
then clicked outside the box and it went away. It was a little
distracting, but it did not affect how I answered.
It was very easy to complete and follow, and there were no
hindering technical problems. However, clicking the first answer in
a section will highlight the entire section in light gray.
Why do you force them to select a current academic status and
demographic info?
Some respondents may not want to provide some or all
demographic information. By forcing them to respond, they may
abandon the questionnaire and you would not get any information
from the later questions.
If they select three in 1, then only three are left, so this question
isn’t needed. You might ask them to rank all in one question.
[Purposes for academic reading]
You could skip this question for faculty or ask about research
emphasis.
Do you really want to limit them to one choice? Given the current
reality, very few (if any) people are likely to select ereaders as their
top (only) choice, when laptops are so common. I suggest asking
for the three most common, and asking them to rank them 1, 2, 3.
That would be a different question format, but it would garner you
more information. You could also do the same for questions 1 and 2
in this section.
What if the subjects answered ‘no’ to the two questions on the
previous page – do they still have to provide their name and email
address? I should think not. Perhaps you should add here: “If you
answered ‘yes’ to either of the questions on the last page, …”
Program Qualtrics to skip.
Yes. And respondents should be allowed to skip any item they do
not want to answer. Typically, the IRB says that respondents can
skip any question they choose.
The listserv is the best option. Your goal is not to increase the
response rate but to get the largest number of respondents. The two
step process [contact information first and distribute later] will
reduce the number.

 

Appendix D.8: Technical problems of survey for the pilot study

Stage
After (the
pilot study)

Mode
of
interview
Email

After

Email

After
After
After
After

Email
Email
Email
Email

Comments
(Note: Quoted directly from email interviews and quoted indirectly
based on in-person interviews)
I think the interface was fine. I felt the survey looked very clean and
streamlined. I have taken surveys in similar formats which made me
feel comfortable about knowing how to navigate, etc.
In general, the words that were highlighted and in color looked like
they would be links, so it was distracting when they were not.
Use a regular font [for definitions]
This can be done as a regular page without footnotes.
Annotations could be a heading. [as a new section]
The questions that require dragging the items to the right and
ranking them was confusing. And, some items seemed better as
“how often” than rankings.






Appendix E.1: Selecting independent variables for follow-up binary logistic regression
with annotation frequency

1) Format
Although no cell of Format had zero or a very low frequency of items, Format had no
significant correlation with Annotation Frequency (2.849 < 3.841 at df =1 and α = 0.05).
Therefore, Format was excluded for follow-up binary logistic regression.
Annotation Frequency
Light
1 (Digital lovers)
Format Cluster
2 (Paper lovers)

Count

Count

19.6%

189

% within Format Cluster

26.4%

148

22.7%

201

73.6% 100.0%

99

% within Format Cluster

235

80.4% 100.0%

53

Count

Total

Heavy

46

% within Format Cluster

Total

337

436

77.3% 100.0%


Value df
Pearson Chi-Square
Continuity Correction
Likelihood Ratio

b

Asymp. Sig. (2-

Exact Sig. (2-

Exact Sig. (1-

sided)

sided)

sided)

2.849a

1

.091

2.475

1

.116

2.842

1

.092

Fisher’s Exact Test
Linear-by-Linear
Association

.108
2.842

1

.058

.092

N of Valid Cases
436
a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 45.64.
b. Computed only for a 2x2 table

2) Device
Although no cell of Device had zero or a very low frequency of items, Device also had no
significant correlation with Annotation Frequency (0.150 < 7.815 at df =3 and α = 0.05).
Therefore, Device was excluded for follow-up binary logistic regression.



Annotation Frequency
Light
Count

1 (Multi players)

2 (Stationary players)
Device Cluster
3 (Mobile players)

4 (Tablet players)

52

21.2%

Count
% within Device Cluster

128

22.4%

Count

108

23.4%

Count

49

23.4%

64

76.6% 100.0%

99

% within Device Cluster

141

76.6% 100.0%

15

% within Device Cluster

165

77.6% 100.0%

33

% within Device Cluster

66

78.8% 100.0%

37

Count

Total

Heavy

14

% within Device Cluster

Total

337

22.7%

436

77.3% 100.0%


Value

df

Asymp. Sig. (2-sided)

Pearson Chi-Square

.150a

3

.985

Likelihood Ratio

.151

3

.985

Linear-by-Linear Association

.130

1

.718

N of Valid Cases

436

a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 14.53.

3) Place
Although no cell of Place had zero or a very low frequency of items, Place had no
significant correlation with Annotation Frequency (0.694 < 3.841 at df =1 and α = 0.05).
Therefore, Place was also excluded for follow-up binary logistic regression.
Annotation Frequency
Light
1 (Public readers)
Place Cluster
2 (Private readers)
Total

Count

58

% within Place Cluster
Count

21.4%
41

% within Place Cluster
Count

24.8%
99

% within Place Cluster



22.7%

Total

Heavy
213

271

78.6% 100.0%
124

165

75.2% 100.0%
337

436

77.3% 100.0%


Value df
Pearson Chi-Square
Continuity Correction

b

Likelihood Ratio

Asymp. Sig. (2-

Exact Sig. (2-

Exact Sig. (1-

sided)

sided)

sided)

.694a

1

.405

.512

1

.474

.689

1

.407

Fisher’s Exact Test
Linear-by-Linear
Association

.412
.692

1

.237

.405

N of Valid Cases
436
a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 37.47.
b. Computed only for a 2x2 table

4) Tool
Because no cell of Tool had zero or a very low frequency of items and Tool had a
significant correlation with Annotation Frequency (27.260 > 5.991 at df =2 and α = 0.05,
Tool was included for follow-up binary logistic regression.
Annotation Frequency
Light
1 (Tool lovers)

Tool Cluster 2 (Music lovers)

3 (Reading lovers)
Total

Count

21

% within Tool Cluster
Count

12.3%
21

% within Tool Cluster
Count

19.6%
57

% within Tool Cluster
Count

36.1%
99

% within Tool Cluster

22.7%

Total

Heavy
150

171

87.7% 100.0%
86

107

80.4% 100.0%
101

158

63.9% 100.0%
337

436

77.3% 100.0%


Value

df

Asymp. Sig. (2-sided)

Pearson Chi-Square

27.260

a

2

.000

Likelihood Ratio

27.160

2

.000

Linear-by-Linear Association

26.247

1

.000

N of Valid Cases

436

a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 24.30.



5) Degree
Because no cell of Degree had zero or a very low frequency of items and Degree had a
significant correlation with Annotation Frequency (25.604 > 7.815 at df =3 and α = 0.05),
Degree was included for follow-up binary logistic regression.
Annotation Frequency
Light
MA

PhD
Degree
Faculty

Other
Total

Count
% within Degree
Count
% within Degree
Count
% within Degree
Count
% within Degree
Count
% within Degree

Total

Heavy

62

132

32.0%

194

68.0% 100.0%

12

122

9.0%

134

91.0% 100.0%

21

59

26.3%

80

73.8% 100.0%

4

24

14.3%

28

85.7% 100.0%

99

337

22.7%

436

77.3% 100.0%


Value

df

Asymp. Sig. (2-sided)

Pearson Chi-Square

25.604

a

3

.000

Likelihood Ratio

28.156

3

.000

2.801

1

.094

Linear-by-Linear Association
N of Valid Cases

436

a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 6.36.

6) Major
Because some cells of Major had only a low frequency of items and Major had no
significant correlation with Annotation Frequency (12.264 < 16.919 at df =9 and α =
0.05), Major was excluded for follow-up binary logistic regression.






Annotation

Total

Frequency
Light
Count
Hard Sciences

% within
Major
Count

Communication, Journalism, and Related

% within

Programs

Major
Count

Education

% within
Major
Count

Foreign Languages, Literatures, and Linguistics

% within
Major
Count

Library Science

% within
Major

Major

Count
Multi/Interdisciplinary studies

% within
Major
Count

Social Sciences

% within
Major
Count

Visual and Performing Arts

% within
Major
Count

History

% within
Major
Count

Dual (or Multiple) Majors

% within
Major
Count

Total

% within
Major



Heavy
4

28.6%
1
6.7%
6
25.0%
1
7.1%
69
27.4%
1
6.3%
7
17.1%
4
19.0%
3
13.6%
3
17.6%
99
22.7%

10

14

71.4% 100.0%
14

15

93.3% 100.0%
18

24

75.0% 100.0%
13

14

92.9% 100.0%
183

252

72.6% 100.0%
15

16

93.8% 100.0%
34

41

82.9% 100.0%
17

21

81.0% 100.0%
19

22

86.4% 100.0%
14

17

82.4% 100.0%
337

436

77.3% 100.0%


Value

df

Asymp. Sig. (2-sided)

Pearson Chi-Square

12.264a

9

.199

Likelihood Ratio

14.206

9

.115

1.299

1

.254

Linear-by-Linear Association
N of Valid Cases

436

a. 7 cells (35.0%) have expected count less than 5. The minimum expected count is 3.18.

7) Gender
Although no cell of Gender had zero or a very low frequency of items, Gender had no
significant correlation with Annotation Frequency (0.004 < 3.841 at df =1 and α = 0.05.
Therefore, Gender was excluded for follow-up binary logistic regression.
Annotation Frequency
Light
Female
Gender
Male
Total

Count

Heavy

74

% within Gender

22.6%

Count

253

22.9%

Count

99

% within Gender

22.7%

327

77.4% 100.0%

25

% within Gender

Total

84

109

77.1% 100.0%
337

436

77.3% 100.0%


Value df
Pearson Chi-Square
Continuity Correction
Likelihood Ratio

Exact Sig. (2-

Exact Sig. (1-

sided)

sided)

sided)

a

1

.947

.000

1

1.000

.004

1

.947

.004
b

Asymp. Sig. (2-

Fisher’s Exact Test
Linear-by-Linear
Association

1.000
.004

1

.947

N of Valid Cases
436
a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 24.75.
b. Computed only for a 2x2 table









.521

8) Age
Although no cell of Age had zero or very low frequency, Age had no significant
correlation with Annotation Frequency (6.038 < 9.488 at df =4 and α = 0.05). Therefore,
Age was excluded for follow-up binary logistic regression.
Annotation Frequency
Light
20 - 29

30 - 39

Age 40 - 49

50 - 59

60 and Older
Total

Count
% within Age
Count
% within Age
Count
% within Age
Count
% within Age
Count
% within Age
Count
% within Age

Total

Heavy

46

117

28.2%

163

71.8% 100.0%

28

107

20.7%

135

79.3% 100.0%

12

58

17.1%

70

82.9% 100.0%

6

35

14.6%

41

85.4% 100.0%

7

20

25.9%

27

74.1% 100.0%

99

337

22.7%

436

77.3% 100.0%


Value

df

Asymp. Sig. (2-sided)

Pearson Chi-Square

6.038

a

4

.196

Likelihood Ratio

6.139

4

.189

Linear-by-Linear Association

2.581

1

.108

N of Valid Cases

436

a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 6.13.



Appendix E.2: SPSS Outputs for binary logistic regression with annotation frequency
(with simultaneous entry)

Case Processing Summary
Unweighted Cases
Selected Cases

a

N
Included in Analysis

Percent
436

100.0

0

.0

436

100.0

0

.0

436

100.0

Missing Cases
Total
Unselected Cases
Total

a. If weight is in effect, see classification table for the total number of
cases.

Dependent Variable Encoding
Original Value

Internal Value

Light

0

Heavy

1

Categorical Variables Codings
Parameter coding
Frequency
Q12Degree

Q10ToolClusterNumber

(1)

(2)

(3)

PhD

134

.000

.000

.000

MA

194

1.000

.000

.000

Faculty

80

.000

1.000

.000

Other

28

.000

.000

1.000

1

171

.000

.000

2

107

1.000

.000

3

158

.000

1.000

Degree (0): Ph.D., the reference category
Degree (1): MA
Degree (2): Faculty
Degree (3): Other
Tool (0): People who use diverse paper tools as well as a computer frequently (cluster 1, tool lovers), the
reference category
Tool (1): People who use a paper tool of pen/pencil as well as a computer frequently, listening to music
frequently (cluster 2, music lovers)
Tool (2): People who use a computer only frequently (cluster 3, reading lovers)



Block 0: Beginning Block
Classification Tablea,b
Predicted
Q5AnnotationFreqCategoryNumber
Observed
Step 0

Light

Percentage

Heavy

Correct

Q5AnnotationFreqCategoryN

Light

0

99

.0

umber

Heavy

0

337

100.0

Overall Percentage

77.3

a. Constant is included in the model.
b. The cut value is .500

Variables in the Equation
B
Step 0

Constant

S.E.

1.225

Wald

.114

df

114.822

Sig.
1

Exp(B)

.000

3.404

Variables not in the Equation
Score
Step 0

Variables

Q10Tool

Sig.

27.260

2

.000

Q10Tool(1)

.767

1

.381

Q10Tool(2)

25.237

1

.000

Q12Degree

25.604

3

.000

Q12Degree(1)

17.048

1

.000

Q12Degree(2)

.701

1

.402

Q12Degree(3)

1.209

1

.272

51.235

5

.000

Overall Statistics

Block 1: Method = Enter
Omnibus Tests of Model Coefficients
Chi-square
Step 1

df

df

Sig.

Step

55.317

5

.000

Block

55.317

5

.000

Model

55.317

5

.000

 

Model Summary
Step

-2 Log likelihood

Cox & Snell R

Nagelkerke R

Square

Square

411.817a

1

.119

.181

a. Estimation terminated at iteration number 5 because parameter
estimates changed by less than .001.
Classification Tablea
Predicted
Q5AnnotationFrequencyCategory
Observed
Step 1

Light

Heavy

Correct

Q5AnnotationFrequencyCategor Light

0

99

.0

y

0

337

100.0

Heavy

Overall Percentage

77.3

a. The cut value is .500

Variables in the Equation
B
Step 1

a

Percentage

S.E.

Q10Tool

Wald

df

Sig.

25.832

2

.000

Exp(B)

Q10Tool(1)

-.388

.345

1.263

1

.261

.679

Q10Tool(2)

-1.411

.297

22.592

1

.000

.244

23.337

3

.000

Q12Degree
Q12Degree(1)

-1.648

.351

22.043

1

.000

.193

Q12Degree(2)

-1.219

.406

9.006

1

.003

.295

Q12Degree(3)

-.641

.635

1.020

1

.313

.527

Constant

3.064

.373

67.435

1

.000

21.422

a. Variable(s) entered on step 1: Q10Tool, Q12Degree_revised_reference.



Appendix E.3: Selecting independent variables for follow-up binary logistic regression
with Annotation Type

1) Format
Because no cell of Format had zero or a very low frequency of items, and Format had a
significant correlation with Annotation Type (11.357 > 3.841 at df =1 and α = 0.05),
Format was included for follow-up binary logistic regression.
Annotation Type

Total

1 (Weak) 2 (Strong)
1 (Digital lovers)
Format Cluster
2 (Paper lovers)

Count

107

% within Format Cluster

45.5%

Count
% within Format Cluster

61.7%

77

53.0%

201

38.3% 100.0%

231

% within Format Cluster

235

54.5% 100.0%

124

Count

Total

128

205

436

47.0% 100.0%


Value
Pearson Chi-Square
Continuity Correction
Likelihood Ratio

Asymp. Sig. (2-

Exact Sig. (2-

Exact Sig. (1-

sided)

sided)

sided)

a

1

.001

10.717

1

.001

11.420

1

.001

11.357
b

df

Fisher’s Exact Test
Linear-by-Linear
Association

.001
11.331

1

.001

.001

N of Valid Cases
436
a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 94.51.
b. Computed only for a 2x2 table

2) Device
Because no cell of Device had zero or a very low frequency of items, and Device had a
significant correlation with Annotation Type (16.484 > 3.841 at df =3 and α = 0.05),
Device was included for follow-up binary logistic regression.










Annotation Type

Total

1 (Weak) 2 (Strong)
Count

1 (Multi players)

% within Device Cluster

2 (Stationary player)
Device Cluster
3 (Mobile player)

4 (Tablet players)

30
45.5%

Count
% within Device Cluster

82

50.3%

Count

48

66.0%

Count

39

39.1%

64

60.9% 100.0%

231

% within Device Cluster

141

34.0% 100.0%

25

% within Device Cluster

165

49.7% 100.0%

93

% within Device Cluster

66

54.5% 100.0%

83

Count

Total

36

205

53.0%

436

47.0% 100.0%


Value

df

Asymp. Sig. (2-sided)

Pearson Chi-Square

16.484a

3

.001

Likelihood Ratio

16.704

3

.001

Linear-by-Linear Association

.323

1

.570

N of Valid Cases

436

a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 30.09.

3) Place
Because no cell of Place had zero or a very low frequency of items, and Place had a
significant correlation with Annotation Type (5.249 > 3.841 at df =1 and α = 0.05), Place
was included for follow-up binary logistic regression.
Annotation Type

Total

1 (Weak) 2 (Strong)
1 (Public readers)
Place Cluster
2 (Private readers)
Total

Count

132

% within Place Cluster
Count

48.7%
99

% within Place Cluster
Count

60.0%
231

% within Place Cluster



53.0%

139

271

51.3% 100.0%
66

165

40.0% 100.0%
205

436

47.0% 100.0%





Value df
Pearson Chi-Square
Continuity Correction

b

Likelihood Ratio

Asymp. Sig. (2-

Exact Sig. (2-

Exact Sig. (1-

sided)

sided)

sided)

5.249a

1

.022

4.806

1

.028

5.274

1

.022

Fisher’s Exact Test
Linear-by-Linear
Association

.023
5.237

1

.014

.022

N of Valid Cases
436
a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 77.58.
b. Computed only for a 2x2 table

4) Tool
Because no cell of Tool had zero or a very low frequency of items, and Tool had a
significant correlation with Annotation Type (27.647 > 5.991 at df =2 and α = 0.05), Tool
was included for follow-up binary logistic regression.
Annotation Type

Total

1 (Weak) 2 (Strong)
1 (Tool lovers)

Tool Cluster 2 (Music lovers)

3 (Reading lovers)
Total

Count

81

% within Tool Cluster
Count

47.4%
41

% within Tool Cluster
Count

38.3%
109

% within Tool Cluster
Count

69.0%
231

% within Tool Cluster

53.0%

90

171

52.6% 100.0%
66

107

61.7% 100.0%
49

158

31.0% 100.0%
205

436

47.0% 100.0%


Value

df

Asymp. Sig. (2-sided)

Pearson Chi-Square

27.647

a

2

.000

Likelihood Ratio

28.185

2

.000

Linear-by-Linear Association

14.834

1

.000

N of Valid Cases

436

a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 50.31.



5) Degree
Because no cell of Degree had zero or a very low frequency of items, and Degree had a
significant correlation with Annotation Type (19.237 > 7.815 at df =3 and α = 0.05),
Degree was included for follow-up binary logistic regression.
Annotation Type

Total

1 (Weak) 2 (Strong)
MA

PhD
Degree
Faculty

Other
Total

Count
% within Degree
Count
% within Degree
Count
% within Degree
Count
% within Degree
Count
% within Degree

123

71

63.4%

194

36.6% 100.0%

54

80

40.3%

134

59.7% 100.0%

43

37

53.8%

80

46.3% 100.0%

11

17

39.3%

28

60.7% 100.0%

231

205

53.0%

436

47.0% 100.0%


Value

df

Asymp. Sig. (2-sided)

Pearson Chi-Square

19.237

a

3

.000

Likelihood Ratio

19.382

3

.000

4.898

1

.027

Linear-by-Linear Association
N of Valid Cases

436

a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 13.17.

6) Major
Because some cells of Major had only a low frequency of items, and Major had no
significant correlation with Annotation Type (12.981 < 16.919 at df =9 and α = 0.05),
Major was excluded for follow-up binary logistic regression.









Annotation Type

Count
Hard Sciences

% within
Major
Count

Communication, Journalism, and Related

% within

Programs

Major
Count

Education

% within
Major
Count

Foreign Languages, Literatures, and Linguistics

% within
Major
Count

Library Science

% within
Major

Major

Count
Multi/Interdisciplinary studies

% within
Major
Count

Social Sciences

% within
Major
Count

Visual and Performing Arts

% within
Major
Count

History

% within
Major
Count

Dual (Multiple) Majors

% within
Major
Count

Total

% within
Major



Total

1

2

(Weak)

(Strong)

8
57.1%
5
33.3%
10
41.7%
4
28.6%
149
59.1%
8
50.0%
18
43.9%
10
47.6%
10
45.5%
9
52.9%
231
53.0%

6

14

42.9% 100.0%
10

15

66.7% 100.0%
14

24

58.3% 100.0%
10

14

71.4% 100.0%
103

252

40.9% 100.0%
8

16

50.0% 100.0%
23

41

56.1% 100.0%
11

21

52.4% 100.0%
12

22

54.5% 100.0%
8

17

47.1% 100.0%
205

436

47.0% 100.0%


Value

df

Asymp. Sig. (2-sided)

Pearson Chi-Square

12.981a

9

.163

Likelihood Ratio

13.105

9

.158

Linear-by-Linear Association

.160

1

.689

N of Valid Cases

436

a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 6.58.

7) Gender
Although no cell of Gender had zero or a very low frequency of items, Gender had no
significant correlation with Annotation Type (1.624 < 3.841 at df =1 and α = 0.05).
Therefore, Gender was excluded for follow-up binary logistic regression.
Annotation Type

Total

1 (Weak) 2 (Strong)
Female
Gender
Male
Total

Count

179

% within Gender

54.7%

Count

52

% within Gender

47.7%

Count

231

% within Gender

53.0%

148

327

45.3% 100.0%
57

109

52.3% 100.0%
205

436

47.0% 100.0%


Value df
Pearson Chi-Square
Continuity Correction
Likelihood Ratio

Exact Sig. (2-

Exact Sig. (1-

sided)

sided)

sided)

a

1

.203

1.353

1

.245

1.621

1

.203

1.624
b

Asymp. Sig. (2-

Fisher’s Exact Test
Linear-by-Linear
Association

.223
1.620

1

.203

N of Valid Cases
436
a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 51.25.
b. Computed only for a 2x2 table



.122

8) Age
Although no cell of Age had zero or a very low frequency of items, Age had no
significant correlation with Annotation Type (5.958 < 9.488 at df =4 and α = 0.05).
Therefore, Age was excluded for follow-up binary logistic regression.


Annotation Type

Total

1 (Weak) 2 (Strong)
20 - 29

30 - 39

Age 40 - 49

50 - 59

60 and Older
Total

Count
% within Age
Count
% within Age
Count
% within Age
Count
% within Age
Count
% within Age
Count
% within Age

95

68

58.3%

163

41.7% 100.0%

72

63

53.3%

135

46.7% 100.0%

29

41

41.4%

70

58.6% 100.0%

20

21

48.8%

41

51.2% 100.0%

15

12

55.6%

27

44.4% 100.0%

231

205

53.0%

436

47.0% 100.0%


Value

df

Asymp. Sig. (2-sided)

Pearson Chi-Square

5.958

a

4

.202

Likelihood Ratio

5.968

4

.202

Linear-by-Linear Association

2.084

1

.149

N of Valid Cases

436

a. 0 cells (.0%) have expected count less than 5. The minimum expected count is 12.69.



Appendix E.4: SPSS Outputs for binary logistic regression with annotation type (with
simultaneous entry)
Case Processing Summary
Unweighted Cases
Selected Cases

a

N
Included in Analysis

Percent
436

100.0

0

.0

436

100.0

0

.0

436

100.0

Missing Cases
Total
Unselected Cases
Total

a. If weight is in effect, see classification table for the total number of
cases.

Dependent Variable Encoding
Original Value

Internal Value

1 (Weak)

0

2 (Strong)

1

Categorical Variables Codings
Parameter coding
Frequency
Q12Degree

Q8DeviceCluster

Q10ToolCluster

Q9PlaceCluster
Q7FormatCluster

(1)

(2)

(3)

PhD

134

.000

.000

.000

MA

194

1.000

.000

.000

Faculty

80

.000

1.000

.000

Other

28

.000

.000

1.000

1

66

.000

.000

.000

2

165

1.000

.000

.000

3

141

.000

1.000

.000

4

64

.000

.000

1.000

1

171

.000

.000

2

107

1.000

.000

3

158

.000

1.000

1

271

.000

2

165

1.000

1

235

.000

2

201

1.000



Block 0: Beginning Block
Classification Tablea,b
Predicted
Q6AnnotationTypeCluster
Observed
Step 0

1 (Weak)

Q6AnnotationTypeCluster

Percentage

2 (Strong)

Correct

1 (Weak)

231

0

100.0

2 (Strong)

205

0

.0

Overall Percentage

53.0

a. Constant is included in the model.
b. The cut value is .500

Variables in the Equation
B
Step 0

Constant

S.E.

-.119

Wald

.096

df

1.549

Sig.
1

Exp(B)

.213

.887

Variables not in the Equation
Score
Step 0

Variables

df

Sig.

Q7Format(1)

11.357

1

.001

Q8Device

16.484

3

.001

Q8Device(1)

.765

1

.382

Q8Device(2)

14.085

1

.000

Q8Device(3)

5.834

1

.016

Q9Place(1)

5.249

1

.022

Q10Tool

27.647

2

.000

Q10Tool(1)

12.240

1

.000

Q10Tool(2)

25.483

1

.000

Q12Degree

19.237

3

.000

Q12Degree(1)

15.235

1

.000

Q12Degree(2)

.023

1

.879

Q12Degree(3)

2.253

1

.133

68.297

10

.000

Overall Statistics
Degree (0): Ph.D., the reference category
Degree (1): MA
Degree (2): Faculty
Degree (3): Other






Device (0): People who use paper and desktop/laptop frequently and sometimes use Amazon Kindle and
Phone (cluster 1, multi players), the reference category
Device (1): People who use paper and desktop/laptop frequently (cluster 2, stationary players)
Device (2): People who use paper and laptop frequently (cluster 3, mobile players)
Device (3): People who use paper, laptop, and iPad frequently (cluster 4, tablet players)
Tool (0): People who use diverse paper tools as well as a computer frequently (cluster 1, tool lovers), the
reference category
Tool (1): People who use a paper tool of pen/pencil as well as a computer frequently, listening to music
frequently (cluster 2, music lovers)
Tool (2): People who use a computer only frequently (cluster 3, reading lovers)
Place (0): People who read at home and in the office frequently sometimes at other places as well (cluster
1, public readers), the reference category
Place (1): People who read at home frequently (cluster 2, private readers)
Format (0): People who use both paper book/journal and digital formats (webpage and PDF online)
frequently (cluster 1, digital lovers), the reference category
Format (1): People who use paper formats (book, journal, and PDF on paper) frequently (cluster 2, paper
lovers)

Block 1: Method = Enter
Omnibus Tests of Model Coefficients
Chi-square
Step 1

df

Sig.

Step

73.623

10

.000

Block

73.623

10

.000

Model

73.623

10

.000

Model Summary
Step
1

-2 Log likelihood
529.250

Cox & Snell R

Nagelkerke R

Square

Square

a

.155

.207

a. Estimation terminated at iteration number 4 because parameter
estimates changed by less than .001.
Classification Tablea
Predicted
Q6AnnotationTypeCluster
Observed
Step 1

Q6AnnotationTypeCluster

1 (Weak)

Percentage

2 (Strong)

Correct

1 (Weak)

157

74

68.0

2 (Strong)

82

123

60.0

Overall Percentage

64.2

a. The cut value is .500

 

Variables in the Equation
B
Step 1a

Q7Format(1)

S.E.

-.730

.231

Q8Device

Wald

df

Sig.

9.971

1

.002

5.029

3

.170

Exp(B)
.482

Q8Device(1)

.121

.324

.139

1

.709

1.128

Q8Device(2)

-.294

.352

.698

1

.404

.745

Q8Device(3)

.454

.384

1.402

1

.236

1.575

-.262

.232

1.276

1

.259

.769

25.758

2

.000

Q9Place(1)
Q10Tool
Q10Tool(1)

.302

.282

1.146

1

.284

1.352

Q10Tool(2)

-1.018

.251

16.489

1

.000

.361

23.141

3

.000

Q12Degree
Q12Degree(1)

-1.197

.255

21.967

1

.000

.302

Q12Degree(2)

-.849

.319

7.098

1

.008

.428

Q12Degree(3)

-.341

.456

.559

1

.455

.711

Constant

1.276

.367

12.122

1

.000

3.583

a. Variable(s) entered on step 1: Q7Format, Q8Device, Q9Place, Q10Tool, Q12Degree_revised_reference.

 

Appendix F: Invitation/recruitment email message for the annotation study in the second
phase
Re: Dissertation Document Analysis> Current Active Reading Practices in Academic
Settings
Dear ___________,
I am HyunSeung Koh, a doctoral candidate in the School of Library and Information
Science at Indiana University, Bloomington, who recently conducted an online survey
regarding current active reading practices in academic settings for my doctoral
dissertation.
First of all, thanks a lot for completing my online survey! Also, thanks for letting me
contact you via email to collect representative samples of your reading materials
(including annotations) and/or notepads (including notes)!
If you are still interested in sending your representative samples of reading materials
and/or notes in the context of active reading, can you send them to me via email as file
attachments (including scanned paper documents and/or digital documents)? If that is not
convenient for you, could you let me know what would be the most convenient way for
you to send them to me?
This study is completely voluntary. You do not have to participate. If you would like
more information about the study, please read the attached Study Information Sheet.
When you send your reading materials and/or notes to me, please kindly make sure that
you delete any sensitive or confidential information in them. Also, please provide the
contextual information below, which will help me to understand your annotations and/or
notes better:
- When, where, what, and why did you read?
- What format (e.g., paper book, scrollable web page) and device (e.g., Paper,
Desktop, iPad) did you use to read?
- Why did you select these particular samples over others? Do you think these
particular samples are more representative than others in terms of your active
reading?
The purpose of this second phase of document analysis in my dissertation is to
understand aspects of active reading practices in academic settings that are rather difficult
for me to understand from the first phase of the online survey.
Thank you very much in advance!
Best regards,

 

HyunSeung Koh
Doctoral candidate
School of Library and Information Science
Indiana University
Bloomington, IN, USA
Note: All documents will be stored in a password-protected personal computer that can
be accessed only by the investigator, HyunSeung Koh. If you have any questions or
concerns, please feel free to contact me, HyunSeung Koh, at hskoh@indiana.edu or the
Human Subjects Office at Indiana University at irb@iu.edu (the IRB approved
study#1106006158).

 

Appendix G.1: Invitation/recruitment email message with multiple options for the first
follow-up interviews in the third phase
Re: Dissertation Follow-Up Interview> Current Active Reading Practices in Academic
Settings
Dear ___________,
I am HyunSeung Koh, a doctoral candidate in the School of Library and Information
Science at Indiana University, Bloomington, who recently collected your reading
materials including annotations (e.g., underlines, notes) in the text and/or in page margins
and/or notes in separate note pads!
First of all, thanks a lot again for providing your materials! Also, thanks a lot for letting
me contact you via email for a follow-up interview. A major goal of the follow-up
interview is to reconfirm my interpretations of your annotations and/or notes in your
reading materials and/or notepads.
An ultimate goal of my dissertation is to collect as naturalistic data as possible. In order
to achieve this goal, I have designed four options for the follow-up interview (further
details of each option are provided in the Study Information Sheet attached):
1) In-person interview (Sorry, only for participants who are or will be in Bloomington,
IN, USA):
I will conduct an interview in a place (e.g., office, home, library) where your active
reading typically takes place. You will have a chance to show me your typical settings
(e.g., a typical setting of your desk including a computer, pens and paper, etc.), additional
materials, and anything that might help me understand your active
reading practices/behaviors.
2) Skype interview with a Web camera or voice call:
I will conduct an interview via Skype while you are in a place (e.g., office, home, library)
where your active reading typically takes place. You will have a chance to show me, with
a Web camera or photos/video clips, your typical settings (e.g., a typical setting of your
desk including a computer, pens and paper, etc.), additional materials, and anything that
might help me understand your active reading practices/behaviors.
3) Email interview:
I will send my interview questions to you via email. You will answer my questions via
email, attaching photos and/or video clips of your typical settings (e.g., a typical setting
of your desk including a computer, pens and paper, etc.), additional materials, and
anything that might help me understand your active reading practices/behaviors.
4) Other (if you do not want to do any of the above three options):

 

Please let me know what would be the most convenient, comfortable way for you to do
an interview in terms of places, methods, and data collection.
Which option do you prefer? Please let me know.
Participation in this study is completely voluntary. You do not have to participate. If you
would like more information about the study, please read the attached Study Information
Sheet.
Thank you very much in advance!
Best regards,
HyunSeung Koh
Doctoral candidate
School of Library and Information Science
Indiana University
Bloomington, IN, USA

 

Appendix G.2: Invitation/recruitment email message with two options for the first followup interviews in the third phase
Re: Dissertation Follow-Up Interview> Current Active Reading Practices in Academic
Settings
Dear ___________,
I am HyunSeung Koh, a doctoral candidate in the School of Library and Information
Science at Indiana University, Bloomington, who recently collected your reading
materials including annotations (e.g., underlines, notes) in the text and/or in page margins
and/or notes in separate note pads!
First of all, thanks a lot again for providing your materials and I am so sorry for getting
back to you too late! Also, thanks a lot for letting me contact you via email for a followup interview. Now, I am forwarding to you my follow-up questions as the file
attachment. Can you kindly insert your answers to each question and get back to me with
the file attachment? Please let me know if you prefer to Skype.
Participation in this study is completely voluntary. You do not have to participate. If you
would like more information about the study, please read the attached Study Information
Sheet (SIS).
Thank you very much in advance!
Best regards,
HyunSeung Koh
Doctoral candidate
School of Library and Information Science
Indiana University
Bloomington, IN, USA

 

Appendix H.1: Preliminary questions for the first follow-up in-person or Skype
interviews in the third phase (with more open-ended questions)
First of all, thanks a lot for your participation! As you know, this study is designed to
understand your active* (or scholarly) reading experience in the context where you read
books/articles, along with your annotations**, to fulfill your scholarly reading purposes.
I reviewed your reading materials, including annotations and/or notes. Today, I am here
to learn about your active reading practices from your own perspective and also talk
about what I found from your reading materials from my own perspective.
Some exemplary questions are as these:
Where, when, and why did you read the books/articles which you selected?
What were you doing (e.g., flipping through pages) while you were reading the
books/articles which you selected?
How differently do you read books/articles and react to text when you read for your
scholarly reading, as compared with leisure or casual reading?
Why did you select some books/articles (over other books/articles) as representative
samples?
I found interesting annotations and notes in your reading materials. Can you tell me what
they mean and why you made them?
Do you have any other comments you want to add?
Thank you so much for your participation! If you have any questions, please feel free to
email me at hskoh@indiana.edu.
*Active reading is defined as ‘a skillful/expert reader’s purposeful/effortful reading, in
which s/he employs (more) active processes, throughout the course of reading, to go
beyond the literal level of comprehension, as opposed to leisurely reading, regardless of
the issue of whether active and passive processes are separable or inseparable.’ (More)
active processes are defined as reading processes where readers employ two reading
processes, ‘deeper comprehending’ (to understand the writer’s intended meanings
completely) and ‘learning’ (to acquire content knowledge), most of time, while spending
little time ‘memorizing’ (for accurate recall for later purposes), ‘skimming’ (to grasp the
main topic quickly), and ‘scanning’ (to find target information).
**Annotations in this study mean everything written except for the original text, such as
text in page margins, underlines, highlights, a memo in a separate notepad or sticky notes,
and the like. Annotation is the action of doing annotations.]

 

Appendix H.2: Questions for the first follow-up email or Skype interviews in the third
phase (with more guided closed-ended questions)

I might ask some questions that seem similar, to which you may feel you are giving the
same answers as to other questions. My purpose in asking such questions is to make sure
that I do not exclude one case that seemingly looks the same as another but is actually not
the same in terms of participants’ underlying intentions. I hope you understand this
purpose when I ask questions that may seem overlapping or redundant.
Questions consist of three types: Opening questions, Body questions, and Closing
questions as below:
I. Opening questions:
1. Your strong preferences for reading device(s) and note-taking behaviors
Can I identify you as a person who has strong preferences for reading on paper
(not digitally or online) and taking notes in a separate digital notepad (not “on”
reading materials)? If not, how would you describe your strong preferences for
reading device(s) and for note-taking behaviors?
I observed that some people prefer to write their annotations, including underlines
and notes, on reading materials. Is there any reason that you wrote your notes in a
separate notepad instead of on reading materials?
2. Your own definition of active reading
• Active reading is …
• How is active reading (in academic settings) different from other kinds of reading
such as leisurely reading and any other kind of academic reading (i.e., How
differently do you read books or articles and react to text when you read actively,
as compared with any other kind of reading)?
• What factors make you become most (or less) active in reading? For example, the
purpose for reading? The nature of text? (e.g., the difficulty level of text) The
familiarity with a topic? The difficulty level of the class? The constraints of time?
3. General information about your active reading
• [Physical settings] Can you forward me photos (or movie clips) of a typical
setting(s) in such place(s) as home, office, bookstore or library where your active
reading usually takes place? Also, can you explain why you set up for active
reading in particular ways?

 

• [Reading practice] Do you change your ways of active reading (e.g., reading
strategies)?
If so, what factors affect your ways of reading? For example, how about your
purpose for reading (e.g., writing vs. teaching)? How about reading devices (e.g.,
paper vs. ebook)? How about formats (e.g., book chapter vs. journal article)?
Also, if so, how do you change your ways of active reading and why?
• [Reading practice] How would you explain the ways you usually do active
reading? For example, do you read one text deeply one time only or read it over
multiple times? What about multi-tasking? What kinds of other activities are you
doing while active reading? For example, printing, web-surfing, drinking a coffee,
etc.?
4. General information about your annotation and/or note-taking strategies
• Did you learn specific ways to annotate and/or take notes? Do you think your
practices have changed over time? If yes, how?
• Can you explain your general, overall annotation and/or note-taking strategies in
brief? You can give me specific examples from your previous reading material
samples and explain why you annotated or took notes as you did.
• I observed that some people were annotating a lot (many highlights, underlines,
and notes), as compared to others. What is your usual practice in this regard? Why
do you think some readers do much more highlighting/annotating than others?
• I observed that some people were doing much more highlighting/annotating in
some text than in others. What is your practice in this regard? Why do you think
some readers do more highlighting/annotating in some text than in others?
5. General information about your reasons for (or your ultimate goals of)
annotating and/or note-taking
• Based on my document (annotation and/or notes) analysis and its follow-up
interviews with other participants, I was able to identify their reasons for (and/or
their ultimate goals of) underlining or highlighting text, adding symbols, and/or
taking notes as below:

 

1) To enhance current (moment-to-moment) reading processes or experiences
(i.e., to engage deeply with content cognitively and/or emotionally) by doing the
following:
1

taking note of properties or elements of a
text that spontaneously (almost
unconsciously) elicits attention (whether
or not they represent the author’s key
ideas)

2

making implicit content explicit, making
complicated (or difficult) content
simpler (or clearer), or elaborating
concise content

3

being more aware of thinking (or
metacognitive) processes

4

examining and developing content
carefully and critically

5

minimizing time-consuming tasks while
reading

Examples
underlining sentences that include
highly salient textual (rhetorical)
structures such as comparison and
contrast, with or without signal
words such as however, whereas,
and unlike
underlining sentences that include
highly salient content that conveys
strong messages, with or without
signal words such as key, must,
impossible, and severely
re-phrasing unusual textual content
(in the original text) in a more
traditional or conventional way
unfolding an abbreviation
writing out the steps or processes
of thinking from initial thought to
final conclusion, in response to the
author’s argument
adding further annotations (e.g.,
circling, underlining) to personal
notes that are taken in page
margins
linking between information or
knowledge in different locations
(e.g., see page# 10)
adding disagreement (criticism),
with or without justification for it,
to the author’s arguments
creating an abbreviation (e.g.,
CNXNS for connections)

Do you also add annotations (e.g., symbols, underlines, highlights) and/or take
notes to enhance your moment-to-moment reading processes or experiences? If
yes, do you also do the same activities as those in the above table to enhance your
moment-to-moment reading processes or experiences? Is there anything that is not
listed in the above table and you do to enhance your moment-to-moment reading
processes or experiences?



2) To enhance future reading processes or experiences by manipulating text in a
way that helps the following:
6

grasp the author’s key ideas for their
quick retrieval (without re-reading the
entire text)

7

retrieve quickly target information or
knowledge that is not necessarily the
author’s key points but find important,
useful, or interesting
undertake further action such as doublechecking something unclear, further
researching on something new, and
doing further discussion with other
people

8

Examples
adding a star(s) to the author’s key
ideas
summarizing the entire text by
paraphrasing
underlining a definition of a key
term
adding a question mark to
something new or unclear

Do you also add annotations (e.g., symbols, underlines, highlights) and/or take
notes to enhance your future reading processes or experiences? If yes, do you also
have the same reasons or goals as those in the above table? Is there anything that
is not listed in the above table and you need to add?
• Is there any other “big” reason for annotating and/or note-taking that you want to
or need to add, in addition to the two big reasons mentioned above (i.e., for
current and future reading processes or experiences)? If yes, what are they?

II. Body Questions:

1. From your entire reading note
• What are highlights for? Does each color (i.e., yellow, cyan, gray, and green)
have a different meaning?
• What are underlines for?
• What is boldface for?
• What are differences among highlights, underlines, and boldface?
• What are differences among different kinds of combinations (i.e., underline only,
boldface only, highlight only, boldface and underline, boldface and highlight, and
underline and highlight)?



• When did you add highlights, underlines, and boldface? For example, while
reading, right after reading and taking notes or right before your exam?
• What is a square bracket [ ] for?
2. Slovic, Finucane, & MacGregor (2005)
I found that you tend to write down notes (in your reading note) that have particular
characteristics as below:
Goals

Characteristics

1

To examine and develop
content carefully and
critically

Link the original text with
external source(s)

2

To make the author’s key
points stand out so that you
can grasp the author’s key
points quickly later
(without re-reading the
entire text)

The author’s key points of
a section or the entire text

To make important, useful
or interesting text (that are
not necessarily the author’s
key points) stand out so
that you can find them
quickly later

Sentences that include
numeral word(s) such as
first and two
Terms or phrases that are
emphasized with
italicization or boldface

3

(Text plays a key role. That
is, you encounter text with
particular characteristics
and react to it almost
immediately and
unconsciously.)

Your own summary about
the author’s key points of a
section or the entire text by
paraphrasing

The definition of a term or
a concept or sentences that
are definitional



Examples
(from your reading note)
framing of a question can
draw on affect as it is able
to create an image that is
positive or negative –
thereby influencing
judgment and decisions.
[Hammond et al. – framing
trap]
“Affect-laden images likely
induce greater perception
of risk in response to the
relative frequency frames.”
–Refer to jellybean study
How information is
presented affects people’s
responses to risks and
benefits when making
decisions. For example,
affect laden images created
by vivid narratives can be
highly motivating, whereas
statistical frequencies
(probability of occurring)
are not
Authors identify 2 basic
ways in which risk is
perceived.
1. Risk as feelings where
people react fast,
instinctively and intuitively
to danger. Affect heuristic?
Visceral?
2. Risk as Analysis invokes
logic and reason and
deliberation for risk
management.
Authors define affect as
“the specific quality of
goodness or badness (a)
experienced as a feeling

Key ideas or assertions of
(distinguished) scholars or
schools in a field
Important (applied)
theories, models or effects
and/or their definitions or
descriptions

Practical (real-life)
examples

4

To undertake further action
later such as doublechecking something
unclear, further researching
on something new, and
doing further discussion
with other people

Double-check a link
between information or
knowledge in different
locations

state (with or without
consciousness) and (b)
demarcating a positive or
negative quality of a
stimulus.”
Daimaso (1994) suggested
that rational action is not
possible without affect
Referring to Epstein’s
(1994) observations for a
dual processing theory of
information (1 – intuitive,
automatic, experiential and
2 – analytic and rational
[p.710]), they note that both
have their place in decision
making.
Framing the presentation of
information is type of
manipulation of people. Is
this Ethical? Ultimately, the
individuals must make the
choice. [cigarettes]
1. Risk as feelings where
people react fast,
instinctively and intuitively
to danger. Affect heuristic?
Visceral?

In other words, while you were reading, you did the four kinds of activities: the first
category is about your purposeful, conscious efforts to examine and develop content
carefully and critically; the second category is about your purposeful, conscious
efforts to grasp the author’s key points or arguments; the third category is about your
unconscious, effortless reactions to text with particular characteristics that are not
necessarily the author’s key points or arguments; and the fourth category is about
your purposeful, conscious efforts to make something you need to or want to
undertake further action with later stand out.
• What do you think about my interpretations? Is there anything I did mistakenly
interpret? If yes, can you look at each example more closely and let me know which
example is not in a right category? Also, can you correct my interpretations by
revising and/or eliminating my own categories (and subcategories) in the above
table or creating your own new categories (and subcategories)?
• Is the following note your simple summary of the author’s key points and/or your
attempt to connect with your personal research?



[Is it possible to be rational without employing emotion as a driver when making
decisions. Can there be a purely rational decision – I think NOT – see slovic et al
2005 p. S36]
• Is the following note your simple summary of the author’s key points and/or your
reflections (thoughts) about the author’s key points?
framing of a question can draw on affect as it is able to create an image that is
positive or negative – thereby influencing judgment and decisions. [Hammond
et al – framing trap]
3. Kunreuther, Meyer, Zeckhause, Slovic, Schwartz, Schade, Luce, Lippman,
Krantz, & Hogarth (2002)
I found that you tend to write down notes (in your reading note) that have
particular characteristics as below:
Goals
1

Characteristics

To examine and
develop content
carefully and
critically

Link the original text
with its relevant
external source(s)

Link the original text
with its relevant
prior knowledge



Examples
(from your reading
note)
Tendency to prefer
Status Quo [One of
Hammond et al.’s
(1998) traps – the
status quo trap] – it
is easier to make no
decision when
presented with many
options
They may take over
protective measures
[This sounds like a
PRUDENCE TRAP]
when it is not
required.
– over-reliance on
social norms – in
general, most people
are not experienced
in making high
stakes decisions and
look to others for
possible strategies
[sounds like social
networking] or
follow social norms.
There is potential
that norms &
strategies are
misguided and may
perpetuate rather

than eliminate
biases.

Link the original text
with its relevant
practical (real-life)
examples

Your disagreement
(criticism) with or
without justification
for it

2

To make the
author’s key points
stand out so that you
can grasp the
author’s key points
quickly later
(without re-reading
the entire text)



The author’s key
points of a section or
the entire text

[info avoidance]
“when faced with
decisions that
involve life and
death trade-offs,
people frequently
remark ‘I’d rather
not think about it’’
or relegate the
decision to an agent
– both potentially
dysfunctional
responses [see
Schwartz et al.,
2002] [My thinking
–sounds like
information
avoidance]
authors discuss how
individuals make
decisions about low
probability (low
chance of occurring)
but high stakes
events – e.g., a
tornado hitting a
Seattle home.
there are situations
when no right course
can be used to
improve decision
making, but the goal
is to train people to
see approaches to
decision that seem
appropriate based on
all aspects of
analysis. [What
about individual
decisions – can they
be trained? I think
not.]
Heuristics
authors discuss how
individuals make
decisions about low
probability (low
chance of occurring)
but high stakes
events – e.g. a
tornado hitting a
Seattle home.

Your own summary
about the author’s
key points of a
section or the entire
text by paraphrasing

3

To make important,
useful or interesting
text (that are not
necessarily the
author’s key points)
stand out so that you
can find them
quickly later
(Text plays a key
role. That is, you
encounter text with
particular
characteristics and
react to it almost
immediately and
unconsciously.)

4

To make
background
knowledge (of the
author’s key points)
stand out so that you
can find them
quickly later

List of parallel
word(s) or concepts
Sentences that
include numeral
word(s) such as first
and two
The definition of a
term or a concept or
sentences that are
definitional

Practical (real-life)
examples

Information or
knowledge that you
want to cite

life does not
generally prepare us
to make high stakes,
low probability
decision, particularly
when poor choice
consequences are
great and
simultaneously
difficult to reverse.
Rules of Departure
from normative
models
2 distinctive
properties of a high
stakes decision
Prescriptive
heuristics are “rules
of thumb that
enhance normative
processing in light of
natural processing
limitations.”
decision makers
must learn to
eliminate biases in
high stakes decisions
but intuitively
recognize the harm
caused by biases –
e.g., build on flood
plain following a
hundred year flood –
recency bias
“The decisions that
matter most in life
are often those that
we are least prepared
to make.”
[NOTE TO SELF –
THIS IS A
REALLY GOOD
QUOTE TO START
WITH]

In other words, while you were reading, you did the four kinds of activities: the first
category is about your purposeful, conscious efforts to examine and develop content
carefully and critically; the second category is about your purposeful, conscious
efforts to grasp the author’s key points or arguments; the third category is about your
unconscious, effortless reactions to text with particular characteristics that are not
necessarily the author’s key points or arguments; and the fourth category is about
your purposeful, conscious efforts to make the background knowledge of the author’s
key points stand out.



• What do you think about my interpretations? Is there anything I did mistakenly
interpret? If yes, can you look at each example more closely and let me know which
example is not in a right category? Also, can you correct my interpretations by
revising and/or eliminating my own categories (and subcategories) in the above
table or creating your own new categories (and subcategories)?
• I found that you have two separate notes for this same article. Can I know why you
wrote two separate notes for the same article?

III. Closing Questions:

1. What do you usually do (e.g., flipping through pages), along with your
annotation/note-taking activities, while you are reading? (This question is about
asking your physical movements while reading.)
2. Do you have any other samples you might want to share with me? If yes, how are
they different from ones that you’ve already provided in terms of the characteristics
of your annotations? For example, do they have more diverse symbols, colors, and
notes? (You can just describe them or actually forward me the actual samples via
email. It’s up to you)
3. What characteristics of ebook readers do you envision as supportive of academic
reading? What existing ebook reader(s), if any, do you consider most supportive?
Have you ever heard any positive or negative feedback on any ebook reader(s), such
as Kindle and Nook, from your friends? If yes, can you tell me more about this
feedback? Why do they think any given ebook readers are good or bad?
4. Do you have any other comments you would like to add?
Thank you so much for your participation! If you have any questions, please feel free to
email me at hskoh@indiana.edu. Meanwhile, may I contact you via email again if I have
additional questions or for further clarification?




Appendix I: The codebook, after the annotation study and follow-up interviews, for the
video study (distance observation) and its follow-up interviews








   

























  
     





! 
$$    
'  $
%  #$  $&

,/"-+,.

    ! 
  
    !
  !(,,+0++0,/1














 





    
       

$    !"  
%
%   
'
&    
)
 
$  
+
%  
,
&   
$#
'  
$$
( $   !"  
$%
( %  
%'
( &   
%)
       
    !"  
%*
   
%+
    
%,


































 



     

           !    "
           
 ! " !  
 " 
!       "     
       !    " 
   

















 

 

  

 


   






-%* !%%! 3..,$*!,& # ,%, !%4! *!&## %#3$4 1!# !%"3$4,$$  
# &#%!$!(, (#%% &# )%%!% !%%! .

-!# &# !%%! ,$%! !%%$ %!!!!#8.,9.!,:. %#$! , ;.
  %'!#$%%%$ %!!!!#<.8! %3$4,  % $ %! $%$$!( 
!(3 *!& !%  %#!%!!!,(#%!( /%#-0 $#%!#9.! :. %#$! !#
#% (%$ $#%!#<.8!  %3$44-

6

8.

8 !#

9.!

&## %

:. %#$! 

*"! %$

;.  %
'
!(

9 %#

%#-22222222

: &# 

!%

; &# 

&%&#































%#-2222222222

78

)%#*

 78

# $%! 

&

7:

2222222222222222



 78 22222222222222222



 +

<.8! %3$45


5$ *$% ! !#!##'! %!#*3$"" )4 !'! %!!(#'! %$ 
%!#*.

!%- '$%%!#( )%%!*!&(*!&#! ,( $%%*!&#!  &*% '$%%!#
$$#*.!#)",*!&( * %* ! !#!##'! %!#*! *!&#!( , % %
 '$%%!#*"*!&!!$!(#'! %$ ! %!#*$! *!&#)" %! , $$#*.


















 






   


 
 



   

























































































































































































































































































    

&#8.+"'$++!  "( !&%&&"'$$)&!"!"' !&-"!##&"!-!"!(-!"!&$%&&"&
%&&3)$&&!4!!"&&"!%-%%!!$!' $&"%")-!)$&&!' $"!&%$(!&#/

&#9."$+!  "( !&-%&"!"&& %!&""""$8/ -9/"-:/
&$%"!-!;/
! !&("$%&&& %!&""""$</8"!& 3%4-!!&!%!&"!%&%%")!
")3 +"'!!"&!!& $" &"""-)$&")!0&$.1!%$&"$9/"!:/
&$%"!"$
$&!)& %!%$& "$</9"! & 3%44.

6

8/ 

8 '$!

9/"

'$$!&

:/

&$%"!


9 '$!

&$.22222222 &$.2222222222

")

: &$

"&



79

2222222222222222

; "$

"&





 78

22222222222222222

























































+%

;/! !&
(
")
 78

! ,

</9"!& 3%45

 !!

78 #" !


5%!+%&!"!"$ "$$("!&"$+3%##!*4! "("!&"")$("!& %!
&"$+/

"&.!(%&&"$)!*&&"+"')+"'$"!-) !%&&+"'$"!!'+&!(%&&"$
!%%$+/"$* #-+"')!+!&+!"!"$ "$$("!&"$+"!+"'$")!-!&!&
!(%&&"$ +#+"'""%")$("!& %!"!&"$+%"!+"'$*#!&"!-!%%$+/
















 






   


 
 



   




























































































































































































































































































        

&#8.+"'$+*&$!&(&%&&"'$$$"%%"' !&%-##&"!%-"$(%-!"!&$%&&"&%&&3)$&&!4
!!"&&"!%!##!*!&+!  "( !&!##!*-%%!!$!' $&"%")-!)$&&
!' $"!&%$(!&#/

&#9."$*&$!&(&+-%&"!"&& %!&""""$8/ -9/"-:/
&$%"!-!;/
! !&("$%&&& %!&""""$</8"!& 3%4-!!&!%!&"!%&%%")!
")3 +"'!!"&!!& $" &"""-)$&")!0&$.1!%$&"$9/"!:/
&$%"!"$
$&!)& %!%$& "$</:"! & 3%44.

6

8/ 

8 "$

9/"%

'$$!&

:/

&$%"!


9 '$!

&$.22222222 &$.2222222222

")

: &$

"&



7:

; "$

"&





 78 22222222222222222

























































+%

;/! !&
(
")
78

! ,

</:"!& 3%45

&"!$+

 78 " #$%"!
2222222222222222


5%!+%&!"!"$ "$$("!&"$+3%##!*4! "("!&"")$("!& %!
&"$+/

"&.!(%&&"$)!*&&"+"')+"'$"!-) !%&&+"'$"!!'+&!(%&&"$
!%%$+/"$* #-+"')!+!&+!"!"$ "$$("!&"$+"!+"'$")!-!&!&
!(%&&"$ +#+"'""%")$("!& %!"!&"$+%"!+"'$*#!&"!-!%%$+/
















 






   


 
 



   






























































































































































































































































































  




 

    

     
      
     
















       

                
!               
"                   
#               













    

       

)%               
*%                 "     
+%              
,%                  $  
      !   % 
-%     $             
       % 
.%        $    %   
/%           
0%       #       
1%    !       $   #        % 
)(%                 !  
         
))%         #           
   
)*%      !            
)+%           $  %  
),%                   
)-%               $%











  

    

              
               
  
          


















































       
 

"$")37$$")37;+#$$ )"$")0""$ ("
!%&"&'$7;$"#1,

71%#$$($0$"$$$($#1

 

'$$$' " "$#"$#$#$%$0'$""$$)
" "#$$%$"2#)#1,
%"&
67

" 

68

"#$

"#$#$#$+'$#$)#$

69

$

$"#%$$

6:

$$#

$$#

6;
6<

6=

#$
 #*

%"

" "$%$$$"$($0--+%$"+)"+$$1

'#$ "'"#" $#0--+#$ #1
"#+ "##+"#$#$$" #*'$$*$+
+"!%$$"#"#$#% #*$"#+
"##+"%##
%"0#10--+$"+%"$1"#$0#1%#%'"#

6>

"#

)$"#" $#0""##'$""$$)"1

6?

$

76

 $#

77

$$#$

 "$$#$$#$$

78

!%$#

 "$$!%$#+$#+"%"#."$"#" $#

79

%$)

)#$$$$$%#!%$)'"#" "###%#
           +  

$$"" $"#$#$$"$
#" $# "$$%"#

$$&



7:

$"%$%"#

)#$$($%0""$"1#$"%$%"##%#%#$+
 "#$"#$+ "#%$+!%#$
#'"+'$"'$%$#'"#0--+ 
1

7;

$"

)#$$$$$&)##$"##+'$"'$%$
#'"#0--+        
       1

7<

"#

 "$$0 1$"#+#+"$#."$"$#
"#" $#

7=

"$

7>

( #

"$'0

$1+##$%#"$")

"$0"/1( #+##$%#"$%$"2#
 $%"%$#











7?

$#

$#1$%&*2)!$+$$%&$# %&% #3$ !%&
#&%$

86

$

*$+$+#&%$+$$#% $+ #)#!%$ 1$%&$ #
#2$ #$ #$ $

87



 #%  # ( &%1#$# #$2%
/ #%#$#!% $

$

$ #%"&$

#$!0$!
88

%$

! #%%%$

89

'%$

$% #'%$1--+ ## 2

8:



$% # #$% # #$%

8;

#

 #%  # ( &% #1$2

8<

$$&

 #%  # ( &%$$&1$2

8=

%

 #%  # ( &%$% #%1$2 #%%1$2

8>

$ 

 #%  # ( &%'$ 1$2

8?

%

 #%  # ( &%%%1$2+!#!1$2+ ##&1$2

96

%#%$

 #%  # ( &%$%#%$

97

#%#$%$

 #%  # ( &%#%#$%$

98

% #

 #%  # ( &% %#&% #%#% #1$2

99

% #

 #%  # ( &%1  2% #1$2

9:

'

 #%  # ( &%'

9;

&

 #%  # ( &%&

9<

 !% 

 #%  # ( &% !% 

9=

 % 

 #%  # (%%$ % 1--+%#$%+$ +
$#$%+& # &$2








82 &$ %## # %%##%%)%1% $%##.$%#% #% 
 # ( #% #$!%&% #.$%% $+#$!%'*2



(%% %  ( #%%#%)%,
67

#%

#% #%  # (1--+ #%  # (%%$
! #%% #*!#%&##!&#! $2%% (%%  #%  &$
(#

68

 %)%&  %)%& #%  &%#1--+* #+( 
# %+(# # $$%#$ &#2

















 




%"" "" "!"&" "$'"%!"#"*
#" ,!""!*' #"!  #%
 34

 !"

 !""%!".%"%/

 35



%".++)!!!#""! " /

 36

'#"
!"

#" 0!' #" #"!")!!"#! 
 #.!# "$/%

 37

'#"
"" 

#" 0!' #" .#'% !  !!/#"
"" "&")!!"#!  #.!# "$/%

 38

# ' #" 0!!# '!")%" %"#"!% !.++)
!"
! "/

 39

# ' #" 0!!# '"" "&")%" %"#"!% !.++)
"" 
! "/

 3:

" #"# 

 " $'"#"  """!" #"#  
 ("!" "" "&"

 3;

!" "

!" "

 3<

"$"! #" 0!"$"!. % ""&"/)! #.!# "$/
%

 43

!

 44

%"!

&!"$%"!) !"$!)  !.++)#" !/)!
 #.!# "$/%

! !)! #.!# "$/%

 45

!

!)#!!)  #"!  !  $"""#" 0!
' #")! #.!# "$/%

  ,!""!*# ""



 46

 

#" 0! #"%"% 

 47

! 

#" 0! #"%"%! 

 48

 ""

#" 0! #""" ""

 49

 

 " %"""  

 4:

" !"

 4;

$

 4<

#  !

 " %""!#  !

 53

# #!

 " %""# #!#"

 " %""" !"
 " %"""#"- $

 54

"

 " %""%"""

 55

#"

 " %""!#".  /!'
# !.!/

 56

#"# 

 " %"""#!# '#"# ""
! 










68

&

&% !  !!/ "' &" " " "&"0
""!" " ! 

69

!#

 "! !""#!#

  -!""!+# " """
6:

!

6;

!

6<

"!

6<

"

!#!)!"')!"$"!""-"!#  
-"%
!"&"!)#"!)# !) "!""-"!#  
-"%
"!" ! "!""-"%
 ""#" 1! #"""-"!# #" -"
# !"

6=

%

74

!!

75



"""%"""#"%"'$! /,,)!!" 
,,!"#"!!"" "&"% $ 
#"! ",0







% " %/""-" $#!'%0
"""%""! !#!!!!




%""  "( ""&"  '""  " "
"!"%  "!)!"%+
 ! "!
 45

&" '

#" 1!&" ' "" #"! ! %"#!"
"" %"#"/,,)#""!!#!!" !
# 0

 46

!"

#" 1!!" "" #"! !) %"#!""
" /,,)" !" !0

 47

 "'

#" 1! "' "" #"! !) %""
"" /,,)"%!" !0

 48

!"

 49

'

#" 1!!" "" #"! !) %"#"
" /,,)!" 0
#" 1!!'# "" #"! !)#""
!# *" """"" /,,)# ' "0

"!!
 4:



"!



  /!# "0 "!"% "
#" 1!' #"! !/,,)  #""! 
""!# "!#.!# "0

















(%% )%#+ #
&#%#

&#%# %% $4..,#,&#5% * ( %$

9;

* $

$* $4..,"& %% #$,$%#$5% *( #4$5* ( %$

9<

# $$$ #% &%%$%!$ #!# $$$ *%# *%% &%% 
* &$ ,#$! $% %&% #6$#&%







 9:

*

 9;

%



(




!%4#2(#%5* #%  # ( &%%%#%)% 
!
!%4 ##2(#%5 #%  # (%%(%% %
!%4 ##2(#%5* (% &%$,$!#% $,"&$% $%%#$
4&##5


 

(%%  %&%!% %% # #% $ %%* %  (-
 9:

$&

'$&&$$&$$,## ($,  #$% &#$ #%$

 9;

#'% $

#% &%#'% $

 9<

% #*

#% (% ( #*% #*4..,)!% 3% 
' !% 5

 9=

#$%

#$%%)%$#  %#&% $

 9>

& &$

& &$)!#$$ $&& &$4..,*#!%
& &$( #/#%*0(%/:BB;05

 9?





 

(%%  #* %  (-

 9<



% #%* %  (-

9:

%%

## ##$% #%)%%%$ %% !&#! $*%
&% #% ' #&*

 9@

!#

 9A

#% 

!#$&&$&%)%& %% #%#%  #
 '% (*

 !% #&%%)%& %%$!#1 ###







 

(%% &%% #%)%# %  (!#$!%'4$5-
9:

 ##%$$

 ##%$$ $&$,$%*, ! $% 

9;

#%*

#%* #& &$$$ %&% #6$#&%

9<

%*

'%*4 ##%$$ # ##%$$5 %&% #6$#&%













37

##$)

##$)$%$"0#"%$."$$
"#/

38

#

!%$).#$"$"#/$%$"0#"%$

39

%#$##

"%#$##&"""%$%$"0#"%$

3:

 $##  $##$%$"0#"%$. #"##
"$$$#%&%/

3;

#

3<

'

43

 #

44

#" #

#" #$$%"$$#$($

45

#

!%$)"#"#

46

)##

!%$)$)##

#.#/
'.#/".#/
.%'"$$"/ #

47

$" "$$ !%$)$" "$$

48

"#









" "$##""#$$#%

"$$%$"0#"%$



'$$  $#*#$'+
$%$
34

"#

$')'"##$

35

#

$'$"$($$#"&$$#

36

%"#

$'$"$($$#"&$%"#

37

$$#

$'$"$($$#"&$$$#

38

$#

39

( #

3:

"$

3;

'

$'$"$($$#"&$$#$$$"$
$'"&$( #"$$#
$'"$"'"$$#
$')'$#"$$#

($"*")%$
3<
43

($"
""

$'$"$($$#"&$($"#%"#
$'$"$($$#"&$ ""'

44

-

$'.$ $%##"$#/$"$($( #
$" "$""-"&

45

$ "") $'$"$($$ "")&$#"##%#"&$$
$

"",# "#%#



46

#"

$'$"$($) "#.%""$"%$%"/"#"

47

( "

$'$"$($) "#( "*&$#*"##%#










6:

%#$

6;

&% #

6<

!





%(* ( %$%##'%)%#%#$1--+$
$&$$ $(%$&!#'$ #$2
%(%&% #1 #&#%#%%&$&$$ 2
%(*&##%#*!#' &$#$+ #%%#
! * (1--+ %0%$!#%!% $*
 %$$$ %(%*!#' &$#$2





(%% %  ( %$#$! $% %&% #3$#&%,
56

 % 

* % #% $1--+2(% #(% &%*#$ $
 #%

57

#%

*1& #!#%2#%(% #(% &%*&$%%  #%

58

$#%

*$#%1#%$2(% #(% &%*&$%%  #%

59

 ##%

5:

 &%$





 #%  # (%%  ##%
* &%$(% #(% &%*$%$!&%  &%%





(%% %$% #%)%*%# &%  ($,
56

 % 

* (# % 1$2 #%&% #3$#&%1--+
&% # & % %#(*2

57

' #

58

$%

59

!!*

5:

&#! $$

*"&$% $ #$%%%$#%% &$ #!#%&#
!&#! $$$&$$$#%% (#%%

5;

$!#

*"&$% $ #$%%%$%%#$!#*%&% #3$
#&%

5<

 





*"&$% $ #$%%%$' # %&% #3$#&%
*"&$% $ #$%%%$$%%&% #3$#&%
*"&$% $ #$%%%$#%(!!* (%
#%)%%  %#$%&% 

*# $%%#!# ' *%&% #3$#&%





(%%  #%% #%)% #* ( %$* %  (,



56

* 

#$ #( #% $* 1--+= #./+> #.$/2

57

#'% 

#%#'% 1--+  $. % $/2

58

&#

&#1--+6+7+82










6:

%$"

$$%$"3#)'"#" "##$$$"""$$$
 "" + $"+"$$"$($

6;

"

$$""3#)'"#" "##$$$"""$$$
 "" + $"+"$$"$($

" "#

%"* "" + $"+"$$"$($) " "#

6<
6=

"

%"* "" + $"+"$$"$($%#"

6>



%"* "" + $"+"$$"$($%#$

6?

$ "

%"* "" + $"+"$$"$($%#$ "

76

( 

%"* "" + $"+"$$"$($%#( 
$$##"$)"#"

77

 

"$#)%'%# $#$$$# 1--+
'"$'.0$0%#" $$"%$#/$
")")"(#2










'$$"*$$"$($1#"#%"2##$$$'$"),
67

%)

"#%"")!%)(1#2

68

&"$

&"$"$








92%#$%



'$$($' " "$#"$#$ %,
)# " "$#,"'"
67

)0#$"

68

#%$

 "&$)0#$"1--+  "#$$&#2
"#%$$#"

69

*

#*$#"

6:

%"$)

%"$)$"&

6;

$

'$$"&1--+ $  %$"#$
#  "#2

6<

"$$)

 "$$)%$#1--+  "#$$ )2

6=

"# "$$

#%$$)%#")$"# "$$1--+""$0
$&#$$#$$)#)$"# "$$2

6>

"#$$)

&"#$$)#% "$0$00"1--+"$)
%""$$+%'$"+$"+"%#2

6?

%#$$)

%#$$)1--+$##$  "2

)# " "$#,#$'"












43

 

($"# ")$#/--+ "# "$
/  "0"$$($#0

44

%"

45

$"#$

"$"#$/--+$"" "#$$$"#$%
'$$"%$$$$%"$%0

46

$"%#&

 $)$%$"%#&/--+ #+#$$"#+
$$"$$"%#&'"."0

47

"#"

 $)$$"#"%$$"$'#%$"
"/--+$"#"' "$$0

48

$$

 $)$$$"$$#'$#/--+  ")
$$"&"$$$$#0

49



 $)$$/--+$$"$"83
%$#"0

4:
4;
4<

$



%""#/--+$%""#$"#
" ###$$&"'"%#0

 $)$ "#"&$#$$'" #$
/--+#!%)"#0

"

 $)$%$$"$.$
 $)""/--+'%$#$"
""&#$"0

#) " "$#
53

$#

#"$%##$" "#.$"$#
/--+$"#"$ )$  " )$(*"$
$#'')"( "" "###0

54

.% 

#$.% 

55

"##%"

56

($"

&($"#$ #/--+$($(##$#$)
$#$$"!%"($"#$ $%$$"$"$($#
#0

57

$"

&.$"#$"/--+$ ##$
 "#0

58

%$

&%$#$$#/--+)'$$$#
#$% #%$&%0

59

&$)

&$)$#"$%"#$$$"

5:

$"$)

$"$)"&"$#/--+"$
'"$"#+$#+"$# "&0

$ "##%"/--+""#$$$"!%"#"$
"0

$&$#,



5;

"

" "$/#

5<

"

" $)

#$'$0""$##










41

#

42



# %
 %   ,))'   
"-

43

"! %

 % $%"! %"+# '
 *! %,))'   %
#+# ' %-

44

 !& 

 %    !& ,! %
- ! .! ,))'%
! $ !-

45

 !

" %$  ! $ 
!! ,))' ,- 
$ %  ! $ 
!! -

46

+

 %   +! 
! ,))'! !  
! -

47

! 

 % ! "% 
",-,))' # ,-   ,-
"   !-

! ( '
48



 %   $ '# ! 
! ,))'"  $   
  $ % -

49



 % ,))'#  %
   "  $ -

4:

 

 %       
"  $ ,))' !  $ 
 %   "  
  "  $  " $ 
 -

! (! 
51

 

 % ! !   ,))'
 % 
# !   -

52

  $ 

 % ! !    $ ,))'
 '  '"% 
# !    $ -

! ( 
53





 %  %  
,))'     % 
 -










54

55

$

%!

!&! !&! "!!"!. & 
"! &! "!&$!"!  ,**(
 &! ! ! & -
!&! !&! "!!"!. "! 
!  "!%! ",**( &
! !  ! %! "-

#! )! ! 
56

&

   ! !    (&
 !!! " !&! "  !
#!,!& -!!+!,$-$!
,**(!+! !!! !
!! ! # -

57

!

   ! ! !$$!,**(
!  !$!! #$! !$-

58

!!

   ! !    (!!
!,""(& !( 
!-(!!+!,$-!#"! ,**(
 !-

59

$

   ! !    ("!
$(!!!(!"!!#,**(
" !"!!!-

5:

! 

   ! ! !!  & !

61

%!

!&!%!&! (%!$! !$
"  #

#! )



62

"!"

"!!&&"!" ,**(!+! !
!( !! (! !$! $!!
&!!-

63

&

!&!!!! (& !!%!(
!#!%!,**( !&!!! !
-

64

#!&

!&!!#!&,- ,**(#!
  !-

65

!!&

!!& # $! ,**(!!(!(
 !-

66

&'

67

 

68



!&! &' # $! 
!&!" !' ,**(!!
!!!!!%!($!!"!. !"!
!&! &-
!&!&!,**( ! 
&$ ( !!(! ( ! -











13



14



#(&&$!)
#'

'
2,



2-

!



(#)!

  
2.

"

"(&&$'
 ")

2/



  #(&&$
!')








0) 



""%
 ,-




































 



         

 #% #*25% % #*254, $%%!!* #% #*0##% !!) #"&
'#'( %54% #$1-

 

(%%  %# &&%!!$ ##% %  (-
 45



%&#0 #!#%1 %#!$

 46

! 

%&!  %%

 47


#+% 

% '# #+%  %%#%)%







 

(%% % # ##%  %  (-
 45

&##%*

(# &##%*%








 

(%%  ' (#0 #$#  (1#  !%  %#! ##% %  (-
 45

'%

&! ,#'%%)%0..,5$%$%!,6$%!1








 

(%%  ' #(#0 #$#  (1% % ! ##% %  (-
45


 &$ 

% &$ $% 







 

(%%  ' (#0 #$# &!1#  !%  %# ##% %  (-



 45



!#' &$ %%

 46

%&%

)(#&##% %%$$%&%% %)% %
!%&# %%#%)%

 47

 $$%$ ) $$%$# $$  #$, #$, ###'$ 
! #%  %% $

 48

%

% %% $%% /'#*

 49



 %% $%% /'#*

 4:



 4;

/%

( %% $%  %% $%% /'#*
( %% $% %)%%% /% %%%#$%!






 .0

%#

 .1

!

#&!%# !#"#'#

 /.



 !##+"#",







#& ! #"


 

&##%&!+!"!$ ,## !!##&)
./

$!(





$#"$!(#!"# 



 

&##%&!+!"!$ ,#####"+ ,!!##&)
 ./

#"  $!$##!#" +",#&"##!"#!
#&"###!#'#








 

&##%  #+!"!$ &,!""$#  "!!##
&)
  ./

 '#&








 
&##


./




$#!!##&)
#" 

$!$##!#" +",#&"##!"#
!#&"###!#'#






 

&##*************!!##&)
./
























         

 #% #*36% % #*38, $%%!!* #% #*1##% !!) #"&
'#'( %8% #$2-



(%%  !! ##%  %  (-
56

% #*

57

#%

#'%#%$

&!% #*










(%% &$% % $.$ %(# ##%  %  (-
56

% #*

57



 #% , (, ##$ &#$

&!% #*










(%%   &% &% ##%  %  (-
 56

 !#$ 

%% !#$ %( %%%$%% % $

 57

*/$%#

#'%*$%#










(%% &$$!#% % ##%  %  (-
56

&#%#

57

&#* #% ($&#* %%#%)%

#% (&#%#% %% (%% &#%1$##2










(%% &%+% )%#
 56

 !#$ 

 57

&%/%$





 1$2 ##%  %  (-

%% !#$ %( %%%$%% % $
%%&%/%$





(%%  ,&$0000000000000 ##%  %  (-
56



















 

  


      

1/ %# $$($.$ "$$ $($/

  '$$ $  '!" !"$# "$# $

#$ %$.'$" " $$)"!"#$$%$ "0#)#/,

2/ %# $"" " $$""$$($.$ #$""-#$"$

 "$  " ' "$ "#!$%$ "-#$$ #+"#!$&)/

  '$$ $  ' "$$"$($,
   '$$ "$$!"$# $($ $&) 
$  '#$ %$,
 ! '$$ !" "$*!"$ $($")$$
" ! "$ "$"$ #!$'! "$#+#
$  ',
 " '$$ ($"* "
$ "$) $  ',
 # '$$  ") $  ',
 $ '$$ $%$!$ $$ " "$ # $$)
 $  ',
 % '$$ %$$ "$($" $  '!"#!$&.#/,
 & '$$   $#+#$  ',
  '$$ $  ' $#"#! #$ $%$ "0#
"%$,
  '$$ $#$ "$($)$" %$  '
#,
  '$$  "$$ "$($ ") ' $#) $
  ',
   '$$  "*$$"$($.#"# %"/##$$ 
$  '$ "),

3/ %# $%

 ! '$$ ($  '!" !"$# "$# $
%,

4/ $"

 " '$$  $  ',






















    


  &##  #!$$#  "!!##&'
  &###  !!!##&'
  &##% &!)!"!&*! ##! 
!!##&'
  &##%!&!)!"!&*##  !!##
&'
  &##% &!)!"!$ *! ##! 
!!##&'
  &##%&!)!"!$ *## !!##
&'

   &##%&!)!"!$ *#####") *!!
##&'
 ! &##%  #)!"!$ &*!""$#  "
!!##&'
 " &##
$#!!##&'
  &##(((((((((((((!!##&'











        


















 #
 $#
  #
 #
!  
&'#
"%%%%%%%%%%%%%#





Appendix J.1: Invitation/recruitment email message to old participants in previous phases
for the video study and follow-up interviews in the fourth and fifth phases
Re: Dissertation Observation - Current Active Reading Practices in Academic Settings
Dear ___________,
This is HyunSeung Koh, the doctoral candidate in the Department of Information and
Library Science, School of Informatics and Computing at Indiana University,
Bloomington, who recently did a follow-up interview with you about annotations in the
text and/or in page margins on your reading materials and/or notes in separate note pads.
First of all, thanks a lot again for providing your materials and participating in the followup interview! Also, thanks for letting me contact you via email to confirm your interest in
participating in the follow-up phase of observation. The main goal of the observation is to
collect data about behavioral and non-behavioral aspects of your active reading while you
are reading, using video teleconferencing technology.
If you agree (by replying back to me by email), you will be invited, at a date and time
that is convenient for you, to come to a conference room in the Collaboration
Technologies office (W305) of University Information Technology Services (UITS) on
the third floor of the Wells Library, Indiana University Bloomington (IUB).
Participation in this study is completely voluntary. For more information about the
observation study, including procedures, time commitment, the video teleconferencing
technology, etc., please read the Study Information Sheet attached.
As a token of gratitude, I will send you a $20 Amazon gift card via email upon
completion of the observation session (for further details about the gift card, see
http://www.amazon.com/gp/gc/ref=topnav_giftcert).
Thank you very much in advance!
Best regards,
HyunSeung Koh
Doctoral candidate
Department of Information and Library Science
School of Informatics and Computing
Indiana University
Bloomington, IN, USA



Appendix J.2: Invitation/recruitment email message to (electronic) mailing lists for the
video study and follow-up interviews in the fourth and fifth phases
Re: Dissertation Observation - Current Active Reading Practices in Academic Settings
Dear subscribers,
This is HyunSeung Koh, a doctoral candidate in the Department of Information and
Library Science, School of Informatics and Computing at Indiana University,
Bloomington.
Recently, I have done part of my dissertation study including a survey about reading
practices, a study of annotation (e.g., underlines, highlights, notes in page margins or in
notepads), and follow-up interviews. As a further follow-up study, I now need to conduct
lab-based observations and recruit about 15 participants (i.e., three groups of five
participants who will read their own text from their own preferred reading device: paper,
a laptop computer, or iPad) who meet all the following criteria:
1) Be a Ph.D. student
2) Have English as your first (native) language
3) Use diverse reading formats (paper-based and digital-based) and tools in your daily
academic life and have a strong preference for a particular reading device: paper, a laptop
computer, or an iPad
4) Have an active reading task at hand (e.g., reading for qualifying exams, lectures,
presentations, or writing a paper)
5) Be able come to the lab in the Wells’ library at Indiana University Bloomington.
The main goal of the observation is to collect data about behavioral and non-behavioral
aspects of your active reading while you are reading, using video teleconferencing
technology.
If you agree (by replying back to me by email), you will be invited, at a date and time
that is convenient for you, to come to a conference room in the Collaboration
Technologies office (W305) of University Information Technology Services (UITS) on
the third floor of the Wells Library, Indiana University Bloomington (IUB).
Participation in this study is completely voluntary. For more information about this
observation study, including procedures, time commitment, the video teleconferencing
technology, etc., please read the Study Information Sheet attached.
As a token of gratitude, I will send you a $20 Amazon gift card via email upon
completion of the observation session (for further details about the gift card, see
http://www.amazon.com/gp/gc/ref=topnav_giftcert).
Thank you very much in advance!



Best regards,
HyunSeung Koh
Doctoral candidate
Department of Information and Library Science
School of Informatics and Computing
Indiana University
Bloomington, IN, USA
P.S. Apologies for duplicate posting if you have already received or keep receiving this
email from other liserves or people.



Appendix J.3: Invitation/recruitment email message to directors, associate deans, and
secretaries for the video study and follow-up interviews in the fourth and fifth phases
Re: Dissertation Observation - Current Active Reading Practices in Academic Settings
Dear Dr. _________________
I am HyunSeung Koh, a doctoral candidate in the Department of Information and Library
Science, School of Informatics and Computing at Indiana University, Bloomington.
Recently, I have done part of my dissertation study including a survey about reading
practices, a study of annotation (e.g., underlines, highlights, notes in page margins or in
notepads), and follow-up interviews. As a further follow-up study, I now need to conduct
lab-based observations and recruit Ph.D. students.
Can you help me by posting the following message on listservs to which doctoral
students in your department or school subscribe? Or can you help me by forwarding this
email to others who might be able to post the message on listservs to which doctoral
students in your department or school subscribe?
Thank you in advance!
Best regards,
HyunSeung Koh
Doctoral candidate
Department of Information and Library Science
School of Informatics and Computing
Indiana University
Bloomington, IN, USA
-----------------------------------------------------------------Re: Dissertation Observation - Current Active Reading Practices in Academic Settings
Dear subscribers,
This is HyunSeung Koh, a doctoral candidate in the Department of Information and
Library Science, School of Informatics and Computing at Indiana University,
Bloomington.
Recently, I have done part of my dissertation study including a survey about reading
practices, a study of annotation (e.g., underlines, highlights, notes in page margins or in
notepads), and follow-up interviews. As a further follow-up study, I now need to conduct
lab-based observations and recruit about 15 participants (i.e., three groups of five

 

participants who will read their own text from their own preferred reading device: paper,
a laptop computer, or iPad) who meet all the following criteria:
1) Be a Ph.D. student
2) Have English as your first (native) language
3) Use diverse reading formats (paper-based and digital-based) and tools in your daily
academic life and have a strong preference for a particular reading device: paper, a laptop
computer, or an iPad
4) Have an active reading task at hand (e.g., reading for qualifying exams, lectures,
presentations, or writing a paper)
5) Be able come to the lab in the Wells’ library at Indiana University Bloomington.
The main goal of the observation is to collect data about behavioral and non-behavioral
aspects of your active reading while you are reading, using video teleconferencing
technology.
If you agree (by replying back to me by email), you will be invited, at a date and time
that is convenient for you, to come to a conference room in the Collaboration
Technologies office (W305) of University Information Technology Services (UITS) on
the third floor of the Wells Library, Indiana University Bloomington (IUB).
Participation in this study is completely voluntary. For more information about this
observation study, including procedures, time commitment, the video teleconferencing
technology, etc., please read the Study Information Sheet attached.
As a token of gratitude, I will send you a $20 Amazon gift card via email upon
completion of the observation session (for further details about the gift card, see
http://www.amazon.com/gp/gc/ref=topnav_giftcert).
Thank you very much in advance!
Best regards,
HyunSeung Koh
Doctoral candidate
Department of Information and Library Science
School of Informatics and Computing
Indiana University
Bloomington, IN, USA
P.S. Apologies for duplicate posting if you have already received or keep receiving this
email from other liserves or people.




Appendix J.4: List of schools and departments that offered doctoral programs at Indiana
University Bloomington as of September 5, 2013
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•

African American and African Diaspora Studies
American Studies
Anthropology
Astronomy and Astrophysics
Biochemistry
Molecular and Cellular
Biology,
Central Eurasian Studies,
Chemistry,
Classical Studies,
Cognitive Science,
Communication and Culture,
Comparative Literature,
Criminal Justice,
East Asian Languages and Cultures,
East Asian Studies,
Economics,
English,
Gender Studies,
Genetics,
Folklore and Ethnomusicology,
French and Italian,
Geography,
Geological Sciences,
Germanic Studies,
History,
History of Art,
History and Philosophy of Science,
Linguistics,
Mathematics,
Near Eastern Languages and Cultures,
Neuroscience,
Philosophy,
Physics,
Political Science,
Psychological and Brain Sciences, Religious Studies,
Second Language Studies,
Slavic Languages and Literatures,
Sociology,
Spanish and Portuguese,



•
•
•
•
•
•
•
•
•
•
•
•
•
•

Speech and Hearing Sciences,
Statistics,
Telecommunications,
Theatre and Drama,
Jacobs School of Music,
Kelley School of Business,
Maurer School of Law,
School of Education,
School of Informatics and Computing,
School of Journalism,
School of Medicine,
School of Optometry,
School of Public and Environmental Affairs,
School of Public Health.

Source: http://iub.edu/academic/majors/by-school.shtml



Appendix K: Scheduling email message to the finalized 22 participants for the video
study and follow-up interviews in the fourth and fifth phases
Re: Dissertation Observation - Current Active Reading Practices in Academic Settings
Dear___________,
In order to finalize your date and time, I created a Doodle poll.
Please follow the following steps;
•
•
•

First, go to http://doodle.com/86wcapdbig22yq68
Second, enter your ID#________ that I created only for you, NOT your real name
for protecting your privacy.
Third, check one slot as your convenient date and time, but do not select any slot
that previous participants check it already. (If you cannot find any slot as your
convenient date and time, please email me.)

Best regards,
HyunSeung Koh
Doctoral Candidate
Department of Information and Library Science
School of Informatics and Computing
Indiana University
Bloomington, IN, USA



Appendix L: Instructions for the video study from the IRB study information sheet
You are invited to participate in a research study aimed at understanding active reading in
academic settings. You were selected as a possible subject for the current ‘observation’
phase of this study because you participated in the follow-up interview about
annotations/notes on your reading materials or in the notepads you provided. We ask that
you read this form and ask any questions you may have before agreeing to be in the
study.
This study is being conducted by HyungSeung Koh, a doctoral student in the Department
of Information and Library Science, School of Informatics and Computing, and
supervised by Dr. Susan Herring. This study is funded by an internal award from the
University Graduate School, Indiana University Bloomington.
STUDY PURPOSE
The main purpose of the ‘observation’ phase of this study is to understand your active
reading behaviors by collecting data about behavioral and non-behavioral aspects of
active reading, such as annotations/notes on reading materials or in notepads, facial
expressions, hand movements (e.g., flipping through pages, highlighting, note-taking,
web-surfing), and other physical activities (e.g., printing).
PROCEDURES FOR THE STUDY:
If you agree to be in this phase of the study, you will do the following:
1) Step 1: Greeting (about 10 minutes)
You will come to the lab* with your own reading materials**, devices (e.g., paper,
iPad, laptop), and additional tools*** (e.g., highlighter pens, notepad, dictionary,
music player, iPad, laptop), as scheduled.
The investigator will greet you, show you around the lab (including the locations of
cameras), the investigator’s room (next to the lab), and the location of a printer (if
necessary), and explain all procedures (the same as in the Study Information Sheet) in
brief.
Then, while the investigator is connecting your laptop or iPad (if you bring one) to a
monitor and turning on cameras and a camcorder, you will be asked to fill in the
information sheet provided (see Appendix A). You may keep this sheet and revise it
later (if you wish), but you will need to submit it to the investigator at the end of the
observation session.
* The lab will be either a conference room in the Collaboration Technologies office
(W305), University Information Technology Services (UITS), Indiana University
Bloomington (IUB), located on the third floor of the Wells Library, or a conference room
(LI 036) in the Department of Information and Library Science, IUB, on the ground floor
of the Wells Library.



** Your own reading materials should be for academic, active reading such as reading for
writing papers, reading for taking exams, reading for preparing lectures, etc.
*** This study is designed to collect as naturalistic data as possible. Thus, please try to
bring all the tools you have been using for your active reading in the past and also let me
know via email beforehand if there is anything that you need but that is not portable, such
as a printer.
2) Step 2: Reading (about an hour)
You will sit and read your reading materials using your own reading devices for about
an hour****. Be prepared to answer two questions right after you finish reading about
what the texts are about and how you read to achieve your purposes for reading. Your
active reading behaviors will be observed and recorded from outside the lab using video
teleconferencing technology (see Appendix B).
The investigator will knock on your door after about an hour to ask you to stop reading.
Last, the investigator will turn off the cameras and the camcorder.
**** You may take short breaks by letting the investigator know in the room next to the
lab.
3) Step 3: Coding (about 30 minutes)
The investigator will ask you two questions about what the texts are about and how
you read to achieve your purposes for reading.
Next, you will be asked to write down***** your intention(s)/reasons(s) for doing each
instance of annotation in the proximity of each instance on paper or in digital form. You
may select your intention(s)/reason(s) from the coding item(s) in the code book provided
or you may create your own coding items and add them to the code book.
The investigator will ask you to stop coding after about 30 minutes. You will be asked to
submit the information sheet, your reading materials, including annotations/notes and/or
your notepads on paper or in digital formats, and the outcomes of your coding.
***** It is desirable that you finish coding all your instances of annotations/notes.
However, if you think you have made many annotations/notes and cannot finish coding
all of them within the 30-minute timeframe, please code only the most important
annotations/notes.
4) Step 4: Debriefing (about 30 minutes)
The investigator will ask you questions about your active reading behaviors such as
“Why did you flip a page here?”, while showing you clips of video footage and recording
using a voice recorder and taking notes.
5) Step 5: Closing (about 10 minutes)



The investigator will wrap up the session by offering you a $20 Amazon gift card and
inviting you to participate in a follow-up interview.
CONFIDENTIALITY
Efforts will be made to keep your personal information confidential. We cannot
guarantee absolute confidentiality. Your personal information may be disclosed if
required by law. Your identity will be held in confidence in reports in which the study
may be published.
Organizations that may inspect and/or copy your research records for quality assurance
and data analysis include groups such as the study investigator and his/her research
associates, the Indiana University Institutional Review Board or its designees, and (as
allowed by law) state or federal agencies, specifically the Office for Human Research
Protections (OHRP), who may need to access your research records.
PAYMENT
I will send you a $20 Amazon gift via email immediately after the observation
session is finished. (Please refer to further details about the gift card at
http://www.amazon.com/gp/gc/ref=topnav_giftcert)
CONTACTS FOR QUESTIONS OR PROBLEMS
For questions about the study, contact the researcher, HyungSeung Koh, at 812-857-1614
or by email at hskoh@indiana.edu.
For questions about your rights as a research participant or to discuss problems,
complaints or concerns about a research study, or to obtain information, or offer input,
contact the IU Human Subjects Office at (812) 856-4242 or (800) 696-2949.
VOLUNTARY NATURE OF THE STUDY
Taking part in this study is voluntary. You may choose not to take part or may leave the
study at any time. Leaving the study will not result in any penalty or loss of benefits to
which you are entitled. Your decision whether or not to participate in this study will not
affect your current or future relations with Indiana University or the Department of
Information and Library Science.



Appendix M: Information sheet for the video study
Date and time you enter the lab (e.g., April 14, 2011, 6:00 P.M.):___________________
Your full name (e.g., Emily
Jackson):_______________________________________________
Your major(s) (e.g.,
English):______________________________________________________
Your academic status (e.g., Ph.D.
student):___________________________________________
Your email address (e.g.,
hskoh@indiana.edu):________________________________________
Title(s) of reading material(s):_______________________________________________
________________________________________________________________________
________________________________________________________________________
________________________________________________________________________
The purpose(s) of reading (e.g., reading for class participation):_____________________
________________________________________________________________________
________________________________________________________________________
________________________________________________________________________
Reading device(s) which you bring to the lab (e.g., paper books, Amazon Kindle):______
________________________________________________________________________
________________________________________________________________________
________________________________________________________________________
Other tool(s) which you bring to the lab (e.g., highlighter pens):____________________
________________________________________________________________________
________________________________________________________________________
________________________________________________________________________
Prior knowledge (yes or no):___________________________
Motivation and interest (high or low):____________________
Text readability (easy or difficult):_______________________
Any additional comments (if any):____________________________________________
________________________________________________________________________
________________________________________________________________________
________________________________________________________________________



Appendix N: Examples of coding from the pilot study





Appendix O: An example of observation notes for the video study



 

Appendix P: Preliminary questions for follow-up interviews in the fifth phase
First of all, thanks a lot for your participation! As you know, this study is designed to
understand your active* (or scholarly) reading experience in the context where you read
books/articles, along with annotations**, to fulfill your scholarly reading purposes.
I reviewed video clips, your codebooks, and your reading materials including annotations
or/and notes. Today, I am here to listen to your active reading practices from your own
perspective and also talk about what I found from video clips, your codebooks, and your
reading materials from my own perspective.
Some exemplary questions are as below:
I found interesting movements and annotations and notes in your reading materials. Can
you tell me what they mean and why you did?
Can you kindly clarify what they mean in your codebooks?
Do you have any other comments you want to add?
Thank you so much for your participation! If you have any questions, please feel free to
email me at hskoh@indiana.edu.
*Active reading is defined as ‘a skilful/expert reader’s purposeful/effortful reading, in
which s/he employs (more) active processes, throughout the course of reading to go
beyond the literal level of comprehension, as opposed to leisurely reading, regardless of
an issue on whether active and passive processes are separable or inseparable.’ (More)
active processes are defined as reading processes where readers employ two reading
processes of ‘deeper comprehending’ (to understand the writer’s intended meanings
completely) and ‘learning’ (to acquire content knowledge) most of time, while spending
little time ‘memorizing’ (for accurate recall for later tests), ‘skimming’ (to grasp the main
topic quickly), and ‘scanning’ (to find target information). **Annotations in this study
mean everything except for the original text, such as text in page margins, underlines,
highlights, a memo in a separate notepad or sticky notes, and the like. Annotation is the
action of doing annotations.]




Appendix Q.1: The codebook after the video study and follow-up interviews: Static
(written) annotations/notes

Category#1. The reader wants to make the following properties or elements of a text [TX] stand out
(whether or not they represent the author’s key ideas):
OLD/
Code #
Descriptions
NEW
Surface level
OLD
TX01
Bibliographic information about the entire text
OLD
TX03
Title or subtitle
OLD
TX04
Footnotes
OLD
TX05
A whole list of parallel words or concepts
OLD
TX06
Terms, phrases, or sentences that are emphasized with italicization, boldface, or
quotation marks or sentences including emphasized terms, phrases, or clauses
OLD
TX07
Numeral(s) or sentence(s) including such words
OLD
TX08
Key terms or concepts (regardless of whether or not they are defined)
OLD
TX09
The definition of a term or a concept or sentences that are definitional
OLD
TX10
(Names or captions of) important tables or figures
OLD
TX11
Important statistical data
NEW
TX13.1 Resources in Notes
NEW
TX13.2 Researchers in Acknowledgements
Content level
OLD
TX14
Highly salient textual (or rhetorical) structures such as cause and effect, comparison
and contrast, problem and solution, and question and answer, with or without signal
words
OLD
TX16
Important (applied) theories, models, effects, and/or their definitions or descriptions
OLD
TX18
Practical (real-life) examples, as distinguished from the author’s conceptual arguments
OLD
TX19.1 Fundamental work for a topic
OLD
TX20
Key ideas, beliefs, arguments, assertions, or excerpts of (distinguished or credible)
scholars or schools in a field
More discipline specific
NEW
TX24.1 The name of (anthropological) field site
NEW
TX24.2 Secondary data source(s)
NEW
TX32.1 Information or knowledge about criteria
NEW
TX36.1 Information or knowledge about a mechanism
NEW
TX36.2 Information or knowledge about a logic behind the statistics
NEW
TX36.3 Information or knowledge about the author’s objection against other researchers’
arguments


Category#2. The reader wants to tag [TG] the following for the entire text:
OLD/
Code #
Descriptions
NEW
OLD
TG01
Target information or knowledge that the reader wants to or needs to focus on while
reading
NEW
TG03
Reference citation based on a particular citation style (e.g., APA)










Category #3. The reader wants to differentiate parts of a text selectively [SL] and make each of the
following stand out:
OLD/
Code #
Descriptions
NEW
The author’s intentions: key arguments or background knowledge
NEW
SL00.1 Key conjunction (e.g., ‘and’ as opposed to ‘or’)
NEW
SL02.1 Key term(s)
NEW
SL02.2 Key word(s) of the author’s key argument
OLD
SL03
The author’s key argument or idea about a section, as distinguished from background
(supportive) knowledge
OLD
SL04
The author’s key argument or idea about the entire text, as distinguished from
background (supportive) knowledge
OLD
SL06
The author’s summary of the entire text, with or without signal words
OLD
SL08
Abstract
NEW
SL08.1 Contextual information (in the section of Forward) for writing the entire text
OLD
SL09
The author’s motivations or background information, as background (supportive)
knowledge
NEW
SL09.1 Objectives
OLD
SL10
Research gaps (new contributions), as background (supportive) knowledge
OLD
SL11
Existing viewpoints, perspectives, or approaches, as background (supportive)
knowledge
NEW
SL11.1 Research question(s)
NEW
SL11.2 Method(s)
OLD
SL12
Finding(s), conclusions, or arguments from research relevant to the author’s key
argument, as background (supportive) knowledge
NEW
SL12.1 Key information in Discussion/Implications
NEW
SL12.2 Limitation(s)
The reader’s intentions: current engagement
OLD
SL13
The author’s argument with which the reader agrees
NEW
SL13.1 The author’s argument about which the reader has thought about before
OLD
SL14
The author’s argument with which the reader disagrees
OLD
SL16
Information or knowledge that the reader needs to remember (as a reminder)
NEW
SL16.1 Information or knowledge that the reader likes
OLD
SL17
Information or knowledge that the reader finds interesting
OLD
SL18
Information or knowledge that the reader finds thought-provoking/inspiring
OLD
SL19
Information or knowledge that the reader finds surprising
NEW
SL19.1 Information or knowledge that the reader finds counter-intuitive (unexpected) content
OLD
SL21
Information or knowledge that the reader wants to cite
OLD
SL24
Index words or phrases (directly copied or extracted from the original text) that the
reader selected for a later search
OLD
SL25
Information, knowledge, articles or books that the reader finds useful
NEW
SL25.1 Information or knowledge that is relevant to the reader’s personal research
NEW
SL25.2 Information or knowledge that is relevant to the reader’s teaching
NEW
SL25.3 Information or knowledge that is relevant to the reader’s group project(s)
NEW
SL25.4 Information or knowledge that is relevant to the reader’s test
NEW
SL25.5 Information or knowledge that is relevant to document(s) the reader read before
NEW
SL25.6 Section(s) that the reader will skip this time
The reader’s intentions: further action to be taken
The meanings of text, equations, figures, or tables that the reader is not sure of or does not know
OLD
SL27
NEW
SL27.1 Information or knowledge that the reader is questioning or doubting
OLD
SL29
New information or knowledge (that the reader did not previously know)
NEW
SL31.1 Reference(s) that the reader (might) want or need to cite
NEW
SL31.2 Reference(s) that the reader finds interesting
NEW
SL31.3 Reference(s) in the body of text that the author introduces




Category #4. The reader wants to prioritize a part of a text hierarchically [HR] and indicate the
degree of importance or the relationship between or among importances, as in the following:
OLD/
Code #
Descriptions
NEW
Degrees of importances
OLD
HR01
The author’s extremely important arguments or ideas or what the reader must look at
later without fail
NEW
HR01.1 The author’s arguments or ideas that are extremely important from the reader’s
(research) perspective.
OLD
HR02
The author’s most important arguments or ideas or what the reader must look at later
NEW
HR02.1 The author’s arguments or ideas that are most important from the reader’s (research)
perspective.
OLD
HR03
The author’s moderately important arguments or ideas or what the reader might look
at later
NEW
HR03.1 The author’s arguments or ideas that are moderately important from the reader’s
(research) perspective.
OLD
HR04
The author’s least important arguments or ideas or what the reader could look at later
NEW
HR04.1 The author’s arguments or ideas that are least important from the reader’s (research)
perspective.
Relationships
NEW
HR06.1 Between a subject (a topic) and its details
NEW
HR06.2 Between a higher level of explanation and its deeper levels of explanation


Category #5. The reader wants to externalize or monitor [MN] thinking by doing the following:
OLD/
Code #
Descriptions
NEW
OLD
MN02
Adding symbols to key word(s) in the reader’s own notes
OLD
MN03
Writing out the steps or processes of the reader’s thinking from the initial thought to
the final conclusion, in response to the author’s argument


Category #6. The reader wants to enhance [EN] recall and/or quick retrieval by doing the following:
OLD/
Code #
Descriptions
NEW
OLD
EN01
Repeating (re-writing) or reviewing key information or knowledge about the entire
text in one place
NEW
EN01.1 Repeating (re-writing) or reviewing key term(s) in page margins
NEW
EN01.2 Repeating (re-writing) or reviewing key information or knowledge that the reader did
not know (new knowledge)
NEW
EN01.3 Repeating (re-writing) or reviewing key information or knowledge that the reader did
not think about
NEW
EN01.4 Repeating (re-writing) or reviewing key information or knowledge that the reader is
not sure about meaning
NEW
EN01.5 Repeating (re-writing) or reviewing key information or knowledge that does not make
sense to the reader
NEW
EN01.6 Repeating (re-writing) or reviewing key information or knowledge that the reader
thinks interesting
NEW
EN01.7 Repeating (re-writing) or reviewing key information or knowledge that the reader
thinks important
OLD
EN02
Repeating (re-writing) or reviewing key information or knowledge that the reader
wants to cite
NEW
EN02.1 Repeating (re-writing) or reviewing resources that the reader uses later






Category #7. The reader wants to articulate [AR] implicit content or elaborate concise content by
doing the following:
OLD/
Code #
Descriptions
NEW
NEW
AR04.1 Adding lines to a graph
NEW
AR04.2 Translating an image, a graph, or a formula into descriptions in written statements
OLD
AR05
Making ambiguous expressions unambiguous
NEW
AR08.1 Identifying information or explanation (missed or unknown) that the author does not
articulate
NEW
AR08.2 Identifying word(s)/term(s) that the reader does not know
NEW
AR08.3 Identifying information or knowledge that the reader does not understand
NEW
AR08.4 Identifying a rationale underlying the author’s arguments


Category #8. The reader wants to evaluate [EV] the original text from the following perspective(s):
OLD/
Code #
Descriptions
NEW
OLD
EV01
The correctness of English usage, style, and composition
OLD
EV02
The clarity or ambiguousness of the author’s argument
OLD
EV03
The validity (correctness or incorrectness) of the author’s argument
OLD
EV07
The completeness of the author’s argument (gaps in logic or missing information that
should have been included)
NEW
EV10.1 Missing or wrong assumption(s)
NEW
EV11.1 Discrepancies against the reader’s prior knowledge
NEW
EV11.2 Missing information that should have been provided
NEW
EV11.3 Redundancy of information
NEW
EV11.4 The quality of definition(s)
OLD
EV12
The quality of research design
NEW
EV12.1 Research methods
NEW
EV12.2 Research tools/equipment
OLD
EV13
The quality of data analysis
OLD
EV14
The quality of interpretation
NEW
EV15.1 The quality of a graph


Category #9. The reader wants to link [LN] elements, as in the following:
OLD/
Code #
Descriptions
NEW
Within one document
OLD
LN07
Between (explicitly directed or logically related) information or knowledge in two
different locations or across multiple locations (or within one same page or across
distant pages)
NEW
LN07.1 Between comparative information (e.g., headings, independent and dependent
variables) in different locations
External, or beyond one document
OLD
LN10
Between the original text and its relevant prior knowledge
OLD
LN11
Between (the conceptual assertions of) the original text and examples of their practical
or real-life relevance
The reader’s personal use
OLD
LN13
Between the original text and the reader’s personal (current or future) research
NEW
LN13.1 Between the original text and the reader’s question(s) that the reader has thought
about before
OLD
LN15
Between the reader’s own notes and their relevant external materials
OLD
LN16
Between the reader and the author (for further intellectual discussion)




Category #10. The reader wants to add [AD] the following comments in response to the author’s
argument:
OLD/
Code #
Descriptions
NEW
OLD
AD03
The reader’s disagreement (criticism) with or without justification for it
NEW
AD05.1 Questions that the reader wants to ask to the author or other colleagues
NEW
AD05.2 The reader’s notes about definition(s) of concept(s)
NEW
AD05.3 The reader’s reminder points for future reading


Category #11. The reader wants to extend [EX] ideas in the original text by introducing the following
ideas:
OLD/
Code #
Descriptions
NEW
OLD
EX01
The reader’s own recommendation(s) for the author’s argument
NEW
EX01.1 The reader’s additional interpretation(s) or solution(s) that the author missed
NEW
EX01.2 The reader’s own interpretation or prediction about what the reader has not known
before (brainstorming)
NEW
EX01.3 Additional lines or arrows that the author might have missed in a diagram
OLD
EX02
The reader’s questions or statements in favor of the author’s argument
OLD
EX05
The reader’s questions or statements created to be used for particular purposes such as
dissertation writing and teaching
OLD
EX06
The reader’s questions or statements that are inspired by the author’s argument
NEW
EX07.1 The reader’s joke


Category #12. The reader wants to shorten [SH] the original text or the reader’s own notes by doing
the following:
OLD/
Code #
Descriptions
NEW
OLD
SH01
Transforming a word into a symbol
OLD
SH02
Using or creating an abbreviation
NEW
SH02.1 Writing down “Q&A” to represent the question and answer form of a statement
OLD
SH03
Numbering
OLD
SH04
Noting the author’s key words or phrases that trigger recall of the content of a
paragraph, a chapter, or the entire text
OLD
SH06
Summarizing a paragraph, a chapter, or the entire text by paraphrasing
OLD
SH08
Summarizing a paragraph, a chapter, or the entire using a table



Category #14. The reader wants to deploy the following properties or elements of the medium [MD]:
OLD/
Code #
Descriptions
NEW
Physical properties: hardware
OLD
MD01
The prevention of eye-strain
OLD
MD02
The resolution of the screen
OLD
MD03
The size of the screen and the device
NEW
MD03.1
Holding experience
NEW
MD03.2
Codex book form factors
NEW
MD03.3
Computational power for running particular software
OLD
MD05
The weight of the reading device
OLD
MD06
The portability of documents
NEW
MD06.1
The capability to hold or carry multiple books
OLD
MD07
The suitability of use for daily transportation



OLD
MD08
The versatility of supporting one-the-go-reading
NEW
MD08.1
Hardware separation between or across reading-related tasks
OLD
MD9
Sustainability
NEW
MD09.1
Tactile, tangible, or touchable experience
NEW
MD09.2
Handwriting interaction with a hand (for better remembering)
NEW
MD09.3
Electricity independent
NEW
MD09.4
No technical glitch
NEW
MD09.5
Hardware that facilitates annotations
Physical properties: software
OLD
MD10
Extra space for adding the reader’s notes
NEW
MD10.1
Enough space for in-between lines
OLD
MD11
The number of colors
OLD
MD12
Color contrast
NEW
MD12.1
Text-size adjustability
NEW
MD12.2
Zoomability
NEW
MD12.3
The capability to expend a screen into a full screen
NEW
MD14.1
The capability to manipulate a page layout
OLD
MD15
The capability to annotate or take notes with ease and with speed
NEW
MD15.1
Selectability of text that enables to copy and paste easily
NEW
MD15.2
Ease to select text
OLD
MD17
The capability to preserve the last location where the reader stopped reading
OLD
MD19
The capability for offline reading
Psychological properties
OLD
MD20
Ease and comfort of use stemming from personal long-term habits
NEW
MD20.1
Non-steep learning curve (intuitive to use)
NEW
MD20.2
Ease to focus on reading for a long period of time
OLD
MD21
Ease of data back-up
OLD
MD23
The convenience of no extra steps
NEW
MD23.1
Ease to manipulate tools
OLD
MD24
The convenience of long-term storage
NEW
MD26.1
High efficiency of time and resource management
NEW
MD27.1
Controllability of turning on and off the reader or others’ annotations
Cognitive benefits: enhancing
OLD
MD29
Search capability
NEW
MD29.1
Quick to go to a particular location
NEW
MD29.2
Ease to move and jump around pages
NEW
MD29.3
Quick to scan and find information
NEW
MD30.1
Hand-writing recognition for searching for hand-written notes
OLD
MD31
The capability to facilitate recall
NEW
MD31.1
Better sense of order
NEW
MD31.2
Better sense of special remembering
OLD
MD32
The capability to express the reader’s individuality via hand-writing, as opposed to a
machine’s uniformity
NEW
MD33.1
The capability to facilitate skimming
NEW
MD35.1
Ease of multitasking
Visual benefits: bracketing, anchoring
OLD
MD37
The capability to bracket or enclose a big block of text, without underlining or
highlighting
OLD
MD38
The capability to anchor
Visual benefits: bringing out
OLD
MD40
The capability to bring out global ideas about the entire page
NEW
MD41.1
The capability to rank my notes by bringing out more important notes upfront
Behavioral benefits: transitions
OLD
MD46
The seamlessness of transitions between reading and writing



OLD
MD49
The seamlessness of transitions from reading to a database system/a filing system
OLD
MD50
The capability to export the reader’s notes
NEW
MD50.1
The capability to interact with other software
NEW
MD50.2
Ease to switch between tools
NEW
MD50.3
Ease to switch between different modes of highlighting
Behavioral benefits: managing
OLD
MD52
The capability to facilitate making notes, copying and pasting text, and retrieving text
OLD
MD54
Compatibility across diverse hardware platforms
OLD
MD55
The capability to synchronize across diverse hardware platforms
NEW
MD55.1
The capability to access data from anywhere
NEW
MD56.1
The capability to automatize meaningful file names
Behavioral benefits: speed of reading
NEW
MD57.1
The capability to adjust the speed of reading according to the depth of reading
Behavioral benefits: vocalize
NEW
MD57.2
The capability to assist spoken reactions to text
Social benefits
OLD
MD58
The capability to share
Socio-economic aspects
OLD
MD61
The price of reading devices
Cultural aspects
OLD
MD62
Ownership of books
OLD
MD63
Cultural norms of acceptability
Environmental aspects
NEW
MD64
Controllability of distraction against active reading
NEW
MD64.1
Controllability of white noise
NEW
MD64.2
Enough physical or virtual space for multiple tasks while reading
NEW
MD65
Capability to support non-academic activities while reading (e.g., drinking coffee,
checking a phone for checking time or notified alerts, taking a break for taking a rest
or having a reflecting time, reading or writing for leisure, reading news, listening to
music, checking personal emails, changing reading locations for being refreshed)





Appendix Q.2: The codebook after the video study and follow-up interviews: Dynamic
movements

Category #1. The reader wants to flip [FLIP] through multiple pages in order to do the following:
OLD/
Code #
Descriptions
Code#
NEW
OLD
FLIP01 Check the number (or percentage) of the remaining pages
MD17.1
(NEW)
OLD
FLIP02 Scan the upcoming content
LN07
MD29.3
OLD
FLIP03 Check the overall organization or structure of the entire text
LN07
MD29.3
NEW FLIP04 Check through headings
LN07.1
MD29.3
NEW FLIP05 Review the reader’s annotations
LN08
EN03
Category #3. The reader wants to move forward (or scroll down) [FOR] from one page to another in
order to do the following:
OLD/
Code #
Descriptions
Code#
NEW
OLD
FOR02
Skip non-relevant, unimportant, or useless section(s)
SL25.6
OLD
FOR03
Go to directed information
LN07
Category #4. The reader wants to move forward (or scroll down) to the last [LAST] page in order to
do the following:
OLD/
Code #
Descriptions
Code#
NEW
NEW LAST02
Check the remaining pages
MD17.1
(NEW)
Category #5. The reader wants to move backward (or scroll up) [BACK] from one page to another in
order to do the following:
OLD/
Code #
Descriptions
Code#
NEW
OLD
BACK01
Recall previous content
LN07
NEW BACK01.1 Correct the reader’s understanding after the reader encounters illogical LN07
or unexpected content
NEW BACK01.2 Understand completely (hard-to-understand) content
LN07
NEW BACK01.3 Re-read (missed or skimmed) content
LN07
OLD
BACK02
Examine where current content is situated in the context of the big
LN07
picture of the entire text
MD29.3
NEW BACK03.1 Examine consistencies across the reader’s notes in page margins
LN08
EN03
OLD
BACK04
Delete annotations that the reader has already made
REVISE
01
(NEW)
OLD
BACK05
Change annotations that the reader has already made
REVISE
02
(NEW)
OLD
BACK07
Add new annotations to text that the reader did not annotate in the first AD
place



NEW
NEW
OLD
OLD

BACK07.1
BACK07.2
BACK10
BACK11

Check if the reader’ annotations are correctly marked as intended
Review the relationships between or across related parts of text
Repair a technical glitch (obstacles)
Review all reference in References

LN08
LN07
MD09.4
SL31.1
SL31.2

Category #6. The reader wants to move backward (or scroll up) to the first [FIRST] page in order to
do the following:
OLD/
Code #
Descriptions
Code#
NEW
NEW FIRST02 Check bibliographic information
TX01
NEW FIRST03 Check a title
TX01
NEW FIRST04 Review and check the reader’s annotations quickly in the entire text
LN08
MD29.3
Category #7. The reader wants to move backward (or scroll up) to the table of contents [TOC] in
order to do the following:
OLD/
Code #
Descriptions
Code#
NEW
NEW TOC02
Find a chapter that the reader wants to read
MD29.4
(NEW)
Category #8. The reader wants to move back and forth (or scroll up and down) [BACKFOR] across
multiple pages in order to do the following:
OLD/ Code #
Descriptions
Code#
NEW
NEW BACKFOR00
Scan or overview the entire text before reading
MD29.3
NEW BACKFOR00.1 Scan or overview the reader’s annotations after reading
EN03
MD29.3
NEW BACKFOR02
Compare relevant contents in multiple locations
LN07
NEW BACKFOR03
Compare between headings in multiple locations
LN07.1
NEW BACKFOR04
Find a section that the reader wants to read next
MD29.4
(NEW)
NEW BACKFOR05
Read and understand separated content across two pages
MD34.1
(NEW)
NEW BACKFOR06
Understand completely or carefully an idea or a paragraph
LN07
NEW BACKFOR07
Skim through to find something useful and remember better
MD29.3
Category #8-1 (NEW). The reader wants to jump (or move backward or forward or scroll up or
down) [JUMP] around pages in order to do the following:
OLD/
Code #
Descriptions
Code#
NEW
NEW JUMP01 Go to a number, a figure, a table, a diagram, or a footnote based on
LN02 directed information in the text
LN05
NEW JUMP02 Go to related information
LN07
NEW JUMP03 Go to target information
MD29.3
NEW JUMP04 Check relevant reference(s) in the body text or in References
LN05.1
(NEW)
NEW JUMP05 Go to the first line of a section
MD29.4
(NEW)

 

Category #9. The reader wants to zoom in and out [ZOOMINOUT] in order to do the following:
OLD/
Code #
Descriptions
Code#
NEW
OLD
ZOOMINOUT01
Figure out the relationship(s) between one section and another
LN07
section or between one section and the entire text
NEW ZOOMINOUT02
Make content in a small screen more legible
MD12.1
Category #9-1 (NEW). The reader wants to zoom in [ZOOMIN] in order to do the following:
OLD/
Code #
Descriptions
Code#
NEW
NEW ZOOMIN01 Stay focused on reading
MD12.2
NEW ZOOMIN02 Enlarge small-size content
MD12.1
Category #9-2 (NEW). The reader wants to zoom out [ZOOMOUT] in order to do the following:
OLD/
Code #
Descriptions
Code#
NEW
NEW ZOOMOUT01 Find relevant or directed content
LN07
Category #10 (NEW). The reader wants to rotate [ROTATE] a page in order to do the following:
OLD/
Code #
Descriptions
Code#
NEW
NEW ROTATE01 Make a maximum use of page margins
MD10
Category #11 (NEW). The reader wants to manipulate a printed book [BOOK] in order to do the
following:
OLD/
Code #
Descriptions
Code#
NEW
NEW BOOK01
Put a paper book inside down to mark the page where the reader stops MD17
reading at
Category #12 (NEW). The reader wants to use the reader’s hand [HAND] in order to do the
following:
OLD/
Code #
Descriptions
Code#
NEW
NEW HAND01
Keep circling using hand-writing to enhance remembering
MN01
NEW HAND02
Move a hand to enhance the reader’s logical thinking
MN03



Appendix Q.3: The codebook after the video study and follow-up interviews: Other
external activities (beyond one document, one application, or one device)

Category #1. The reader wants to open a web [WEB] in order to do the following:
OLD/
Code #
Descriptions
NEW
OLD
WEB01
Look up a dictionary
OLD
WEB02
Find relevant articles
NEW WEB02.1 Visit a school’s library website for looking up resources
NEW WEB02.2 Do a Google search for looking up additional information or knowledge
NEW WEB02.3 Check the availability of ebook
NEW

WEB03

Check academic emails or send a reminder via email

Code#
LN09
LN09
LN09
LN09
MD49.1
(NEW)
LN09

Category #2. The reader wants to use additional applications/software [APP] in order to do the
following:
OLD/
Code #
Descriptions
Code#
NEW
OLD
APP01
Look up a dictionary
LN09
NEW APP02.1
Pull out reading materials from reading applications such as iBooks and MD49
Preview
NEW APP03
Pull out data from or enter annotated bibliography into reference
MD47
management applications such as EndNote and Mendeley
NEW APP04
Pull out data from or storage data in file sharing and cloud content
MD49
management applications such as Dropbox
MD46
NEW APP05
Take notes about, write, or edit something, like a summary, key
information, an outline, and works-in-progress paper, in writing
applications such as EverNote and MS Word
Category #3. The reader wants to print [PRINT] out a document in order to do the following:
OLD/
Code #
Descriptions
Code#
NEW
NEW PRINT03
Read document on paper as the reader’s favorite reading device
MD20
Category #4. The reader wants to use a separate notepad [PAD] in order to do the following:
OLD/
Code #
Descriptions
Code#
NEW
NEW PAD03
Write down key information
EN01
NEW PAD04
Organize or rearrange (chronically) key information that the reader needs
EN01
to remember
Category #6 (NEW). The reader wants to utilize the following additional device(s) [DEVICE] in
order to do the following:
OLD/
Code #
Descriptions
Code#
NEW
NEW DEVICE01 Paper books or printed articles to refer to relevant information
LN09
NEW DEVICE02 An iPad to check class notes or google additional information
LN09
NEW DEVICE03 A laptop or desktop to check class notes
LN09
NEW DEVICE04 An external drive to back up data
MD21
NEW DEVICE05 A filing cabinet to organize documents
MD49



Appendix R: The final codebook

#

1

2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17

18
19
20
21
22
23

1
2

Category#1. The reader wants to make the following properties or elements of a text [TX] stand
out (whether or not they represent the author’s key ideas):
OLD/
Code #
Code #
Descriptions
NEW
Surface level
Bibliographic information about the entire text
OLD
TX01
FIRST0
2
FIRST0
3
OLD
TX03
Title or subtitle
OLD
TX04
Footnotes
OLD
TX05
A whole list of parallel words or concepts
OLD
TX06
Terms, phrases, or sentences that are emphasized with italicization,
boldface, or quotation marks or sentences including emphasized
terms, phrases, or clauses
OLD
TX07
Numeral(s) or sentence(s) including such words
OLD
TX08
Key terms or concepts (regardless of whether or not they are defined)
OLD
TX09
The definition of a term or a concept or sentences that are
definitional
OLD
TX10
(Names or captions of) important tables or figures
OLD
TX11
Important statistical data
NEW
TX13.1
Resources in Notes
NEW
TX13.2
Researchers in Acknowledgements
Content level
OLD
TX14
Highly salient textual (or rhetorical) structures such as cause and
effect, comparison and contrast, problem and solution, and question
and answer, with or without signal words
OLD
TX16
Important (applied) theories, models, effects, and/or their definitions
or descriptions
OLD
TX18
Practical (real-life) examples, as distinguished from the author’s
conceptual arguments
OLD
TX19.1
Fundamental work for a topic
OLD
TX20
Key ideas, beliefs, arguments, assertions, or excerpts of
(distinguished or credible) scholars or schools in a field
More discipline specific
NEW
TX24.1
The name of (anthropological) field site
NEW
TX24.2
Secondary data source(s)
NEW
TX32.1
Information or knowledge about criteria
NEW
TX36.1
Information or knowledge about a mechanism
NEW
TX36.2
Information or knowledge about a logic behind the statistics
NEW
TX36.3
Information or knowledge about the author’s objection against other
researchers’ arguments
Category#2. The reader wants to tag [TG] the following for the entire text:
OLD/
Code #
Code#
Descriptions
NEW
OLD
TG01
Target information or knowledge that the reader wants to or needs to
focus on while reading
NEW
TG03
Reference citation based on a particular citation style (e.g., APA)



1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32

Category #3. The reader wants to differentiate parts of a text selectively [SL] and make each of
the following stand out:
OLD/
Code # Code #
Descriptions
NEW
The author’s intentions: key arguments or background knowledge
NEW
SL00.1
Key conjunction (e.g., ‘and’ as opposed to ‘or’)
NEW
SL02.1
Key term(s)
NEW
SL02.2
Key word(s) of the author’s key argument
OLD
SL03
The author’s key argument or idea about a section, as
distinguished from background (supportive) knowledge
OLD
SL04
The author’s key argument or idea about the entire text, as
distinguished from background (supportive) knowledge
OLD
SL06
The author’s summary of the entire text, with or without signal
words
OLD
SL08
Abstract
NEW
SL08.1
Contextual information (in the section of Forward) for writing
the entire text
OLD
SL09
The author’s motivations or background information, as
background (supportive) knowledge
NEW
SL09.1
Objectives
OLD
SL10
Research gaps (new contributions), as background (supportive)
knowledge
OLD
SL11
Existing viewpoints, perspectives, or approaches, as background
(supportive) knowledge
NEW
SL11.1
Research question(s)
NEW
SL11.2
Method(s)
OLD
SL12
Finding(s), conclusions, or arguments from research relevant to
the author’s key argument, as background (supportive)
knowledge
NEW
SL12.1
Key information in Discussion/Implications
NEW
SL12.2
Limitation(s)
The reader’s intentions: current engagement
OLD
SL13
The author’s argument with which the reader agrees
NEW
SL13.1
The author’s argument about which the reader has thought about
before
OLD
SL14
The author’s argument with which the reader disagrees
OLD
SL16
Information or knowledge that the reader needs to remember (as
a reminder)
NEW
SL16.1
Information or knowledge that the reader likes
OLD
SL17
Information or knowledge that the reader finds interesting
OLD
SL18
Information or knowledge that the reader finds thoughtprovoking/inspiring
OLD
SL19
Information or knowledge that the reader finds surprising
NEW
SL19.1
Information or knowledge that the reader finds counter-intuitive
(unexpected) content
OLD
SL21
Information or knowledge that the reader wants to cite
OLD
SL24
Index words or phrases (directly copied or extracted from the
original text) that the reader selected for a later search
OLD
SL25
Information, knowledge, articles or books that the reader finds
useful
NEW
SL25.1
Information or knowledge that is relevant to the reader’s personal
research
NEW
SL25.2
Information or knowledge that is relevant to the reader’s teaching
NEW
SL25.3
Information or knowledge that is relevant to the reader’s group



33
34
35
36

37
38
39
40
41

1
2
3
4
5
6
7
8

9
10

1
2
3

project(s)
Information or knowledge that is relevant to the reader’s test
Information or knowledge that is relevant to document(s) the
reader read before
NEW
SL25.6 FOR02 Section(s) that the reader will skip this time
The reader’s intentions: further action to be taken
OLD
SL27
The meanings of text, equations, figures, or tables that the reader
is not sure of or does not know
NEW
SL27.1
Information or knowledge that the reader is questioning or
doubting
OLD
SL29
New information or knowledge (that the reader did not
previously know)
NEW
SL31.1 BACK
Reference(s) that the reader (might) want or need to cite
11
NEW
SL31.2 BACK
Reference(s) that the reader finds interesting
11
NEW
SL31.3
Reference(s) in the body of text that the author introduces
NEW
NEW

SL25.4
SL25.5

Category #4. The reader wants to prioritize a part of a text hierarchically [HR] and indicate the
degree of importance or the relationship between or among importances, as in the following:
OLD/
Code # Code #
Descriptions
NEW
Degrees of importances
OLD
HR01
The author’s extremely important arguments or ideas or what the
reader must look at later without fail
NEW
HR01.1
The author’s arguments or ideas that are extremely important
from the reader’s (research) perspective.
OLD
HR02
The author’s most important arguments or ideas or what the
reader must look at later
NEW
HR02.1
The author’s arguments or ideas that are most important from the
reader’s (research) perspective.
OLD
HR03
The author’s moderately important arguments or ideas or what
the reader might look at later
NEW
HR03.1
The author’s arguments or ideas that are moderately important
from the reader’s (research) perspective.
OLD
HR04
The author’s least important arguments or ideas or what the
reader could look at later
NEW
HR04.1
The author’s arguments or ideas that are least important from the
reader’s (research) perspective.
Relationships
NEW
HR06.1
Between a subject (a topic) and its details
NEW
HR06.2
Between a higher level of explanation and its deeper levels of
explanation

Category #5. The reader wants to externalize or monitor [MN] thinking by doing the following:
OLD/
Code #
Code #
Descriptions
NEW
OLD*
MN01
HAND0 Adding further annotations (e.g., circling, underlining) to the
1
reader’s own notes
OLD
MN02
Adding symbols to key word(s) in the reader’s own notes
OLD
MN03
HAND0 Writing out the steps or processes of the reader’s thinking from
2
the initial thought to the final conclusion, in response to the
author’s argument



1
2
3
4
5
6
7
8
9
10
11

1
2
3
4
5
6
7

1
2
3
4

Category #6. The reader wants to enhance [EN] recall and/or quick retrieval by doing the
following:
OLD/
Code #
Code #
Descriptions
NEW
OLD
EN01
PAD03
Repeating (re-writing) key information or knowledge
PAD04
about the entire text in one place
NEW
EN01.1
Repeating (re-writing) key term(s) in page margins
NEW
EN01.2
Repeating (re-writing) key information or knowledge that
the reader did not know (new knowledge)
NEW
EN01.3
Repeating (re-writing) key information or knowledge that
the reader did not think about
NEW
EN01.4
Repeating (re-writing) key information or knowledge that
the reader is not sure about meaning
NEW
EN01.5
Repeating (re-writing) or reviewing key information or
knowledge that does not make sense to the reader
NEW
EN01.6
Repeating (re-writing) or reviewing key information or
knowledge that the reader thinks interesting
NEW
EN01.7
Repeating (re-writing) or reviewing key information or
knowledge that the reader thinks important
OLD
EN02
Repeating (re-writing) or reviewing key information or
knowledge that the reader wants to cite
NEW
EN02.1
Repeating (re-writing) or reviewing resources that the
reader uses later
Repeating (re-writing) or reviewing the reader’s own
OLD*
EN03
FLIP05
thoughts, inspirations, and questions that arise (during
BACK03.1
BACKFOR00 reading)
.1
Category #7. The reader wants to articulate [AR] implicit content or elaborate concise content
by doing the following:
OLD/
Code # Code #
Descriptions
NEW
NEW
AR04.2
Adding lines to a graph
NEW
AR04.1
Translating an image, a graph, or a formula into descriptions in
written statements
OLD
AR05
Making ambiguous expressions unambiguous
NEW
AR08.1
Identifying information or explanation (missed or unknown) that
the author does not articulate
NEW
AR08.2
Identifying word(s)/term(s) that the reader does not know
NEW
AR08.3
Identifying information or knowledge that the reader does not
understand
NEW
AR08.4
Identifying a rationale underlying the author’s arguments
Category #8. The reader wants to evaluate [EV] the original text from the following
perspective(s):
OLD/
Code # Code #
Descriptions
NEW
OLD
EV01
The correctness of English usage, style, and composition
OLD
EV02
The clarity or ambiguousness of the author’s argument
OLD
EV03
The validity (correctness or incorrectness) of the author’s
argument
OLD
EV07
The completeness of the author’s argument (gaps in logic or
missing information that should have been included)



5
6
7
8
9
10
11
12
13
14
15

1
2
3
4
5
6

7
8

9

10

NEW
NEW
NEW
NEW
NEW
OLD
NEW
NEW
OLD
OLD
NEW

EV10.1
EV11.1
EV11.2
EV11.3
EV11.4
EV12
EV12.1
EV12.2
EV13
EV14
EV15.1

Missing or wrong assumption(s)
Discrepancies against the reader’s prior knowledge
Missing information that should have been provided
Redundancy of information
The quality of definition(s)
The quality of research design
Research methods
Research tools/equipment
The quality of data analysis
The quality of interpretation
The quality of a graph

Category #9. The reader wants to link [LN] elements, as in the following:
OLD/
Code #
Code #
Descriptions
NEW
Within one document
OLD*
LN02
JUMP01
Between the original text and its relevant tables
OLD*
LN03
JUMP01
Between the original text and its relevant figures
OLD*
LN04
JUMP01
Between the original text and its relevant footnotes
OLD*
LN05
JUMP01
Between the original text and its relevant notes at the end
of the article
OLD*
LN05.1 JUMP04
Between the original text and its relevant reference
Between (explicitly directed or logically related)
OLD
LN07
FLIP02
information or knowledge in two different locations or
FLIP03
across multiple locations (or within one same page or
FOR03
across distant pages)
BACK01
BACK01.1
BACK01.2
BACK01.3
BACK02
BACK07.2
BACKFOR02
BACKFOR06
ZOOMINOUT
01
ZOOMOUT01
NEW
LN07.1 FLIP04
Between comparative information (e.g., headings,
BACKFOR03
independent and dependent variables) in different
locations
Between the reader’s own annotations/notes in different
OLD*
LN08
FLIP05
locations
BACK03.1
BACK07.1
FIRST04
External, or beyond one document
Between the original text and its relevant external sources
OLD*
LN09
WEB01
(e.g., academic emails, class notes, paper book, articles,
WEB02
dictionary library website, Google)
WEB02.1
WEB02.2
WEB03
APP01
DEVICE01
DEVICE02
DEVICE03
OLD
LN10
Between the original text and its relevant prior
knowledge



11

OLD

12

The reader’s personal use
OLD
LN13

13

NEW

LN13.1

14

OLD

LN15

15

OLD

LN16

1
2
3
4

1
2

1
2
3
4
5
6
7
8

LN11

Between (the conceptual assertions of) the original text
and examples of their practical or real-life relevance
Between the original text and the reader’s personal
(current or future) research
Between the original text and the reader’s question(s) that
the reader has thought about before
Between the reader’s own notes and their relevant
external materials
Between the reader and the author (for further intellectual
discussion)

Category #10. The reader wants to add [AD] the following comments in response to the
author’s argument:
OLD/
Code # Code #
Descriptions
NEW
OLD
AD03
The reader’s disagreement (criticism) with or without
justification for it
NEW
AD05.1
Questions that the reader wants to ask to the author or other
colleagues
NEW
AD05.2
The reader’s notes about definition(s) of concept(s)
NEW
AD05.3
The reader’s reminder points for future reading
Category #10’ (NEW). The reader wants to revise [RV] annotations by doing the following:
OLD/
Code # Code #
Descriptions
NEW
OLD*
RV01
BACK
Deleting annotations that the reader has already made
04
Changing annotations that the reader has already made
OLD*
RV02
BACK
05
BACK
07

Category #11. The reader wants to extend [EX] ideas in the original text by introducing the
following ideas:
OLD/
Code # Code #
Descriptions
NEW
OLD
EX01
The reader’s own recommendation(s) for the author’s argument
NEW
EX01.1
The reader’s additional interpretation(s) or solution(s) that the
author missed
NEW
EX01.2
The reader’s own interpretation or prediction about what the
reader has not known before (brainstorming)
NEW
EX01.3
Additional lines or arrows that the author might have missed in a
diagram
OLD
EX02
The reader’s questions or statements in favor of the author’s
argument
OLD
EX05
The reader’s questions or statements created to be used for
particular purposes such as dissertation writing and teaching
OLD
EX06
The reader’s questions or statements that are inspired by the
author’s argument
NEW
EX07.1
The reader’s joke



1
2
3
4
5
6
7

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27

Category #12. The reader wants to shorten [SH] the original text or the reader’s own notes by
doing the following:
OLD/
Code # Code #
Descriptions
NEW
OLD
SH01
Transforming a word into a symbol
OLD
SH02
Using or creating an abbreviation
NEW
SH02.1
Writing down “Q&A” to represent the question and answer form
of a statement
OLD
SH03
Numbering
OLD
SH04
Noting the author’s key words or phrases that trigger recall of the
content of a paragraph, a chapter, or the entire text
OLD
SH06
Summarizing a paragraph, a chapter, or the entire text by
paraphrasing
OLD
SH08
Summarizing a paragraph, a chapter, or the entire using a table
Category #14. The reader wants to deploy the following properties or elements of the medium
[MD]:
OLD/
Code #
Code #
Descriptions
NEW
Physical properties: hardware
OLD
MD01
The prevention of eye-strain
OLD
MD02
The resolution of the screen
OLD
MD03
The size of the screen and the device
NEW
MD03.1
Holding experience
NEW
MD03.2
Codex book form factors
NEW
MD03.3
Computational power for running particular software
OLD
MD05
The weight of the reading device
OLD
MD06
The portability of documents
NEW
MD06.1
The capability to hold or carry multiple books
OLD
MD07
The suitability of use for daily transportation
OLD
MD08
The versatility of supporting one-the-go-reading
NEW
MD08.1
Hardware separation between or across reading-related
tasks
OLD
MD9
Sustainability
NEW
MD09.1
Tactile, tangible, or touchable experience
NEW
MD09.2
Handwriting interaction with a hand (for better
remembering)
NEW
MD09.3
Electricity independent
NEW
MD09.4 BACK10
No technical glitch
NEW
MD09.5
Hardware that facilitates annotations
Physical properties: software
OLD
MD10
ROTATE01
Extra space for adding the reader’s notes
NEW
MD10.1
Enough space for in-between lines
OLD
MD11
The number of colors
OLD
MD12
Color contrast
NEW
MD12.1 ZOOMINOUT0 Text-size adjustability
2
ZOOMIN02
NEW
MD12.2 ZOOMIN01
Zoomability
NEW
MD12.3
The capability to expend a screen into a full screen
NEW
MD14.1
The capability to manipulate a page layout
OLD
MD15
The capability to annotate or take notes with ease and
with speed



28
29
30

NEW
NEW
OLD

MD15.1
MD15.2
MD17

31

NEW

MD17.1

32
33

OLD
MD19
Psychological properties
OLD
MD20
PRINT03

34
35
36
37
38
39
40
41

NEW
NEW
OLD
OLD
NEW
OLD
NEW
NEW

MD20.1
MD20.2
MD21
MD23
MD23.1
MD24
MD26.1
MD27.1

BOOK01
FLIP01
LAST02

DEVICE04

47

Cognitive benefits: enhancing
OLD
MD29
NEW
MD29.1
NEW
MD29.2
NEW
MD29.3 BACK02
FIRST04
BACKFOR00
BACKFOR00.1
BACKFOR07
FLIP02
FLIP03
FLIP04
JUMP03
OLD*
MD29.4 TOC02
BACKFOR04
JUMP05
NEW
MD30.1

48
49
50
51

OLD
NEW
NEW
OLD

52
53
54

NEW
MD33.1
OLD*
MD34.1 BACKFOR05
NEW
MD35.1
Visual benefits: bracketing, anchoring
OLD
MD37

42
43
44
45

46

55
56

MD31
MD31.1
MD31.2
MD32

57

OLD
MD38
Visual benefits: bringing out
OLD
MD40

58

NEW

MD41.1

Selectability of text that enables to copy and paste easily
Ease to select text
The capability to preserve the last location where the
reader stopped reading
The capability for checking the remaining pages
The capability for offline reading
Ease and comfort of use stemming from personal longterm habits
Non-steep learning curve (intuitive to use)
Ease to focus on reading for a long period of time
Ease of data back-up
The convenience of no extra steps
Ease to manipulate tools
The convenience of long-term storage
High efficiency of time and resource management
Controllability of turning on and off the reader or
others’ annotations
Search capability
Quick to go to a particular location
Ease to move and jump around pages
Quick to scan and find information

Quick to go to table of contents (TOC)
Hand-writing recognition for searching for hand-written
notes
The capability to facilitate recall
Better sense of order
Better sense of special remembering
The capability to express the reader’s individuality via
hand-writing, as opposed to a machine’s uniformity
The capability to facilitate skimming
The capability to make discontinued text connected
Ease of multitasking
The capability to bracket or enclose a big block of text,
without underlining or highlighting
The capability to anchor
The capability to bring out global ideas about the entire
page
The capability to rank my notes by bringing out more
important notes upfront

 

59

Behavioral benefits: transitions
OLD
MD46
APP05

60

OLD*

MD47

APP03

61

OLD

MD49

62
63
64
65
66

APP02.1
APP04
DEVICE05
WEB02.3

67

OLD*
MD49.1
OLD
MD50
NEW
MD50.1
NEW
MD50.2
NEW
MD50.3
Behavioral benefits: managing
OLD
MD52

68
69

OLD
OLD

70
71

NEW
MD55.1
NEW
MD56.1
Behavioral benefits: speed of reading
NEW
MD57.1

72

MD54
MD55

79
80

Behavioral benefits: vocalize
NEW
MD57.2
Social benefits
OLD
MD58
Socio-economic aspects
OLD
MD61
Cultural aspects
OLD
MD62
OLD
MD63
Environmental aspects
NEW
MD64
NEW
MD64.1
NEW
MD64.2

81

NEW

73
74
75
76
77
78

MD65

The seamlessness of transitions between reading and
writing
The seamlessness of transitions across processes, from
citation management to note-taking (while reading) and
retrieving documents
The seamlessness of transitions from reading to a
database system/a filing system
The capability to check the availability of ebook
The capability to export the reader’s notes
The capability to interact with other software
Ease to switch between tools
Ease to switch between different modes of highlighting
The capability to facilitate making notes, copying and
pasting text, and retrieving text
Compatibility across diverse hardware platforms
The capability to synchronize across diverse hardware
platforms
The capability to access data from anywhere
The capability to automatize meaningful file names
The capability to adjust the speed of reading according
to the depth of reading
The capability to assist spoken reactions to text
The capability to share
The price of reading devices
Ownership of books
Cultural norms of acceptability
Controllability of distraction against active reading
Controllability of white noise
Enough physical or virtual space for multiple tasks
while reading
Capability to support non-academic activities while
reading (e.g., drinking coffee, checking a phone for
checking time or notified alerts, taking a break for
taking a rest or having a reflecting time, reading or
writing for leisure, reading news, listening to music,
checking personal emails, changing reading locations
for being refreshed)

Note: OLD* means that it was newly added from the old codebook in the process of re-coding for items in
dynamic movements and in other external activities.





Appendix S: IRB Human Subjects paperwork






 

 

HyunSeung [“HonSong”] Koh
Address: 1320 E. 10th St., LI 011, Bloomington, IN 47405-3907, USA
Email: hskoh@indiana.edu or koh623@gmail.com
________________________________________________________________________
Research and Teaching Interests
• Human-Computer Interaction, Human-Information Interaction, Usability
• Information Behaviors, Information Architecture, Knowledge Management, Digital
Libraries
• Ebooks, (textual) reading online, book/reading history
• The design of (textual) reading interfaces that enhance reading experiences in terms
of cognitive, emotional, behavioral, social, and cultural aspects
• Mixed (multi-) methods, surveys, interviews, (distant) observation, document
analysis, discourse/text Analysis, content analysis for the Web, computer-mediated
discourse analysis
• Interdisciplinary research
Dissertation
Title: “From reading text to re-designing it: Ebook design insights from a mixed method
user study of active reading”
Research Committee:
Dr. Susan C. Herring (chair), Dr. Hamid C. Ekbia, Dr. Jeffrey Bardzell, Dr. Erik
Stolterman (minor advisor)
Education
Department of Information & Library Science, School of Informatics and Computing,
Indiana University, Bloomington, IN, USA
Ph.D. studies in Information Science, HCI
May 2015
Advancement to Candidacy July 1, 2010
School of Library & Information Science, Indiana University, Bloomington, IN, USA
Master of Information Science, HCI/Usability
Dec. 2006
Graduate School of Global Business, Hankuk University of Foreign Studies, Seoul,
Korea
Master of Business Administration, Information Management
Aug. 2002



School of Natural Sciences, SungShin Women’s University, Seoul, Korea
Bachelor of Sciences, Mathematics
Feb. 1994
Publications
Articles and Book Chapters
Koh, H., & Herring, S. C. (2014). Ebooks, ereaders, and ebook device design. In M.
Khosrow-Pour (Ed.), The Encyclopedia of Information Science and Technology (3rd ed.).
Hershey, PA: IGI Global.
Koh, H. (2012). Understanding reader-text interaction: Implications for ebook design.
The Bulletin of the IEEE Technical Committee on Digital Libraries, 8(2).
http://www.ieee-tcdl.org/Bulletin/v8n2/
Koh, H., & Bardzell, J. (2010). Supporting the experience of active reading in the design
of e-books. Design Principles and Practices: An International Journal, 4(4), 315-332.
Refereed Conference Proceedings
Koh, H. (2011). Annotations and Rhetorical Structure Theory: Implications for the design
of ebooks. In Proceedings of ED-MEDIA 2011 – World Conference on Educational
Multimedia, Hypermedia & Telecommunications (pp. 1549-1557). Chesapeake, VA:
AACE.
Koh, H. (2009). Predicting successful global online group projects from online discussion.
In Proceedings of the Forty-Second Hawai'i International Conference on System
Sciences (pp. 88-97). Los Alamitos, CA: IEEE Press.
Koh, H., & Herring, S. C. (2007). Is interactivity important in information literacy
tutorial sites? Comparison between highly-rated and randomly-selected online tutorials.
In R. Carlsen, K. McFerrin, J. Price, R. Weber, & D. A. Willis (Eds.), Proceedings of
Society for Information Technology & Teacher Education International Conference 2007
(pp. 1297-1302). Chesapeake, VA: AACE.
Workshop Papers
Koh, H. (2012). Is there one kind of qualitative (quantitative) research? Qualitative
Research in HCI, The ACM SIGCHI Conference on Human Factors in Computing
Systems
(CHI),
Austin,
Texas,
USA.
http://www.ischool.drexel.edu/faculty/jrode/chiparticipants.html
Koh, H. (2011). Manipulable texts: Let readers create their own world of texts. Beyond
the Binding: Exploring the Future of the Book, The Eighth ACM Conference on
Creativity and Cognition, Atlanta, Georgia, USA.
https://sites.google.com/site/futureofbook/program/manipulable-texts



Presentations
Full Papers
Koh, H. (2012, May 19). What is the best design approach to avoid difficulties in
interdisciplinary research? Presented at The Eighth International Congress of Qualitative
Inquiry,
University
of
Illinois
at
Urbana-Champaign,
Illinois,
USA.
www.icqi.org/docs/QI2012FinalProgram041812.pdf
Koh, H. (2011, November 3). Manipulable texts: Let readers create their own world of
texts. Presented at a workshop, Beyond the Binding: Exploring the Future of the Book,
the Eighth ACM Conference on Creativity and Cognition, Atlanta, Georgia, USA.
https://sites.google.com/site/futureofbook/
Koh, H. (2011, June 30). Annotations and Rhetorical Structure Theory: Implications for
the design of ebooks. Presented at the Twenty-Second ED-MEDIA 2011 – World
Conference on Educational Multimedia, Hypermedia & Telecommunications, Lisbon,
Portugal.
Koh, H., & Bardzell, J. (2010, February 13). Supporting the experience of active reading
in the design of e-books. Presented at the Fourth International Conference on Design
Principles and Practices, University of Illinois, Chicago, IL.
Koh, H. (2009, January 8). Predicting successful global online group projects from online
discussion. Presented at the Forty-Second Hawai'i International Conference on System
Sciences. Waikoloa, Big Island, HA.
Posters
Koh, H. (2014, January 22). A user study of active reading in academic settings using
mixed methods: Implications for ebook design. Poster presented at the 2014 ALISE
Annual Conference/Jean Tague-Sutcliffe Doctoral Poster Competition, Philadelphia, PA.
Koh, H. (2014, January 21). Challenges and lessons learned from a mixed method study.
Poster presented at the 2014 ALISE Annual Conference, Philadelphia, PA.
Koh, H. (2012, January 17). Understanding reader-text interaction: Implications for
ebook design. Poster presented at the 2012 ALISE Annual Conference, Dallas, TX.
Koh, H., & Herring, S. C. (2007, March 28). Is interactivity important in information
literacy tutorial sites? Comparison between highly-rated and randomly-selected online
tutorials. Poster presented at the Eighteenth Society for Information Technology &
Teacher Education (SITE), San Antonio, TX.



Clements, M., Holloway, T., Koh, H., & Mutsuddi, A. (2006, May 22). Visualizing the
landscape of U.S. university patents at twenty patenting intensive universities. Poster
presented at the NetSci 2006 (International Workshop and Conference on Network
Science), Bloomington, IN. [Best Conference Poster Award, 3rd place]
Other
Koh, H. (2009, October 17). Understanding annotations using the Heideggerian concepts
of ready-to-hand and present-at-hand for supporting active reading. Presented at the
School of Library and Information Science Doctoral Research Forum. Bloomington, IN.
Koh, H. (2008, October 11). Naturalistic diary studies: A method for capturing the
reading experience. Presented at the School of Library and Information Science Doctoral
Research Forum. Bloomington, IN.
Teaching Experience
School of Library and Information Science, Indiana University, Bloomington Fall
2010
Adjunct Lecturer, S401 Computer-Based Information Tools (Required course for new
graduate students in the Master of Library Science program)
o Fundamental networking
o Online searching
o XHTML/CSS
o MS Excel, MS PowerPoint, and MS Access
School of Library and Information Science, Indiana University, Bloomington Fall
2009
Teaching Assistant (Co-taught), S516 Human-computer Interaction (Graduate-level
course), Supervisor: Dr. Hamid R. Ekbia
o Researched and updated up-to-date reading materials
o Designed and led activity/discussion sessions
o Graded essay-style reports
Professional Employment, Assistantships, and Internships
School of Library and Information Science, Indiana University, Bloomington Fall
2007 - Spring 2008
Research Assistant, Netscan/Usenet Project, Supervisor: Dr. Susan C. Herring
o Assisted with data assessment, sampling, and building a coding scheme



Digital Library Program, Indiana University, Bloomington
Aug. 2006 – Dec. 2006
Intern, Usability project (EAD IU Online Finding Aids)
o Researched and reviewed previous user studies on finding aids
o Designed a usability study (retrospective walkthrough interview)
o Completed Human Subjects application process
o Administered study (user interviews)
o Gathered and analyzed interview data
o Prototyped for re-designing the current website
Information and Technology Services, City of Bloomington
Sep. 2005 – Nov. 2005
Intern, Usability project (Noisy database system)
o Analyzed an internally developed application with user interviews, contextual
inquiry, & heuristic evaluation
o Reported on findings including recommendations as to changes that should be made
to enhance the user interface and improve its usability for city staff
Ann Taylor Sourcing Korea Branch, Seoul, Korea
Nov. 1999 – July 2003
Senior Merchandising Representative
(Awarded as the best employee in 2001)
o Independently worked with an account for LOFT (an Ann Taylor brand),
coordinating all teams involved, such as the head office (in the USA), quality
assurance teams (in Korea), and vendors/mills (in Korea)
o Assisted with the head office’s needs for product development and production, such
as quoting competitive retail prices, scheduling product development and
production shipment, and monitoring quality of products
o Mediated between the head office (in the USA) and vendors/mills (in Korea) and
between the head office and the quality assurance team (in Korea)
PBMS (Pacific Buying and Marketing Services), Seoul, Korea
June 1996 – Oct. 1999
Section Chief Merchandising Representative
(Streamlined the workflow among business partners overseas by digitalizing data and
making them re-usable)
o Assisted with current and prospective buyers’ needs for product development and
production, such as quoting competitive retail prices, scheduling product
development and production shipment, and monitoring quality of products
o Mediated between buyers (in the USA) and current vendors/mills (in Korea) and
between buyers and the quality assurance team (in Korea)



Awards, Fellowships, Scholarships, Grants
Internal and External Awards and Grants
o Fee Assistance Awards (2013), The IU Office of International Services, Indiana
University, $1500
o Grant in Aid of Doctoral Research (2012), The University Graduate School, Indiana
University, Bloomington, $1000
o Fee Assistance Awards (2012), The IU Office of International Services, Indiana
University, $2000
o IU Women in Science Travel Grant (2012), The Office for Women's Affairs,
Indiana University, Bloomington, $700
o Travel funding including registration, transportation, lodging, and meals (2012), the
National Science Foundation, for ten doctoral students accepted to the JCDL
Doctoral Consortium, $662.90 + $360 (registration, prepaid)+ about $357 (hotel,
prepaid)
o Travel Funding (2012), the National Science Foundation, for twenty-six doctoral
students accepted to the iConference Doctoral Colloquium, $1241.45
Fellowships/Scholarships from the School of Library and Information Science (SLIS),
Indiana University
o Margaret Rufsvold Fellowship, Sarah Reed Fellowship, Clayton A. Shepherd
Scholarship (Fall 2012-Spring 2013)
o Sarah Reed Fellowship (Fall 2010-Spring 2011)
o Rob Kling Social Informatics Fellowship (Fall 2010-Spring 2011)
o Margaret Griffin Coffin Fellowship (Fall 2009-Spring 2010)
o SLIS Fellowship (Fall 2009)
o Sarah Reed Fellowship and Margaret Griffin Coffin Fellowship (Fall 2008-Spring
2009)
o Sarah Reed Fellowship (Fall 2007-Spring 2008)
Travel Awards from the School of Library and Information Science, Indiana University
o IU SLIS Doctoral Student Travel Award, The ALISE Annual Conference, 2014
o IU SLIS Doctoral Student Travel Award, The ACM SIGCHI Conference on Human
Factors in Computing Systems (CHI), 2012
o IU SLIS Doctoral Student Travel Award, The ED-MEDIA - World Conference on
Educational Multimedia, Hypermedia & Telecommunications, 2011
o IU SLIS Doctoral Student Travel Award, The Eighth ACM Conference on
Creativity and Cognition, 2011
o IU SLIS Doctoral Student Travel Award, The Fourth International Conference on
Design Principles and Practices, 2010
o IU SLIS Doctoral Student Travel Award, The Forty-Second Hawai'i International
Conference on System Sciences (HICSS), 2009
Scholarships from the Graduate School of Global Business, Hankuk University of
Foreign Studies, Seoul, Korea
o Distinction Scholarship (Spring 2002, Fall 2001)



Professional Development
As a selected presenter:
Koh, H. (2012, June 10). Understanding reader-text interaction: Implications for ebook
design (A summary of the dissertation proposal), JCDL (The ACM/IEEE Joint
Conference on Digital Libraries) 2012 Doctoral Consortium (for accepted students, with
NSF travel funding), The George Washington University, Washington, DC, USA.
Koh, H. (2012a, February 10). Interdisciplinarity (Answers to questions with regard to
the nature of inquiry in the information field and challenges in the dissertation proposal),
iConference 2012 Doctoral Colloquium (for accepted students, with NSF travel funding),
Toronto, Canada.
Koh, H. (2012b, February 10). Understanding reader-text interaction: Implications for
ebook design (A summary of the dissertation proposal), iConference 2012 Doctoral
Colloquium (for accepted students, with NSF travel funding), Toronto, Canada.
As an attendee:
The Nineteenth Annual Preparing Future Faculty (PFF) conference, Indiana University
Bloomington, February 7, 2014. http://www.indiana.edu/~pffc/
Dr. Eric Metzler, Dr. Lisa Kurz, & George Rehrey, Course Development Institute (CDI),
The Center for Innovative Teaching and Learning and Instructional Consulting, Indiana
University Bloomington, June 7, 10, 12, & 14, 2013. http://citl.indiana.edu/
programs/cdi/index.php
Dr. Aaron Blaisdell, Dr. Adele Goldberg, Dr. Dan Jurafsky, Dr. Ed Wasserman, Dr.
Harald Baayen, Dr. Michael Ramscar, Dr. Mark Davies, Dr. Mark Liberman, & Dr.
Morten Christiansen, The Big Data workshop: What can we do with 500 billion words?,
The IU Institute for Advanced Study (IAS) and the IU Cognitive Science Program,
Indiana
University
Bloomington,
April
18-20,
2013.
http://mypage.iu.edu/~meldye/workshop/
Dr. Lisa Given, Dr. Diane Rasmussen, & Dr. Marie Radford, The ALISE Academy: The
Quality behind Qualitative Research, the ALISE Annual Conference, January 22, 2013.
Dr. Lisa D. Pearce, Using mixed methods in social science research, the Workshop in
Methods (WIM), the Consortium for Education and Social Science Research (CESSR),
Indiana University Bloomington, April 13, 2012.
Dr. Tim Hallett, The Demystifying Qualitative Analysis workshop, the Indiana Intensive
Didactic Seminar (IIDS), April 2, 2011.



Service and Volunteer Experience
Reviewer (for conference papers)
o The ACM CHI Conference on Human Factors in Computing Systems, 2014 present
o Advances in Teaching and Learning Technologies minitrack, HICSS (Hawai’i
International Conference on System Sciences), 2009-present
o Persistent Conversation minitrack, HICSS (Hawai’i International Conference on
System Sciences), 2010
Referee (for journal or chapter submissions)
o The Encyclopedia of Information Science and Technology (3rd ed.), 2013
o Nordic Journal of Youth Research, 2012
o Design Principles and Practices: An International Journal, 2010
Volunteer
o Research Assistant/Instructor, June - July, 2005
Clinical Teaching for Students with Reading Disabilities
Pinnacle School, Bloomington, Indiana
Department of Curriculum and Instruction, School of Education, Indiana University
Technical Experience and Skills
Platforms: Windows, Mac OS, Unix
Web development: Hand-coded (X)HTML, DHTML, CSS, JavaScript, PHP
Graphics: Photoshop, Fireworks, Illustrator
Databases: MS Access
Programming: Perl/CGI, JAVA
Statistical tools: SPSS
Qualitative data analysis software: HyperRESEARCH
Professional Memberships
ACM SIGCHI
American Society for Information Science & Technology
Association for Library and Information Science Education
International Reading Association
Reference
Available upon request.



