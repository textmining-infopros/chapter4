Information Behaviors and Cognitive Modes Used
for Cyber Situation Assessment
A Thesis
Submitted to the Faculty
of
Drexel University
by
Thomas Heverin
in partial fulfillment of the
requirements for the degree
of
Doctor of Philosophy
June 2014

UMI Number: 3629473

All rights reserved
INFORMATION TO ALL USERS
The quality of this reproduction is dependent upon the quality of the copy submitted.
In the unlikely event that the author did not send a complete manuscript
and there are missing pages, these will be noted. Also, if material had to be removed,
a note will indicate the deletion.

UMI 3629473
Published by ProQuest LLC (2014). Copyright in the Dissertation held by the Author.
Microform Edition © ProQuest LLC.
All rights reserved. This work is protected against
unauthorized copying under Title 17, United States Code

ProQuest LLC.
789 East Eisenhower Parkway
P.O. Box 1346
Ann Arbor, MI 48106 - 1346

© Copyright 2014
Thomas Heverin. All Rights Reserved.

ii

Dedications
For my little Nancy Drew and my big Frank Hardy.

iii

Acknowledgements
This dissertation would have not been possible without the support of many
people. My greatest thanks to my dissertation chair, Lisl Zach, who mentored me and
guided me through all of the ups and downs throughout the PhD process. Thanks to your
support I now feel like a solid researcher and learned to be patient with the whole
research process. I am highly grateful to my dissertation committee members: Denise
Agosto, Lori Brainard, Xia Lin, and Kris Unsworth. Your advice and support helped me
move along with finishing the dissertation.
Thank you to all of the staff at the College of Computing & Informatics especially
Brenna Martin and Mari Fazio. Without their support, I would have not be able to
navigate all of the challenges in completing this PhD journey. A special thank you goes
to Drexel University Library’s interlibrary loan staff. Without your help in fulfilling
numerous requests, I would not have had the knowledge needed to complete the
dissertation. A special thanks to Mike Zarro who provided the best support a fellow PhD
student and candidate could provide.
Finally, I own thanks to my parents who have supported me throughout this whole
process.

iv

Table of Contents
Dedications ............................................................................................................................... ii
Acknowledgements ................................................................................................................. iii
Table of Contents .................................................................................................................... iv
List of Tables ............................................................................................................................ vi
List of Figures ......................................................................................................................... viii
Abstract .................................................................................................................................... ix
CHAPTER 1: INTRODUCTION ................................................................................................... 1
1.1 Threat of Cyber Attacks .......................................................................................... 1
1.2 Cyber Defenders and Cyber Defense ..................................................................... 2
1.3 Cyber Situation Assessment ................................................................................... 4
1.4 Theoretical Approach ............................................................................................. 5
1.5 Research Questions ................................................................................................ 6
1.6 Significance of the Dissertation Research ............................................................. 7
Need for Research in Cyber Situation Assessment ..................................................... 9
CHAPTER 2: LITERATURE REVIEW .........................................................................................11
2.1 Naturalistic Decision Making ................................................................................11
2.2 Recognition Primed Decision Model ...................................................................15
2.3 NDM Situation Assessment Research..................................................................21
2.4 Task Complexity and Information Behavior ........................................................28
2.5 Cognitive Continuum Theory ...............................................................................54
2.6 Literature Review Summary .................................................................................66
CHAPTER 3: METHODOLOGY .................................................................................................68
3.1 Overview of Methods ...........................................................................................68
3.2 Case Study Approach ............................................................................................70
3.3 Multiple-Case Studies Approach for the Dissertation Research........................72
3.4 Limitations of Methods.......................................................................................109
CHAPTER 4: FINDINGS ..........................................................................................................111
4.1 Information Behaviors and Cognitive Modes Used for the Phishing Attempt
SA-Task .......................................................................................................................112
4.2 Information Behaviors and Cognitive Modes Used for the Zero-Day Exploit SATask.............................................................................................................................122

v
4.3 Information Behaviors and Cognitive Modes Used for the Malware Attack SATask.............................................................................................................................135
4.4 Comparison of Overall Patterns of Information Behaviors and Cognitive
Modes Used for Different SA-Task Types ................................................................149
4.5 Statistical Analysis of Information Behaviors ....................................................152
CHAPTER 5: DISCUSSION .....................................................................................................171
5.1 Summary of the Findings ....................................................................................171
5.2 Significance of the Dissertation Research ........................................................175
5.3 Implications .........................................................................................................178
5.4 Suggestions for Future Research .......................................................................180
List of References .................................................................................................................183
Appendix A. Institutional Review Board Approval .............................................................197
Appendix B. Interview Protocol...........................................................................................198
Appendix C. Recruitment Email...........................................................................................200
Appendix D. Task Complexity Coding .................................................................................201
Appendix E. Cognitive Modes Coding .................................................................................205
Appendix F. Freeman-Halton Extension Calculation Procedure .......................................208
Appendix G. Frequencies of Information Sources and Types Used for the .....................209
Phishing Attempt SA-Task....................................................................................................209
Appendix H. Frequencies of Information Sources and Types Used for the .....................210
Zero-Day Exploit SA-Task .....................................................................................................210
Appendix I. Frequencies of Information Sources and Types Used for the Malware Attack
SA-Task ............................................................................................................................211
Vita ........................................................................................................................................212

vi

List of Tables
Table 1 Department of Defense Requests for Proposals Related to Dissertation
Research ................................................................................................................... 10
Table 2 Problem Dimensions Identified by MacMulling and Taylor (1984) .................... 32
Table 3 Information Traits Identified by Taylor (1986) ..................................................... 34
Table 4 Theoretical Propositions from LIS Research Task-Complexity Research ........... 49
Table 5 Cognitive Continuum Index..................................................................................... 59
Table 6 Task Continuum Index ............................................................................................. 60
Table 7 Background of Expert Cyber Defenders Interviewed ............................................ 77
Table 8 Gender of Expert Cyber Defenders Interviews ...................................................... 78
Table 9 Critical Decision Method Interview Probes .......................................................... 83
Table 10 Types of Content Analysis ..................................................................................... 86
Table 11 Task Complexity Characteristics Used for the Dissertation Research .............. 90
Table 12 Characteristics of Cognitive Modes Used for the Dissertation Research ......... 93
Table 13 Cohen's Kappa Values for Task Complexity Coding Categories ....................... 95
Table 14 Cohen's Kappa Values for Information Source and Information Type
Coding Categories ................................................................................................ 96
Table 15 Cohen's Kappa Values for Cognitive Modes Coding Categories ....................... 96
Table 16 3 x3 Contingency Table for Number of Information Sources and SA-Task
Complexity ............................................................................................................. 99
Table 17 SA-Tasks and Cognitive Modes ..........................................................................151
Table 18 Number of Information Sources Used for the Phishing Attempt SA-Task .......155
Table 19 Number of Information Sources Used for the Zero-Day Exploit Task.............155
Table 20 Number of Information Sources Used for the Malware Attack SA-Task .........155
Table 21 Contingency Table (3 x 3) for Number of Information Sources Used
and SA-Task Complexity.....................................................................................156
Table 22 Number of External Sources Used for the Phishing Attempt SA-Task.............158
Table 23 Number of External Sources Used for the Zero-Day Exploit Task ..................158
Table 24 Number of External Sources Used for the Malware Attack SA-Task...............158
Table 25 Contingency Table (3 x 3) for Number External Sources Used and
SA-Tank Complexity ...........................................................................................159
Table 26 Number of People Used as Sources for the Phishing Attempt SA-Task...........161
Table 27 Number of People Used as Sources for teh Zero-Day Exploit SA-Task ..........161
Table 28 Number of People Used as Sources for the Malware Attack SA-Task .............161
Table 29 Contingency Table (3 x 3) for Number of People Used as Sources and
SA-Task Complexity ............................................................................................162
Table 30 Number of Experts Used as Sources for the Phishing Attempt SA Task ..........164
Table 31 Number of Experts Used as Sources for the Zero-Day Exploit Task ................164
Table 32 Number of Experts Used as Sources for the Malware Attack SA-Task............164
Table 33 Contingency Table (3 x 3) for NUmberof Experts Used as Sources and
SA-Task Complexity ............................................................................................165
Table 34 Number of Technical Pieces of Information Used for the Phishing
Attempt SA-Task ..................................................................................................167
Table 35 Number of Technical Pieces of Information used for the Zero-Day

vii
Exploit Task .........................................................................................................167
Table 36 Number of Technical Pieces of Information Used for the Malware
Attack SA-Task ....................................................................................................168
Table 37 Contingency Table (3 x 3) for Number of Technical Pieces of Information
Used and SA-Task Complexity ...........................................................................169
Table 38 Summary of Fisher-Freeman-Halton Exact Test Probabilities ........................170

viii
List of Figures
Figure 1. Cyber Defense Tasks from NIST (2012, p. 21) ..................................................... 3
Figure 2. Schema-based Model of the RPD Model (Elliott, 2005, p. 12) .......................... 25
Figure 3. General Model of Information Seeking of Professionals .................................... 40
Figure 4. Information Seeking Model Surrounding Task Completion ............................... 53
Figure 5. The Lens Model ..................................................................................................... 70
Figure 6. Overview of Multiple Case Studies Design Used for the
Dissertation Research ........................................................................................... 70
Figure 7. Taxonomy of Theoretical Contributions from Colquitt and
Zapata-Phelan (2007, 0. 1283) ............................................................................. 73
Figure 8. Information Sources and Information Types Used for the Phishing
Attempt SA-Task ................................................................................................119
Figure 9. Information Sources and Information Types Used for the Zero-Day
Exploit SA-Task ..................................................................................................142
Figure 10. Information Sources and Information Types Used for the Malware
Attack SA-Task ..................................................................................................157
Figure 11. Information Sources and Information Types Used for the Phishing
Attempt SA-Task ................................................................................................150
Figure 12. Information Sources and Information Types Used for the Zero-Day
SA-Task..............................................................................................................150
Figure 13. Information Sources and Information Types Used for the Malware
Attack SA-Task .................................................................................................150

ix

Abstract
Information Behaviors and Cognitive Modes Used
for Cyber Situation Assessment
Thomas Heverin

The purpose of this dissertation research was to examine the information behaviors and
cognitive modes used by expert cyber defenders when completing cyber situation
assessment tasks (SA-tasks) of different complexities. Theoretical propositions from
Library and Information Science (LIS) task-complexity research and the Cognitive
Continuum Theory (CCT) informed the theoretical framework. LIS task-complexity
research predicts that increased task complexity results in numerous changes in
information-source and information-type use. The CCT predicts that increased task
complexity results in a shift from analytical to intuitive cognition.
A multiple-case studies design was selected as the research approach. The Critical
Decision Method served as the basis for semi-structured, retrospective interviews
conducted with 21 expert cyber defenders from small defense companies. The data
analysis techniques included directed content analysis, pattern matching, and statistical
analysis (the Freeman-Halton extension of Fisher’s Exact test).

The main findings of this study are as cyber SA-task complexity increased, the expert
cyber defenders sought more technical information, used more external sources,
including external experts, and based their information behaviors on intuitive cognition.
These findings support several of the theoretical predictions from LIS task-complexity
research and the CCT.

x
The findings are important because they show that the expert cyber defenders base their
information behaviors on years of experience in the cyber defense domain and on years
of experience in designing their own companies’ security postures. Each company has its
own security posture as well as its own level of acceptance of risk. Therefore, cyber
situation assessment tools need a design that can be tailored for each company.
Additionally, methods are needed to elicit the intuitive processes used by expert cyber
defenders in order to train novice cyber defenders as well as other expert cyber
professionals taking over the experts’ localized cyber defense roles.

1
CHAPTER 1: INTRODUCTION
1.1 Threat of Cyber Attacks
Cyber attacks represent a considerable threat to national security and American
business interests. Cyber attacks can cause serious consequences such as the disruption of
military and other critical operations, theft of intellectual property, loss of revenue, and
even loss of life. Criminal groups, hackers, terrorists, and even nation states make use of
various types of cyber attacks to “…compromise information or adversely affect
computers, software, a network, an organization’s operation, an industry, or the Internet
itself” (U.S. Government Accountability Office, 2013, p. 6). According to the recent
Worldwide Assessment of Global Threats given by the U.S. Director of National
Intelligence (2013) , cyber attacks represent the number one threat to the U.S. The threat
posed by cyber attacks toped threats such as terrorism and transnational crime, weapons
of mass destruction, and North Korea’s nuclear stance (Clapper, 2013).
All types of companies have fallen victims to cyber attacks. Recent examples
include the Target Corporation’s data breach1 and University of Maryland’s data breach2.
U.S. government agencies and defense companies have increasingly become targets of
cyber attacks. A recent report shows a 782 percent increase in the number of cyber
attacks that targeted government agencies from 2006 to 2012 (U.S. Government
Accountability Office, 2013). Companies that work with the U.S. government especially
the Department of Defense (DoD) have also been targeted by cyber attacks. For example,
one defense company faced a three-year long cyber intrusion in which all of the

1

https://corporate.target.com/about/shopping-experience/payment-card-issue-FAQ

2

http://www.umd.edu/datasecurity/

2
company’s computers and research were compromised 3. This dissertation research
focused on small defense companies, companies with less than 500 employees that hold
contracts to work with the DoD. Small businesses companies represent one of the largest
growth areas for cyber attacks (Symantec Corporation, 2013).
1.2 Cyber Defenders and Cyber Defense
Companies and government agencies employ cyber professionals to defend and
protect networks as well as national security information. These professionals hold titles
such as network administrator, information security manager, network security engineer,
intrusion detection team member, information assurance analyst, and computer network
defense analyst (D’Amico & Whitley, 2008; Paul & Whitley, 2013). This dissertation
research uses the term “cyber defender” to capture all of the above mentioned roles. This
term has been used in previous research (D’Amico & Whitley, 2008). Depending on the
size of a company, cyber defenders may work alone or work on teams to detect and
analyze cyber attacks. This dissertation research focused on cyber defenders who hold the
sole responsibility of defending their company’s networks and resources from cyber
attacks. This type of cyber defender completes tasks for the entire cycle of cyber defense.
In contrast, cyber defenders who work on cyber defense teams may not complete tasks
for the entire cycle of cyber defense and therefore may only hold a partial view of cyber
defense. Only cyber defenders who hold the sole responsibility of protecting their
companies’ networks were selected to participate in this study.
The National Institute of Standards and Technology (NIST) (2012) defines the
main tasks of the cyber defense cycle as Preparation; Detection and Analysis;
3

http://www.bloomberg.com/news/2013-05-01/china-cyberspies-outwit-u-s-stealing-militarysecrets.html

3
Containment, Eradication and Recovery; and Post-Incident Activity. These main tasks are
displayed in Figure 1.

Figure 1. Cyber Defense Tasks from NIST (2012, p. 21)

The Preparation task consists of cyber defenders ensuring systems, networks, and
applications are secure to prevent cyber attacks. This task also consists of formulating
policies and plans for cyber attack response. The Detection and Analysis task consists of
cyber defenders monitoring intrusion and detection systems (IDS), intrusion detection
and prevention systems (IDPS), antivirus software, and network device logs for
suspicious activity. This task also involves analyzing signals that might indicate an attack
is taking place. Upon detecting an attack, a cyber defender gathers more information
about the attack, identifies systems impacted by the attack, assesses the severity of the
attack, and assesses the damage caused by the attack as well as potential damage.

4
The Containment, Eradication, and Recovery task focuses on containing the
attack to limit its impact, eradicating malicious components of the attack, and then
restoring systems to normal operation. Finally, the Post-Incident Activity task involves
developing lessons learned and retaining evidence. The cyber defense tasks are iterative
as represented by arrows in Figure 1.
1.3 Cyber Situation Assessment
The cyber defense task of detecting and analyzing cyber attacks is also called the
situation assessment task (SA-task) or “cyber situation assessment” task (Barford et al.,
2010; Cichonski et al., 2012; A. D’Amico, Whitley, Tesone, O’Brien, & Roth, 2005).
The SA-task is an information intensive task that consists of viewing an initial set of
information about a situation, evaluating and selecting information sources, and
integrating new information into existing evidence (Ben-bassat & Freedy, 1982;
Gorodetsky, Karsaev, & Samoilov, 2005). The SA-task involves identifying and
clarifying the state of a problem including why the situation appears the way it does, the
risks of the situation, and actions that can minimize these risks (Kirillov, 1994; D. Noble,
1993; Salas, Rosen, & DiazGranados, 2010). Completing the SA-task leads to obtaining
situation awareness (Endsley, 2000).
Cyber defenders face various challenges when completing the SA-task. Cyber
defenders must review massive amounts of data from multiple sources to determine if an
attack is taking place and to understand characteristics of the attack. The abundance of
data needed to be reviewed results in data overload for the cyber defenders (A. D’Amico
et al., 2005; Erbacher, Frincke, Wong, Moody, & Fink, 2010; Tyworth, Giacobe,
Mancuso, & Dancy, 2012; Yen et al., 2010). In addition to facing data overload, cyber

5
defenders need to fuse data from complex sources including internal sources and external
sources (A. D’Amico et al., 2005; Goodall, Lutters, & Komlodi, 2009). The information
gathered from these sources often contains a high level of uncertainty (Yen et al., 2010)
and a high level of deception (Tyworth et al., 2012). Another challenge for cyber
defenders when completing the SA-task consists of the uniqueness of each cyber attack.
The uniqueness of each attack makes it difficult for cyber defenders to use information
found on previous attacks to respond to a current attack (A. D’Amico et al., 2005;
Erbacher et al., 2010). Additionally, cyber attacks are dynamic and change over time
even when being analyzed by cyber defenders (Tyworth et al., 2012; Yen et al., 2010).
Several automated techniques have been developed to assist cyber defenders in
completing the SA-task. Examples of these techniques include information fusion (Sabata
& Ornes, 2006), clustering (Kang & Mayfield, 2003), ontology reasoning (Anita
D’Amico, Buchanan, Goodall, & Walczak, 2009), machine learning algorithms (Stroeh,
Mauro Madeira, & Goldenstein, 2013), and network visualization techniques (Holsopple
et al., 2010). Although automated solutions can help cyber defenders complete the SAtask, these automated solutions often ignore the importance of the human elements of
cyber security including communication, collaboration, cognitive processes, and
information behaviors (Forsythe, Silva, Stevens-Adams, & Bradshaw, 2012; Knott et al.,
2013; McNeese et al., 2012; Paul & Whitley, 2013). As a result, more research is needed
on the human side of cyber security.
1.4 Theoretical Approach
Naturalistic Decision Making (NDM) research focuses on the human elements of
decision making in contexts with high stakes, high time pressure, and high uncertainty.

6
Situation assessment has been found to be a critical process for expert decision makers in
NDM contexts (Klein, 1993). NDM situation assessment research has demonstrated that
experts seek more information than novices when completing the SA-task (R. Lipshitz &
Shaul, 1997) and base their information behaviors on intuitive cognition (David F. Noble,
Boehm-Davis, & Grosz, 1986). However, NDM situation assessment research lacks a
theoretical foundation for testing predictions in information behavior and cognitive
modes used by experts when completing SA-tasks of different complexities. In this
dissertation research, information behavior is defined as “how people need, seek,
manage, give, and use information in different contexts” (Fisher, Erdelez, & McKechnie,
2005, p. xix)
Library and Information Science (LIS) task-complexity research (Byström &
Järvelin, 1995) provides a theoretical approach for examining the information behaviors
used by expert cyber defenders when completing SA-tasks of different complexities.
Additionally, the Cognitive Continuum Theory (CCT) (Hammond, Hamm, Grassia, &
Pearson, 1997) provides a theoretical approach for examining the cognitive modes used
by expert cyber defenders when completing SA-tasks of different complexities. The
theoretical predictions of LIS task-complexity research and the CCT were tested in this
dissertation research in the context of cyber situation assessment.
1.5 Research Questions
The purpose of this dissertation research was to test the theoretical propositions of
LIS task-complexity research and the CCT in the context of cyber situation assessment.
The broad research question for this dissertation research included:

7
How does situation-assessment task complexity influence information behaviors
and cognitive modes used by expert cyber defenders in the context of cyber situation
assessment?
More specifically, this dissertation research focused on the following:
How does situation-assessment task complexity influence the information
behaviors of expert cyber defenders when completing situation assessment
tasks?
How does situation-assessment task complexity influence the cognitive modes
used by expert cyber defenders when completing situation assessment tasks?
LIS task-complexity research states the following: as task complexity increases
the number of information sources used, the use of external sources, the use of people as
sources, the use of experts as source, and the use of problem solving/domain information
increase (Byström & Järvelin, 1995). The CCT states that low task complexity induces
the use of analytical cognition (step-by-step, deliberate processing) and high task
complexity induces the use of intuitive cognition (automatic, non-conscious processing)
while medium task complexity induces a mix of analytical and intuitive cognition (quasirational cognition) (Hammond et al., 1997).
1.6 Significance of the Dissertation Research
The findings of this dissertation research will further our understanding of how
situation assessments are formed in NDM contexts. The information behaviors and
cognitive modes used for situation assessments have not been examined together in NDM
situation assessment research. The findings of this dissertation research will be compared
to NDM situation assessment research conducted in contexts such as U.S. Navy ship

8
warfare and submarine warfare. This dissertation study shows how LIS theory can be
incorporated with theory from other fields, as in the case of the CCT from cognitive
psychology, to examine decision-making processes in real world contexts.
The findings of this dissertation research will also further our understanding of
information behaviors used by professionals in contexts with high stakes, high time
pressure, and high uncertainty, contexts not typically focused on in LIS research.
Additionally, the theoretical propositions posed by LIS task-complexity research and the
CCT have yet to be tested in the context of cyber defense. LIS task-complexity research
has primarily focused on non-NDM contexts such as public administration. Additionally
this dissertation research will further our understanding of information behaviors of a
specific group of professionals not previously studied in LIS research – expert cyber
defenders.
Significance for Cyber Defense Training
Current cyber defense training relies on traditional, instructor-led classroom
training. The dissertation findings suggest that this traditional training may not work for
all SA-tasks. For example, this dissertation’s findings suggest that for SA-tasks with low
complexity, cyber defenders follow a step-by-step deliberative process. For these low
complexity SA-tasks, traditional, instructor-led classroom training may be sufficient.
However, the dissertation findings also suggest that for SA-tasks with high complexity,
the expert cyber defenders follow a more non-conscious, intuitive process. Therefore, the
traditional cyber defense training method may not appropriate for these tasks. Instructorled classroom training does not allow decision makers to develop situation assessment
skills needed to complete complex SA-tasks. As a result, training methods need to be

9
developed to help novice cyber professionals acquire situation assessment skills to face
the complexities of cyber defense. Previous methods applied in other NDM contexts that
may prove effective in cyber defense include training higher order cognitive skills,
training on using critical cues, and providing situation assessment feedback (Salas,
Prince, Baker, & Shrestha, 1995) along with scenario-based training (Oser, Gualtieri,
Cannon-Bowers, & Salas, 1999).
Significance for System Design
The findings of the dissertation research suggest the need for secure, collaborative
information seeking and sharing tools. For SA-tasks with high complexity, the
dissertation findings showed that expert cyber defenders relied heavily on the research
conducted by external experts and that expert cyber defenders reached out to
communicate directly with external experts. However, none of the expert cyber defenders
stated the use of secure, collaborative information seeking or sharing tools. Rather the
expert cyber defenders relied on general instant messaging tools (such as Yahoo or
Google), forums, blogs, and email to share and exchange information. With these
communication channels, the experts found it difficult to share confidential or nonidentifiable information. Secure, collaborative information seeking and sharing tools are
needed to provide cyber defenders the capability of exchanging confidential information
with trusted external experts.
1.7 Need for Research in Cyber Situation Assessment
The need for research on the cyber situation assessment has been evidenced by
several recent DoD requests for proposals (RFPs). Table 1 shows recent examples of

10
DoD RFPs that focus on the cyber situation assessment as well as the cognitive processes
used in cyber defense.

Table 1
Department of Defense Requests for Proposals Related to Dissertation Research
Topic Name/Number
Agency
Description
Effective Cyber Situation
Awareness (CSA)
Assessment and Training /
OSD12-T08
Cognitive Modeling for
Cyber Defense / N132-132

Adaptive, Immersive
Training to Counter
Deception and Denial
Tactics, Techniques and
Procedures (TTPs) for
C4ISR / AF141-031
Enhancing Intuitive
Decision Making Through
Implicit Learning /
ONRBAA012-011

Office of the
Secretary of
Defense

The goal of this project is to develop a
novel human-in-the loop simulation
and assessment system for cyber
situation awareness and for assisting
cyber analyst training
U.S. Navy
Modeling the complex cognitive
processes involved in cyber defense.
The modeling includes cues, features,
and characteristics monitored by
defenders and attackers.
U.S. Air Force The goal of this project is to develop a
cyber-training environment that
represents current actual environments
(high stakes, high uncertainty, and high
deception) and that includes current
cognitive science developments.
Office of Naval The expected results of this research
Research
include laying the scientific foundation
for understanding intuitive decision
making that support warfare areas
including cyber warfare.

The findings of this dissertation can contribute to improving cyber defense efforts
in protecting national security information and American business interests.

11

CHAPTER 2: LITERATURE REVIEW

The NDM research paradigm is used in this dissertation because it focuses
explicitly on how experts make decisions in contexts with high stakes, high time
pressure, and high uncertainty, contexts similar to cyber defense. This literature review
provides an overview of NDM research including the Recognition Primed Decision
(RPD) Model (Klein, 1993) and situation assessment research (R. Lipshitz & Shaul,
1997). Although, NDM situation assessment research focuses on information behaviors
as well as the cognitive basis of these behaviors, this line of research lacks a theoretical
foundation for testing predictions on how task complexity influences information
behavior and cognitive modes used by experts when completing SA-tasks. LIS taskcomplexity research (Byström & Järvelin, 1995) provides a theoretical framework for
examining differences in information behaviors used by expert cyber defenders for
completing SA-tasks of different complexities. The CCT (Hammond et al., 1997)
provides a theoretical framework for examining the differences in cognitive modes used
by expert cyber defenders when completing SA-tasks of different complexities.
2.1 Naturalistic Decision Making
Decision making research has evolved from studies that focused on simulated
tasks completed by novice research participants in controlled laboratory studies (classical
decision making) to studies that focused on complex, real world tasks completed by
experts (naturalistic decision making) (Randel, Pugh, & Reed, 1996). A description of the

12
evolution from classical decision making to naturalistic decision making is provided
below.
2.1.1 Classical Decision-making Description
Through the 1970’s classical decision making research (also labeled as rational
decision making research) focused on experimental laboratory studies and developed
models based on formal or mathematical foundations such as Bayesian probability theory
and decision theory (Nemeth & Klein, 2011). Lipshitz et al. (2001, p. 333) stated that
classical decision making research contained four essential characteristics: choice
(choosing among alternatives), input-output orientation (predicting which alternative a
decision maker will choose), comprehensiveness (a deliberate process requiring complete
information for optimal performance), and formalism (the establishment of quantitative
models). In this approach, an ideal decision maker selects the optimal choice from an
array of concurrent options after reviewing all information about each option. Following
this way is the “rational” way (Beach & Lipshitz, 1993, p. 22).
Classical decision making assumes that choices are clearly defined, information is
fully available, goals are isolated, and that probabilities can be accurately estimated
(Klein & Calderwood, 1991). Additionally, Randel , Pugh, and Reed (1996) stated that
classical decision making focused on well defined problems and relatively stable
environments. A major strength of the classical decision making approach includes
demonstrating its applicability across a wide range of domains and developing powerful
techniques for improving decision quality where feasible (Klein & Calderwood, 1991).
Examples of classical decision making approaches include multi-attribute utility analysis
(Edwards and Newman, 1982) and elimination by aspects (Tversky, 1972).

13
2.1.2 Naturalistic Decision-making Description
In the classical decision making research, NDM contexts (contexts that contain
high stakes, high time pressure, and high uncertainty) were not touched (Hammond,
1988). However, in naturalistic contexts, early research indicated that decision makers
were not following the rational approach as predicted by classical decision making
(Klein, Calderwood, & MacGregor, 1989); rather, expert decision makers were following
an intuitive decision making approach. Prior to the late 1980s and early 1990s, intuitive
decision-making was not considered to be serious concept in classical decision making
research. Intuitive decision making was viewed as reliable as flipping a coin (Simpson,
2001).
To address the early findings that showed that experts were using intuitive
decision making in contexts with high stakes, high time pressure, and high uncertainty,
researchers started to develop the NDM approach. NDM evolved rapidly starting in the
late 1980s (Kahneman & Klein, 2009; Raanan Lipshitz et al., 2001; Simpson, 2001). The
accidental shooting down of an Iranian commercial aircraft by the USS Vincennes, a U.S.
Aegis guided missile cruiser, in 1988 created a strong interest in NDM from the U.S.
military. After that incident, the U.S. Navy, as well as the U.S. Army, sought to improve
decision making in high stakes, high time pressure, and high uncertainty situations
(Klein, 2008; Schraagen, Browne, & Hoffman, 2008). The U.S. Army sponsored the first
NDM conference in 1989 as well as other research efforts. Additional research funding
and support for the NDM has come from the Office of Naval Research, the U.S. Marine
Corps, the Army Research Institute, the Army Research Laboratory, the Human
Effectiveness Directorate of the U.S. Air Force, and the National Aeronautics and Space

14
Administration (NASA) (Schraagen et al., 2008). NDM has been incorporated into the
following military doctrine and training (Klein, 2008):
U.S. Army Field Manual on Command and Control
U.S. Marine Corps planning guidance
Tactical mission planning for the Swedish Armed Forces
Recommendations for training decision making and cognitive skills based on
NDM studies with the U.S. Navy – Tactical Decision Making Under Stress
(TADMUS)
The goal of NDM research is to understand how decision makers handle difficult
cognitive demands of their work in naturalistic contexts (Cannon-Bowers, Pruitt, & Salas,
1996; Schraagen et al., 2008). NDM research encompasses the skills, knowledge, and
experience of decision makers, aims to improve expert decision making, aims to help
non-experts achieve expertise faster, and emphasizes the cognitive processes used by
decision makers (Schraagen et al., 2008). Rather than focusing on novices, NDM
research focuses on experts (Cannon-Bowers et al., 1996).
There are several NDM models. From a review of nine different NDM models
that were developed in parallel, Lipshitz (1993) summarized the main tenants of the
models as follows: experts use prior experience to make decisions rather than generating
and comparing options; experts form situation assessments before making a decisions;
and experts rely on prototypes of situations to make decisions (Klein, 2008). Three NDM
approaches are discussed in this dissertation research: the RPD Model (Klein, 1993),
NDM situation assessment research (R. Lipshitz & Shaul, 1997; David F. Noble et al.,
1986), and the CCT (Hammond et al., 1997) . These NDM approaches were developed

15
based on studies focusing on the decision making of experts such as Navy commanders,
nuclear power plant operators, fire-ground commanders, Army small unit leaders,
airplane pilots, highway engineers, and nurses.
2.2 Recognition Primed Decision Model
2.2.1 RPD Model Background
The RPD Model often serves as the prototypical NDM model (Flin, Slaven, &
Stewart, 1996; Raanan Lipshitz et al., 2001). The RPD Model focuses explicitly on
decision making in situations with three attributes: high time pressure, high level of
expertise, and high consequences. At the time that the RPD Model was developed,
previous research decision making research focused on situations without low time
pressure, naïve decision makers (college students trained on new tasks), and laboratory
studies which lacked high consequences (Klein, Calderwood, & Clinton-Cirocco, 2010).
Klein (1993, pp. 143–144) stated that the RPD Model is different from other decision
models in that:
The RPD Model focuses on situation assessment and not decision events.
The RPD Model describes how people bring their experience to bear on a
decision.
The RPD Model relies on satisficing rather than optimizing.
The RPD Model asserts that experienced decision makers evaluate an option
by conducting mental simulations of a course of action to see if it will work,
rather than contrasting strengths and weaknesses of different options.
In the RPD Model, decision makers first assess a situation (complete the SA-task)
and then select an action that is believed to be most appropriate based on that assessment

16
(McLennan & Omodei, 1996). The SA-task completion is based on recognizing a current
situation as being similar to a previous situation. This is labeled as “recognitional
decision making”. Recognitional decision making has be found to hold three forms
(Kaempf, Klein, Thorsden, & Wolf, 1996):
Simple Match: the decision maker recognizes the situation as familiar or
typical allowing the decision maker to make a rapid decision.
Developing a Course of Action: in this situation, the decision maker appraises
courses of action by selecting the first one that can work and then running a
mental simulation of what the outcome would be. This is done through serial
evaluation of options rather than concurrent evaluation.
Complex RPD Strategy: in this situation, the decision maker encounters an
unfamiliar situation. When facing an unfamiliar situation, the decision maker
reassesses the situation and tries to find more information. Once the situation
is recognized as similar to a previous one, the decision maker conducts the
mental simulation, modifies as necessary, and then implements the decision.
In the RPD Model, the process of completing the SA-task consists of
understanding the goals that can be accomplished based on the situation, increasing the
salience of important cues in the situation (though information seeking), forming
expectations which can be used to conduct a check on the situation assessment, and
identifying typical actions to take (Klein, 1993, p. 142). A decision makers’ experience
developed over time allows him or her to effectively complete SA-tasks.
2.2.2Review of RPD Model Studies
Foundational Study

17
The foundational study that provided the initial formation of the RPD Model
focused on the decision making of fire ground commanders (leaders at the scene of a fire
who determine where to send personnel and equipment to fight fires) (Klein,
Calderwood, & Clinton-Cirocco, 1986). The CDM served as the interview protocol
surrounding 32 critical incidents discussed by 26 fire ground commanders who had an
average of 23 years of experience (Klein et al., 2010). The researchers expected the fire
ground commanders to prescribe to the classical decision making perspective of
concurrent option evaluation. However, the results provided almost no evidence to
support this classical decision making research perspective (Klein et al., 2010).
The researchers found that rather than trying to assess concurrent options the fire
ground commanders attempted to first form a situation assessment. When forming a
situation assessment, the fire ground commanders attempted to match the current
situation with situations they had faced in the past. Upon recognizing a situation as
similar to a previous one, the fire ground commanders selected the first course of action
that came to mind. The researchers labeled this as “recognitional decision making” and
found that that 80% of the fire ground commanders’ decisions were recognition-based
while only 12% consisted of option deliberation (Ross, Shafer, & Klein, 2009).
Support for the RPD Model
Support for the RPD Model has come from many studies in the military domain.
For example, Kaempf et al. (1996) examined how 20 experienced U.S. Navy officers
(officers that led anti-air warfare teams on a U.S. Navy Aegis cruiser) made complex
decisions in a high time pressure, high stakes environment. The researchers found that the
Navy officers worked in an environment in which doctrine and rules of engagement

18
controlled actions. In order to determine the appropriate course of action, the officers had
to determine what type of situation they were facing. The researchers found that the
officers used a recognitional decision strategy in 95% of the actions taken.
Numerous other studies have the shown the dominance of recognitional decision
making used by various types of experts in NDM contexts including Army officers in
command and control situations (Pascual & Henderson, 1997), Navy officers in the
Combat Information Center (CIC) of a Navy cruiser (Kaempf, Wolf, & Miller, 1993),
highly experienced nurses in a neonatal intensive care unit (NICU) (Crandall &
Calderwood, 1989), and off-shore emergency response team leaders responding to
emergencies (Flin et al., 1996).
Recognitional vs. Analytical Strategies
Several differences have been found in outcomes when using recognitionalprimed decision-making strategies vs. rational decision-making strategies. Johnston,
Driskell, and Salas (1997) examined the decision making of 90 U.S. Navy enlisted
personnel in a technical training school. The participants performed a simulation of a
naval command and control task (identifying unknown air, surface, and sub-surface
contacts) and were trained on using either recognitional-primed decision making
strategies or rational decision making strategies. For the recognitional-primed decision
making strategies, the participants were trained on scanning the information needed to
assess a threat, scanning information in any sequence, rapidly attending to specific data
points, and reviewing needed information only when required (Johnston et al., 1997, p.
617). For the rational decision making strategy, the participants were trained on scanning
all available information, scanning information in a systematic manner, devoting a

19
consistent amount of attention to each data point, and reviewing all alternatives before
making a decision.
The results showed that when facing a naturalistic task (a task with high stakes,
high time pressure, and high uncertainty) military personnel trained with the
recognitional-primed decision making strategy outperformed those trained on analytical
decision making strategies (Johnston et al., 1997). Similarly, Driscoll, Salas, and Hall
(1994) also found that Navy officers who were trained to systematically review all
available information prior to making a decision showed degraded performance when
compared to Navy officers who were trained on using recognitional-primed decision
strategies.
RPD Model: Novices vs. Experts
Differences between recognitional decision-making have been found between
experts and novices. Randel, Pugh, and Reed (1996) studied the decision-making
processes used by 28 U.S. Navy electronic warfare technicians. There were three
categories of participants: novices, intermediates, and experts. The researchers found that
the intermediates and experts focused primarily on the SA-task while the novices focused
more on selecting a course of action. In a study on tank platoon commanders, Brezovic,
Klein, and Thorsden (1990) identified command decisions and environmental features of
the situations encountered by the novice and expert commanders. The researchers found
that both the novices and experts (nine instructors) placed attention on the same
environmental cues; however, the novices tended to misinterpret the importance of the
cues (Brezovic et al., 1990). The researchers posited that novices used conscious

20
deliberation when they lacked the experience to recognize a situation. It was observed
that students would even stop in the middle of the battlefield to deliberate possible COAs.
2.2.3 Limitations of the RPD Model
One criticism of the RPD Model is that it does not necessarily fit across all
situations and therefore lacks generalizability (Joshua Klayman, 2001; Patel, Kaufman, &
Arocha, 2002). However, the RPD Model does not attempt to generalize across all
situations; rather the use of the RPD Model focuses on situations in which the decision
maker is experienced, time pressure is high, and the conditions are unstable (Klein,
1993). Additionally, the RPD strategy has been found to not be appropriate to follow for
all tasks. For example, the RPD strategy may not be well suited for tasks that require
optimizing rather than satisficing, tasks requiring decisions to be justified, tasks requiring
agreement from multiple stakeholders, and tasks where the level of expertise is low
(Klein & Crandall, 1996).
The RPD Model suggests that information seeking only comes into play for the
Complex RPD Strategy of the RPD Model when experts face unfamiliar situations
(Kaempf et al., 1996). However, NDM situation assessment research shows that experts
seek more information than novices even when forming situation assessments even when
the experts have experienced the same type of situation in the past (R. Lipshitz & Shaul,
1997). The RPD Model cannot adequately explain these findings on the information
behaviors of experts. The RPD Model posits that the experts would not need to seek
information when facing a situation that they faced before. NDM research that focuses on
situation assessment attempts to resolve this issue.

21
2.3 NDM Situation Assessment Research
2.3.1 Situation Assessment Background
Situation assessment is viewed as crucial for decision making in NDM contexts
(David F. Noble et al., 1986; Salas et al., 2010; Simpson, 2001). Situation assessment can
be viewed as the process that leads to the situation awareness (Endsley, 1995; 2005;
Randel et al., 1996). Forming a situation assessment is called completing a “situation
assessment task” (David F. Noble et al., 1986). Ben-bassat and Freedy consider this task
to be a “puzzle building task” as decision makers put together pieces of information to
understand a situation (1982, p. 489). The SA-task consists of viewing initial information
about a situation, evaluating and selecting sources, and integrating new information into
existing evidence (Ben-bassat & Freedy, 1982; Gorodetsky et al., 2005). Several NDM
situation assessment studies have examined information behaviors of experts and several
studies have conceptualized the cognition underlying this information behavior.
2.3.2 Situation Assessment and Information Behaviors
Several NDM studies have examined the situation assessment processes of
experts, which include information behaviors. Kaempf et al. (1996) examined how 20
experienced U.S. Navy officers responded to complex situations in a ship’s CIC. The
researchers found that most actions taken by the Navy officers focused on acquiring more
information about potential threats in order to form a situation assessment. The experts
also sought information about internal resources to make sure potential actions could be
carried out. For example, they sought information about whether Navy aircraft had
enough fuel and weapons to carry out a mission. The results supported Cohen et al.’s

22
(1994) analysis on battle commanders which found that intricate situation assessments
formed by experts were critical for successful mission accomplishment.
Some studies have shown that expert decision makers place a greater emphasis on
developing a situation assessment than novices. In a study on U.S. Navy electronic
warfare technicians, Randel et al. (1996) examined the differences in SA-task completion
by experts and novices. The findings showed that the experts placed a greater emphasis
on the SA-task while the novices placed a greater emphasis on deciding on a COA. The
researchers suggested that the experts concentrated on getting the situation assessed
correctly and then once the situation was understood correctly they could react quickly
(Randel et al., 1996). In a study on U.S. Marines in a battle command-post scenario,
Kobus, Proctor, Bank, and Holste (2001) also found that novices spent more time
deliberating over a COA while experts spent more time trying to understand the situation.
These results aligned with Orasanu and Connolly’s (1993) position that experts focus
more on the SA-task than novices.
The differences in information behavior between experts and novices for situation
assessment have also been examined in NDM contexts. Lipshitz and Shaul (1997)
examined the differences in the information sought for the SA-task between expert and
novice Navy commanders facing gun boat situations. The researchers found that the
expert commanders collected more information for the SA-task than the novice
commanders. The researchers stated that the novices were more likely to make decisions
based on what was given to them rather than actively seeking more information as the
experts did. Other research has also shown that experts collect far more information about
a situation prior to making a decision when compared to novices as in the case of battle

23
planners facing a Persian Gulf wartime scenario (Serfaty, MacMillan, Entin, & Entin,
1997).
Experts also tend to look for different types of information for situation
assessment than novices. In an anti-submarine warfare scenario, Kirschenbaum (1992)
found that experts used more raw, unprocessed data than computer processed information
(the system calculating the speed of an unknown contact). In a study on weather
forecasters, Pliske, Crandall, & Klein (2004) also found that experts not only relied on
computer models but also relied on sub-elements of the model to find data that they
needed. Other research has shown that experts seek more information from more sources
on more varied aspects of the situation (R. Lipshitz & Shaul, 1997; Pliske et al., 2004).
Research has also shown that experts can better organize information than novices (Waag
& Bell, 1997) and that experts conduct more directed information searching than novices
(Kirschenbaum, 1992).
Overall, these studies show that experts, when facing complex NDM contexts,
placed a great emphasis on the SA-task and seek a lot of information (as compared to
novices) to complete the SA-task. Simpson (2001) posited that expert decision makers
know how much information they need to make a correct situation assessment while
novices might not know what information is missing resulting in less information being
sought by novices. Additionally, even though experts and novices may view the same
information, experts can see more complexity in the situation than novices (Serfaty et al.,
1997). Noble et al. (1986) and Lipshitz and Shaul (1997) posit that schemas, cognitive
structures developed through years of experience, guide experts in their information
behavior. This concept is discussed in more detail in the next section.

24
2.3.2 Situation Assessment and Cognition
As stated before, the RPD model cannot accurately explain why experts require
more information to complete a SA-task than novices (R. Lipshitz & Shaul, 1997). Noble
et al. (1986) and Lipshitz and Shaul (1997) conceptualize the schema serve as a way for
explaining this information behavior. In the NDM perspective, experts complete SA-tasks
based on schema that have developed through years of experience. Lipshitz and Shaul
(1997, p. 295) define schema as “situation or domain specific cognitive structures that
(a) direct external information search, (b) specify which available information will be
attended to and which information will be ignored, (c) organize information in memory,
(d) direct the retrieval of information from memory, and (e) become more differentiated
as a function of experience.” Schema allow experts to determine which information is
missing, where it can be obtained, and how to organize information in a meaningful way
(R. Lipshitz & Shaul, 1997; D. Noble, 1985; Serfaty et al., 1997). According to Elliot
(2005, p. 215) “A schema helps determine what we attend to, what we perceive, and what
we remember and infer.”
(Elliott, 2005, p. 12) provides an overview of this NDM perspective on schema
and information behaviors for completing SA-tasks in NDM contexts as compares this
perspective to the RPD Model.

25

Figure 2. Schema-based Model of the RPD Model (Elliott, 2005, p. 12)

The schema-based model on the right side of shows that as experts identify cues
in the environment of a situation, schema are activated which guide their information
behaviors. Once the situation is recognized as being familiar to a previous situation
encountered, a mental model is created which allows the expert to run a simulation in his
or her head, which then leads to a decision being made and then implemented.
When schema are used by expert decision makers, several researchers have
conceptualized that the expert decision makers are using intuitive cognition –
unconscious, recognition-based information processing. Some researchers have

26
conceptualized the direct link between schema and intuitive cognition. Noble, BoemanDavis, and Grosz (1986, p. 61) state:
“Schema for situation assessment support "intuitive" decision making. This kind
of decision-making is based on recognizing that an observed situation is similar to
other situations in which particular decisions or strategies generally work well.
"Intuitive" decision making requires data in memory that supports the necessary
similarity assessment.”
This means that expert decision makers use their memory to form situation
assessments. For example, if a decision maker faces a situation that matches the
properties of a situation that is stored in the decision maker’s memory, the previous
situation becomes “strongly activated” in the decision maker’s mind and guides task
completion (Zsambok, Beach, & Klein, 1992). When a new or unfamiliar situation fails
to match properties of a similar situation, the decision maker matches features of similar
situations or modifies the response of a previous situation. Schema provide the basis of
expert performance by enabling experts “to recognize the similarity between new and
previously experience situations and to adapt old procedures for new situations” (D.F.
Noble, 1989, p. 473).
Cohen et al. (1994, p. 73) explicitly stated how structures within an expert
decision maker’s memory (called knowledge structures) are connected with intuitive
cognition: “Intuitive processing tends to involve domain-specific knowledge structures
that are developed through experience.” Cohen et al. (1994) differentiates between
domain-specific knowledge structures and general-purpose knowledge structures.
Intuitive processing consists of using domain-specific knowledge structures drawn out

27
over time through experience while analytical processing consists of using generalpurpose knowledge structures learned through instruction. The intuitive processing and
analytical processing described by Cohen et al. (1994) are synonymous with Hammond’s
(Hammond et al., 1997) descriptions of intuitive cognition and analytical cognition
respectively.
In the NDM situation assessment perspective, schema are developed over time
and through experience. When expert decision makers use the schema for situation
assessment and information behaviors, they are relying on intuitive cognition.
2.3.3 Limitations of Situation Assessment Research
One limitation of NDM situation assessment research is that previous studies do
not show how the process of completing SA-tasks differs for experts across tasks of
varying complexity. Rather NDM situation assessment research tends to focus on the
differences between expert and novice information behavior when completing SA-tasks
(Kirschenbaum, 1992; R. Lipshitz & Shaul, 1997; Serfaty et al., 1997; Waag & Bell,
1997). There lacks a solid theoretical framework for examining these differences in
information behavior. LIS task-complexity research (Byström & Järvelin, 1995) provides
a solid theoretical framework for examining the differences between the information
behaviors used for completing SA-tasks with different complexities (Vakkari, 1999).
Another limitation of NDM situation assessment research is that previous studies
have not empirically examined the cognitive processes used by experts when completing
SA-tasks. NDM research posits that experts develop schema based on years of experience
(D.F. Noble, 1989) which contribute to intuitive decision making (Cohen et al., 1994) and
guide information behaviors. However, the use of intuitive cognition for information

28
behaviors when forming situation assessments has not been adequately tested in NDM
research. The CCT (Hammond et al., 1997) provides a theoretical framework work for
examining differences in the cognitive modes used by experts when completing SA-tasks
of different complexities. LIS task-complexity research and CCT studies are reviewed in
the next sections.
2.4 Task Complexity and Information Behavior
2.4.1 LIS Models of Tasks Characteristics and Information Behavior
A task is an activity or set of activities to be performed in order to accomplish a
goal. Numerous researchers in LIS have stated that tasks greatly affect information
behavior (Belkin, Chang, Downs, Saracevic, & Zhao, 1990; Byström & Järvelin, 1995;
Leckie, Pettigrew, & Sylvain, 1996; Taylor, 1986; Vakkari, 1998). Two general models
of information behavior of professionals have been developed: Taylor’s (1986)
Information Use Environment Model (IUE Model) and Leckie et al’s GMISP (1996).
Overall, these two models state that task characteristics influence information behaviors.
However, these models lack theoretical predictions. LIS task-complexity research
provides theoretical predictions on the influence of task complexity on information
behaviors. Taylor’s IUE Model, Leckie’s GMSIP, and LIS task-complexity research are
discussed below. These LIS models are included in this literature review due to the fact
that although NDM situation assessment research states that information behavior is a
core component of situation assessment, there is a minimal amount of NDM situation
assessment studies that have primarily focused on information behaviors. LIS models
provide a foundation for examining these information behaviors.

29
The Information Use Environment Model
Background of the IUE Model
The context of the environment influences how members of a defined group (i.e.
engineers, lawyers, doctors) assess the value of information to help solve their problems.
Taylor (1991, pp. 25–26) defines IUE as the “set of those elements that (a) affect the flow
and use of information messages into, within, and out of any definable entity; and (b)
determine the criteria by which the value of information messages will be judged.” The
IUE affects the availability and access to information used and determines the criteria
used to judge whether information is relevant and useful (Agada, 1999). The IUE is
embedded in the total external environment of the individual and consists of the
“environmental elements that are most salient to information seeking and use”
(Berryman, 2008). The foundations of the IUE Model stem from Dervin (1983), Paisley
(1980), Wilson (1981), Roberts (1982), and Wersig and Windel (1985).
The IUE Model explicitly places the individual at the center of its conceptual
framework (Rosenbaum, 1996) and is considered to be a “user- and context-centric
construct for framing practice” (Durrance, Souden, Walker, & Fisher, 2006). The
individual evaluates information in relation to objectives that created his or her need.
Although individuals may conduct searches surrounding a specific subject, the choices of
information are not just based on subject matter, rather they are based on other elements
found in the context within which people live or work (Rieh, 2004).The IUE is dynamic
in that it changes in response to new information and how individuals interact with the
information and others (Rosenbaum, 1996).

30
Although the IUE Model initially focused on problems faced in the workplace
(Berryman, 2008), the IUE Model can “…serve as a generalized model, a useful means
for organizing, describing, and predicting the information behaviors of any given
population in a variety of contexts (Luo, 2008, p. 605).” The IUE Model has been used
as a framework to understand information seeking of inner city gatekeepers (Agada,
1999), individuals in their homes (Rieh, 2004), community organizers (Durrance et al.,
2006), foster care children (Hersberger, Murray, & Sokoloff, 2006), middle managers
(Maurel & Bergeron, 2007), high school principals (Luo, 2008), public sector workers
(Berryman, 2008), and medical practitioners (Olatokun & Ajagbe, 2010).
Taylor (1986, p. 35) defines three general types of IUEs:
Geographical – defined by a physical limit such as a neighborhood, city,
region or a nation.
Organizational – defined as a complex social unit designed to achieve a
specific purpose. Examples include a police department, a hospital or a
department within a hospital.
Social/Intellectual/Cultural – defined as a group of people, even unknown to
each other, whose professional activities form a foundation for various
information services. Examples include all members of a religious faith, all
chemists, and all chamber music players.
The IUE Model has four components: sets of people, typical problems
experienced by these sets of people, typical settings, and resolutions of the problems.
Detailed explanations of these four components are described below.

31
Sets of People
Sets of people share work or organizational settings or other types of interests.
The education, professional training, occupation, and daily activities influence the
assumptions and attitudes about the nature of an individual’s work (Luo, 2008). Sets of
people can be defined by demographic variables (age, sex, marital status, education, race
etc.) as well as non-demographic characteristics including assumptions and preferences
for different sources and attitudes about certain phenomena (Durrance et al., 2006).
More specifically, sets of people tend to share similar characteristics in media use (i.e.
print, electronic, verbal), social networks (i.e. networks within the company, networks
within the profession etc.) and attitudes towards technology, education, risk taking, and
innovation (Taylor, 1991). Taylor (1991) categorizes four general sets of people: the
professions (engineers, lawyers, scientists etc.), the entrepreneur (farmer, small business
owner etc.), special interest groups (community organizations, political action groups
etc.), and special socioeconomic groups (minorities, the elderly etc.).
Typical Problems and Problem Dimensions
According to Taylor (1986, p. 41) “problems represent the use environment…”
and these problems influence information use (Durrance et al., 2006). Problems are
defined by the individuals in the group and are often dynamic in nature. Each IUE has a
discreet class of problems produced by the setting and profession (Taylor, 1991).
Problem dimensions establish the criteria for judging the relevance of information
to a problem or class of problems and go beyond subject matter (Taylor, 1986, p. 42).
MacMullin and Taylor (1984) defined 11 problem dimensions as shown in Table 2 and
represented each dimension on a continuum.

32

Table 2
Problem Dimensions Identified by MacMulling and Taylor (1984)
Problem Dimension
1. Design/Discovery

Description
Discovery
Description of the natural world

2. Well-structured/Illstructured

Well-Structured
Can be solved by application of
logical or algorithmic process
3. Simple/Complex
Simple
Path from initial statement to
solution is easily defined
4. Specific/ Amorphous Specific Goals
Goals
Goals can be measured
5. Initial State
Initial State Understood
Understood/Not
Interrelationships among
Understood
contributing factors are
understood to some degree or
completely
6. Assumptions Agreed Assumptions Agreed Upon
Upon/Not Agreed
Centered on an accepted
Upon
knowledge based (i.e. natural
sciences)
7. Assumptions
Assumptions Explicit
Explicit/Not Explicit Analysis and explication of
assumptions available
8. Familiar
Familiar Pattern
Pattern/New Pattern Problems are procedural
9. Risk Not Great/
Risk Not Great
Great
Consequence of failure low
10. Susceptible/Not
Susceptible to Empirical Analysis
Susceptible to
Problems rely on data which are
Empirical Analysis
objective and aggregated
11. Internal/External
Imposition

Internal Imposition
Problems are sought out

Description
Design
Things and processes made by
humans
Ill-Structured
Cannot be resolved through
strictly analytical means
Complex
Path from initial statement to
solution is not easily defined
Amorphous Goals
Goals cannot be measured
Initial State Not Understood
Interrelationships among
contributing factors are not
understood
Assumptions Not Agreed Upon
Lacking an accepted
knowledge base (i.e. policy
sciences)
Assumptions Not Explicit
Analysis and explication of
assumptions not available
New Pattern
Problems are non-procedural
Risk Great
Consequence of failure high
Not Susceptible to Empirical
Analysis
Problems based on judgment
call
External Imposition
Problems come from the
environment

33
Each of these problem dimensions appear to have “an effect on the kinds of
information deemed useful” (Taylor, 1991, p. 226). Although not explicitly stated by
MacMullin and Taylor (1984), the problem dimensions on the right hand side of Table 2
(for example, ill-structured, amorphous goals, high risk, initial state not understood etc.)
could be described as characteristics of complex problems.
Typical Settings
The setting, usually the work setting, produces constraints and opportunities
(Durrance et al., 2006). The setting can be classified as a common physical setting that a
group of people (i.e. doctors) work in (i.e. hospitals) (Luo, 2008). The setting can be
grounded in physical space or grounded in virtual space as in the case of an “invisible
college” (Zuccala, 2006). Additionally, the setting can consist of a “loosely connected
collection” of dispersed individuals across an area as in the case of individuals attempting
to solve community problems (Durrance et al., 2006).
Problem Resolution
This component consists of the attitudes and approaches to problem resolution
that influence information seeking and use (Durrance et al., 2006).The perceptions about
the problem resolution “regulate the intensity of an individual’s information search and
his or her expectations about the kinds of information he or she needs” (Luo, 2008, p.
605).
Taylor (1991, p. 229) states that problems “pose different requirements on the
type of information perceived as necessary, and hence different uses to which
information is put in the process of resolution.” Taylor (1991, pp. 229–230) categorizes

34
eight non-exclusive classes of information use that are generated by the need perceived
by users in particular situations:
1. Enlightenment – the desire for context information or ideas to make sense
of a situation
2. Problem Understanding – better comprehension of particular problems
3. Instrumental – finding out what to do and how to do something
4. Factual – need for precise data
5. Confirmational – need to verify a piece of information
6. Projective – future oriented, concerned with estimates and probabilities
7. Motivational – related to personal involvement
8. Personal or Political – has to do with relationships, status or reputation
Taylor (1986) defines nine information traits that determine how users prefer
information to be presented to them to help solve their problems (Detlor, 2000).
Although these traits are content oriented, they go beyond subject relevance and focus on
situational relevance as in the case of helping in a specific work situation (Detlor, 2000).
The information traits are related to the problem dimensions and information needs of the
individuals. The nine information traits are listed in Table 3.

Table 3
Information Traits Identified by Taylor (1986)
Information Traits
Quantitative continuum

Data continuum

Description

Description

Quantitative
Derived from phenomena that
can be measured numerically
Hard Data
Result of observation, able to
be replicated

Qualitative
Derived from qualitative and
descriptive information
Soft Data
Data cannot be observed,
must be inferred

35
Temporal continuum

Solution continuum

Historical
Information on what has
taken place
Single Solution
One desired, best solution

Focus continuum

Precision
Requires exactness of
information

Specificity of use continuum

Applied
Immediately useful in an
operational sense

Substantive continuum

Applied
Immediately useful in an
operational sense
Clinical
Information drawn from an in
depth single case
Causal
Why something happens

Aggregation continuum

Causal or diagnostic
continuum

Forecasting
Information on what will be
or should be taking place
Option range
A range of solutions can be
used
Diffusion
Does not require exactness,
rather information is used to
orient or gain perspective
about situation
Theoretical
Gives possible clues about
how something works or
behaves
Descriptive
Describes content and
meaning of a phenomenon
Census
Information drawn from
entire populations
Diagnostic
What is happening

Review of Studies with the IUE Model
Several studies used the IUE Model to provide descriptive accounts of different
types of information seekers in different contexts. For example, Agada (1999) examined
the information behavior of inner city gatekeepers and found that their most prevalent
information needs focused on discrimination and race relations, crime and safety, and
family planning. Hersberger, Murray, and Sokoloff (2006) applied the IUE Model to
examine the information behavior of foster children being adjudicated by a court of law
for being maltreated and found their needs focused on adjustment (why children are
removed from their homes), maintenance (what will happen to the foster children), and
case closure (reunification with parent(s) or relative placement; parental rights are

36
terminated). Olatokun and Ajagbe (2010) used the IUE Model to examine the
information behaviors of traditional medical practitioners who treat sickle cell anemia.
Based on responses to surveys, the researchers found that the practitioners primarily used
information sources through professional associations. Additionally, it was found that the
practitioners relied on orally stored knowledge of medical practice, which resulted in a
lack a collection of practices across various situations.
Other IUE studies have found connections in specific contexts between problem
type and information behaviors. Berryman (2008) used a multiple-case study, semistructured interview approach with 21 public sector workers to investigate factors that
influenced the workers’ assessments of “enough” information. The researcher found that
the public sector workers faced complex problems that lacked structure, were unclear,
and held conflicting goals from different stakeholders. To resolve the challenges posed
by these complex problems, public sector workers used various channels and sources of
information. Luo (2008) found similar results in a study on the data-driven decision
making of 183 public high school principals. The results suggested that complex or illstructured problems (such as student achievement and school improvement) required
more thought and increased the role of information collection. Conversely, structured
problems demanded less thought and decreased the role of information collection.
Additionally, Berryman’s (2008) study on public sector workers and Durrance et al.’s
(2006) study on community workers show that for complex problems, information
seekers were more likely to seek information provided by people rather than from other
types of sources.

37
Several studies have shown how the organizational setting of workers influences
information behaviors. Maurel and Bergeron (2007) used the IUE Model to examine the
problem situations of 30 middle managers. Based on in-depth critical-incident interviews
and direct observations, the researchers found that problems for middle managers arose
primarily from internal contextual factors including power and responsibility-sharing,
compliance with policies and procedures, and strategic organizational priorities all of
which influences information seeking. Berryman (2008) found that two characteristics of
the organizational settings, bureaucratic style of management and organizational attitudes
towards risk and uncertainty, influenced the information behavior of the public sector
workers (Berryman, 2008). In a comparison of information seeking in the home and
work setting, Rieh (2004) found that information seekers held more diverse kinds of
goals for information seeking in their home settings, sought information at separate times
for the same task, and initiate searches for entertainment purposes rather than only for
problems.
Limitations of the IUE Model
The previous studies that used the IUE Model provide rich, descriptive accounts
of the information behaviors of various sets of people. However, the IUE Model does not
predict how the eleven problem dimensions listed in Table 2 influence how professionals
resolve problems or what types of information are sought. A couple of IUE Model studies
provide an initial starting point for investigating this further. For example, Berryman’s
(2008) study and Durrance et al.’s (2006) study showed that when faced with more
complex tasks, workers used multiple sources and reached out more to other people. Luo
(2008) found that when public high school principals faced complex tasks, the principals

38
required more information than when facing simple tasks. More research on the
relationship between task complexity and information behavior is needed.
Another limitation of the IUE model is that it implies that most information
behavior is rational and conscious (Lievrouw, 2001). None of the above-mentioned
studies focused on decision makers in high stakes, high time pressure, and high
uncertainty contexts. Taylor (1986, pp. 156–157) states that ideal decision makers
carefully analyze problems to determine the nature of the problem, then review a wide
range of alternative courses of action, weigh the costs and risks of consequences of each
course of action, assimilate new information, reexamine consequences of all known
alternatives, and make detailed provisions for selecting a course of action. For each step
one could make a “checklist for assessing the likelihood of an optimal decision” (Taylor,
1986, p. 157).
The use of sequential steps, the comparing of options, and the use checklist to
reach an optimal decision represent a rational style of decision making (Hammond et al.,
1997; Klein et al., 2010). Taylor (1991, p. 249) admits that decision research has focused
primarily on rational decision making “… excluding the importance of hunch and
intuition based on experience and personal association. We need to have a better
understanding of the nonrational (less rational?) environmental factors affecting these
processes” (Parentheses from Taylor). The lack of focus on situations with high stakes,
high time pressure, and high uncertainty may explain the lack of focus on non-rational
decision-making.

39
General Model of Information Seeking of Professionals
In addition to Taylor’s IUE Model (1991), Leckie et al.s’ GMISP offers another
framework for understanding the influence of task characteristics on information
behavior in professional settings.
Background of the GMISP
Based on the analysis of empirical studies of the information behaviors of various
types of professionals (engineers, health care professionals, and lawyers), Leckie et al.
(1996) developed the GMISP. Leckie et al. (1996, p. 181) stated that “the basic
supposition of the model is that the roles and related tasks undertaken by professionals in
the course of daily practice prompt particular information needs, which in turn give rise
to an information seeking process.”
The GMISP consists of the following components:
1. work roles
2. associated tasks
3. characteristics of information needs
4. awareness
5. sources
6. outcomes
Figure 3 illustrates the relationships between these six components.

40

Figure 3. General Model of Information Seeking of Professionals

Work Roles and Associated Tasks
In the GMISP view, workers may assume a variety of roles including service
provider, administrator/manager, researcher, educator, and student. A professional may
assume one or multiple roles depending on the context of work (Landry, 2006). Each role
requires different associated tasks. The enactment of certain roles and tasks influence the
information behaviors of professionals. For example, an engineer (categorized as a
service provider) must carry out technical and non-technical tasks such as building
systems and subsystems or conducting financial analyses; these tasks require specific
information found in technical manuals or datasets (Leckie et al., 1996).

41
Characteristics of Information Needs
Information needs are not constant and can be influenced by various factors.
According to Leckie et al. (1996, pp. 182–183) the following factors influence
information needs:
Individual demographics (age, profession, specialization, career state, geolocation)
Context (situation specific need, internally or externally prompted)
Frequency (recurring need or new)
Predictability (anticipated need or unexpected)
Importance (degrees of urgency)
Complexity (easily resolved or difficult)
Each of these factors exists on a “continuum of intensity and interacts with the
others in a complex fashion” (Leckie et al., 1996, p. 183).
Sources
Professionals use different channels or formats of information sources including
formal or informal, internal or external, oral or written, and personal
knowledge/experience (Landry, 2006). Professionals may use a combination of sources to
fulfill their information needs. The sources may be used simultaneously or in sequence.
Leckie et al (1996, p. 184), stated that the continual interaction of sources “…contributes
to the overall complexity of the source as a variable affecting information seeking.”

42
Awareness
The professional’s awareness of various information sources can determine the
path of information seeking. The variables that a professional maintains or develops
awareness about include (Leckie et al., 1996, p. 185):
Familiarity and prior success (results previously obtained from a source)
Trustworthiness (how reliable or helpful)
Packaging (convenience, usefulness and others)
Timeliness (found when needed)
Cost (relative cost-effectiveness in terms of psychological or physical effort)
Quality (level of detail, accuracy, and more)
Accessibility (relative ease of access)
As in the case of the interaction of sources, these awareness variables continually
interact with each other and change over time.
Outcomes
Outcomes consist of the end-point for the requirements of the tasks. The optimal
outcome consists of the information need being met for the professional to complete his
or her task. However, if the optimal outcome is not reached, the GMISP states
professional will continue searching to complete the task.
Review of Studies with the GMISP
There have been a limited number of empirical studies conducted with the GMISP
as the primary framework. Wilkinson (2001) conducted interviews with over 150 lawyers
and found that the lawyers considered informal sources to be their primary information
sources. Additionally, the lawyers preferred internal organizational sources rather than

43
external sources, although this was found less true for lawyers from smaller firms.
Wilkinson (2001) found the results fit under the GMISP; however it was recommended
that the organizational context (size of firm) and demographics of the user (although not
found significant in the study) should be included in the GMISP.
Baker (2004) used the GMISP to further the understanding of the information
needs and information behaviors of seven undercover police officers in a prostitution
sting. Various variables were found to impact the police officers’ information needs. The
researcher found that context (an externally-prompted, situation-specific need) greatly
influenced the information needs of the officers. The officers needed to know the
location, appropriate dress to fit in at the location, the language to use, and characteristics
of “johns” (potential clients of prostitutes). For these needs, the officers used informal
sources including team members or members of the community.
The complexity of each encounter in Baker’s (2004) study also affected the
information needs of the police officers. The complexity stemmed from the conversation
with the “johns” and situational/environmental factors such as other people on the street.
An additional variable found to impact information behavior was the immediacy of the
situation. The police officers needed to get information from the johns quickly and
efficiently and needed to adjust their own behavior. Overall, Baker’s (2004) study
showed that task complexity influenced the information behavior of the undercover
police officers.
Landry (2006) used the GMISP as a conceptual framework to conduct multiple
rounds of interviews with 12 dentists to examine their information behaviors. The results
showed that different work-role tasks shaped the dentists’ choices of information sources.

44
The dentists performed various roles including service provider, student (learning),
educator, administrator, and researcher (investigating unusual cases). Each role resulted
in different preferred sources. According to Landry, (2006, p. 1903)
Textbooks were the preferred source for the patient management/service provider
task, professional associations were favored for CDE/student and patient
education/educator tasks, vendors and sales representatives were first for the
practice management/administrator task, and colleagues and journals were chosen
for the research task.
Interestingly, dentists preferred to use traditional information sources to meet
their information needs rather than using the Internet for all types of tasks. The internet
was considered to be an alternate information source. Search engines and specific
websites offered value as well. Overall, Landry (2006) found support for the GMISP.
Greyson, Cunningham, and Morgan (2012) examined the information behavior of
15 pharmaceutical policy decision makers via semi-structured interviews and compared
the results to the GMISP. The researchers used the critical incident technique (Flanagan,
1954) and found that characteristics of information needs included: topic, depth/breadth
of questions, and time sensitivity. Depending on the characteristics of problems and
resources available, the information seeking approaches were either “scattershot”,
systematic, or delegated. Primary information sources were fellow experts, electronic
resources, and trusted organizations. Based on using the GMISP, the researchers formed
design recommendations including recommending a design of a rapid-response service to
answer questions and a design for a better information-sharing infrastructure. The

45
researchers found the information behavior of the research participants fit with the
GMISP.
Overall, these GMISP studies show that different contexts (such as law, police
investigations, health care and pharmaceutical decision making) and roles within those
contexts (such as lawyers, police officers, dentists, and policy makers) influence
information seeking. Additionally, different situations within those contexts also
influence information seeking.
Limitations of the GMISP
The GMISP holds similar limitations to Taylor’s (1991) IUE Model. The GMISP
states that an individual will keep searching until an optimal decision is reached.
Reaching an optimal decision is representative of rational decision-making. However, the
GMISP does consider personal knowledge and experience to be a “primary source of
information” (Leckie et al., 1996, p. 184). Also, similar to the IUE Model, the GMISP
has not been used to examine situations with high time pressure and high stakes with the
exception of one study that focused on undercover police officers (Baker, 2004). In the
study on undercover police officers, Baker (2004) expressed concerns with the GMISP
and stated that it is “…limited in its ability to describe the fast-paced, give and take, real
time information world…” of undercover police officers and similar professionals.
Finally, the GMISP model, as shown in Figure 3 places a significant emphasis on
workers’ tasks which are shaped by the workers’ roles; however, no prediction is
provided on how different task characteristics will influence information behaviors of the
workers. More research is needed in this area.

46
2.4.2 Task Complexity and Information Behavior
As stated by the IUE Model (Taylor, 1986) and the GMISP (Leckie et al., 1996),
in a professional setting, information needs and information behaviors depend on a
worker’s task. Task complexity has been identified as a critical factor that affects
information behavior and can be described in numerous ways.

Background of Task Complexity
Culnan (1983) defines task complexity as being related to the external
environment; in other words, the level of complexity in the environment determines the
level of complexity of the task. According to Wood (1986), task complexity can be
examined by the components of the task (number of acts needed to execute the task and
number of information cues needed to be processed), coordinative nature of the task
(relationship between inputs and products as well as sequencing of inputs), and dynamic
nature of the task (adapting to changes in the world that have an effect on task inputs and
products). In this view, a simple task does not require many steps, has a small number of
information cues, has a defined set of sequential steps to follow, and is static. A complex
task has many steps, has a large number of information cues, lacks steps or consists of
multiple co-occurring steps, and is dynamic (Wood, 1986).
Campbell (1988) developed a classification scheme to resolve differences in
definitions of task complexity. A complex task consists of the of the following: presence
of multiple paths to arrive at an end goal, presence of multiple desired outcomes,
presence of conflicting interdependence among paths and multiple desired outcomes, and

47
presence of uncertain or probabilistic linkages among paths and outcomes (Campbell,
1988, p. 46).
Daft and Macintosh (1981) define task complexity as consisting of task variety
and task analyzability. Task variety consists of the occurrence of unexpected and novel
events. A complex task consists of unpredictable events while a simple task consists of
predictable events. Task analyzability refers to the ability to follow an objective or
computational procedure to resolve problems. In this category, a complex task would not
be able to be solved by objective or computational procedures. Zeffane and Gul (1993)
also consider task variety and task analyzability to be useful for categorizing task
complexity in addition to task interdependence. Task interdependence refers to “the
amount of work (normal job activities) which require checking on or working with
others” (Zeffane & Gul, 1993, p. 709). A complex task consists of work requiring a
considerable amount of checking or working with others while a simple task consists of
zero to a minimal amount of working with others. Pinelli et al. (1993) also considered
task interdependence to be useful for measuring task complexity.
Drawing on previous definitions of task complexity, Tiamiyu (1992) and Byström
and Järvelin (1995) define task complexity as the predeterminability of information
requirements, procedures, and outputs. For simple tasks, the inputs, processes, and
outcomes of tasks can be a priori determined. For complex tasks, they cannot. Vakkari
(1998) states that this definition of task complexity covers a broad common area across
studies on task complexity.
Several of MacMullin and Taylor’s (1984) eleven problem dimensions relate to
other descriptions of task complexity. For example, the initial state understood/not

48
understood dimension relates to the predeterminablity of information requirements
(Byström & Järvelin, 1995; Tiamiyu, 1992); the susceptible/not susceptible to empirical
analysis dimension relates to task analyzability (Daft & Macintosh, 1981; Zeffane & Gul,
1993); and the simple/complex dimension relates to the presence of uncertain or
probabilistic linkages among paths and outcomes (Campbell, 1988).
Leckie et al.’s (1996, pp. 182–183) factors that influence information needs also
lend themselves to characteristics of task complexity. For example, the factors of
frequency (recurring need vs. new need), predictability (anticipated or unexpected), and
importance (degree of urgency) can be used to describe task complexity. A complex task
consists of a new need, is unexpected, and has a high degree of urgency.
Other task characteristics that relate to task complexity include the amount of risk
(tasks with high complexity have high risk) (MacMullin & Taylor, 1984) as well as the
amount of time pressure (tasks with high complexity have high time pressure) (Liu & Li,
2012). Mahan (1994) also considered high time pressure and high stress to be indicative
of a task with high complexity.
Review of Studies on Task Complexity and Information Behavior
Vakkari (2003) states that there has been limited research conducted on task
complexity and information behavior. However, some general theoretical propositions
evolved from this research. According to Zeffane and Gul (1993) and Daft and
Macintosh(1981), the main theme of this research revolves around the following concept:
complex, non-routine tasks require more information than simple, routine tasks. Other
themes from the research conducted on task complexity and information behavior revolve
around the use of external sources, use of people as sources, use of experts as sources,

49
and use of different information types. Table 4 summarizes the theoretical propositions
supported by previous LIS research on task complexity and information seeking. These
theoretical propositions are tested in this dissertation research in the cyber defense
domain.

Table 4
Theoretical Propositions from LIS Research Task-Complexity Research
Theoretical Propositions
As task complexity increases, the amount of
information sources used increases
As task complexity increases, the use of external
sources increases
As task complexity increases, the use of people
as sources increases
As the task complexity increases, the use of
experts increases
As task complexity increases, the needs for
domain information and problem solving
information increase

Previous Studies
Daft and Macintosh (1981), Culnan (1983),
Tiamiyu (1992), Zeffane and Gul (1993),
Byström and Järvelin (1995)
Tiamiyu (1992), Pinelli et al. (1993),
Zeffane and Gul (1993), Byström (2002)
Culnan (1983), Tiamiyu (1992), Byström
(2002)
Tiamiyu (1992), Byström (2002)
Culnan (1983), Byström and Järvelin (1995),
Byström (2002)

A review of these theoretical propositions follows.
Task Complexity and Amount of Information Sources Used
Based on a quantitative analysis of questionnaires conducted with 24 work units,
Daft and Macintosh (1981), found that as task complexity increased (based on task
analyzability and task variety) the amount of information processing increased. In another
study with 362 analysts from two large companies, Culnan (1983) found that as task
complexity increased, the use of information sources increased by the analysts. Tiamiyu
(1992) found similar results in a questionnaire-based study conducted with 274 senior
civil servants. In another survey-based study conducted with 1300 full-time employees of

50
a large public sector telecommunications organization, Zeffane and Gul (1993) found
that an increase in task variety (an indicator of task complexity) increased the need to
acquire more information. From an analysis of 25 tasks performed by public
administrators, Byström and Järvelin (1995) also found that as task complexity
increased, the quantity of information processed also increased.
Task Complexity and Use of External Sources
Pinelli et al. (1993) conducted an exploratory study to understand the information
behaviors of U.S. aerospace engineers and scientists. The researchers examined the use of
information sources based on survey responses surrounding tasks performed by 2,016
research participants. The researchers found that as task complexity increased the use of
external information increased. Tiamiyu’s (1992) study also showed an increase in the
civil servants’ use of external sources based on an increase in task complexity. Zeffane
and Gul (1993) found that the more technical uncertainty involved with a task the more
external written sources were used. Byström’s (2002) study on municipal administrators
demonstrated similar results.
Task Complexity and Use of People as Sources
In addition to finding that increased task complexity increased the amount of
information sources used, Culnan (1983) found that as task complexity increased the use
of internal people as sources increased. Tiamiyu’s (1992) study on civil servants also
showed that increasing task complexity increased the use of people as sources. In a later
study, Byström (2002) asked 39 municipal administrators to complete semi-structured
self-recorded journals and to participate in interviews. The results showed that increasing
task complexity increased the use of people as sources.

51
Task Complexity and Use of Experts
In Byström’s (2002) study on task complexity and information use by 39
municipal administrators, the results showed that as task complexity increased, the use of
experts increased. Experts were found internal to the public administrators’ organizations
as well as external to their organizations. Furthermore, the results showed that external
experts were used more than internal experts as task complexity increased. Tiamiyu’s
(1992) earlier study also demonstrated this relationship.
Task Complexity and Use of Different Information Types
In their study on tasks performed by public administrators, Byström and Järvelin
(1995) defined various information types: task information, domain information, and
task-solving information.
Task Information: this information describes the structure, properties, and
requirements of the task/problem at hand (e.g. names, numbers, places, statements
or events.) “This information type is seen to comprise mainly answers to the
information requirements that are related only to the particular task.” (Byström,
1999, p. 45). For example, when a journalist seeks facts about a specific traffic
accident, this information is task information (Byström, 1999). Task information
is related to Taylor’s (1991) classification of “factual information” which focused
on the need for precise data.
Domain Information: this information consists of laws, concepts, and proven
theories of the task/problem and is applicable to several tasks of the same kind.
Going back to the journalistic context, Byström (1999) provides the example of a

52
journalist seeking information about the general reasons for traffic accidents or
information about laws in traffic accidents.
Task-solving or domain information: this information covers the methods or
procedures across several tasks. It describes how problems should be viewed and
formulated and what domain information should be used. For example, a
journalist would be looking for how to structure a news story about a traffic
accident and how to investigate a traffic accident (Byström, 1999).
In their study, Byström and Järvelin (1995) found that as task complexity
increased, the need for domain information and problem solving information increased.
Byström (2002) found similar results in a later study. In a previous study, Culnan (1983)
found that as task complexity increased, the use of general information sources increased.
Limitations of Studies on Task Complexity and Information Behavior
Similar to the IUE Model (Taylor, 1986) and the GMISP (Leckie et al., 1996),
the main limitation LIS task-complexity research is that the foundation of this research
rests on rational decision making. Byström and Järvelin (1995) proposed an information
seeking model surrounding task completion as shown in Figure 4.

53

Figure 4. Information Seeking Model Surrounding Task Completion
In the center of this model, the “Choice of Action” component depends on the
identification of alternatives, ranking of the alternatives, and the selection of the best
action. The generation of alternatives and then ranking them represents rational decision
making; however, in contexts with high time pressure and high stakes, rational decision
making has been found not be used by individuals (Klein, 1993; Mahan, 1994). Vakkari
(2003, p. 420) states: “It is evident that the research community in information searching
would extend the understanding of these phenomena, if ideas generated in other fields
concerning task performance and analysis were taken into account.”
Similar to Taylor’s (1991) IUE Model and Leckie et al.’s (1996) GMISP, LIS
research on task complexity and information seeking has not been examined in high
stakes, high time pressure, and high uncertainty environments. Overall, in LIS research,
there lacks focus on information seeking research in these type of environments (Allen,

54
2011; Mishra, Allene, & Pearman, 2011). NDM research focuses explicitly on
environments with high stakes, high time pressure, and high uncertainty and provides a
conceptual framework to understand information seeking in these types of environments.
2.5 Cognitive Continuum Theory
2.5.1 Theoretical Foundations of CCT
NDM situation assessment research conceptualizes that intuitive cognition, based
on schema developed over years of experience, forms the foundation of expert SA-task
completion (R. Lipshitz & Shaul, 1997; D. Noble, 1985; Serfaty et al., 1997). As stated
for the limitations of NDM situation assessment research, there lacks empirical research
on the cognitive modes used by experts for SA-task completion and there lacks a
theoretical foundation for predicting the cognitive modes used by exerts when completing
SA-tasks of different complexities. The CCT provides a framework to address these gaps.
The theoretical foundations of CCT draw mainly from Brunswik (1943) who
developed the concept of probabilistic functionalism and the Lens Model both of which
contributed to Social Judgment Theory, another foundation of CCT. These theoretical
foundations, the concepts posed by CCT, and the results of empirical CCT studies are
described in this section.
Probabilistic Functionalism
Brunswik (1943) claimed that previous psychology research of his time focused
primarily on the individual without any emphasis placed on the environment. However,
Brunswik (1943) stated that both the environment in which an individual is embedded
and the individual should receive equal focus in theory and research. In the Brunswikian
perspective, an individual selects which environmental cues to use out of many available

55
environmental cues to achieve his or her goals. These cues may or may not portray the
actual state of the environment. Therefore an individual cannot know his or her
environment with complete certainty; the environment can only be known
probabilistically (Doherty & Kurz, 1996). This forms the basis of probabilistic
functionalism.
According to Hammond (1996), each cue used to interpret the environment offers
limited validity and may be related to other cues, redundant to other cues, and able to
substitute for other cues. Additionally, individuals have the cognitive ability to change
their selection of cues to make inferences about their environments. Hammond (1996)
calls this vicarious functioning.
The Lens Model
Brunswik (1952) developed the Lens Model to provide further insights into
probabilistic functionalism. The Lens Model stems from theories of visual perception and
posits that perceptions of the environment are derived from multiple probabilistic sources
of information or cues (Hammond, 1996). According to Rappoport and Summer (1973), a
state of the environment consists of a distal object, event or variable that is presented to
the individual as an array of cues. The cues relay information to the individual about
aspects of the environment which are not directly observable by the individual (Standing,
2008). Brunswik’s model suggests that a “lens” collects information from the cues and
refocuses them within the cognitive system of the individual who makes a judgment
about the environment (Hammond, 1996).
Hammond (1996, p. 87) provides two questions researchers consider under the
Lens Model perspective:

56
1. What cues are present and available to the individual in his/her effort to reach
an inference about an intangible object or event of interest or what
information that can be “seen” is available to make inferences about the
“unseen”?
2. How is this information that can be “seen” used by the individual to make
inferences about the “unseen”?
Figure 5 provides a visual representation of the Lens Model.

Figure 5. The Lens Model

Figure 5 shows the degree of validity to each cue, a weight attached to each cue
by a judge, and the accuracy of the judgment. More specifically, the cues used for
judgment are at the center of the figure (Xi) with the array of cues representing a criterion
in the environment Ye. Each cue’s validity (accuracy of representation of the true state of
environment) is represented by re,i. The weight the judge places on each cue (defined as
cue utilization) is represented by rs,i. The final judgment is represented by Ys which is

57
then compared to the environmental criterion Ye for accuracy to obtain the level of
achievement ra. Goldstein and Hogarth (1997, p. 7) state the Lens Model, as derived
from probabilistic functionalism, shows “the proximal cues are related only
probabilistically to the identity and properties of the distal object.”

Social Judgment Theory
Hammond and Stewart (1975) further developed the Brunswikian perspective by
formulating the Social Judgment Theory (SJT). According to Cooksey (1996b), SJT
evolved through the 1960s and 1970s as a methodology and a perspective for
understanding the judgment process in various contexts. SJT describes the weighting and
combining of information by individuals for making judgments as related to judgment
accuracy (Doherty & Kurz, 1996). More specifically, SJT states that the accuracy of an
individual’s judgment about an event or object depends on the weight the individual
attaches to the cues coming from the event or object. If cues are weighted to reflect the
real event or object, then the judgment will be accurate; if the cues are not weighted to
reflect the real event or object, then the judgment will be inaccurate. Although SJT is
sometimes listed as a theory, Cooksey (1996b, p. 145) states SJT “should not be
construed as a formal theory of the judgment process… [rather it] provides the
methodology through which the predictions of Cognitive Continuum Theory may be
tested.” (1996a, pp. 25–26).

58
2.5.2 CCT Theory Description
The conceptual model of CCT is derived from Brunswik’s probabilistic
functionalism and the Lens Model as well as Hammond’s SJT. The CCT focuses on the
following cognitive modes: analytical cognition, intuitive cognition, and quasi-rational
cognition. Analytical cognition involves conscious, methodological, and time-consuming
information processing while intuitive cognition involves non-conscious, holistic, and
rapid information processing. Quasi-rational cognition represents a combination of these
two cognitive modes. According to Hammond (1996), the literature on social psychology
from the 1960s to the 1980s viewed intuitive cognition as a hazard flawed by biases and
untrustworthiness. In opposition to the previous research on the separation of intuitive
and analytical cognition, Hammond (1996) suggests that a dichotomy should not be
placed between intuitive and analytical cognition; rather, intuitive and analytical
cognition should be placed on a continuum in which individuals can use aspects of both
modes of cognition depending on the environment or environmental tasks.
Cognitive Continuum Index
Hammond (1996) developed the cognitive continuum index (CCI) as a way to
describe the characteristics of each mode of cognition and represent the concept of a
continuum for cognitive modes. The CCI is displayed in Table 5.

59

Table 5
Cognitive Continuum Index
Cognitive Property
Rate of information
processing
Cue use
Cognitive control

Intuitive Cognition

Analytical Cognition

Rapid

Slow

Simultaneous
Unconscious information
processing

Sequential
Conscious information
processing
Formal rules available and
used
Reliance on quantitative cues
Cues evaluated at
measurement level
Task specific organizing
principle

Availability of rules

Formal rules unavailable

Cue type

Reliance on qualitative cues

Cue evaluation

Cues evaluated perceptually

Organizing principle

Pattern recognition, averaging

The representation of intuitive and analytical cognition on a continuum allows for
the conceptualization that an individual could move back and forth between the two
modes of cognition in the judgment process (Cooksey, 1996a). For example, if an
individual cannot solve a problem with the use of one mode of cognition, then he or she
could use the other mode of cognition and alternates between the two modes until the
problem is solved (Cooksey, 1996b; Hammond, Frederick, Robillard, & Victor, 1989;
Hammond, 1996). The continuum also allows an individual to utilize the advantages of
each mode of cognition as well as overcome the disadvantages of each mode of
cognition.
According to Hammond (1996) analytical cognition can provide precision in
specific circumstances and intuitive cognition can provide robustness over a wide range
of conditions. A downside to using analytical cognition is that the models and formulas
used to predict an answer may produce errors which are a magnitude larger than when

60
intuitive cognition is used (Doherty & Kurz, 1996). Additionally, there may be a poor fit
between the model and the data available as well as the environment. Intuitive cognition
while being robust is often imprecise. There may be demands from others for analytical
accountability or demands for a precise judgment resulting in a conflict with using
intuitive cognition.
Additionally, the CCI provides a middle ground between intuitive and analytical
cognition. Hammond (1996, p. 150) defines the mixture of the two modes of cognition as
“quasirationality” or quasi-rational cognition. Dunwoody et al (2000, p. 37) consider
quasi-rational cognition to be “robust and adaptive” and state that cognition is rarely only
intuitive or analytical; rather it is more likely a mixture of the two.
Task Continuum Index
In addition to representing the modes of cognition on a continuum, CCT also
posits that there is a relationship between characteristics of tasks faced and the modes of
cognition induced by these tasks (Hammond, 1996). Hammond (1996) developed the
Task Continuum Index (TCI) that parallels the CCI to represent this relationship. The
TCI lists several properties of tasks that are considered to induce the use of intuitive and
analytical cognition as shown in Table 6.

Table 6
Task Continuum Index
Task Properties
Number of cues
available
Order in which cues are
displayed
Type of cue

Intuitive Cognition Inducing

Analytical Cognition Inducing

Large, >5

Small, < 5

Simultaneous

Sequential

Perceptual

Objective

61
measurement required
Reliability of cue
measurement
Cue distribution
characteristics
Redundancy among cues
Degree of a priori
decomposition
Uncertainty of the
criterion
Degree of nonlinearity in
the correct
environmental model
Extent to which cues are
combined in the correct
environmental model
with equal weights
Availability of an
organizing principle

Low

High

Continuous, highly variable,
normally distributed
High

Dichotomous, valued in specific
numbers, distribution unknown
Low

Low

High

High

Low

Low

High

High

Low

Low

High

Overall, CCT suggests that a complex, ambiguous, ill-structured task with a
short time period induces intuitive cognition (Mahan, 1994). While a highly structured,
deterministic task requiring a high degree of accuracy and a methodological approach
induces analytical cognition (Mahan, 1994). Lipshitz (1993) also stated that when task
properties align with the appropriate cognitive modes, there will be more accurate
judgments.
Although the TCI parallels the CCI, Hammond et al. (1997) state that the parallels
of the cognitive and task continuums are not deterministic: analytical cognition can be
applied to intuitive cognition inducing tasks (if there is time) and intuitive cognition to
analytical cognition inducing tasks (if time is limited). Furthermore, Doherty and Kurz
(1996) point out that there is no absolute catalog of cognitive inducing task
characteristics; each situation or task may elicit different task characteristics.

62
In the CCT perspective, if a judge’s mode of cognition (intuitive or analytical
cognition) on the CCI aligns with cognition inducing task properties (intuitive or
analytical cognition inducing task characteristics) on the TCI, then judge performance
will be optimal resulting in high task achievement (Dunwoody et al., 2000; Harvey,
2001). If there is a mismatch between the mode of cognition used and task characteristics
faced, then performance will be sub-optimal resulting in low task achievement.
Dunwoody et al. (2000) provide an example of a mismatch between task properties and
cognitive mode: an individual would fail at highway driving (a fast paced environment
requiring the processing of a large number of continuous, simultaneous cues) if he or she
solely followed an analytical cognitive approach (using a sequential, slow rate of
processing for the cues and relying on calculation of precise measurements for each cue).
2.5.3 Review of CCT Studies
Numerous studies have employed CCT as the primary theoretical framework. In
the foundational CCT study, Hammond et al. (1997) examined the judgment processes of
highway engineers when facing tasks with different task characteristics. The researchers
gave 20 highway engineers three tasks consisting of characteristics which were
hypothesized to induce intuitive, analytical or quasi-rational cognition. The results
showed that achievement in a judgment task increased as the degree of congruence
increased between the task properties on the TCI and the cognitive modes on the CCI. In
other words, intuitive tasks were best handled with intuitive cognition, analytical tasks
were best handled with analytical cognition, and quasi-rational tasks best handled with
quasi-rational cognition.

63
As Harvey (2001, p. 110) stated, the results of Hammond (1997)study showed
that “it is possible to use a set of task factors to structure knowledge in a way that allows
predictions to be made about how tasks that have not been previously studied will be
performed.” The results also demonstrated that intuitive cognition can be both efficient
and effective in making certain types of judgments (Cooksey, 1996a). Overall, the results
showed there is not a dichotomy between intuitive and analytical cognition in that
individuals can use either cognitive mode depending on the types of tasks faced as well
as a mix of the two. Other studies have also demonstrated the effectiveness of
quasirationality (Bjørk & Hamilton, 2011; Hamm, 1988b).
Support for the relationship between task complexity and cognitive mode use has
been demonstrated in other studies (Dowding, Spilsbury, Thompson, Brownlow, &
Pattenden, 2009; Dunwoody et al., 2000). Dowding et al. (2009) showed that when heartfailure nurse specialists faced unclear tasks (as in the case of administering medication
for palliative care to relieve the suffering of patients), the nurse specialists predominantly
used intuitive cognition. When the nurse specialists faced a task with both clear and
unclear tasks (the administering of medication for medication titration), they
predominantly used quasi-rational cognition as the CCT predicted. Dunwoody et al.
(2000) showed that when decision makers faced a task with highly visual cues, the
decision makers use more intuitive cognition than when facing a task with more
numerical cues.
Some CCT studies have shown how decision makers can move back and forth
between intuitive cognition and analytical cognition. Hamm (1988b) conducted a
moment-by-moment analysis of high way engineer’s decision making processes and

64
found that the engineers alternated between intuitive and analytical cognition. Based on
the analysis of eight medical students’ diagnoses of six patient cases, Hammond et al.
(1989) also found that the students alternated between using intuitive and analytical
cognition often using both modes evenly in the overall judgment process. Offredy,
Kendall, and Goodman (2008), also found that nurse medication prescribers changed
their use of cognitive modes based on the tasks encountered.
Other CCT studies have shown that additional concepts may need to be
considered by the CCT. For example, Offredy, Kendall, and Goodman (2008) showed
that when nurse medication prescribers lack prescribing knowledge for a specific case the
nurses would switch from using analytical cognition to using intuitive cognition. This
study showed that a lack of knowledge about a task can also induce intuitive cognition
and that a decision maker’s level of expertise plays role in the cognitive mode used.
Mahan (1994) focused on the impact of stress conditions on the use of intuitive and
analytical cognition when completing a complex judgment task. Mahan (1994) varied
task uncertainty and task duration for research participants and found that an increase in
task uncertainty and an increase in task duration led to a decrease in two things: in
judgment accuracy and a decrease in the consistency of using learned judgment policies.
The results showed there was a shift towards the intuitive cognition on the CCI in
response to these stress conditions.
One CCT study only found partial support for the CCT. Dunwoody et al. (2000)
conducted an experiment with 104 undergraduate students to examine how judgments
were made in a simulated, multiple-cue threat assessment task (assessing the potential
threat of hostile aircraft while being stationed on a naval aircraft carrier). Based on

65
providing conditions to induce different modes of cognition (intuitive, analytical and
quasi-rational), the results provided partial support to CCT. More specifically, Dunwoody
et al. (2000) varied surface (information representation) and depth characteristics of tasks
(task structure). The results showed that more visual representations of information
induced intuitive cognition and more numerical representations of information induced
analytical cognition.
However, the results did not show a correlation between a group of four task
characteristics (number of cues presented, redundancy among cues, the degree that the
cues were equally weighted in the optimal strategy and the total environmental
predictability from the available cues) and the cognitive mode used as predicted by the
CCI. Dunwoody et al. (2000) describes the potential reason for partial support of the
CCT: the type of judgments required in their study (threat assessments) differed from the
type of judgments required in Hammond et al.’s (1997) study (engineering-based
judgments).
2.5.4 CCT Limitations
The CCT has been categorized as one of the original NDM approaches (Klein,
2008; R. Lipshitz, 1993); however, the CCT has been predominantly been used to
examine the cognitive processes of professionals that were not facing high stakes, high
uncertainty, and high time pressure situations. These professionals include healthcare
professionals (Bjørk & Hamilton, 2011; Dowding et al., 2009; Hammond et al., 1989;
Offredy et al., 2008) and engineers (Hamm, 1988b; Hammond et al., 1997). The two
CCT studies that focused on high time pressure and high stakes situations used
simulations with college students and not experts (Dunwoody et al., 2000; Mahan, 1994).

66
However, the RPD Model, which focuses on these types of situations, demonstrates the
main relationships of the CCT in that complexity induces the use of intuitive cognition.
Unlike NDM situation assessment research, the CCT does not consider information
seeking as a primary component of its theory. As a result, CCT studies do not focus on
information behaviors which are viewed as critical when conducting situation
assessments (R. Lipshitz & Shaul, 1997).
2.6 Literature Review Summary
The RPD Model, a representative NDM model, shows that experts rely heavily on
forming situation assessments prior to making decisions (Klein, 1993). Although the
RPD Model considers information behaviors to be a critical component of forming
situation assessments, this model lacks a focus on how experts go about information
seeking. NDM situation assessment research shows that experts seek more information
than novices and base their information behavior on schema developed over years of
experience (R. Lipshitz & Shaul, 1997). However, NDM situation assessment research
lacks theoretical foundations for testing predictions on information behaviors and
cognitive processes used when completing SA-tasks of different complexities.
LIS research provides a solid foundation for examining information behaviors
when experts complete SA-tasks. Taylor’s IUE Model (1991) and Leckie et al.’s (1996)
GMISP both state that task characteristics influence the information behaviors of
professionals. However, these models to not provide predictions on how task
characteristics influence information behaviors. LIS task-complexity research (Byström
& Järvelin, 1995) provides predictions which state that an increase in task complexity
results in an increase in the following: the number of information sources used, number

67
of people used as sources, number of external sources used, number of experts used as
sources , and the amount of domain and problem solving information used. As a result,
LIS research on task complexity and information behavior (Byström & Järvelin, 1995)
provides a solid theoretical framework for examining the influence of SA-task
complexity on information behaviors of expert cyber defenders. Additionally, the CCT
(Hammond et al., 1997) provides a theoretical framework for examining the influence of
SA-task complexity on the cognitive modes used by expert cyber defenders. The CCT
predicts that an increase in task complexity induces the use of intuitive cognition. The
domain of cyber defense provides a unique domain for examining the information
behaviors and cognitive modes used for situation assessment.

68
CHAPTER 3: METHODOLOGY

3.1 Overview of Methods
The purpose of this dissertation research was to test the theoretical propositions of LIS
task-complexity research and the CCT in the context of cyber situation assessment.
The main research questions for the dissertation are restated below:
How does situation-assessment task complexity influence the information behaviors
of expert cyber defenders when completing situation assessment tasks?
How does situation-assessment task complexity influence the cognitive modes used
by expert cyber defenders when completing situation assessment tasks?
The researcher selected a multiple-case studies design for the dissertation’s research
design. For this dissertation study, “cases” consisted of SA tasks completed by expert cyber
defenders from small defense companies (companies with less than 500 employees that were
awarded contracts to work with the DoD) when responding to phishing attempts, zero-day
exploits, and malware attacks. The expert cyber defenders discussed a total of 38 SA-tasks. SA
tasks were selected as cases due to expert cyber defenders from the initial interviews discussing
multiple types of attacks. The discussion of multiple types of attacks provided the opportunity to
compare SA-tasks across the different types of attacks. A SA-task became a case when an expert
cyber defender was able to provide a full description of forming a situation assessment from the
initial detection of an attack to deciding on which actions to take to combat the attack.
The CDM (Klein et al., 1989) served as the foundation of semi-structured interviews
conducted with 21 expert cyber defenders. For data analysis, the researcher followed a directed
content analysis approach (Hsieh & Shannon, 2005; Potter & Levine-Donnerstein, 1999) and

69
developed coding categories based on LIS models of (professional information seeking and task
complexity) and NDM research. The LIS models included Taylor’s (1986) IUE Model, Leckie et
al.’s (1996) GMISP, and LIS task-complexity research (Byström & Järvelin, 1995). The NDM
approaches included the RPD Model (Klein, 1993) and the CCT (Hammond et al., 1997). To
enhance the research quality of the dissertation research, the dissertation researcher conducted
intercoder reliability testing on all coding categories.
Pattern matching was used to examine the emergence of patterns of information-source
use, information-type use, and cognitive modes used for wach SA-task type (the phishing
attempt, zero-day exploit, and malware attack SA-tasks). The overall patterns found for each
SA-task type were compared with patterns found in the other SA-task types. The dissertation
researcher also used the Freeman-Halton extension (Freeman & Halton, 1951) of Fisher’s Exact
test , to examine relationship between SA-task complexity and several information behaviors.
The frequencies of information-source use and information-type use were derived from the
interview transcripts and used in the statistical analysis. Figure 6 provides an overview of the
multiple-case studies design, adapted from Yin (2009, p. 57), that was used for the dissertation
research.

70

Figure 6. Overview of Multiple Case Studies Design Used for the Dissertation Research

3.2 Case Study Approach
3.2.1 Background of the Case Study Approach
Characteristics of Case Studies

71
A case study is defined as a strategy for examining “in depth a program, an event, an
activity, a process, or one or more individuals” (Creswell, 2009, p. 15). Case study research can
describe phenomena, build theory or test existing theoretical concepts and relationships (Cavaye,
1996). Benbasat, Goldstein, and Mead (1987, p. 371) state that in the case study approach
researchers study phenomenon in a natural setting, examine one or a few entities (person, group
or organization), do not impose experimental controls, answer “how” or “why” questions, and
focus on contemporary events. Case studies have been used in a wide variety of research
domains including deception detection (Thomas & Biros, 2011), information systems (Cavaye,
1996; Walsham, 1995), and LIS (Fidel, 1984; Zach, 2006).
Case study research often consists of qualitative methods (although quantitative methods
may also be used), and multiple data collection techniques including interviews, observations,
questionnaires, and document analysis (Darke, Shanks, & Broadbent, 1998). Creswell (2009)
states that a researcher should select either a quantitative or qualitative (as well as mixed
methods) approach based on the researcher’s experience and training.
3.2.2 Single vs. Multiple Case Studies
A case study researcher can select either a single-case study design or a multiple-case
studies design. A single-case study design is appropriate when a single case represents either a
critical case for testing a theory, an extreme or unique case, a representative or typical case, a
revelatory case, or a longitudinal case (R. K. Yin, 2009). Additionally, within a single case study,
a researcher can employ an embedded design in which the researcher uses multiple units of
analysis, such as an entire organization, a department in the organization, and individuals all
within the same case study (R. K. Yin, 2009).

72
The multiple-case studies design consists of a researcher conducting multiple single-case
studies. The multiple-case studies design allows for cross-case comparisons and the potential for
generalizable results. The use of multiple-case studies can strengthen research findings as in the
case of using multiple experiments to strengthen experimental research findings (Benbasat et al.,
1987). However, multiple cases are not selected for statistical sampling purposes; rather multiple
cases are selected for theoretical reasons. Cases are selected for either literal replication, in which
similar results are predicted across cases, or for theoretical replication, in which contradictory
results are predicted across cases for anticipated reasons (Benbasat et al., 1987). In order to
strengthen research findings and to conduct cross-case comparisons, a multiple-case studies
design was selected for this dissertation research. Cases consisted of SA-tasks completed by
expert cyber defenders from small defense companies (companies with less than 500 employees
that were awarded contracts to work with the DoD) when responding to phishing attacks, zeroday exploits, and malware attacks.
3.3 Multiple-Case Studies Approach for the Dissertation Research
This section provides a more in-depth description of steps used in multiple-case studies
research design of this dissertation research. These steps included the use of theoretical
propositions, selection of cases, data collection, the conducting of the case studies, data analysis,
and the writing up of findings. Yin’s (2009) guided approach for conducting case studies
provided the foundation for this dissertation research design. Prior to beginning the dissertation
research, the researcher received Institutional Review Board approval to conduct the overall
study (Appendix A. Institutional Review Board Approval).

73
3.3.1 Theoretical Propositions
The first step in the multiple-case studies design consists of using theoretical propositions
to guide the research. According to Yin (2009), theoretical propositions provide a basis for the
overall research objectives and data collection methods. As Cavaye (1996) stated, case study
research can describe phenomena, build theory or test existing theoretical concepts and
relationships. Based on data drawn from 74 issues of the “Academy of Management Journal”
spanning 50 years, Colquitt and Zapata-Phelan (2007) developed a taxonomy of theoretical
contributions along two dimensions: theory building and theory testing. This taxonomy is shown
in Figure 7.

Figure 7. Taxonomy of Theoretical Contributions from Colquitt and Zapata-Phelan (2007, 0.
1283)

74

In this taxonomy, building new theory (located on the vertical axis) “…captures the
degree to which an empirical article clarifies or supplements existing theory or introduces
relationships and constructs that serve as the foundations for new theory” (Colquitt & ZapataPhelan, 2007, p. 1283). Theory testing, located on the horizontal access, “…captures the degree
to which existing theory is applied in an empirical study as a means of grounding a specific set of
a priori hypotheses” (Colquitt & Zapata-Phelan, 2007, p. 1284)
Colquitt and Zapata-Phelan (2007) also define five distinct types of studies: reporters,
testers, qualifiers, builders, and expanders.
Reporters hold low levels of theory building and theory testing.
Testers contain high levels of theory testing but low levels of theory building.
Qualifiers contain moderate levels of theory building and theory testing.
Builders contain high levels of theory building but low level of theory testing.
Expanders contain high levels of theory building and testing.
This dissertation research focuses on testing theory rather than building theory and
therefore is labeled as a “tester.” The main theoretical research propositions tested in this
dissertation research focus on theoretical propositions from LIS task-complexity research
(Byström & Järvelin, 1995) and the CCT (Hammond et al., 1997) . These theoretical
propositions include the following:
As task complexity increases...
the number of information sources used increases (LIS task-complexity research)
the number of external sources used increases (LIS task-complexity research)
the number of people used as sources increases (LIS task-complexity research)
the number of experts used increases (LIS task-complexity research)

75
the use of domain information and problem solving information increases (LIS taskcomplexity research)
the use of intuitive cognition increases (CCT)
3.3.2 Selection of Cases
In this dissertation research, cases consisted of expert cyber defenders completing
phishing attempt, zero-day exploit, and malware attack SA-tasks. Benbasat et al. (1987, p. 373)
stated that when focusing on individuals or processes in work settings (as in the case of
completing SA-tasks), case selection criteria may include characteristics such as “the industry,
company size, organizational structure, profit/not-for-profit status, and public or private
ownership” as well as other criteria. The dissertation researcher invited expert cyber defenders to
participate in the study if they worked for small defense companies with less than 500
employees. According to 2011-2012 data provided on the Small Business Innovation Research
(SBIR) program’s website (http://www.sbir.gov/), the DoD awarded 1644 small defense
companies SBIR contracts to work with DoD agencies in 2011 and 2012.
The researcher selected small defense companies as criteria for case selection for several
reasons. Defense companies, due to their interactions with the DoD and their possession of
classified data, make them prime targets for cyber attacks. Furthermore, small defense
companies are perceived to have lower staff numbers, lower budgets, and fewer resources than
large defense companies all of which contribute to making small defense companies high-value
targets for cyber attackers. Additionally, cyber defenders in small companies typically complete
the entire cyber defense cycle by themselves rather than as part of a team. The dissertation
researcher wanted to ensure that the cyber defenders in the study could provide an in-depth view
of forming situation assessments of cyber attacks. Cyber defenders that work for large

76
companies often work on teams and may only be able to provide in-depth views on one task of
the cyber defense cycle (such as post-incident activity) and not the SA-task.
Additional criteria used to select research participants included level of expertise. There
lacks a standard definition for the number of years of experience that an expert should have. For
example, the years of experience for experts cited from previous research ranges from five years
(Benner, 2001) to ten years of experience (Klein et al., 1986). For this dissertation research,
expert cyber defenders were considered to be cyber professionals who held at least seven years
of experience in detecting and analyzing cyber attacks. Seven years was selected since it falls in
the middle of the range of five years to ten years. The research participants for this dissertation
research held an average of 11 years of experience with a range of 8-15 years of experience.
Table 7 displays the years of experience, education background, and titles of roles held by the
expert cyber defenders who participated in the study. The cyber security industry has a high
incidence of males. All research participants were males and this not surprising considering the
domain.

77
Table 7
Background of Expert Cyber Defenders Interviewed
Expert Cyber
Defender (CD)
CD1

Years of
Experience
10 years

Education
Background
B. S., M. S.

CD2

13 years

B. S.

CD3

10 years

B. S.

CD4
CD5

13 years
15 years

B. S.
B. S., M. S.

CD6

10 years

B. S., M.S.

CD7

8 years

B. S.

CD8

11 years

B. S.

CD9
CD10
CD11
CD12
CD13

12 years
10 years
10 years
11 years
9 years

B. S.
B. S.
B.A
B. S., M.S.
B. S

CD14

8 years

B. S., M.S.

CD15

12 years

B. S

CD16

10 years

B. S., M.A.

CD17
CD18

11 years
11 years

B. S
B. S.

CD19
CD20

8 years
15 years

B. S., M.S.
B. S.

CD21

12 years

B. S., M.S.

Title of Role
Cyber security operations
manager
Information security
consultant
Network security
specialist
Cyber security consultant
Network security
administrator
Information operations
specialist
Information assurance
engineer
Senior information
assurance consultant
Security engineer
Network engineer
Systems administrator
Systems administrator
Information systems
manager
Information security
professional
Information systems
manager
Network security
manager
Chief information officer
Chief information
security officer
Network engineer
Information assurance
manager
Cyber security analyst

All of the expert cyber defenders are males as shown in Table 8.

State
NY
VA
VA
MD
DC
PA
VA
CA
FL
TN
CO
CO
MD
FL
TN
NY
MA
PA
UT
WA
MA

78

Table 8
Gender of Expert Cyber Defenders Interviewed
Expert Cyber Defender (CD)
CD1
CD2
CD3
CD4
CD5
CD6
CD7
CD8
CD9
CD10
CD11
CD12
CD13
CD14
CD15
CD16
CD17
CD18
CD19
CD20
CD21

Gender
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male
Male

The small defense companies that expert cyber defenders work for complete various
types of projects for the DoD. Examples of these projects include: developing automated
maintenance tools for a new class of submarines, modeling intelligence information gathering
processes, designing new hardware for new classes of Navy ships, developing effective training
methodologies for soldiers entering high stakes environments, and developing facial recognition
software for drones.
There lacks a hard-set rule on the number of cases to include in a multiple-case studies
design. Yin (2009) suggests using two to three case studies for literal replication and using four

79
to six more cases for theoretical replication; however, Yin (2009, p. 58) also states that
designating the number of replications depends upon the level of certainty desired by the
researcher. According to Eisenhardt (1989), the appropriate number of cases depends on how
much is known about the phenomenon under study and how much new information will emerge
from adding more cases. As the researcher approached 38 cases derived from 21 interviews with
expert cyber defenders, the researcher found that no new findings emerged from the data
resulting in saturation. The researcher consulted with the dissertation supervisor of this
dissertation research and the decision was made to discontinue data collection.
3.3.3 Data Collection – Critical Decision Method
Benbasat et al. (1987, p. 374) stated that the goal of case study research is “to obtain a
rich set of data surrounding the specific research issue, as well as capturing the contextual
complexity.” Although various sources of evidence should be considered in a case study design,
interviews are considered to be one of the most important data collection techniques in case
study research (Walsham, 1995; R. K. Yin, 2009). Interviews allow a researcher to gain access to
the interpretations of the participants as well the participants’ views of themselves and others
(Walsham, 1995).
The dissertation researcher used semi-structured interviews as the primary data collection
method for this dissertation research. The initial questions of each interview focused on the
background information of the expert cyber defenders including length of time in the field,
education level, and title of role. The remainder of the interview focused on the CDM. Klein,
Calderwood, and Macgregor (1989, p. 464) define CDM as “a retrospective interview strategy
that applies a set of cognitive probes to actual non-routine incidents that required expert
judgment or decision making.” CDM has been categorized as a method for “eliciting intuitive,

80
experienced based knowledge” of experts (Crandall & Getchell-Reiter, 1993, p. 43). Probe
questions used in CDM identify important cues, choice points, actions plans and the role of
experience (Raanan Lipshitz et al., 2001, pp. 343–344)
CDM evolved from Flanagan’s (1954) critical incident technique (CIT) which was
developed from interviews and reports given in response to critical aviation incidents. Both the
CIT and CDM focus on specific incidents which provide rich sources of data and allow for the
elicitation of tacit knowledge that is not part of formalized procedures in the domain (Crandall,
Hoffman, & Shadbolt, 1998). By focusing on specific incidents, researchers gain more specific
and useful information from research participants rather than focusing on every-day, routine
events (Klein et al., 1989). CDM differs from the CIT in that CDM focuses on eliciting
responses that allow the participants to reflect on strategies they used and the bases for their
decisions (Klein et al., 1989, p. 465).
According to Crandall and Getchell-Reiter (1993), CDM has been used in various
domains including critical care nursing, computer programming, fireground command,
instructional design, design engineering, and battle planning. Results from CDM can be used
“for training, taxonomies of informational or diagnostic cues, and as a basis for assessing skill
levels” (Raanan Lipshitz et al., 2001). CDM consists of five steps: selecting an incident,
obtaining an unstructured incident account, constructing an incident timeline, performing
decision point identification, and conducting decision point probing. These five steps of CDM
are discussed below in relation to the dissertation research.
Selecting an Incident
Klein et al. (1989) suggested that researchers ask the interviewees to select an incident
that was challenging to respond to and required a high level of expertise. Interviewees might

81
provide examples of different incidents; however, a researcher can guide the interviewee to focus
on one incident first and other incidents if time allows. For the dissertation research, expert cyber
defenders were asked to discuss a recent cyber attack that required their expertise to conduct
research on it. The attacks discussed included phishing attempts, zero-day exploits, and malware
attacks. In several of the cases, research participants discussed more than one type of cyber
attack.
Obtaining an Unstructured Incident Account
After deciding on an attack to examine, the expert cyber defenders were asked to provide
an account of the attack from initial detection of the attack to when the research was completed
on the attack. The expert cyber defenders were allowed to proceed uninterrupted when providing
their initial accounts. According to Klein et al. (1989, p. 466), this technique allows the
interviewee to provide his or her own “phenomenological perspective of the event” which helps
offset the researcher’s biases of the event. Additionally, Klein et al. (1989, p. 466) state that this
procedure also helps to develop a high level of cooperation from interviewees since the
researchers can be immediately be viewed as “listeners rather than interrogators.” Below is an
example of an uninterrupted phishing-attempt SA-task account provided by Cyber Defender
Interviewee 6 (CD 6)
First, I became aware of the potential phishing email thanks to my [email] security
system. Upon opening the email within my security system, I looked at the header
information. This email in particular displayed that is was coming from a .gov address
and described a conference that was coming up. I wanted to see if the actual sender
displayed truly represented coming from a .gov email address. The header showed that
the email was coming from a yahoo account. In some cases, government contractors who
send out conference invites do actually use non-.gov email address but not usually a
general email like Yahoo or Gmail. The contractors use their .org emails. This email also
had an attachment and links within the email. I opened the attachment, which was a PDF
within my system to see what it would do. Numerous processes started which I noted.
This processes indicated executables starting that normally a PDF would not initiate.
Also, I used Internet Explorer to view the actual landing page of the conference link in

82
the email as I suspected the landing page was different then what the displayed linked
said. After viewing the header, examining processes from opening the file, and examining
the links, I determined that the email under review was a malicious email that was trying
to trick the recipient into downloading the file or clicking on the link. CD6
Constructing an Incident Timeline and Identifying Decision Points
While listening to the uninterrupted account, the researcher developed an incident
timeline or a series of steps as stated by the interviewees (Klein et al., 1989). Things to note on
the timeline include specific actions taken or decisions made as well as the thoughts and
perceptions reported by the interviewees. When constructing the incident timeline, a researcher
will ask clarifying questions to fill in any gaps when comparing the timeline to the initial
uninterrupted incident account. The purpose of identifying decision points is to allow for further
probing around each decision (Klein et al., 1989). The remainder of the interviews focused on
these decision points. Based on the incident account provided above by CD6, the following
timeline was created:
Became aware of potential phishing email by notice from email security system
Reviewed email header information
o Reviewed sender email address


Determined email was not from “displayed” email sender

Examined file within email
o Examined processes started when opening file


Determined processes were malicious

Examined link within email
o Used Internet Explorer to examine actual landing page


Determined “displayed” landing page was deceptive

Determined email under review was a phishing email

83
Conduct Decision Point Probing
For each decision point identified, a researcher can select from several cognitive probe
types as shown in Table 9. Although CDM provides specific cognitive probes to use, Crandall
and Getchell-Reiter (1993) stated that interviewers should use active listening skills, use probes
as they see fit depending on the decision point (i.e. not using all probe questions for each
decision point), and be flexible in varying the order of questions.
Table 9
Critical Decision Method Interview Probes
Critical Decision Interview Probes

Probe Content

Cues

What were you seeing, hearing, smelling…?

Knowledge

What information did you use in making this
decision and how was it obtained?
Were you reminded of any previous
experience?
What were your specific goals at this time?

Analogues
Goals
Options
Basis
Experience
Aiding
Time Pressure
Situational Assessment

Hypotheticals

What other courses of actions were considered
by or available to you?
How was this option selected? How were other
options rejected? What rule was being
followed?
What specific training or experience was
necessary or helpful in making this decision?
If the decision was not the best, what training,
knowledge or information could have helped?
How much time pressure was involved in
making this decision?
Imagine you were asked to describe the
situation to a relief officer at this point, how
would you summarize the situation?
If a key feature of the situation had been
different, what difference would it have made
in your decision?

84
Overall, the cognitive probes used for each decision in CDM solicit the following: “goals
that were considered during the incident; options that were generated, evaluated, and eventually
chosen; cue utilization; contextual elements; and situation assessment factors specific to
particular decisions” (Crandall & Getchell-Reiter, 1993, p. 43). The CDM interview protocol
used for this dissertation research is provided in Appendix B. Interview Protocol.
3.3.4 Conducting the Case Studies
For the dissertation research, each participant in this study was contacted directly via
email if their email address was publicly accessible (see Appendix C. Recruitment Email). If
their email address was not publicly accessible, the researcher contacted a human resources
representative of the company, identified the researcher by name and affiliation, provided a brief
explanation of the study, and requested the contact information of an expert cyber defender. The
dissertation researcher has numerous contacts in the defense industry. These contacts suggested
companies and expert cyber defenders that the researcher could contact. The previous military
experience of the researcher helped to establish credibility and helped to establish rapport with
the research participants. The researcher conducted the interviews via telephone since traveling
to 21 interview sites would have taken a considerable amount of time beyond the scope of this
dissertation research.
When approaching companies for case study research, Darke et al. stated (1998, p. 280)
that a case study researcher needs to ensure that the research problems are “appropriate in terms
of their interest, significance and value” for both the research community and for the
practitioners under study. Expert cyber defenders were approached with the identification of the
problem (cyber defenders researching cyber attacks) and the potential benefits of the study
(improving the research process).

85
The researcher tape recorded each interview after receiving permission from the research
participants. Eisenhardt (1989) recommends writing down all impressions because they may at
the time seem insignificant but later turn out to be significant to the study. During the interview
and immediately after each interview, the researcher took impressionistic notes to capture
impressions in the moment.
Given the sensitive nature of this cyber defense research topic, numerous steps were
taken to protect the confidentiality of the expert cyber defenders’ identities and information
shared. These steps included letting the expert cyber defenders know that their names and the
names of their companies (as well as any other identifying information) would not be shared, the
tape recording of semi-structured interviews was optional, and write-ups about their cases prior
to the sharing of results could be viewed. Furthermore, the expert cyber defenders were assured
that they could cease their participation in the study at any time and that they did not have to
provide answers for every question asked. The dissertation researcher noted in a couple of cases
in which an expert cyber defender stated that he or she did not want a specific piece of
information shared in the final report.
3.3.5 Directed Content Analysis
The interview data for each case, including the recordings of the interviews and the
researcher’s notes taken during and after the interviews, were reviewed using content analysis to
look for themes, propositions and questions of the case study (R. K. Yin, 2009). When using
content analysis, a researcher can select one of three approaches: conventional, summative or
directed (Hsieh & Shannon, 2005). These approaches are summarized in Table 10.

86
Table 10
Types of Content Analysis
Type of Content
Analysis
Conventional
content analysis
Summative
content analysis

Study Starting
Points
Observation

Directed content
analysis

Theory or previous Codes are defined
research
before data analysis

Keywords

Timing for Defining
Codes or Keywords
Codes are defined
during data analysis
Keywords are identified
before and during data
analysis

Source of Codes or
Keywords
Codes are derived
from data
Keywords are
derived from
interest of
researchers or
review of literature
Codes are derived
from theory or
relevant findings

Conventional or classical content analysis consists of drawing codes from data that are
under analysis rather than reviewing the data with predetermined theories or models. Therefore,
researchers use an inductive approach in the content analysis (Potter & Levine-Donnerstein,
1999). Theories and relevant models are discussed in the findings rather than at the onset of the
research study. Hsieh and Shannon (2005, pp. 1279–1280) state that an advantage of using the
conventional content analysis is letting the data tell the story without “imposing preconceived
categories or theoretical perspectives.”
Summative content analysis consists of initially “identifying and quantifying certain
words or content in text with the purpose of understanding the contextual use of the words or
content” (Hsieh & Shannon, 2005, p. 1283). The main purpose in the initial step of summative
content analysis is to explore usage of words and not to infer meaning. Following the analysis of
usage, a researcher then attempts to discover underlying meanings of words or content.
Summative analysis can provide insights to how certain words are used.

87
Directed content analysis consists of a deductive approach and uses previous theory and
research in the analysis (Mayring, 2000; Potter & Levine-Donnerstein, 1999). In this approach,
researchers provide the following: explicit definitions of coding categories, examples from
research participant responses, and coding rules derived from theory and previous research
(Hsieh & Shannon, 2005; Mayring, 2000). Additionally, a researcher can develop his or her own
subcategories of predetermined main categories (Hsieh & Shannon, 2005). By basing coding
categories on existing theory, the researcher can increase the confidence of his or her coding
scheme (Potter & Levine-Donnerstein, 1999). Directed content analysis was selected as the final
approach for the dissertation research and coding categories were based on LIS models of
professional information seeking and NDM. The LIS models included Taylor’s (1986) IUE
Model, Leckie et al.’s (1996) GMISP, and LIS task-complexity research (Byström & Järvelin,
1995). The NDM approaches included the RPD Model (Klein, 1993) and the CCT (Hammond et
al., 1997).
The researcher used Weft QDA,4 an open source qualitative data analysis tool, to aid in
the directed content analysis. Weft QDA provided a method for coding each transcript based on
codes derived from previous LIS and NDM research, for annotating segments as needed for
further review, and for viewing segments that only fell under a selected code. For example, after
coding all of the interview texts, the researcher could select the code “time pressure” and view
segments from all of the interviews that discussed or were related to “time pressure.” Weft QDA
provided a robust way of coding and sorting the interview data. The following section provided
the details of the coding categories used for analysis while utilizing Weft QDA.
Coding Categories

4

http://www.pressure.to/qda/

88
Tasks
The categories of SA-tasks were not predetermined; rather the categories of SA-tasks
evolved from the data of initial cases (from Interviews 1-4) and were reaffirmed in the later cases
(from Interviews 5-9). The three categories of SA-tasks include the phishing attempt, zero-day
exploit, and malware attack SA-tasks.
Phishing Attempts
Phishing consists of an adversary sending a fake email to a broad audience. The fake
email aims to deceive the receivers into clicking on links or downloading innocent-looking files,
which contain malicious software. Spear-phishing is a type of phishing tactic that specifically
targets a small number of users based on background research conducted by the adversary. For
this dissertation research, the term phishing will be used as a broad category for both phishing
emails and spear-phishing emails. To combat phishing attempts, expert cyber defenders use
email security systems from various vendors. These email security systems attempt to
automatically detect and delete suspect emails as well as bring questionable emails (emails that
may actually be legitimate) to the attention of expert cyber defenders.
Zero-Day Exploits
Zero-day exploits (also called zero-day vulnerabilities) consist of an adversary exploiting
a hole in the code of software. Vendors, such as Adobe and Microsoft, provide protection for
software that they distribute to protect the end user. However, adversaries find holes in the
vendors’ security measures and attempt to exploit the holes. “Zero-day” represents the first day
that the exploit is known. As an example, in February of 2013, a zero-day exploit was found for
Adobe providing the opportunity for adversaries to send PDFs with malicious software or

89
tracking software to unsuspecting users 5. Other examples of software compromised by zero-day
exploits include Internet Explorer 6 and Java 7. When forming situation assessments of zero-day
exploits, expert cyber defenders review the software versions that are impacted to see if the
exploits affect the systems that the defenders have in place.
Malware Attacks
Malware, malicious software, represents a dangerous threat to expert cyber defenders.
The response to a malware attack consists monitoring an intrusion and detection system (IDS) or
intrusion detection and prevention system (IDPS), antivirus software, and network device logs
for suspicious activity. Once suspicious activity is found expert cyber defenders will attempt to
find more details to determine if an attack is taking place. If an active attack is taking place, the
expert cyber defenders will attempt to examine the capabilities of the malware and the potential
impacts.
All three SA-tasks (forming a situation assessment of phishing attempts, zero-day
exploits, and malware attacks) consist of expert cyber defenders becoming aware of the threats
and then evaluating the impact of the threats to determine future actions.
Task Complexity
The characteristics used to examine SA-task complexity in this dissertation research were
drawn from numerous studies as shown in Table 11.

5

http://www.adobe.com/support/security/advisories/apsa13-02.html

6

http://arstechnica.com/security/2013/05/internet-explorer-zero-day-exploit-targets-nuclear-weaponsresearchers/
7

targets/

http://arstechnica.com/security/2013/03/another-java-zero-day-exploit-in-the-wild-actively-attacking-

90
Table 11
Task Complexity Characteristics Used for the Dissertation Research
Task Characteristic
A priori
determinability of
inputs

Low Complexity
Initial state
understood

High Complexity
Initial state not
understood

A priori
determinability of
outcomes

Possible
outcomes
understood

Possible outcomes
not understood

Level of task
variety

Low level of task
variety

High level of task
variety

Level of risk

Low level of risk

High level of risk

Level of time
pressure

Low level of time
pressure

High level of time
pressure

Sources
MacMullin and Taylor
(1984), Byström and
Järvelin (1995), Leckie
et al. (1996), Hammond
et al. (1997)
MacMullin and Taylor
(1984), Byström and
Järvelin (1995),
Hammond et al. (1997)
MacMullin and Taylor
(1984), Leckie et al.
(1996), Hammond et al.
(1997)
MacMullin and Taylor
(1984), Klein (2008)
Hammond et al. (1997),
Klein (2008)

For tasks with low complexity, the inputs, processes, and outcomes of tasks can be a
priori determined and there is low task variety, low risk, and low time pressure. For tasks with
high complexity, the inputs, processes, and outcomes of tasks cannot be a priori determined and
there is high task variety, high risk and high time pressure. Tasks with medium complexity
consist of a mixture of task characteristics of low and high complex tasks. Further explanation of
these codes can be found in

91
Appendix D. Task Complexity Coding.
Information Source Types
The categories of information sources were drawn from Leckie et al. (1996) and
Byström (2002) who defined broad categories of information. Additional categories were added
based on the iterative review of each case. Leckie et al. (1996) defined three broad categories of
information sources: formal, informal, and personal. Byström (2002, p. 583) also defined three
broad categories of information sources: people, documentary sources (formal) and visits.
Additionally, both Leckie et al. (1996) and Byström (2002) allowed each broad category to be
labeled as either internal or external. As recommend by Byström’s (1999, p. 47), these broad
categories were combined and tailored for this dissertation research. The information source
categories include:
People Types (people contacted purposely by research participants for two-way
communication)
o People concerned directly with the matter at hand (organizational team members,
supervisors, subordinates or colleagues involved in the task)
o Experts (people not a priori connected with the task at hand but who hold
expertise in solving the problem or related problem)
Internal –sources within the organization or on a company’s network; examples
o Entity under review (phishing email or malware attack) that is located within the
organization’s network
o Server logs, log files
o Network activity
o Fellow employees or colleagues; experts within the company

92
External – sources outside of organization; examples:
o Social networking sites (Facebook, Twitter, MySpace)
o Online forums
o Blogs (either company sponsored or individual authored)
o Open source in general (stating “open source” but not clarifying further)
o Websites provided by vendors
o Experts from outside of the company
Information Types
Information type categories were primarily drawn from Byström and Järvelin (1995).
Technical or Task Information: this information describes the structure, properties,
and requirements of the task/problem at hand (e.g. names, numbers, places,
statements or events.) “This information type is seen to comprise mainly answers to
the information requirements that are related only to the particular task” (Byström,
1999, p. 45). Examples for this dissertation research include technical code,
capabilities, potential impacts, and software versions of compromised software.
Domain Information (Information on How to Solve a Type of Cyber Attack
Problem): this information consists of laws, concepts, facts, and proven theories of
the task/problem; applicable to several tasks of the same kind. Examples for this
dissertation research include information about how to detect phishing emails in
general, how to respond to zero-day vulnerabilities in general or how to respond
malware attacks in general.
Problem-solving information (General Information about Cyber Defense): this
information covers the methods or procedures across several tasks. It describes how

93
problems should be viewed and formulated and what domain information should be
used. Examples for this dissertation research include how to go about planning for
and responding to cyber attacks in general (such as the NIST cyber incident handling
guide) and how to set up defenses to detect and analyze cyber attacks.
Cognitive Modes
The foundation for coding cognitive modes stems from the CCI of the CCT (Hammond
et al., 1997). The characteristics of cognitive modes used for this dissertation research are
provided in Table 12.

Table 12
Characteristics of Cognitive Modes Used for the Dissertation Research
Cognitive Mode
Characteristic
Insight into the
judgment process
Level of methods or
rules used
Basis of decision
Confidence in method

Intuitive Cognition
Low insight into
judgment process,
difficult to retrace and
defend
Not methods driven;
no rules used
Based on experience
Low confidence in
method

Analytical Cognition

Sources

High insight into
judgment process;
publicly retraceable

(Hammond, 1980)

Methods driven; rules
used
Based on training or
education
High confidence in
method

(Hamm, 1988a;
Hammond, 1980)
(Hamm, 1988a;
Hammond, 1980)
(Hammond, 1980)

Details for coding cognitive modes are provided in Appendix E. Cognitive Modes
Coding.

Intercoder Reliability
Although the dissertation researcher established coding categories based on coding from
previous research (LIS models on professional information and NDM approaches including the

94
RPD Model and the CCT), there still exists the possibility of subjectivity used in the coding
(Potter & Levine-Donnerstein, 1999). To increase the reliability of the coding, the dissertation
tested for intercoder reliability (Krippendorff, 2004).
Hayes and Krippendorff (2007, p. 78) stated that intercoder reliability consists of
“…evaluating whether a coding instrument, serving as common instructions to different
observers of the same set of phenomena, yields the same data within a tolerable margin of error.”
The greater the agreement between independent observers, the greater the reliability of the
coding instrument (Hayes & Krippendorff, 2007).
The dissertation researcher used Cohen’s Kappa values to test for intercoder reliability.
According to Neuendorf (2002, p. 145) “a coefficient of .90 or greater would be acceptable to all,
.80 or greater would be acceptable in most situations, and below that, there exists disagreement.”
For this dissertation research, a Cohen’s Kappan value of .80 was deemed to be acceptable.
When testing intercoder reliability, testing all of the data is labor and time intensive. Therefore,
Lombard, Snyder-Duch, and Bracken (2004) recommend testing a sample of the data with a
measure of 50 units of analysis or 10 % of the data depending on the needs of the study. The
testing of intercoder reliability for this dissertation research involved the coding of data from 4
cases of the 38 cases examined (11% of the data).
Testing for intercoder reliability consisted of two sessions. The first session consisted of
the dissertation researcher explaining the dissertation’s code book to the independent reviewer.
The code book included categories falling under task complexity, information source and
information types, and cognitive modes. After gaining an understanding of the coding categories,
the independent reviewer coded a sample of the data. The dissertation researcher and the
independent reviewer then compared their coding results for this first sample. For most of the

95
categories, in general, the dissertation researcher and independent reviewer agreed on the coding.
However, considerable differences were found in the following categories: “Initial State of
Attack Understood” (falling under the main Task Complexity category) and “General
Information about Cyber Defense” (falling under the main Information Source and Information
Types category). The dissertation researcher and independent reviewer shared their
interpretations of the coding for these two categories. The discussion resulted in the dissertation
researcher defining these two categories more explicitly.
A second round of coding was then conducted on the remaining data. The final results
were discussed between the dissertation researcher and the independent reviewer. The results
showed that the coding among the categories was generally in agreement. The Cohen’s Kappa
was then calculated for all 25 categories after all of the data was coded. For all categories, the
Cohen’s Kappa values were found to be greater than .80. The final results of the agreements
between the dissertation researcher and the independent reviewer are shown in Tables 13-15.

Table 13
Cohen's Kappa Values for Task Complexity Coding Categories
Task Complexity Coding Categories
Initial state of attack understood
Initial state of attack not understood
Possible outcomes of attack understood
Possible outcomes of attack not understood
Low level of task variety
High level of task variety
Low level of risk
High level of risk
Low time pressure
High time pressure

Cohen’s Kappa Value
0.912
0.945
0.978
1.00
0.842
1.00
1.00
0.945
0.988
0.966

96

Table 14
Cohen's Kappa Values for Information Source and Information Type Coding Categories
Information Source and Information
Type Coding Categories
Person as a source
Internal source
External source
Expert
Technical information for task at hand
Information on how to solve a type of
cyber attack problem
General information about cyber defense

Cohen’s Kappa Value
0.891
0.912
0.955
0.967
0.898
0.875
0.845

Table 15
Cohen's Kappa Values for Cognitive Modes Coding Categories
Cognitive Modes Coding Categories
Low insight into judgment process
High insight into judgment process
Use of rules or methods
No use of rules of methods
Formal training or education
High confidence in completing task
Low confidence in completing task

Cohen’s Kappa Value
0.924
1.00
1.00
1.00
0.955
0.966
0.975

3.3.6 Pattern Matching for Information Behaviors and Cognitive Modes
This dissertation researcher used pattern matching to examine the information behaviors
and cognitive modes used for each SA-task: the phishing attempt, zero-day exploit, and malware
attack SA-tasks. Pattern matching consists of comparing patterns found in cases with predicted
patterns as hypothesized early in a study also known as pattern-matching logic (Robert K. Yin,
2011). For this dissertation research, the predicted patterns stem from the theoretical propositions

97
of LIS task-complexity research (Byström & Järvelin, 1995) and the theoretical propositions of
the CCT (Hammond et al., 1997). These predicted patterns include:
As task complexity increases...
the amount of information sources used increases (LIS task-complexity research)
the use of external sources increases (LIS task-complexity research)
the use of people as sources increases (LIS task-complexity research)
the use of experts increases (LIS task-complexity research)
the use of domain information and task solving information increases (LIS taskcomplexity research)
the use of intuitive cognition increases (CCT)
Pattern matching consists of identifying preliminary patterns from the literature review,
augmenting the preliminary patterns with initial interviews, identifying predictable patterns that
emerge, and evaluating whether subsequent interviews continue match the pattern (Zach, 2006).
After conducting pattern matching for each SA-task type, the overall patterns of information
behaviors and cognitive modes used for each SA-task type (phishing attempt, zero-day exploit,
and malware attack) were then compared against the other SA-task types. The dissertation
researcher used visual displays to compare patterns across the SA-task types.
3.3.7 Statistical Analysis of Information Behaviors
As stated by Yin (2009), statistical analysis can strengthen case study findings. The
purpose of the statistical analysis was to determine if there was a significant relationship between
SA-task complexity (low, medium and high) and the use of following information-behavior
variables:
Number of Information Sources Used

98
Number of External Sources Use
Number of People Used as Sources
Number of Experts Used as Sources
Number of Technical Pieces of Information Used
The statistical analysis consisted of several steps including: transforming the frequencies
of each information-behavior variable into categorical variables of Low, Medium and High;
creating a contingency table (relationship table) to display the counts of low, medium, and high
for each information-behavior variable against each SA-task complexity level (low SA-task
complexity, medium SA-task complexity, and high SA-task complexity); and then conducting
the Freeman-Halton extension of Fisher’s exact test to test for statistical significance. These steps
are described in more detail below.

Organizing the Data
The categories Low, Medium, and High were calculated for each information-behavior
variable through the use of Excel. For example, for the variable Number of Information Sources
Used, the frequencies found for the number of information sources used each individual case of
phishing attempts, zero-day exploits, and malware SA-tasks were all placed into Excel as one
array. This array consisted of 38 cells (38 represents the total number of cases discussed by
research participants) with counts of information sources used. The data were then sorted from
lowest to highest and the Percentile Function with Excel was used on this sorted array of data to
find the 33rd and 66th percentiles to divide the data into three groups of Low, Medium, and
High. For example, for Number of Information Sources Used, the 33rd percentile was found to

99
the value of 2 and the 66th percentile was found to be the value of 4. Therefore, original counts
for number of information sources used were categorized as following:
Low Number of Information Sources Used: less than or equal to 2
Medium Number of Information Sources Used: 3-4 information sources
High Number of Information Sources Used: greater than or equal to 5
The resulting transformation of frequency counts to categories of Low, Medium, and
High allowed for the creation of a 3 × 3 matrix to examine relationships. As an example, Table
16 shows the 3 × 3 matrix for the Number of Information Sources Used (categorized as Low,
Medium, and High) and the three SA-tasks of low, medium, and high complexity (phishing,
zero-day exploits, and malware).
Table 16
3x3 Contingency Table for Number of Information Sources and SA-Task Complexity
Low SA-Task
Complexity
(Phishing
Attempts)

Medium SA-Task
Complexity
(Zero-Day
Exploits)

High SA-Task
Complexity
(Malware
Attacks)

Low

9

1

0

Medium
High

0
0

9
2

1
17

Number of Information
Sources

This type of table able is called a contingency table and shows the combination of values
of two variables (Ruxton & Neuhäuser, 2010). The transformation of frequency counts to
categories resulted in five 3 × 3 contingency tables, one for each of the following informationbehavior variables: Number of Information Sources Used, Number of External Source Used,
Number of People Used as Sources, Number of External Experts Used, and Number of Technical
Information Piece Used.

100
Performing the Statistical Test
After creating the five 3 × 3 tables, the researcher used the Freeman-Halton extension
(Freeman & Halton, 1951) of Fisher’s Exact test to test for significant differences between
categorical variables. The chi-squared approximation was not suitable for this data analysis due
to the small sample sizes in this study and several cell values in the contingency tables having a
value less than five (Howell, 2011).
The Fisher exact test is used for variables with two categories (2 × 2 cross-tabulation
tables). The Freeman-Halton extension was developed to use for variables with three or more
categories (such as 3 × 3 contingency tables) (Conover & Conover, 1980). Both of these tests are
used to determine if there are nonrandom associations between categorical variables.
The Freeman-Halton extension of Fisher’s exact test was used in a LIS study focusing on
the search success of research participants when using online finding-aid systems (Daniels &
Yakel, 2010). For example, “search success” was divided into three categories of Low, Medium
and High and then compared to five occupation categories (historian, genealogist, librarian,
graduate student, and undergraduate student). This resulted in a 3 × 5 (search success categories
by occupation categories) contingency table. The researchers presumed that occupation type was
important in determining search success. However, the Freeman-Halton extension of Fisher’s
exact test did not show a significant relationship between search success and occupation type.
Although SPSS can be used for conducting the calculations for Fisher’s Exact test (2 × 2
contingency tables), the general educational version of SPSS is not tailored to conduct the
Freeman-Halton extension for 3 × 3 tables. As a result, Ruxton and Neuhäuser (2010)
recommended the use of an open-source statistical computational tool provided by Vassar
College (http://vassarstats.net/). VassarStats provides several statistical computational tools as

101
well as a companion statistics textbook (Lowry, 2013). Several scientific research studies have
used the VassarStats open-source statistical computational tool for the Freeman-Halton extension
of Fisher’s exact test (Bertram, Rook, Fitzsimmons, & Fitzsimmons, 2011; Johannesen,
Keyghobadi, Schuler, Stauffer, & Vogt, 2013; Zaremba et al., 2009; Zhang & Hammond, 2010).
As a result, this open-source statistical computational tool was deemed as a credible statistical
tool to use for this dissertation research.
Evaluating Test Results
When using the Freeman-Halton extension of Fisher’s Exact test, the null hypothesis
states that there is no significant relationship between categorical variables. The alternative
hypothesis rejects the null hypothesis indicating that there is a significant relationship between
the categorical variables. The Freeman-Halton extension provides two-tailed p-values of
probability of significance. The decision to accept or reject the null hypothesis is based on the
following (Gall, Borg, & Gall, 2007):
If the p-value is greater than 0.05, we accept the null hypothesis that there is no
significant relationship between categorical variables
If p-value is less than or equal to 0.05, we reject the null hypothesis in that there is a
significant relationship between categorical variables.

3.3.8 Iterative Nature of Research Design
Challenges in Initial Research Scope
The research design for this dissertation research evolved over time from the initial
proposed research to the final research design. The dashed, light-colored arrows in Figure 6 (the
overview of the multiple-case studies design selected for this research) signify the iterative

102
nature of case study research. The research focus for this dissertation changed over time due to
issues found with the significance of original research focus for the participants, issues found
with lack of research participation from prospective participants, and evidence of themes found
from the initial data analysis.
As Darke et al. stated (1998), a case study researcher needs to ensure that research
participants consider a study’s focus to be significant. In late 2012, the researcher initially
intended to interview law enforcement analysts to ask questions about how they detected
deception in spear-phishing emails. The CCT provided the theoretical framework to examine the
cognitive processes used in deception detection. However, after informally talking with law
enforcement analysts and researching online if there were reports of law enforcement agencies
falling victim to spear phishing attacks, the researcher found that spear phishing was not a
primary concern for law enforcement agencies. Based on further research, the researcher found
that several defense companies were recently targeted by and fell victim to spear-phishing
attempts. This led the researcher to change his research participant focus from law enforcement
analysts to expert cyber defenders from defense companies.
After initial IRB approval was received, over 30 interview invitations were sent via email
to expert cyber defenders from defense companies for a pilot study. However, all but one expert
declined the invitation to participate due to not feeling comfortable in discussing specific
deception detection practices. Several expert cyber defenders stated that their deception detection
practices were confidential and could not be shared. This presented another barrier to research.
The researcher then discussed this issue informally with expert cyber defenders in his
network and found that expert cyber defenders tended to conduct a lot of research online to
understand cyber attacks. Additionally, the researcher found that the information gathered by

103
expert cyber defenders tended to come from publicly available sources. This led the researcher to
ask expert cyber defenders from defense companies if they were willing to discuss how they
conducted research on new cyber attacks.
This change of focused resulted in an increase in the invitation acceptance rate for
participating in the study. 12 invitations were sent to expert cyber defenders from small defense
companies requesting participation in the study and all 12 stated that they were willing to
participate. The researcher was able to set up interviews with 9 of the 12 expert cyber defenders
for the pilot study. Due to scheduling conflicts and other responsibilities, the other three expert
cyber defenders requested to participate in the future rather than around the time of pilot study.
Interestingly, the new approach actually resulted in expert cyber defenders sharing specific
tactics as well as general strategies for combating cyber attacks including spear-phishing emails.
Iterative Analysis
Eisenhardt (1989) recommends becoming intimately familiar with each individual case
since each case may have its own topics, themes, propositions or questions. The content analysis
and subsequent comparing of cases resulted in changes in the theoretical framework used for this
dissertation research. The interview data from first interview were analyzed with content
analysis. When the second interview was completed, themes from the second interview were
compared to themes found in the first interview to look for similarities and differences. As the
third interview was completed, themes from that interview were compared to themes from the
first two interviews.
After the fourth interview was completed, the researcher started examining themes across
the four interviews. In Interview 1, the research participant discussed three examples of tasks:
phishing attempt, zero-day exploit, and malware attack SA-tasks. In Interviews 2, 3 and 4, each

104
participant discussed only one type of cyber attack: zero-day exploits (Interview 2) or malware
attacks (Interviews 3 and 4). The researcher then attempted to see if other research participants
would discuss more than one type of cyber attack in Interviews 5 and 6. After Interviews 1-6
were completed, the researcher noticed differences in the responses depending on the types of
cyber attacks discussed. This prompted a review of LIS task-complexity literature. Cases 7-9
confirmed differences in responses based on the type of cyber attack discussed and confirmed the
incorporation of the LIS task-complexity research.
The first nine interviews conducted for the pilot study were included in the final 21
interviews conducted for this dissertation research. As Interviews 11-21 were conducted, the
researcher continued to use an iterative approach in reviewing each case resulting in each case
being reviewed multiple times. Additionally, the iterative nature of the research design helped
the researcher maintain an open perspective for the incorporation of other theoretical
frameworks, such as NDM situation assessment research, into the final overall framework used
in the dissertation research.
3.3.9 Writing up Findings
According to Yin (2009, p. 165), the reporting of findings is critical for case study
research since the findings can “make a significant contribution to knowledge or practice.”
Runeson and Höst (2009, p. 156) suggested using a “linear analytic” structure for reporting on
case studies. The linear analytic structure provides a description of the problem, related work,
methods, analysis, and conclusions. Walsham (1995) stated that case study researchers should
provide details on the collection of data (sites selected and reasons for this selection) and data
analysis (how interviews were conducted, how they were analyzed, and how the iterative process

105
between data and theory evolved over time). The linear analytic structure was used in this
dissertation research.
Case study research, as well as qualitative research, faces criticisms from quantitative
researchers that should be considered in the write-up of findings as well as throughout the
carrying out of case studies. Case study research has received two primary criticisms including
the perceived lack of rigor and the lack of generalizability (Darke et al., 1998; R. K. Yin, 2009).
Yin (2009) states that the perceived lack of rigor may stem from previous case studies that did
not follow a systematic approach. Yin (2009) also states that non-case study researchers may
expect case studies to be generalizable to populations (statistical generalization); however, case
studies are generalizable only to theoretical propositions (analytical generalization). Also,
Eisenhardt (1989) states that it may be challenging to generalize findings from a single case
study; however, using a multiple-case studies design can make it easier to generalize findings.
For this dissertation research, the researcher followed a systematic approach as
recommended by Yin (2009). Although a systematic approach was followed, case study research
design allows for flexibility. During the conduct of the multiple-case studies design, the
researcher for this dissertation research aimed to address credibility, transferability, and validity
of the research.
Credibility
Credibility refers to the focus of the research conducted and how well data and processes
addressed the focus (Graneheim & Lundman, 2004). To address credibility, Zach (2006)
recommends using a robust data collection plan. In this dissertation research, the researcher used
a previously defined semi-structured interview technique: the CDM-based semi-structured
interview technique (Crandall et al., 1998; Klein et al., 1989). During the course of the

106
interviews, the researcher took impressionistic notes and took notes immediately following the
interview. The interview recordings, interview transcripts, in-progress interview notes, and postinterview notes provided rich sources of data to analyze. Another way to demonstrate credibility
is to provide representative quotations from transcribed text (Graneheim & Lundman, 2004). The
researcher included quotations from several research participants in the Findings section in order
to show the research participants’ perspectives on forming situation assessments of cyber attacks.
An additional technique for increasing credibility includes member checking. Member
checking consists of the researcher soliciting reactions of respondents to the researcher’s findings
(Schwandt, Lincoln, & Guba, 2007; R. K. Yin, 2009). Although member checking can be
conducted in different ways (as in the case of sharing verbatim reports of participant comments),
Creswell (2009) recommended that member checks should be conducted with more polished
reports that demonstrate the themes and patterns found in the data. For this dissertation research,
the researcher sent the Findings chapter to research participants. Sending the Findings chapter
has been recommended as one way to increase the credibility of a dissertation study (Demps,
Lincoln, & Cifuentes, 2011). Five expert cyber defenders provided feedback on the Findings
section. The member checks provided by the five expert cyber defenders reinforced the findings
of this dissertation research. Below is representative quotation from an expert cyber defender
who read the Findings chapter:
The report that you showed me definitely holds true in my view. I mean for these
advanced attacks there are no procedures that we follow step-by-step. Rather we make
decisions based on our previous knowledge and being immersed in this complex
malicious environment for years. Step-by-step procedures really wouldn’t help us and
definitely would not help new guys at our company. For simple things like emails, stepby-step methods can easily be taught and followed. Otherwise, we need to train new guys
side by side so they can pick up what we experienced professionals do. CD15
Transferability

107
When addressing transferability, Graneheim and Lundman (2004) suggest providing a
detailed description of contents, characteristics of research participants, data collection details,
and description of data analysis. The researcher provided a description of the research
participants’ education background, years of experience, and title of role held in Table 7. The
researcher provided details of the CDM-based semi-structured interviews as well as the interview
protocol in Appendix B. Interview Protocol. Additionally, the researcher provided data analysis
details in this Method section as well as in

108
Appendix D. Task Complexity Coding and Appendix E. Cognitive Modes
Coding.
Validity
Potter and Levine-Donnerstein (1999) state that one way to address validity in
content analysis is to develop a coding scheme based on a previously used standard. The
researcher developed coding schemes based on previous research as shown below:
The task complexity coding scheme was derived from LIS studies focused on
professional information seeking Leckie et al. (1996), MacMullin and Taylor
(1984), Byström and Järvelin (1995), the CCT, and the RPD (Klein, 2008).
The information source coding scheme was derived from a foundational
information seeking of professionals study (Leckie et al., 1996) and a
foundational task complexity and information behavior study (Byström,
2002).
The information type coding scheme was developed from a previous task
complexity and information behavior study (Byström & Järvelin, 1995).
The cognitive modes coding scheme was derived from previous CCT studies
(Hamm, 1988a; Hammond, 1980).
The dissertation researcher also tested for inter-coder reliability in order to
increase the validity of the coding categories. For all categories, the Cohen’s Kappa
values were greater than .80 which is cited as an acceptable level by Neuendorf (2002, p.
145).
Theoretical Sensitivity

109
Theoretical sensitivity is defined as “…having insight into, and being able to give
meaning to, the events and happenings in the data” (Strauss & Corbin, 1998, p. 46) and
can be derived from previous literature and professional experience. As stated in the
Literature Review section, situation assessment research that focused on information
behaviors tended to focus on decision making in the U.S. Navy surface ship and
submarine warfare domains (Johnston et al., 1997; Kaempf et al., 1996, 1993;
Kirschenbaum, 1992; R. Lipshitz & Strauss, 1997; Randel et al., 1996). This dissertation
researcher served six years as a U.S. Navy Surface Warfare Officer and faced numerous
real-world situations examined in these NDM studies. However, as Strauss and Corbin
(1998) stated, the researcher must balance his or her own experience with the
interpretations of the experience as shared by the research participants. To overcome this
pitfall, the dissertation researcher used the CDM interview to listen to uninterrupted
accounts of the research participants’ experiences at the beginning of the interview. This
sets the stage for the researcher being the “listener” and helps offset the researcher’s
biases of the participants’ experiences (Klein et al., 1989)
3.4 Limitations of Methods
A limitation for the methods used for this dissertation research includes the use of
interviews. The dissertation research relied on the research participants’ ability to recall
specific events and the reasoning for why they followed the steps that they did. Some
participants may not have recalled an event accurately or may have altered their
descriptions of the events. They may have altered their descriptions of the events based
on having time to reflect on what happened or based on trying to show to the interviewer
that they successfully completed a task. However, the common themes found across

110
interviews helped mitigate challenges faced with research participants’ recall. Another
limitation in the methods includes the use of only one data collection method: semistructured interviews. Using multiple methods provides the opportunity for triangulation.
Given the confidential and sensitive nature of cyber defense, using other methods would
have provided a challenge for the dissertation research. For example, the conducting
observations of the expert cyber defenders when forming situation assessments of cyber
attacks would have been time consuming and may have caused a lack of participation
from research participants.
An additional limitation is the sample size. Although 21 expert cyber defenders
were interviewed for this dissertation research, their experiences in information seeking
when forming a situation assessment of cyber attacks may not be generalizable to all
expert cyber defenders. However, the results may be transferable to expert cyber
defenders who work in companies of similar size. The goal of qualitative research is
transferability and not generalizability (Lincoln & Guba, 1985). The limitations stated
here provide opportunities for future research.

111
CHAPTER 4: FINDINGS
The purpose of this dissertation research was to test the theoretical propositions of
LIS task-complexity research and the CCT in the context of cyber situation assessment.
The main research questions are restated here:
How does situation-assessment task complexity influence the information
behaviors of expert cyber defenders when completing situation assessment
tasks? Included in these behaviors are number of information sources used,
number of external sources used, number of people used as sources, number
of experts used as sources, and number of technical pieces of information
used.
How does situation-assessment task complexity influence the cognitive modes
used by expert cyber defenders when completing situation assessment tasks?
The cognitive modes include analytical cognition, intuitive cognition, and
quasi-rational cognition.
For each SA-task type (the phishing attempt, zero-day exploit, and malware attack
SA-task), the following findings are reported on: task complexity, information sources
used, information types used, and cognitive modes used. Patterns were examined for each
SA-task type. Included in these findings are numerous quotations from expert cyber
defenders that were pulled from the interview transcripts. Expert cyber defenders are
labeled as CD1, CD2, CD3 etc. based on the order in which they were interviewed.
After the information behavior and cognitive mode findings for each SA-task type
are provided, the patterns or each case SA-task type are compared with the patterns from
the other SA-task types. Finally, the results of statistical analysis are presented based on

112
the number of information sources, information source types, and information types used
by the expert cyber defenders when completing the SA-tasks.
4.1 Information Behaviors and Cognitive Modes Used for the Phishing Attempt SATask
4.1.1 Level of Task Complexity of the Phishing Attempt SA-Task
The research participants who discussed the phishing attempt SA-task (CD 1, 6, 8,
9, 12, 13, 15, 19, and 21) described this task as having a low level of complexity. All of
these expert cyber defenders used email security systems to deter malicious emails. Email
security systems use pre-determined criteria to automatically discard or mark suspected
malicious emails similar to how popular email programs, such as Gmail and YahooMail,
attempt to automatically identify spam. Email security systems are customizable in that
expert cyber defenders can alter the pre-defined criteria or provide their own criteria for
the systems to use. Additionally, the expert cyber defenders can establish criteria for
emails that they want to review as stated by CD6.
I have a [email security system technical] policy set up for our emails. If a new
email gets through the system, I can go back into the policy and add that IP
address to it to prevent that IP address from getting another email through.
However, there are some emails that I want to see such as ones that say they are
coming from some type of .gov email or something like that. I want to make sure
we aren’t missing anything. CD6
The emails that are individually reviewed by the expert cyber defenders are
placed in a queue by the email security system.
So what you do is review the ones in the queue to make sure that you can purge
them. Usually these are fake messages, but I have to make sure. I will give a quick
once over and then either send them on to the employee or discard them. CD8
Our email security system makes it easy to pinpoint the emails that you need to
review. If we did not use this automation tool I would have to manually go
through each and every email or place the burden on individual employees to

113
review each email. I am sure most could do that but there is a risk involved too.
Why add that risk to the employees when a system can do it automatically? CD15
The emails that need to be reviewed by the expert cyber defenders are based on
system-defined criteria and expert cyber defender defined criteria. The expert cyber
defenders know they need to review the email because it is placed in the cue by the email
security system. Therefore, the initial inputs are understood and provided to the expert
cyber defenders. The outcomes for the phishing attempt SA-task consist of two options:
the email is determined to be malicious or the email is determined to not be malicious.
CD9 and C19 state succinctly:
It is a straightforward process. It [the email] is either fraudulent or real. There
are really no surprises. CD9
The process is pretty clear-cut. You determine whether it is a fake message or not.
CD19.
It is either a choice of a real email that landed in the queue that someone needs or
a malicious email that will try to get the reader to download [a virus]. CD21
The alternatives (malicious or non-malicious email) are clear to the expert cyber
defenders. The expert cyber defenders stated that they used a consistent, straightforward
approach for reviewing suspected phishing emails:
All I have to do is look at the sender username, then look at the real email address
that it is coming from and look at the header. CD1
You go straight to the header. You look at if it is coming from who actually sent
the email. It is quite simple to actually to do that. It takes little time to see that it is
coming from a different source than it says it’s coming from. CD8
For every message I need to review, there are clear cut steps or email specifics
that I look at like the date and time of the email, the files attached, the sender, the
real sender’s email address and so forth. CD19

114
None of the expert cyber defenders mentioned any unpredictable events or
occurrences. Furthermore, the email security systems presented suspected emails in a
static fashion, on a list or in a queue as stated above. The expert cyber defenders also
seemed to attach a low level of risk with phishing attempts. For example CD1, stated:
Once every couple of days, someone is trying to use social engineering aka
phishing on us. However, in all, it is quite easy to catch them with our monitoring
system. I just review them [emails] if I need to and I see they are coming from a
previously identified or similar to a previously identified source, you know an IP
address. If it is a new source, I just add the IP address to a blocking list. CD1
Similarly, CD15 stated about his company’s email security system:
Our system is highly reliable in detecting these emails. Even if one gets through,
our employees are primarily scientists and engineers and I know these guys will
be able to detect anything fishy in emails they receive. I trust they can make the
right judgments. C15
The expert cyber defenders discussed the regular occurrence of being hit with
phishing attempts but did not express concern over them.
These [phishing] attempts don’t worry us too much since our security solution
automatically screens for them. And when I have to actually check one out, it’s
not like it already went through to one of my employees. So there is not a lot of
risk. Maybe once in a while one will get through but what tends to happen is the
guy who received something that seems a little off, he will ping me to let me know.
So we are well protected against these. CD8
The expert cyber defenders stated that there lacked an immediate need to review
emails in their queues. Emails in the queues were either reviewed within the same day or
after a few days but not viewed immediately. The only time pressure placed on the expert
cyber defenders occurred when an employee contacted them.
I may review it that day or another day but it only becomes urgent if a guy
contacts me and says “hey, I have been waiting for an email from another
company and I haven’t seen it. Have you?” Then I will go immediately to the
queue and see if I have it there. CD1

115
Really the only time pressure is when someone is waiting for an email that was
placed in the holding pattern. That really is the only reason for when I need to
expedite reviewing the email. I also need to check why this legit email was placed
in the holding pattern in the first place so I can change the policy as needed.
CD21
For the phishing attempt SA-task, the following patterns emerged from the
directed content analysis: the expert cyber defenders faced known inputs, understood the
potential outcomes, faced predictable situations, viewed the task as having low risk, and
viewed the task as having low time pressure. These patterns suggest that the phishing
attempt SA-task represents a task with low complexity.
4.1.2 Information Sources Used for the Phishing Attempt SA-Task
For the phishing attempt SA-task, the expert cyber defenders tended to not seek
out information sources outside of the email under review. All of the expert cyber
defenders who discussed the phishing attempt-SA task stated that they used email headers
as a primary information source. CD1 stated:
All of the information I need is right there in the email, primarily in the header.
Outside of the email I don’t need to look at anything else. CD1
Fortunately, all I need to review is details within the email and about the email
such as the header. CD13
Other expert cyber defenders also stated the importance of using the header and
described other sources of information within the email.
All I need to look at is the header information like who it was from…well what the
name says but also the real sender information as well as the subject, the time, the
IP address. Then I will look at the content and see if there are any files. I can play
with the files within my security system without things going beyond it [the
security system]. So I can open it without risking the infection of files or software.
CD6

116
The header information is undoubtedly the most important piece of information
that I review for phishing, followed by links and attachments. All I had to do for
this instance was look at that. CD15
The header really has all that you need, well at least for the initial review. The
header is the first place I went. But text within the email and files within give you
clues too. But the header is the primary source. CD13
The attachments were critical to look at. When a user clicks on one, he may
actually be downloading malware that finds itself into our network. CD19
In some rare cases, an expert cyber defender might need to correspond with a
fellow employee about a phishing attempt.
Sometimes I might reach out to a guy in one of our divisions to ask if he was
waiting for an external email from such and such a guy in such and such a
company. You definitely don’t want to stop business emails from going through,
that’s why in some instances you just need to check to clarify. CD9
CD1 also mentioned the possibility of interacting with fellow employees:
Maybe once in a while one [phishing email] will get through but what tends to
happen is the guy who received something that seems a little off, he will call me
or email me to let me know. CD1
Overall for phishing attempt SA-task, the primary information source for the
expert cyber defenders consisted of the email itself. In rare cases, the expert cyber
defenders corresponded with fellow employees to verify some things.
4.1.3 Information Types Used for the Phishing Attempt SA-Task
The experts used several details within the header for the phishing attempt SAtask. Within the header information, the expert cyber defenders looked at items such as IP
addresses found in received lines that provided information on the path that the email
took to arrive at the companies.

The header information allowed me to see which path the email took as it arrived
out our doorstep. I was able to trace the email to its origin. By finding the source

117
of this email I was able to block other emails originating from the same place.
CD15
The path found in the email header tells you how the email crossed different mail
servers. I just reviewed the received lines in the header to see which email servers
that the email passed through to get to us. You can see the IP addresses and
dates. But these guys [phishing attackers] can even create fake received lines.
CD21
The final received line information did not match the email address of the
company that the email said it was coming from. I then knew it really did not
come from the company that the email claimed it was coming from. CD12
In addition to the IP addresses in the received lines, the expert cyber defenders
also looked at information about the senders.
After reviewing the” from line” from the header, I could immediately see that the
from address was phony. Even though it said helpdesk in the from line, there was
an extra character. It was a dash, it was either hyphen or an underscore. But
whatever it was, the from address highly resembled our helpdesk email address.
CD21
The from address made it appear that it came from a legitimate .gov address.
However, after further investigation, I could see that it was coming from a Yahoo
address. CD13
The expert cyber defenders also reviewed the text in the emails for grammar and
spelling emails.
A string of spelling and grammar errors usually accompany these emails. They
are pretty obvious errors. CD13
You see, this email stated it came from a .gov address and focused on information
concerning a major research area that we work in, we will say subs for example.
However, there were numerous obvious typos. I doubt that such an important
email would contain these blatant typos. CD9
Additionally, some expert cyber defenders assessed the actions called for in the
emails.
As I said before many of these emails are easy to detect. Beside the header
information, the text of the email provides many clues. If there is a tone of

118
urgency, like “you need to click this now or your email account will be closed”
then that sets off an alarm in your head. CD15
These emails [phishing emails] tend to ask you to perform an action such as
entering in user account or personal details. Sometimes these requests are
embedded within the email. Other times the link takes you right to this site. CD13
The links in the email were also heavily reviewed by the expert cyber defenders.
Links in these emails tend to look legitimate just based on looking at the text. But
you gotta hover over the link to see what the link is actually linking to. To make it
even harder for employees to think they are clicking on legitimate links, the links
take you to web pages that look exactly like the real webpages the real links are
supposed to take you to. I never click on a link without seeing where it really
goes. CD12
A typical user may click on a link just based on the text that is shown in the email.
However, once you actually check the read address of the landing page, you can
see it does not take you to an actual company’s URL. CD19
Another piece of information reviewed by the expert cyber defenders consisted of
the attachments.
Using my security system, I am able to open attachments and then see what
processes the attachments carry out. For instance, in this example, something was
downloaded in addition to the PDF file. If an employee, opened this file, he would
have ended up downloading a virus without him even knowing that he did. CD13
One of the most common file types in the phishing emails are PDFs. Other
common files are xls, and doc or docx type files. CD19
These are used so heavily within our company and our industry. And there are
many vulnerabilities found with Adobe. Many times it is not just the fact that the
email has a PDF it is the fact that there is the PDF as well as typos or a sense of
urgency or something else that makes you think twice of opening the file. CD15
All of the information types described by the expert cyber defenders during the
phishing attempt SA-task consisted of descriptive information or data found within the
emails. For phishing attempts, none of the experts sought “how to” type information on
detecting phishing attempts (domain information) or information on how to go about
setting up cyber defense (problem solving information). All of the information described

119
by the expert cyber defenders consisted of technical information (information only
related to the task at hand).
4.1.4 Counts of Information Sources and Information Types Used for the
Phishing Attempt SA-Task
While conducting the directed content analysis, the frequencies of information
sources and information types were counted from the interview transcripts. Figure 8
shows the average number of information sources, average number of external sources,
average number of people used as sources, average number of experts used as sources,
and average number of technical pieces of information used for the phishing attempt SAtask. The categories are non-exclusive. The original counts are found in Appendix G.

Information Sources and Information Types Used for the Phishing
Attempt SA-Task (N = 9)
Average Number of Sources Used
Average Number of External
Sources
Average Number of People as
Sources

Average Number of Experts as
Sources
Average Number of Technical
Pieces of Information
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

Figure 8. Information Sources and Information Types Used for the Phishing Attempt SATask

120
4.1.5 Cognitive Modes Used for the Phishing Attempt SA-Task
Overall, expert cyber defenders tended to use analytical cognition when
completing the phishing attempt SA-task. The experts were able to describe step-by-step
how they evaluated suspected phishing emails. This demonstrated that these expert cyber
defenders had a high level of insight into their judgment processes.
First, our email security software filters out suspect emails. Some are
automatically filtered out, however others are brought to my attention in the
queue. The first thing I do is look at the header of the email to check if the
message is really coming from who is says it is coming from. That usually leads to
the judgment about whether it is fake or not. If I need to, then look at the file types
that are enclosed in the email if there are any. Then I can easily use Internet
Explorer to view the full link if a link is embedded in the email. I can view the full
link without even opening it. CD6
Although, CD6 did not state the use of procedures, it is evident that he follows a
methodological approach in reviewing emails that are possible phishing emails. CD1 also
stated that his first step was reviewing the header.
Well, the reason I go to the header first is since it has the information you need to
examine the email. It just takes a click to see the full header and you can quickly
see that an email from Joe Schmoe is actually from some other name. Then you
know something is suspect once you see that. Then I can see the originating IP
address. Those clues let you know how to process it. CD1
CD13 also presented a similar step-by-step process.
First thing I do is quickly scan the email for obvious things like typos or emails
that ask to provide personal or confidential information right away. Then I go to
the header to look at the receiving lines. In tandem with that I look at who the
email is really from. It is almost the same process for each email. The header is
the key. CD13
When asked about rules or checklists used for reviewing possible phishing emails,
none of the expert cyber defenders cited any use of rules or checklists. However, since
many of the expert defenders stated similar steps, it seems that many are using similar
methods. Additionally, it seems that they are using “yes/no” rules. For example, does

121
the sender email address actually represent a legitimate email address? Yes or no. Does
the path of the email follow a legitimate path? Yes or no. Are there typos or grammatical
errors in the text? Yes or no. Are there illegitimate actions that are carried out when
downloading the file? Yes or no.
The expert cyber defenders were asked how they knew to follow the steps that
they did. CD9, just like several other of the expert cyber defenders, said he learned
through experience.
You just pick it up as you go. All you have to do is look at the header. You don’t
really get trained on it. It’s common sense. CD9
CD6 and CD 12 also expressed similar views.
Over time after looking at so many emails, you just know what to do. I don’t think
other employees know to look at the header information right away. I was just
something I picked up. CD6
It is based on experience. You pick up what the scammers are doing to do over
time. There are only so many things that they can manipulate. So you can catch
them. CD12
The expert cyber defenders expressed a high level of confidence in their ability to
detect phishing emails. CD1 quantified his ability:
I am 99% sure I can capture all of these types of emails based on how I have my
[email security system] policy set up. CD1
Others expressed a similar level of confidence:
I can get all of these [phishing attempts] before they [employees] see them. It is
like a multilayered defense. First obvious ones are purged, other ones I need to
review. Going to the header easily gets rid of the bad ones. CD9
With my email [security] system I am sure I can detect these emails. The phishers
are tricky but by looking at the header and other parts of the email, I can catch
these with no problem. CD15
Without a doubt I can protect our assets when I review messages. CD13

122
As CD9 stated there are multiple layers of defense that an email goes through.
The email security systems used by the expert cyber defenders conduct an automatic first
review of incoming emails based on system defined and expert defined criteria. Then if
some emails need more attention based on certain criteria, the expert cyber defenders will
follow their methods of looking at the header and other criteria to make a judgment.
These procedures contribute to a high level of confidence in detecting phishing attempts.
The following patterns emerged from the expert cyber defenders’ accounts of the
phishing attempt SA-task: expert cyber defenders demonstrated a high insight into their
judgment process, showed a methodological approach in their judgment process, and held
a high level of confidence in their methods. Although a checklist or procedure is not
being followed, the expert cyber defenders followed a step-by-step process that they
could easily verbalize. These processes represent the use of analytical cognition. On the
other hand, the expert cyber defenders based their decisions on experience (indicative of
intuitive cognition) rather than formal rather than training or education. However, the
majority of the processes used by the expert cyber defenders represented the use of
analytical cognition.
4.2 Information Behaviors and Cognitive Modes Used for the Zero-Day Exploit SATask
4.2.1 Level of Task Complexity of Zero-Day Exploit SA-Task
Zero-day exploits try to reach a broad user base by exploiting software such as
Adobe and Internet Explorer. Expert cyber defenders review the zero-day exploits to see
if they need to alter their network defenses or if they need to install a patch to fill the hole
that was exploited. The expert cyber defenders who discussed the zero-day exploit SA-

123
task (CD 1, 2, 5-9, 12, 14, 17, 19, and 21) commented on how they were provided clear
inputs about the zero-day exploits.
One of the sources we use of course is vendor resources such as Adobe,
Microsoft, Cisco and this would be related to vulnerabilities. We would get an
alert from them. One of the RSS feeds, something online. Either way we get alerts
from them. CD2
Information about the zero-day exploits are contained on the vendors’ websites.
When going to the vendors’ websites the expert cyber defenders expected to see
information that focused on information about the threat, including impacted software or
systems, and recommendations. For example:
There was the recent [Adobe] Flash vulnerability. I received an alert, don’t
remember how….maybe a feed or email but whatever…I went to the Adobe site.
Adobe has this security blog or bulletin that gives info on versions of Flash that
are affected. There are a lot of details on these bulletins. I can check what version
we are running to see what actions I need to take. CD9
The Mozilla security bulletin had a lot of the information I needed to get started
on the response. I go there and then take it from there. CD12
I viewed the Cisco advisory first. These [advisories] have tons of info I can use to
determine how I will change my defenses when needed. Details focus on impacted
products, how to do a work around, and range of the vulnerability. CD21
Although the expert cyber defenders can form an understanding of the initial sate
of the vulnerability, they cannot always predict the outcomes. Each expert cyber defender
has tweaked his or her company’s defense posture over time and may accept a different
level of risk than experts from other companies.
We try to determine if that specific threat, try to see if we have the resources to
mitigate it or if we will just accept the risk. If the probability is really small that it
will affect us we accept it. CD8
With this threat to Adobe, I had to evaluate our response. Given the need to get
information out during the current SBIR cycle[Small Business Innovation
Research proposal cycle], there was no way I could freeze the use of PDFs. I had
to research more information to find out what else I could do. The risk was small

124
with this vulnerability and I took on the risk due to the priorities of our proposal
teams. CD9
This shows that although vendor websites provide a starting point for initially
understanding the vulnerability, the expert cyber defenders still need to evaluate other
aspects of the vulnerability to determine the outcome. Additionally, even though the
expert cyber defenders go to vendor websites and receive the same categories of
information on the sites, there is still a high level of task variety involved.
You can’t predict what you will find on the security bulletins. You kinda know
what information will be provided to you like the software versions affected and
recommendations for how to work around it but you don’t know the level of threat
or the level of confidentiality that’s affected. CD12
Everyone of these are the same in the sense that it a vulnerability was found. But
each one is also different because there are so many factors that make up the
vulnerability. So some have a high level of threat, have a different way that they
can impact your mission, and can either be ignored or need an urgent response.
CD17
For the zero-day exploits, there tended to be a greater sense of urgency in finding
more information about them as compared to finding information about phishing
attempts.
I tend not to waste time. I tend to immediately follow up on the information. One
day can be costly. [I] tend not to wait on it. CD2
Others also expressed a similar sense of urgency based on these exploits.
You need to respond to these within a day. That is the nature of these types of
exploits. That’s why they call it a zero-day exploit because the vendor or someone
just found out about it and now this is the first day that you have to respond to it.
CD5
These require an immediate response because if you don’t respond you have may
a piece of version of software that is used widely throughout your company that
has a high level of risk associated with it. Guys could be using it and passing
confidential information back and forth all while using software that has a hole in
it. CD21

125
The other expert cyber defenders also mentioned about responding to the zero-day
exploits within a day. CD19 summed up the response time for zero-day exploits
succinctly:
Zero-day means the same day, meaning that the vulnerability was found that day.
This is the first day, the zero-day. I need to at least look at the vulnerability that
day if it is connected to what we do. I can take an initial look and decide if I need
to take action. But I have to respond within a day, hence the name “zero-day.”
CD19
The analysis of the expert cyber defenders’ descriptions of the zero-day exploit
SA-task suggest that for this task a priori determinability of inputs exists, (alerts and
information are provided by vendors), the outcomes are generally understood (the need to
respond or not to respond; however they need to determine the level of response), there
exists a range in the task variety, there is a medium level of risk, and there is a low level
of time pressure. These task characteristics suggest a medium level of SA-task
complexity.
4.2.2 Information Sources Used for the Zero-Day Exploit SA-Task
For the zero-day exploit SA-task, the expert cyber defenders primarily used
external sources including vendor sources. Examples of these sources include Adobe
Security Bulletins and Advisories8; Microsoft Security Bulletins9; Cisco Security
Responses, and Notices, Advisories 10; and Firefox Security Advisories11. CD2 states
One of the sources we use of course is vendor resources such as Adobe,
Microsoft, Cisco and this would be related to vulnerabilities. CD2

8

http://helpx.adobe.com/security.html
http://technet.microsoft.com/en-us/security/dn481339
10
https://tools.cisco.com/security/center/publicationListing.x
11
http://www.mozilla.org/security/known-vulnerabilities/firefox.html
9

126
Other CDs reaffirmed that for zero-day vulnerabilities, vendor security bulletins,
notices, and reports were the only sources that needed to be reviewed.
I didn’t really need to go beyond Adobe’s bulletin site. Adobe’s bulletins provide
summaries, software specifications, and actions to take when a vulnerability is
found. You can get everything you need from there and then go off to look at what
you have and to initiate your actions. Sometimes you end up not needing to do
anything. That’s the purpose of these bulletins, is to inform everyone about
whether or not they need to take actions if they have the versions that are affected.
CD9
CD7 confirmed the need to only review the vendor’s sites.
Many companies put out these notices or alerts that recommend you to download
a new version of their software or to download some type of patch. Their sites are
like guides. But I need the alerts to become aware of the exploits. Luckily, you can
pretty much get all you need from the alerts or sites. CD7.
Microsoft security bulletins provide a wealth of information on affected software
that I use in my analysis. CD17
When something was wrong with our search capabilities I went right to Mozilla’s
security site. This site offered the most recent vulnerabilities found in Firefox as
well as Thunderbird, an email system that allows you to encrypt emails and
receive encrypted emails. Obviously, we need to stay on top of these types of
vulnerabilities. CD12
These examples show that vendors’ security bulletin and advisory websites
contain core information that expert cyber defenders used to form an initial understanding
of zero-day exploits. However, several expert cyber defenders stated that these types of
sites were only starting points for finding information. There are also third party sites that
provide information about vulnerabilities.
I used MITRE CVE that provided a short description of the vulnerability and
provided references for further review. The references, as in most cases, took me
to either a blog or a security website like Secunia. CD21
MITRE’s CVE repository let me search across vulnerability sites to find the
details I needed to evaluate the threat on Adobe Flash. CD9

127
I used the Zero-day Initiative website, but I do not end here. Zero-day provided
technical details but pushed me to Oracle’s blogs, which then pushed me to
[MITRE] CVE. From each site I was able to gather the technical details I needed.
CD14
I used the OSVDB, I think stands for Open Sourced Vulnerabilities Database.
Within this report, I can quickly gauge the impact and general solution. CD8
Sites like MITRE CVE12 and Open Sources Vulnerability Database 13 (OSVDB)
provide a list of publicly known security vulnerabilities and were cited by several expert
cyber defenders. Sites like Secunia 14 provide information beyond just one vendor’s
products and reach across vendors such as Google products, Internet Explorer, and
Microsoft.
Secunia offers a one-stop shop, or one of many one-stop shops, that offers
information about different vulnerabilities coming from the big companies. It’s
great to use these to preview what you need to follow up on. CD19
Most of the expert cyber defenders did not reach out to communicate with
external experts. However, CD1 stated how, in one case, he needed to email a
representative from a vendor’s company to inquire more about a zero-day exploit.
I got an alert about this Java vulnerability and noticed that the DNS domain was
protected against so I emailed the VP of DNS and actually got a response from
the president to get further assistance. CD1
Overall, for the zero-day exploit SA-task, the expert cyber defenders heavily used
external sources and rarely communicated with experts. For the most part, expert cyber
defenders initially went to vendor’s websites to review the information provided on
security bulletins, reports, and notices to obtain the information needed to evaluate their
security posture and actions that need to be taken (or not taken). From these vendor sites,
12

http://cve.mitre.org/

13

http://osvdb.org/

14

http://secunia.com/community/advisories/

128
they went to third party sites that collect vulnerability information across vendor sites and
non-vendor sites.
4.2.3 Information Types Used for the Zero-Day Exploit SA-Task
The expert cyber defenders who discussed the zero-day exploit SA-task stated the
importance of gathering technical details from vendors’ security bulletins, notices and
reports as well as from third party vulnerability sites.
Microsoft’s bulletins contain several details as well as summaries of what has
been compromised. Usually generic information is described first and then a list
by list detail of versions infected and list by list detail of what versions are needed
to download or to extract from your system. CD5
We try to find information on techniques that are used. You are looking for more
information on techniques through other sources and other things that they can
help you with. CD2
Expert cyber defenders used the security bulletins and third party sites to
investigate which systems, software, and hardware were affected.
For the security bulletins, I am looking for the list of patches applied to the
vulnerability, the operation systems affected, and any hardware specifications
that I needed to know. CD19
I look for specific software names and versions. I want to see what the overall
threat is and the level of severity. A lot of times the security notices or
descriptions provide response actions. CD9
Expert cyber defenders also sought information about what processes the
vulnerabilities impacted or what processes the vulnerabilities would carry out.
I found in the vulnerability report whether code was executed or not. I found that
the vulnerability provided attackers privileges in performing actions within a
network and even allowing them to elevate their privileges. CD7
Adobe’s security advisory on Adobe Reader provided details on the vulnerability
and listed the versions of reader for both Windows and Macs. The advisory stated
that Reader would crash and then allow the attacker to take control of the
affected system. A solution was provided to install the latest Adobe Reader of 11.0
CD8

129
Other types of information sought about vulnerabilities focused on work-arounds
or tips about what to do while the vulnerability was being patched.
The Computerworld site provided an overview of the threat, in this case an
Internet Explorer bug. It provided info on the versions affected. Details on the
work around were found here. Sites outside of the vendor sites provide tips not
included in the official security bulletins. For instance, in this exploit, one tip was
to simply use another browser like Google Chrome or Firefox until a permanent
fix was found. CD17
Work-around details are great because you can provide a temporary solution to
the problem you found and still allow work process to continue in your company.
Then you can search around for how others fixed the problem or encountered
other problems with the work-around. CD9
Several expert cyber defenders stated the need to find all of the types of
information stated above. CD21 provides a rich summary.
On the CISCO site, I was able to pull several technical bits for my review. First, I
quickly scanned what exact products and versions were vulnerable. Just because
it says it is vulnerable does not mean the system was infected. After the sca, of
products, I viewed the vulnerability level of the overall threat and found that there
was an official fix recommended. From there, I found out how to go about getting
the newest version or protected version of software. But before I finished, I went
back to the vulnerable products list to see the exact details of what was viewed as
vulnerable. There were even measures listed on the bulletin that told me how to
see if I had a specific version of the product that was deemed vulnerable. So as
you can see, lots of details are provided on these bulletins. CD21
For the zero-day exploit SA-task, the expert cyber defenders primarily sought
technical information task-based information including affected products, details on how
to respond to the specific threat, and work-arounds. None of the expert cyber defenders
discussed looking for information on how to respond to zero-day vulnerabilities overall
(domain information) or how to set up cyber defense in response to vulnerabilities
(problem solving information).

130
4.2.4 Counts of Information Sources and Information Types Used for the
Zero-Day Exploit SA-Task
While conducting the directed content analysis for the zero-day exploit SA-task,
the frequencies of information sources and information types were counted from the
interview transcripts. Figure 9 shows the average number of information sources, average
number of external sources, average number of people used as sources, average number
of experts used as sources, and average number of technical pieces of information used
for zero-day exploit SA-task. The original counts are found in Appendix H.

Information Sources and Information Types Used for the
Zero-Day Exploit SA-Task (N = 12)
Average Number of
Information Sources Used

Average Number of External
Sources
Average Number of People
as Sources

Average Number of Experts
Average Number of
Technical Pieces of…
0 1 2 3 4 5 6 7 8 9 101112131415

Figure 9. Information Sources and Information Types Used for the Zero-Day
Exploit SA-Task

4.2.5 Cognitive Modes Used for the Zero-Day Exploit SA-Task
For the zero-day exploit SA-task, the expert cyber defenders tended to use
analytical cognition initially and then intuitive cognition as their research on the zero-day

131
exploits progressed. For forming an initial understanding of zero-day exploits, the expert
cyber defenders tended to describe a step-by-step process.
Initially, you receive an alert from a vendor. Then you know to go to their
website. For example, earlier this year, I got an alert from Cisco. I went to their
site. Their bulletin provided details that could have followed step by step. For
example, I look for software that is impacted, the exact details, any workarounds,
versions of the software, and so on. What I get from the site, I then use to check
against what we are holding. CD5
CD7 and CD21 provided similar steps.
All of these vendors give you information in their varied formats. It is almost like
a checklist that they provide. Each alert from the same company is formatted in
the same way. So every time you go to their alerts page you know what types of
details will be provided or at least the categories of details since every
vulnerability is different. CD7
I pretty much use the same steps to review the Cisco bulletins or other bulletins
for that matter. I check the vulnerable products or systems, see what the
recommended fix is, if there is one, check the level of threat, and get into the
details of the vulnerability. CD21
Although none of the expert cyber defenders used a checklist for capturing
information from vendors’ sites, CSE 5 used the term “step by step” and CD7 used the
term “like a checklist” to describe how they get information from the sites. The step-bystep procedures described by the expert cyber defenders demonstrated a high level of
insight into their judgment process and showed use of a methodological approach. When
asked about using a checklist to pulling information from the vendor sites, CD9
responded:
We don’t use a checklist for these things. The sites [from vendors] provide the
information required to move forward with your response. If we had a checklist it
would probably be filling in what the vendor already has put out there so no
checklist is really needed on our part. I do note in my head if we have certain
versions of software that the vendor is talking about but that’s about all I guess.
CD9

132
Although he followed a methodological approach in the initial process of forming
a situation assessment, he used a more intuitive approach in the later process. In another
example, CD14 states:
Even though I started with MITRE’s CVE, I still wanted more information. The
results from a search on CVE provide official information, but my set up for
defenses and for our systems here cause me to respond in a unique way. From this
initial search, I have a base of information but I need more information from
others who may have a similar set up as mine or have similar work processes
going on that my company does. That’s why I need to see what others individuals
provide on either blogs or their websites about what they did. CD14
CD12 also stated a similar view.
The security advisory might say to patch this or get a new version of this or that
but the security bulletin does not know that I need that version of software to work
with a version of a different type of software from another platform. I won’t go
into too much detail, but for instance we do a lot of numerical simulations under
one software program. This simulation program may only work with one version
of an Adobe product that we use. So the Adobe bulletin may say to install a newer
Adobe version. But if we did that then the numerical software we use may not
speak to that Adobe version. The hope is that there is a newer version of the
simulation software that matches the new Adobe version. I want to see what
others who are facing this same situation say. CD1
CD5 and CD8 also stated that each company’s work processes and defense
posture cause each company to respond differently to zero-day vulnerabilities, which
impacts their information seeking.
I can get a lot of information from the current [security] bulletin on Adobe’s site
but I still need to evaluate my posture based on this information. For example, if
there is an exploit in PDFs, I need to consider things like other processes taking
place. When we have a DoD proposal deadline, everyone working on proposals is
making use of PDFs to submit their proposals. So I need to research the proposal
deadlines to see if I can absorb the risk to PDFs as in the case of proposals being
due the next day or if I can impact work processes for some time to resolve the
issue. CD8
The information guides me on how I will evaluate my defense in depth security
posture. Everyone’s posture or every company’s posture is set up differently. So
one guy [an expert cyber defender from another company] will have to do things
differently from what I do because he probably has a different configuration then

133
I do. So it’s not like the bulletin tells everyone exactly what to do for their
company. You just have to know how the details affect you. CD5
Other CDs provided similar views on the need to find more information about
specific software versions that they run and how others have responded. This shows that
although the expert cyber defenders can gain an initial understanding of a vulnerability
from a vendor’s or third-party’s site, they still have other information needs that are
based on their own company’s defenses. When finding information from others that have
similar defenses, they did not follow a methodological step-by-step process, rather they
followed a more intuitive process.
When I am looking for how others responded, I sense where to go. Over the years,
I developed a sense for which bloggers, even though they may be anonymous,
have similar concerns that I do business-wise. They are not necessarily defense
contractors but they might work on similar types of projects such as natural
language processing of medical records. CD14
When you start going beyond the security bulletins, that’s when it gets a little
more tricky. Many people will post on blogs or forums about the bulletin, only
providing the exact same information or summary of the information from the
bulletins. It takes a while to figure out which blogs or forums to ignore and which
ones are worthwhile reading. It’s hard to explain but it just takes time getting
familiar with the blogs that are out there. And for each type of vulnerability like
an Adobe one or a Microsoft one, there are different experts. CD17
When asked about evaluating the zero-day vulnerabilities, none of the expert
cyber defenders stated that they based their decisions on training or education. Rather it
was based on experience.
You based it on your experience and the assets you have in your company. You
learn how to look at these things over time. CD7
You make a judgment on the risk involved with each exploit. Sometimes you do
need to take action but other times you can absorb the risk. For instance, if it is
an Adobe exploit, you need to determine if you need to shut down the use of PDFs
which could impact the work flow. You have to make a judgment call based on the

134
information gathered about the exploit. That judgment must come from
experience. CD8
No, I was never trained on finding information on vulnerabilities. Of course you
can just Google things and find information but there is more to it. You know how
to evaluate and find information based on your experience in defense and
experience at your own specific company. CD2
In terms of confidence, the expert cyber defenders seemed highly confident they
could get the information needed from vendor’s websites and confident in knowing what
to do when receiving a notice about an exploit.
I’m pretty sure the Adobe’s bulletins have all I need to carry out my responses. I
rarely need to go beyond the bulletin for any other information. The bulletin gives
me my info and I base my responses on that information and what I know about
the [software] versions I am running here. There is nothing tricky about it. CD6
The following pattern of cognitive modes used emerged from the zero-day exploit
SA-task: the expert cyber defenders initially used analytical cognition followed by
intuitive cognition. When forming an initial understanding of zero-day vulnerabilities,
the expert cyber defenders described a step-by-step, methodological process when
reviewing vendors’ and third-party websites. They also showed a high level of
confidence in finding the information they needed from these sites. These two aspects
represent the use of analytical cognition. However, when the experts needed more
information about how to respond to the vulnerabilities based on their companies’
defense postures, they had a difficult time in explaining why they went to specific sites
and how they knew how to evaluate them both of which represented a low insight into
their judgment process. Additionally, the experts based their information seeking on
experience over the years rather than on formal education of training. These two aspects
suggest the use of intuitive cognition. Since both analytical cognition and intuitive

135
cognition tended to be used by the expert cyber defenders, this suggests that the expert
cyber defenders used quasi-rational cognition for the zero-day exploit SA-task.
4.3 Information Behaviors and Cognitive Modes Used for the Malware Attack SATask
4.3.1 Level of Task Complexity of the Malware Attack SA-Task
The expert cyber defenders who discussed the malware attack SA-task (CD 1, 311, 13-18, and 20) discussed several challenges when completing this task. One challenge
with forming an understanding of malware attacks is detecting them in the first place.
CD3 stated:
And basically what we started to see was a hit on our anti-virus and intrusion
detection systems. It was kind of strange in the sense that it was giving off a
rather old signature and was not actually indicative of the threat that the
signature was looking for. So it was a little strange. It showed some antivirus
anomalies as well. It was close to a signature that was a couple of years old. In
that case the first thing you have to do is see if it is a problem with your signature
or is it something actually live. CD3
IDSs use attack signatures to identify malware attacks. As time goes on the
signatures change and the IDS needs to be tweaked to capture current signatures of
attacks. Several expert cyber defenders stated that although their IDS may provide
indications that something is happening, the expert cyber defenders still need to
investigate that an attack is actually taking place. The inputs are not clear about exactly
what is happening. CD4 offered a unique account of analyzing a malware attack while on
a Navy ship.
As a matter of fact we got hit by a malware on a ship I was stationed on. It was
detected by our advanced scanning tools onboard. However, we initially had to
see if it was an actual attack or something different. Sometimes it ends up being
nothing. You have to alter the configurations on the IDS to try to filter out the
noise. CD4

136
CD7 also discussed the challenge of initially detecting a malware incident.
So you wonder if you are missing the event or if the event did not occur. How do
you know if you got the right signature if it is not actually occurring? We kept
correlating things and kept tweaking signatures until we were able to detect
something. CD7
CD17 stated that even though his IDS provides alerts, he feels overwhelmed with
the number of false positives.
The IDS is a great tool, well to some degree but it generates a lot of false
positives. In fact, I spend a lot of time having to go through these to actually find
suspicious activity that is worth investigating. So it does alert you but it also
alerts you too much. CD17
For malware attacks, even though the expert cyber defenders received some type
of notification that something was amiss in their networks, the expert cyber defenders
still had to evaluate the initial cues to see if malware attack was really taking place.
Numerous expert cyber defenders discussed the difficulties with the dynamics and
deceptive nature of malware attacks.
Imagine that you are firefighter and your job is to put out fires and you don't even
know where the fires are. You are in the job of firefighting. You don't know where
to send the trucks. You don't even know what kind of fire so you don't even know
whether to pour water on it or sand or Purple K. Or if you have to put something
different on it. CD3
This shows that not only is it difficult to detect a malware attack but it is difficult
to determine how to respond to it. This also shows the difficulty in determining outcomes
as well as a high level of task variety. CD6 also discussed the uncertainty surrounding
malware attacks.
You have no idea what you will find or when the process will end when trying to
analyze the malware. You don’t know the extent of the impact, you don’t know if
you need to shut down some software or systems in your network. It’s quite
difficult to figure out while conducting your analysis. CD6

137
CD8 stated that malware can change over time making it more difficult to respond
to during the detection and analysis phase.
The malware kept changing. [When going] through [an] iteration of response
cycle, the malware morphed. CD8
Similarly, CD20 stated that malware can be constructed to change when examined
by cyber defenders.
These guys [malware authors] are tricky. They know how you will analyze it and
what steps you will take. They make it so it will change with your response
actions. For this attack, I started the analysis of network activity to see if it was
indeed an attack. But what I thought was there initially then seemed to not be
there upon reanalysis. In another attack, the executables were found to have been
self-deleted making it hard to determine what the attack executed. CD20
CD17 held a similar view.
This malware incident was not created to stay the same. In one case, I thought I
had the analysis down but then it changed on me right during the analysis. That
made it even harder to understand. CD17
The expert cyber defenders stated specific risks and dangers associated with
malware attacks.
The particular piece of malware, could have shut us down pretty hard. It could
have spread to four machines. Malware can worm through the network, it can
shut you down. You can't neutralize it. So a malware could infect maybe 8 or 9 or
30 machines. You need to have a sense of urgency. Malware viruses on the
network can slowdown or shutdown your network. CD4
CD5 expressed a similar perception on the risk of malware attacks.
Malware attacks are some of the most dangerous threats out there. If you don’t
respond immediately, it can completely shut you down. In our industry, you have
to make sure it does not spread through your network. I mean you, depending on
your work, may have to protect sensitive or classified data that you don’t want to
fall into the wrong hands. Malware is dangerous in that regard. You know they
are trying to get into your system to get things out that they should not have. CD5

138
Additionally, the CDs tended to express a great sense of time pressure for forming
situation assessments of malware attacks. For example, CD5 in the above comment
remarked about responding “immediately.” CD3 provided another example.
Imagine that you are in this firefighting mode with all these bongs and whistles
going off and you don't know where to send the firefighters. That is the kind of
analogy for time frames especially when you are dealing with sensitive data,
classified data. CD3
In this case the sense of time pressure has to do with responding in time to prevent
the malware from negatively impacting more systems or the entire network. Other CDs
offered their perceptions of the time pressure in regards to forming situation assessments
of malware attacks.
You have to respond immediately. If I didn’t capture the activity of this malware
right away, our whole network could have been compromised. CD12
With this high security threat, the time pressure absolutely increases. CD2
It is extreme time pressure. CD7
It is a high time pressure. CD8
The patterns that emerged from the expert cyber defenders’ accounts of malware
attack SA-tasks consist of the following: the expert cyber defenders faced challenges in
initially detecting a malware attack (which required further analysis), challenges in
analyzing the outcomes, a high variety in the attacks, high risks posed by the attacks, and
high time pressure. These task characteristics suggest a level of high complexity for the
malware attack SA-task.
4.3.2 Information Sources Used for the Malware Attack SA-Task
The information sources selected by expert cyber defenders for the malware
attack SA-task consisted of multiple sources including internal and external sources as

139
well as experts. Publicly available sources were widely cited by the expert cyber
defenders:
There are security experts out there that work for companies or organizations and
they collaborate in an open source forum whether that is Malware.org or
"Security Threats" or a vast number of other blogs or other post sites that are
security in focus. Sometimes you can talk about the malware or event without
saying your organization has been attacked. Many times what you are seeing, you
will see in the open source format first. People are operating honeypots, they are
capturing the malware before anybody before a targeted event. CD3
Sometimes open source has the information or related information you need to
analyze the malware. Or at the least it gives you an idea of how to get started with
the analysis. CD1
In addition to using publicly available forums or open source sites, expert cyber
defenders also mentioned the use of company or expert blogs.
It is essential to keep up with security focused blogs. They often provide the most
up to date information about current malware attacks, provide an in depth
analysis of the malware as well as information on potential impacts on specific
systems. CD5
Several expert cyber defenders mentioned the use of open source repositories.
One source I used was VirusTotal. You can capture a file name in your analysis
and slide it over to VirusTotal to identify if there has been an analysis on the file
or if that file has indeed been infected. You can also search by URL. Using
something like VirusTotal definitely helps with your analysis. I think it is run by
Google or sponsored by Google. That’s why the searches are so fast. CD15
Other expert cyber defenders described the use of sources like VirusTotal.
The great thing about VirusTotal and other sites like ThreatExpert is that it
provides extreme technical details about specific threats. All you have to do is
submit a file and it analyzes it for you. They also have a search engine to see what
was analyzed before if you have the right details. It’s updated throughout the day
so you can get the details on the most current threats. CD18
Other cyber experts mentioned government sponsored sources including National
Vulnerability Database (NVD) 15. The NVD contains information about current and

15

nvd.nist.gov/

140
previous vulnerabilities and give information on access complexity, confidentiality
impact, and integrity impact. The U.S. Computer Emergency Readiness Team 16 (CERT)
also was mentioned as a source by several expert cyber defenders.
The use of social media was only mentioned by two expert cyber defenders (CD2
and CD16). The use of news media sites was cited by CD4, CD6, and CD20. In two
extremely challenging malware attacks discussed by the expert cyber defenders, inperson meetings with fellow experts were essential for forming situation assessments of
malware attacks. In CD1’s case, the malware attack infected his company and another
company that one of his employees was working with for on a DoD contract. The
response to the malware required numerous discussions over an extended time period.
For this attack, we had regular phone conversations over the span of four months.
It took us that long and that many conversations to deal with this. Normally, DoD
companies don’t work on security things together or collaborate but in this case
we needed to for us to resolve this threat. CD1
CD4 also discussed the need to work with external experts based on a challenging
threat that he faced.
The research was done my by guys and a NWS shop, we also had cyber security
from Cyber Defense Ops Command [onboard the ship]. They were the SMEs
[subject matter experts]. They were coordinating over phone, email, chat with
folks from Norfolk, Virginia. A lot of manhours involved. It was two people on our
end and two to three on their end. They were working day and night. CD4
In this case, CD4 (in reference to a malware attack while onboard a Navy ship)
stated that external experts were already visiting, working on another task when they
became aware of an active malware attack. Even with the experts onboard the ship, it
took a considerable amount of time to resolve the threat. This case also represented CD4
working with other internal expert cyber defenders as well as experts outside of his
16

http://www.us-cert.gov/

141
immediate organization. CD3 also mentioned that he was paired with another expert
cyber defender internal to his organization to conduct research about the malware
incident.
In our case there was a team of a few of us that were there to do incident response
handling and tuning the sensor network. I was pulled aside to go research this
specific malware. CD3
All of the CDs discussed the need to work with others external to their
organizations to combat the malware attacks. Some mentioned the need to check what
other experts had written about the threats. However, CD4 was the only one to state that
he never consulted open source sources.
The Navy had a good repository network of incident data. The response guys can
go back and do the research through that. I guess we use open source indirectly.
That stuff might get into our SIPRNET [a Navy secure network]. It is a more
formal cyber security repository. It [research] mostly happens on the SIPRNET.
CD4
The expert cyber defenders who formed situation assessments of malware attacks
also used numerous internal sources of information.
Of course the first thing I use to see if there is an attack is our IDS. The IDS looks
for a signature of an attack. Sometimes I have to go into the signature database to
alter things to make sure I can find existing attack signatures. CD13
Several expert cyber defenders stated the important of scanning network activity.
I view the log analyzer to view the network activity within our network. I filtered
the activity based on IP addresses and protocols. My goal is to find which activity
on the network set off the IDS alert that actually caused me to investigate this
more. I often have to do this for the false alerts too. By using the log analyzer I
can filter out the false positives. CD14
The data and information provided by the log analysis allow me to narrow down
to what alerts I really need to look at and which alerts I can ignore. CD17
I need to monitor tools such as file and registry access, network communications,
process activities. CD18

142

In general, when completing the malware attack SA-task, the expert cyber
defenders tended to use more external information sources and external experts.
Additionally, the expert cyber defenders corresponded via email, phone, and chat with
fellow experts. The experts also used internal sources such as logs and network activity
parameters to complete the malware attack SA-task.
4.3.3 Information Types Used for the Malware Attack SA-Task
Expert cyber defenders who discussed the malware attack SA-task stated that they
primarily searched for technical pieces of information. CD3 stated:
I have a file name or I have a file name and a hash, I have maybe what I saw on
DCamm, or some little granular thing and amazingly the more and more people
use it the more you will find. Of course you have to find the closest to what you
are looking for. What you are looking for is code, the technical code. You don’t
have time to look at all of the malware code yourself. You hope someone else has
done the research and provided the codes. CD3
CD7 provided a similar view on the type of information he was seeking.
The best thing you are trying to find is if when someone is attacked they provide
the technical information in a public forum. The more technical details provided
the better the rest of us can protect ourselves. CD7
CD9 also stated the importance of finding specific details about the malware
attack.
Since there is so much code to analyze in the malware, you look online to see if
you can find more specifics about the malware rather than trying to go line by
line yourself. You could be there forever if you had to do that. You try to find what
files are infected and then use those in your search. CD9
Expert cyber defenders used specific technical details about an attack to search
online for more information.
I used the MDF fingerprint to search for information about it on the internet.
There are resources out there like VirusTotal that allow you to search for MD5

143
fingerprints. With tools like these you can use SHA1 and SHA256 hashes too.
CD20
I went to a vulnerabilities database to find what the actual threat was posed by
the malware. In this case, I found that this instance of malware sends passwords
in clear text allowing the intruder to find the administrator password. If he was
able to use the admin log on we would have been in deep trouble. CD15
The expert cyber defenders also sought more technical, descriptive information
about the malware attacks.
For a malware analysis, I also want to see more information about a suspect file
such as the time stamp of its creation and when it was last modified along with its
code entry point. I also look for source and target IP addresses. CD13
The expert cyber defenders also looked at changes in network activity that may
indicate an attack is taking place.
What I use the most are log files and metadata to detect suspicious activity on the
network. I am looking at the raw data. CD17
One thing checked was to see if there was an increase in traffic that is normally
should not be there. I found an increase in traffic from our server inside our
network. That immediately set off alarms to me. CD13
One key piece of information I look for is ports. I will do port scans, look if ports
are open that are usually not open. I will also look for an unusual amount of
network traffic. CD20
In addition to monitoring network activity, the experts also viewed other types of
activity.
I also want to see processes of virtual and physical memory usage. CD17
I checked the modifications of registry entries and files systems. CD14
I went to see if were are any callouts being made by the malware and I found that
there were processes there that tried to resolve DNS addresses. CD10
I searched my system memory track the imported calls that were redirected to
other functions. CD11

144
The pattern found in the responses from experts who discussed the malware SAtask shows that the experts heavily sought task-based technical information. The experts
used specifics found within codes or file names to search online for information, searched
for abnormal network traffic or other types of traffic, and looked for suspicious processes
carried out by programs for files. None of the experts discussed seeking domain (how to
go about responding to malware attacks) or problem solving information (how to set up
cyber defense).
4.3.4 Counts of Information Source and Information Types Used for the
Malware Attack SA-Task
The frequencies of information sources and information types used for the
malware attack SA-task were counted from the interview transcripts. Figure 10 shows the
average number of information sources, average number of external sources, average
number of people used as sources, average number of experts used as sources, and
average number of technical pieces of information used for the malware attack SA-task.
The original counts are found in Appendix I.

Information Sources and Information Types Used for the
Malware Attack SA-Task (N = 17)

Average Number of External …

Average Number of People as …
Average Number of Experts
Average Number of Technical …
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

145

Figure 10. Information Sources and Information Types Used for the Malware
Attack SA-Task

4.3.5 Cognitive Modes Used for the Malware Attack SA-Task
When completing the malware attack SA-task, expert cyber defenders tended not
to use a methodological approach or step-by-step procedures. Numerous expert cyber
defenders stated that their seeking of information sources was based on their “sense” and
that this “sense” developed over time.
You get a sense when the sites are providing the same value as the used to. Over
time you develop a sense for what type of thing you are looking at or
classification of the thing you are looking at so you can make your searches more
efficient. CD3
When you have been in this [cyber defense] for so long you kind of know where to
go, who to talk to, and how to find what you need. You have to be it for a while to
get the feel of it. CD20
You need to be involved with the search process for some time to really
understand how some sources of information change over time. I mean you have
to get a sense for when the value of a source changes because you don’t always
know who is doing the writing behind the source. But if you read the source on a
regular basis you can tell when the author changes. When that happens, the value
of the source changes. Unless you have used that source before you won’t know
how to sense that change. CD16
These above participant comments demonstrate how no rules or methods are
followed when forming situation assessments of malware attacks. Rather, the expert
cyber defenders sense what information is needed and sense the value, as well as changes
in the value of information sources. The expert cyber defenders tended to have a difficult
time answering how they knew when to stop their search process. None of the expert

146
cyber defenders could clearly describe the steps that were taken to reach the stopping
decision.
I just reach a judgment when to stop. You look online and try to find out the
details about the malware itself. At some point, I just reach the conclusion that I
have enough for what I need to start analyzing the malware. I can’t describe it.
Each threat is different so you look for different things and then you just go from
there. CD6
CD8 also stated that the stopping process was more of a judgment than a process
to stop.
This varies by threat; however I try to make the best judgment call on the
information received. CD8
CD15 expressed difficulty in describing stopping decision when asked about how
he knew when to stop searching.
Wow, that is a hard one to answer. I don’t know how to describe it. I just know
when to stop. It’s more of my own decision rather than someone or something
telling me when to stop. I just go with my gut feeling on this. CD15
In response to interview questions about the use of checklist to form a situation
assessment of malware attacks, the consensus was that no checklists were used.
No, no checklist is used. You kinda develop a checklist in your head over time.
CD3
For the Navy, in the strike groups, we don’t have standard means to do computer
forensics. CD4
No, no checklist is used. You go out (online) and find what you need each time.
CD13
There is no checklist that we use for researching about malware. After doing this
for so long, you find what you are looking for based on your own experience.
CD10

147
CD3 was asked to describe his mental checklist but he said it was too hard to
explain. When asked about how he knew to reach out to peers for malware attacks, CD5
responded:
It’s just experience over time. You quickly learn that peers are a great source of
information. Pairing up is just learned over time. I was never trained on it. It
comes from experience and learning from others. CD5
Other expert cyber defenders held similar views:
We [cyber defenders] were never taught that reaching out to peers would be
essential for malware analysis. Basically we were trained to do it ourselves,
independently of other companies or other professionals. Without my peers I
could forever be in malware analysis. CD10
Several expert cyber defenders stated that the basis of their decisions for
researching malware attacks came from experience rather than formal training or
education. CD1 talked about how he was planning to retire soon and was then asked how
someone new in his position would take over his role in combating malware attacks.
I built our security from the ground up for defending [against] these type of
threats. I was the third employee of this company. I learned from things in the
past, things that hurt. In the beginning, during many, many times the CEO was
breathing down my neck. The email system went down and things were on me to
fix. I learned from the school of hard knocks. If someone new were to come in
here even with some type of M.S. degree it would take him three to four years to
figure all of this, to protect against advanced threats. I would want to spend at
least a year, maybe two years, with him side by side with him so he could try to
pick all of this up. CD1
CD1’s perceptions on how a new person should be trained provide evidence that
his approach for combating malware attacks is based on his experience and not formal
training or education. CD1’s desire for a one or two year shadowing shows that
education alone could not prepare someone new to his role. CD11 also commented the
turnovers between cyber defenders are too short.

148
When we do a turnover with a new guy we only get one day or two at most. That
is way too short for new guys to gain the knowledge the needs for these advanced
attacks. Ideally, we would need months of turnover so he could at least get an
initial grasp of how to do this. He has to be embedded in our environment for a
while, like I said months, to get a feel for how we analyze these advanced threats.
CD11
Some of the research participants were asked about how a decision aid could
assist in their situation assessment process for malware attacks. The consensus was that
no aid could help them.
I don’t think anything could help me. I think an automated system would find a lot
of information but I think it would also miss out on a lot of information that I
really want to see. That’s why I want to be intricately involved in the research
process. I want to be able to make the decision to say “yeah” or “nay” to
information as well as to the sources. CD16
So many people will probably say they are so used to doing it my way, that
nothing could help them. CD3
No nothing could help me. CD4
The expert cyber defenders expressed a lack of confidence in the methods they
use to respond to malware attacks. A common theme in expert cyber defenders responses
centered on their perception of their own lack of expertise.
It takes more effort and more resources than we had on our ship to deal with that
[a malware attack]. I just don’t have the expertise to deal with all of these
malware attacks. That’s why I need to reach out to the experts. Without their help,
I could not do this. CD4
Your hope is that someone else has paid that price of time and resources first.
Obviously others in a lab environment are better suited or in an academic
environment. CD3
It can be really difficult to deal with these malware attacks. It is really hard to
come up with a solid answer on them. They write this malware to get by you.
CD7
I could never find the answer all by myself. I don’t have the skills and time for all
of these malware analyses. That’s why I go online right way to find out if others

149
have done the analysis already. The malware can be so difficult to deal with and
is sometimes beyond my skill set. CD20
The patterns that emerged from the expert cyber defenders who discussed the
malware attack consist of the following: the expert cyber defenders showed a low level of
insight into their judgment process, lacked methods to use including formal rules, based
decisions on experience rather than education or training, and expressed a low confidence
in their methods. All of these characteristics suggest that the expert cyber defenders were
using intuitive cognition for the malware attack SA-task.
4.4 Comparison of Overall Patterns of Information Behaviors and Cognitive Modes
Used for Different SA-Task Types
Patterns of information behavior and cognitive modes used for each SA-task type
were compared across all the SA-task types (phishing attempt, zero-day exploit, and
malware attack SA-tasks) via a display of the data. Figures 11-13 provide a visual
comparison across case the SA-task types based on the averages of number of
information sources used, number of external sources used, number of people used as
sources, number of experts used as sources, and number of technical pieces of
information used.

150

Information Sources and Information Types Used for the Phishing
Attempt SA-Task (N = 9)
Average Number of Information Sources Used
Average Number of External Sources
Average Number of People as Sources
Average Number of Experts as Sources
Average Number of Technical Pieces of
Information

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

Figure 11. Information Sources and Information Types Used for the Phishing Attempt
SA-Task
Information Sources and Information Types Used for the Zero-Day
SA-Task (N = 12)
Average Number of Information Sources Used
Average Number of External Sources
Average Number of People as Sources
Average Number of Experts as Sources

Average Number of Technical Pieces of
Information

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

Figure 12. Information Sources and Information Types Used for the Zero-Day SA-Task
Information Sources and Information Types Used for the Malware
Attack SA-Task (N = 17)
Average Number of Information Sources Used
Average Number of External Sources
Average Number of People as Sources
Average Number of Experts as Sources
Average Number of Technical Pieces of
Information

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

Figure 13. Information Sources and Information Types Used for the Malware Attack SATask

151

Figures 11-13 displayed above suggest the following overall pattern exists - as
SA-task complexity increased, the following increased:
Average number of information sources used
Average number of external sources used
Average number of people used as sources used
Average number of experts used
Average number of technical pieces of information used
The suggested findings from the directed content analysis conducted for cognitive
modes are displayed in Table 17 suggests that as SA-task complexity increased from the
phishing attempt to the zero-day exploit to the malware attack SA-task, the use of
intuitive cognition increased while the use of analytical cognition decreased.

Table 17
SA-Tasks and Cognitive Modes
Phishing Attempt
SA-Task
Low Task Complexity

Zero-Day Exploit
SA-Task
Medium Task Complexity

Malware Attack SA-Task

Analytical Cognition

Quasi-rational Cognition

Intuitive Cognition

High Task Complexity

Overall, the directed content analysis suggests that increased SA-task complexity
influences the information behaviors and cognitive modes used by expert cyber
defenders. The statistical analysis conducted in the next section examines if there is a

152
significant difference between the information behaviors for the different levels of SAtask complexity.
4.5 Statistical Analysis of Information Behaviors
The subsections of this section describe the statistical analysis conducted on the
following based on descriptions provided by expert cyber defenders for the phishing
attempt, zero-day exploit, and malware attack SA-tasks:
Number information sources used (Section 4.5.1)
Number of external information sources used (Section 4.5.2)
Number of people used as sources (Section 4.5.3)
Number of experts used as sources (Section 4.5.4)
Number of technical pieces of information used (Section 4.5.5)
4.5.1 Statistical Analysis for Number of Information Sources Used
The original counts for the Number of Information Sources Used will be used as
an example of how original counts were transformed into categorical data tables. The
categorical data tables were used to conduct the Freeman-Halton extension (Freeman &
Halton, 1951) of Fisher’s Exact test in order test for significant differences between
categorical variables. The procedure described below was used for all categorical
variables (Number of Information Sources Used, Number of External Sources Used,
Number of People Used as Sources, Number of Experts Used as Sources as Sources, and
Number of Technical Pieces of Information Used).
The original counts for the Number of Information Sources Used for the phishing
attempt SA-task were:
1 2 2 1 1 1 1 1 1

153
The original counts for Number of Information Sources Used for the zero-day
exploit SA-task were:
3 4 5 3 4 3 3 2 5 4 3 3

The original counts for the Number of Information Sources Used for the malware
attack SA-task were:
10 7 7 8 8 12 13 9 10 9 7 7 12 9 8 8 9

The above original counts for the Number of Information Sources Used for the
phishing attempt, zero-day exploit, and malware attack SA-tasks were combined and
sorted smallest to largest:
1

1

1

1

1

1

1

2

2

2

3

3

3

3

3

3

4

4

4

5

5

7

7

7

7

8

8

8

8

9

9

9

9

10

10

12

12

13

The data were placed into Excel and the PERCENTILE function was used to
compute the percentiles desired (33rd and 66th percentiles) in order to form three
categories of Low, Medium, and High for the original counts. The 33rd percentile was
found to be value of 2 and the 66th percentile was found to be a value of 4. Therefore,
original counts for Number of Information Sources Used were categorized as following:
Low number of information sources used: less than 3
Medium number of information sources used: 3-4 information sources
High number of information sources used: greater than 4 information sources
With the Low, Medium, and High categories defined, the researcher went back to
the original counts of the Number of Information Sources Used to transform these
original counts into category counts for Low, Medium, and High. Tables 18-20 show the
original counts for Number of Information Sources Used, the category that each original

154
count fell into, and sum of the category counts for each type of SA-task. In the tables,
cases are labeled as case numbers for each type of cyber attack in terms of the order they
appeared in the interviews. L, M, and H represent categories of Low, High, and Medium.

155
Table 18. Number of Information Sources Used for the Phishing Attempt SA-Task
Phishing –
Number of
Information
Sources
Used
Original
Count

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

1

2

2

1

2

1

1

1

1

Category

L

L

L

L

L

L

L

L

L

Total
11
9L
0M
0H

Table 89. Number of Information Sources Used for the Zero-Day Exploit Task
Zero-Day Number of
Information
Sources
Used
Original
Count

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Case
10

Case
11

Case
12

3

4

5

3

4

3

3

2

5

4

3

3

Category

M

M

H

M

M

M

M

L

H

M

M

M

42
1L
9M
2H

Total

Table 20. Number of Information Sources Used for the Malware Attack SA-Task
Malware Number of
Information
Sources
Used
Original
Count

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Case
10

Case
11

Case
12

Case
13

Case
14

Case
15

Case
16

Case
17

10

7

7

8

8

12

13

9

10

9

7

7

12

9

8

8

9

Category

H

H

H

H

H

H

H

H

H

H

H

H

H

H

H

H

H

Total
153
0L
0M
17 H

156
The total counts that fell into the Low, Medium, and High categories for the three types
SA-tasks were then placed in a 3 × 3 contingency table as shown in Table 21. Contingency tables
show the combinations of values of different categorical variables (Ruxton & Neuhäuser, 2010).

Table 21
Contingency Table (3 x 3) for Number of Information Sources Used and SA-Task Complexity
Low SA-Task
Complexity
(Phishing
Attempts)

Medium SA-Task
Complexity
(Zero-Day
Exploits)

High SA-Task
Complexity
(Malware
Attacks)

Low

9

1

0

Medium
High

0
0

9
2

1
17

Number of Information
Sources Used

The Freeman-Halton extension of Fisher’s exact test (Freeman & Halton, 1951) was used
to determine the significant probability between relationships in the Number of Information
Sources Used and SA-task complexity. An open-source statistical computational tool from
Vassar College (Lowry, 2013) was used to conduct the calculations for the Freeman-Halton
extension of Fisher’s exact test. The results of the test indicated p <0.05 (2.2e-13). Since the pvalue is less that 0.05, we reject the null hypothesis and can state that there is a significant
relationship between the Number of Information Sources Used and SA-task complexity.
4.5.2 Statistical Analysis for Number of External Sources Used
The original counts of the Number of External Sources Used for the phishing attempt,
zero-day exploit, and malware attack SA-tasks were placed into Excel to determine the
categories of Low, Medium and High. The PERCENTILE function (using 33rd and 66th
percentiles) informed the definitions of the categories as following:

157
Low Number of External Sources Used: less than 3
Medium Number of External Sources Used: 3-4
High Number of External Sources Used: greater 4
With these categories defined, the researcher relabeled the original counts of the Number
of External Sources Used as Low, Medium or High. Tables 22-24 show the original counts for
Number of External Sources Used, the category that each original count fell into, and sum of the
category counts for each type of SA-task.

158
Table 9. Number of External Sources Used for the Phishing Attempt SA-Task
Phishing –
Number of
External
Sources

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Count

0

0

1

0

0

0

0

0

0

Category

L

L

L

L

L

L

L

L

L

Total
1
9L
0M
0H

Table 23. Number of External Sources Used for the Zero-Day Exploit Task
Zero-day Number of
External
Sources
Used

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Case
10

Case
11

Case
12

Count

3

4

5

3

4

3

3

2

5

4

3

3

Category

M

M

H

M

M

M

M

L

H

M

M

M

42
1L
9M
2H

Total

Table 10. Number of External Sources Used for the Malware Attack SA-Task
Malware Number of
External
Sources

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Case
10

Case
11

Case
12

Case
13

Case
14

Case
15

Case
16

Case
17

Count

8

4

5

5

6

9

5

6

7

5

6

5

8

6

9

5

4

Category

H

M

H

H

H

H

H

H

H

H

H

H

H

H

H

H

M

Total
103
0L
2M
15 H

159
The total counts that fell into the Low, Medium, and High categories for the three SAtasks were then placed in a 3 × 3 table as shown in 25.

Table 25
Contingency Table (3 x 3) for Number External Sources Used and SA-Tank Complexity
Low SA-Task
Complexity
(Phishing
Attempts)

Medium SA-Task
Complexity
(Zero-Day
Exploits)

High SA-Task
Complexity
(Malware
Attacks)

Low

9

1

0

Medium
High

0
0

9
2

2
15

Number of External
Sources

The Freeman-Halton extension of Fisher’s exact test (Freeman & Halton, 1951) was used
to determine the significant probability between relationships in Number of External Sources
Used and SA-task complexity. The results of the test indicated that p < 0.05 (6.4e-11). Since
the p-value is less that 0.05, we reject the null hypothesis and can state that there is a significant
relationship between the Number of External Sources Used and SA-task complexity.
4.5.3 Statistical Analysis for Number of People Used as Sources
The original counts of the Number of People Used as Sources for the phishing attempt,
zero-day exploit, and malware attack SA-tasks were placed into Excel to determine the
categories of Low, Medium and High. The PERCENTILE function (using 33rd and 66th
percentiles) informed the definitions of the categories as following:
Low Number of People Used as Sources: less than 1
Medium Number of People Used as Sources: 1-2
High Number of People Used as Sources: greater than 2

160
With these categories defined, the researcher relabeled the original counts of the Number
of People Used as Sources as sources as Low, Medium or High. Tables 26-28 show the original
counts for Number of People Used as Sources, the category that each original count fell into, and
sum of the category counts for each type of SA-task.

161
Table 11. Number of People Used as Sources for the Phishing Attempt SA-Task
Phishing –
Number of
People Used
as Sources

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Count

0

1

1

0

0

0

0

0

0

Category

L

M

M

L

L

L

L

L

L

Total
2
7L
2M
0H

Table 12. Number of People Used as Sources for teh Zero-Day Exploit SA-Task
Zero-day Number of
People Used
as Sources

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Case
10

Case
11

Case
12

Count

0

1

1

1

0

1

1

1

0

1

0

1

Category

L

M

M

M

L

M

M

M

L

M

L

M

8
4L
8M
0H

Total

Table 13. Number of People Used as Sources for the Malware Attack SA-Task
Malware Number of
People Used
as Sources

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Case
10

Case
11

Case
12

Case
13

Case
14

Case
15

Case
16

Case
17

Count

4

3

4

4

4

4

2

3

4

3

4

3

3

4

3

3

4

Category

H

H

H

H

H

H

M

H

H

H

H

H

H

H

H

H

H

Total
59
0L
1M
16 H

162
The total counts that fell into the Low, Medium, and High categories for the three SAtasks were then placed in a 3 × 3 table as shown in Table 29.

Table 29.
Contingency Table (3 x 3) for Number of People Used as Sources and SA-Task Complexity
Low SA-Task
Complexity
(Phishing Attempts)

Medium SA-Task
Complexity
(Zero-Day Exploits)

High SA-Task
Complexity
(Malware Attacks)

Low
Medium

7
2

4
8

0
1

High

0

0

16

Number of External
Sources

The Freeman-Halton extension of Fisher’s exact test (Freeman & Halton, 1951) was used
to determine the significant probability between relationships in the Number of People Used as
Sources and SA-task complexity. The results of the test indicated that p <0.05 (2.9e-10). Since
the p-value is less that 0.05, we reject the null hypothesis and can state that there is a significant
relationship between the Number of People Used as Sources and SA-task complexity.
4.5.4 Statistical Analysis for Number of Experts Used as Sources as Sources
The original counts of the Number of Experts Used as Sources for the phishing attempt,
zero-day exploit, and malware attack SA-tasks were placed into Excel to determine the
categories of Low, Medium and High. The PERCENTILE function (using 33rd and 66th
percentiles) informed the definitions of the categories as following:
Low Number of Experts Used as Sources: less than 1
Medium Number of Experts Used as Sources: 1-2
High Number of Experts Used as Sources: greater than 2.

163
With these categories defined, the researcher relabeled the original counts of the Number
of Experts Used as Sources as Low, Medium or High. Tables 30-32 show the original counts for
Number of Experts Used as Sources, the category that each original count fell into, and sum of
the category counts for each type of SA-task.

164
Table 30. Number of Experts Used as Sources for the Phishing Attempt SA Task
Phishing –
Number of
Experts
Used as
Sources

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Count

0

0

0

0

0

0

0

0

0

Category

L

L

L

L

L

L

L

L

L

Total
1
9L
0M
0H

Table 31. Number of Experts Used as Sources for the Zero-Day Exploit Task
Zero-day Number of
Experts
Used as
Sources

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Case
10

Case
11

Case
12

Count

0

1

1

1

0

1

1

1

0

1

0

1

Category

L

M

M

M

L

M

M

M

L

M

L

M

8
4L
8M
0H

Total

Table 14. Number of Experts Used as Sources for the Malware Attack SA-Task
Malware Number of
Experts

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Case
10

Case
11

Case
12

Case
13

Case
14

Case
15

Case
16

Case
17

Count

4

3

4

4

4

4

2

3

4

3

4

3

3

4

3

3

4

Category

H

H

H

H

H

H

M

H

H

H

H

H

H

H

H

H

H

Total
59
0L
1M
16 H

165

The total counts that fell into the Low, Medium, and High categories for the three SAtasks were then placed in a 3 × 3 table as shown in Table 33.

Table 33.
Contingency Table (3 x 3) for NUmberof Experts Used as Sources and SA-Task Complexity
Low SA-Task
Complexity
(Phishing
Attempts)

Medium SA-Task
Complexity
(Zero-Day
Exploits)

High SA-Task
Complexity
(Malware
Attacks)

Low

9

4

0

Medium
High

0
0

8
0

1
16

Number of Experts Used
as Sources as Sources

The Freeman-Halton extension of Fisher’s exact test (Freeman & Halton, 1951) was used
to determine the significant probability between relationships in Number of Experts Used as
Sources and the SA-task complexity. The results of the test indicated that p <0.05 (3.1e-11).
Since the p-value is less that 0.05, we reject the null hypothesis and can state that there is a
significant relationship between the Number of Experts Used as Sources and SA-task
complexity.
4.5.5 Statistical Analysis for Number of Technical Pieces of Information Used
The original counts of the Number of Technical Pieces of Information Used for the
phishing attempt, zero-day exploit, and malware attack SA-tasks were placed into Excel to
determine the categories of Low, Medium and High. The PERCENTILE function (using 33rd
and 66th percentiles) informed the definitions of the categories as following:
Low Number Technical Pieces of Information Used: less than 6
Medium Number Technical Pieces of Information Used: 6-10

166
High Number Technical Pieces of Information Used: greater than 10
With these categories defined, the researcher relabeled the original counts of Number
Technical Pieces of Information Used as Low, Medium or High. Tables 34-36 show the original
counts for Number Technical Pieces of Information Used, the category that each original count
fell into, and sum of the category counts for each type of SA-task.

167
Table 15. Number of Technical Pieces of Information Used for the Phishing Attempt SA-Task
Phishing –
Number of
Technical
Pieces of
Information

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Count

3

4

2

3

3

2

3

3

3

Category

L

L

L

L

L

L

L

L

L

Total
26
9L
0M
0H

Table 35. Number of Technical Pieces of Information used for the Zero-Day Exploit Task
Zero-day Number of
Technical
Pieces of
Information
Used

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Case
10

Case
11

Case
12

Count

7

6

5

6

8

9

7

7

6

6

5

4

Category

M

M

L

M

M

M

M

L

H

M

L

L

Total
76
4L
7M
1H

168
Table 16. Number of Technical Pieces of Information Used for the Malware Attack SA-Task
Malware Number of
Technical
Pieces of
Information

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Case
10

Case
11

Case
12

Case
13

Case
14

Case
15

Case
16

Case
17

Count

14

12

11

12

13

15

16

14

14

19

8

12

12

11

14

9

9

Category

H

H

H

H

H

H

H

H

H

H

M

H

H

H

H

M

M

Total
215
0L
3M
14 H

169
The total counts that fell into the Low, Medium, and High categories for each type of SAtask were then placed in a 3 × 3 table as shown in Table 37.

Table 37.
Contingency Table (3 x 3) for Number of Technical Pieces of Information Used and SA-Task
Complexity
Low SA-Task
Complexity
(Phishing
Attempts)

Medium SA-Task
Complexity
(Zero-Day
Exploits)

High SA-Task
Complexity
(Malware
Attacks)

Low

9

4

0

Medium
High

0
0

7
1

3
14

Number of Technical
Pieces of Information
Used

The Freeman-Halton extension of Fisher’s exact test (Freeman & Halton, 1951) was used
to determine the significant probability between relationships in Number of Technical Pieces of
Information Used and SA-task complexity. The results of the test indicated that p <0.05 (2.50E09). Since the p-value is less that 0.05, we reject the null hypothesis and can state that there is a
significant relationship between the Number of Technical Pieces of Information Used and SAtask complexity.
4.5.6 Summary of Statistical Analyses for Information Behaviors
For each variable (Number of Information Sources Used, Number of External Sources
Used, Number of People Used as Sources, Number of Experts Used as Sources as Sources, and
Number of Technical Pieces of Information Used), the original counts were transformed into
categories of Low, Medium and High. The category counts were then placed into 3 × 3
contingency tables to conduct the Freeman-Halton extension of Fisher’s exact test to test the
significant probability for relationships between the categorical variables and SA-task

170
complexity. The decision to accept or reject the null hypothesis was based on the following (Gall
et al., 2007):
If the p-value is greater than 0.05, we accept the null hypothesis that there is no
significant relationship between categorical variables
If p-value is less than or equal to 0.05, we reject the null hypothesis in that there is a
significant relationship between categorical variables.
The results of the tests are summarized in Table 38.

Table 38
Summary of Fisher-Freeman-Halton Exact Test Probabilities
Information Behavior Variable
Number of Information
Sources Used
Number of External Sources
Used
Number of Peoples Used as
Sources
Number of External Experts
Used as Sources
Number of Technical Pieces
of Information Used

p < 0.05

Significant Relationship Exists
between Information-Behavior
Variable and SA-Task
Complexity? (Y/N)
Yes

p < 0.05

Yes

p < 0.05

Yes

p < 0.05

Yes

p < 0.05

Yes

Freeman-Halton extension of
Fisher’s exact test (p value)

As Table 38 shows, a significant relationship was found between the information
behavior variables under study and SA-task complexity.

171
CHAPTER 5: DISCUSSION
5.1 Summary of the Findings
The purpose of this dissertation research was to test the theoretical propositions of LIS
task-complexity research and the CCT in the context of cyber situation assessment. A multiplecases study design was selected as the research design for this dissertation research. CDM
served as the basis of semi-structured interviews conducted with 21 expert cyber defenders from
small defense companies. In response to interview questions, the expert cyber defenders
provided their accounts of how they formed situation assessments of phishing attempts, zero-day
exploits, and malware attacks resulting in a total of 38 attacks (cases) being discussed.
Based on a directed content analysis approach, coding categories for this dissertation
research were derived from LIS task-complexity research and NDM research including the RPD
Model and the CCT. The dissertation researcher tested for intercoder reliability on the coding
categories resulting in acceptable levels for all categories (Cohen Kapp coefficients > 0.80).
The analysis showed that forming situation assessments of phishing attempts represented a SAtask with low task complexity, forming situation assessments of zero-day exploits represented
medium SA-task complexity, and forming situation assessments of malware attacks represented
high SA-task complexity. The frequencies of number of information sources, number of external
sources number of people used as sources, number of experts, and number of technical pieces of
information were tracked and then used for statistical analysis. A summary and discussion of the
results are provided below.

172
5.1.1Task Complexity and Information Behaviors
Based on directed content analysis and statistical analysis using the Freeman-Halton
extension of the Fisher exact test, the findings of this dissertation research suggest the following
in regards to information behaviors:
For expert cyber defenders, as SA-task complexity increased:
Finding 1. The number of information sources used increased
Finding 2. The number of external sources used increased
Finding 3. The number of people use as sources increased
Finding 4. The number of experts used as sources increased
Finding 5. The use of task-based technical information increased
Findings 1-4 support theoretical propositions posed in previous LIS task-complexity
research. More specifically, Findings 1-4 align with findings from several empirical studies on
task complexity and information studies (Byström & Järvelin, 1995; Byström, 2002; Culnan,
1983; Daft & Macintosh, 1981; Pinelli et al., 1993; Tiamiyu, 1992; Zeffane & Gul, 1993)
This is significant because it shows how several theoretical propositions of LIS research
on task complexity and information seeking (derived from non-NDM contexts) hold in a NDM
context with high stakes, high time pressure, and high uncertainty.
Finding 5 represents a difference from previous theoretical propositions posed in
previous LIS task-complexity research. Previous LIS task-complexity research, posited that as
task complexity increases the use of domain and problem solving information increases
(Byström & Järvelin, 1995; Byström, 2002; Culnan, 1983). However, this dissertation research
suggests in the cyber defense context, a NDM context, as task complexity increased the use of
task-based technical information increased and not the use of domain and problem solving

173
information. In fact, none of the expert cyber defenders discussed the use of any domain and
problem solving information. The difference in context of the professionals under study in this
dissertation research and the contexts examined in previous LIS task-complexity research may
explain this difference. For example, in previous LIS task-complexity research, the studies
focuses on experts in non-NDM contexts such as municipal administrators (Byström, 2002), civil
servants (Byström, 2002), and professionals conducting environment scanning in large
corporations (Culnan, 1983).
The LIS task-complexity contexts mark a difference from contexts focused on in NDM
studies such as Navy ship and submarine warfare. Previous NDM situation assessment studies
showed that experts, when faced with tasks of high complexity, sought technical information
(Kirschenbaum, 1992; Pliske et al., 2004) and only sought information on the task at hand rather
than domain or problem solving information (Kaempf et al., 1996; R. Lipshitz & Shaul, 1997;
Serfaty et al., 1997) . As an example, Kirschenbaum (2001) found that expert submarine
decision maker sought data focused on the changing direction, speed, and/or depth of unknown
contacts rather than how to go about detecting contacts. Also, NDM situation assessment
research suggests that experts in NDM contexts are focused at the threat at hand as in the case of
enemy submarines or air threats rather than trying to learn how to complete the task (Kaempf et
al., 1996). Perhaps during downtime, when the experts are not facing a situation with high stakes,
high time pressure, and high uncertainty, the experts would seek more domain and problem
solving information as in the case of training purposes.
5.1.2 Task Complexity and Cognitive Modes Used
The dissertation findings on cognitive modes suggest the following:
For expert cyber defenders, as SA-task complexity increased.

174
Finding 6. The use of intuitive cognition increased
This finding on cognitive modes used supports theoretical propositions from NDM
research (the RPD and the CCT). Both the RPD and CCT posited that as task complexity
increases the use of intuitive cognition increases (Hammond et al., 1997; Klein, 1993). In this
dissertation research, for the tasks with low complexity (forming a situation assessment of
phishing attempts), the expert cyber defenders used more analytical cognition. When faced with
tasks of high complexity (forming a situation assessment of malware attacks), the experts used
more intuitive cognition. Additionally, for with a medium level of complexity (forming a
situation assessment of zero-day exploits), the expert cyber defenders use quasi-rational
cognition, a mix of intuitive and analytical cognition. The connection of low task complexity
with analytical cognition, middle task complexity with quasi-rational cognition, and high task
complexity with intuitive cognition all support previous findings of other CCT studies (Dowding
et al., 2009; Dunwoody et al., 2000; Hammond et al., 1997). This suggests that theoretical
propositions from CCT hold in the domain of forming cyber situation assessments.
Also, Finding 5 relates to previous situation assessment research that stated experts use
schemas, that are based on experience, for information seeking in NDM contexts. Previous
NDM situation assessment research stated that experts develop schemas based on years of
experience (R. Lipshitz & Shaul, 1997; David F. Noble et al., 1986) indicating that schemas are
not formal checklists or procedures followed by experts. This dissertation research provides
initial empirical evidence to support these NDM situation assessment conceptualizations.

175

5.1.3 Limitations of the Dissertation Research
One of the limitations of the study included the lack of generalizability of the results. The
only professionals interviewed for this dissertation research consisted of expert cyber defenders
who work for small defense companies. Caution must be placed on generalizing the results to
other types of small companies as each company holds its own context, which will influence
behaviors.
Another limitation of the dissertation research consists of relying solely on the research
participants’ accounts of their actions when forming situation assessments. Due to the
confidentiality of cyber defense, the research participants may have not shared all of the steps
that they took when forming situation assessments. Therefore, the dissertation researcher cannot
claim that the findings represent the absolute truth of how the expert cyber defenders formed
situation assessments of various cyber attacks.
Finally, although the dissertation researcher’s familiarity with NDM situation assessment
contexts (such as Navy ship warfare) helped form an understanding of the expert cyber
defenders’ information behaviors and cognitive modes used, the dissertations researcher’s
familiarity may have also introduced bias into the study.

5.2 Significance of the Dissertation Research

The findings of this dissertation research lead to three unexpected concepts:
When using intuition, the expert cyber defenders sought a lot of information rather than
just relying on their “gut feelings.”

176
Rather than following a step-by-step, linear process to form a situation assessment in a
high stakes domain with severe consequences, the expert cyber defenders followed a nonlinear process.
In a domain considered to be highly confidential, the expert cyber defenders relied
heavily on informal collaboration and the use of unofficial sources of information.
Each of these is described in more detail.
Typically when one thinks of experts using intuition to complete a task one may think that
the experts only rely on their “gut feeling” and their expertise without the need for seeking any
additional information. However, this dissertation research shows that when the experts relied
heavily on intuition they also sought a lot of information. The reason that the expert cyber
defenders seek a lot of information when using their intuition may be due to the complexity of
the cyber attacks. Each cyber attack is unique and contains an abundance of cues that need to be
evaluated by the expert cyber defenders to determine if an attack is taking place. Given that each
attack is unique as well as highly deceptive, the expert cyber defenders cannot recognize an
attack as completely similar to a previous attack. Therefore, the expert cyber defenders use their
intuition to determine areas to investigate in a network and seek information to see if their
intuition is correct.

In a high stakes domain in which cyber attacks occur on a regular basis, it was expected that
the expert cyber defenders would follow step-by-step methods in forming situation assessments
However, the dissertation findings suggest that the expert cyber defenders followed a non-linear
approach. As stated above, each cyber attack is unique and contains an abundance of cues to
evaluate. Therefore, it may not be feasible to follow a step-by-step approach when forming

177
situation assessments of complex cyber attacks. This is significant for training because it shows
that training that promotes step-by-step procedures for detecting and analyzing cyber attacks may
not be suitable for the real-world environment of cyber defense. The findings suggest that cyber
professionals should be trained on recognizing patterns in cues and on how to form situation
assessments across a variety of situations.
Another unexpected concept derived from the findings consists of the observation that
although the expert cyber defenders work in a highly confidential domain with barriers to
information sharing, the expert cyber defenders relied heavily on informal collaboration and
unofficial information sources authored by peers. The dissertation findings suggest that expert
cyber defenders consider collaboration and peer-authored sources to be critical for forming
situation assessments of cyber attacks. The collaborative relationships are built up over time
based how expert cyber defenders evaluate the author of a source as well as the information
provided by the source. Additionally, the expert cyber defenders have to evaluate whether or not
to trust an information source as well as the creator of the source since cyber attackers often
create deceptive information sources. More research is needed to examine how cyber defenders
evaluate the credibility of sources and the authors of the sources.
Overall, these findings will lead to more research in the relationship of increased information
seeking and the use of intuition, how to elicit and use tacit knowledge of information seeking,
and examining the trust and evaluative nature of information seeking in domains with high
stakes, high time pressure and high uncertainty.

178
5.3 Implications
5.3.1 Implications for LIS Research
The findings of this dissertation research contribute to the demonstrating the application
of LIS research to other fields as in the case of NDM situation assessment research. NDM
situation assessment research showed the importance of information seeking in contexts with
high stakes, high time pressure, and high uncertainty. However, there lacked a solid foundation
for examining the information behaviors and a lack of consistency in methods used. As shown in
this dissertation research, LIS professional information seeking models can be applied to
professional contexts outside of education and academia. Furthermore, this dissertation research
shows that information seeking is a key componenUt of cyber defense and may present an
opportunity for an LIS education focus. For example, none of the expert cyber defenders said
that they were trained on finding and evaluating information sources. Additionally, several of the
cyber defenders said that novices have a hard time keep track of the information sources that
they used for research new cyber attacks. This presents an opportunity for LIS educators to
explore the role of LIS in professional settings as in case of intelligence analysis. For example,
the types of skills that LIS educators teacher including identifying, retrieving and evaluating
information are all important in intelligence analysis.
5.3.2 Implications for Cyber Defense Training
The findings of this dissertation research suggest that expert cyber defenders used
intuitive cognition when forming situation assessments of complex cyber attacks. NDM research
has shown that forming a situation assessment is critical for decision making in NDM contexts.
Cohen et al. (1994) stated that it is important to understand the process of performing a situation

179
assessment so it can be taught and performed well. However, none of the expert cyber defenders
stated any formal training or education that they received for forming situation assessments.
Current cyber security training methods that focus on instructor-led classroom training do
not address the realistic challenges faced by cyber defenders. These current training systems
focus on rational decision making or deliberate, step-by-step decision making. However, cyber
defense falls into the area NDM that focuses on intuitive decision making when facing the realworld challenges similar to ones faced by cyber defenders. A virtual cyber security training
system that is based on the NDM approach can better train cyber defenders.
An approach that can support the virtual training of novices in forming situation
assessments consists of the Event-Based Approach to Training (EBAT) (Oser et al., 1999).
EBAT focuses on scenario-based training in simulated environments. The EBAT approach has
been used to develop training programs in other NDM contexts including the Combat
Information Centers (CICs) on Navy ships, air coordination training, and multi-service
distributed teams. This approach suggests that training novices, such as novice cyber defenders,
should not consist only of lecture based training. Rather scenario based training that provides
realistic content and naturalistic conditions (high time pressure, high stakes, and high
uncertainty) should be used to develop situation assessment skills.
Additionally, training on situation assessment skills should also focus on collaboration.
All of the expert cyber defenders stated the importance of collaborating with or reviewing the
information provided by others especially when facing complex attacks. However, they all stated
that this was something that was not taught to them and something they did not practice in their
formal training. Rather training consisted of them responding to attacks with no opportunity for
communication with others.

180
5.3.3 Implications for System Design
The results from this dissertation research can also provide suggestions to information
system designers who design tools for cyber defenders. When forming situation assessments of
complex attacks, the expert cyber defenders stated the need to search online and to communicate
with external experts. Many expert cyber defenders stated they used online forums, blogs, instant
messaging, chat, and telephone calls. However, none of the expert cyber defenders stated that
they used a secure, collaborative information sharing space to work with and communicate with
fellow experts. A secure, collaborative information sharing space may support the information
seeking of cyber defenders. Examples of features that could be used included in a collaborative
sharing system include collaborative tagging of information sources, automatic evaluation of
information sources, methods for sharing different levels of confidential information, and storage
of information sources used for documentation and for later research.
Additionally, a system that allows expert cyber defenders to share confidential
information in a secure way (such as stripping a company’s identifying information) would be
beneficial to expert cyber defenders.
5.4 Suggestions for Future Research
This dissertation research provided an in depth understanding of the information
behaviors and cognitive modes used by expert cyber defenders when forming situation
assessments of different cyber attacks. However, future research is needed to confirm the
findings. For example, this dissertation research focused solely on retrospective interview
techniques; additional data collection techniques such as survey, laboratory studies with
simulations or observational studies would also confirm the findings.

181
To increase the transferability of the findings, further research is needed to examine the
information behaviors and cognitive modes used by expert cyber defenders in small businesses
outside of the DoD domain. Additional research is needed to examine the information behaviors
and cognitive modes used by expert cyber defenders in larger organizations. This would allow
the examination of team processes in information seeking and cognition.
Additional research is needed to examine the information seeking and cognitive
processes used by novice cyber defenders when forming situation assessments of the same type
of attacks examined in this dissertation research. By using the focusing on the same types of
attacks and using the same research design in this dissertation research, we could examine
whether there are differences that have been found in previous NDM situation assessment studies
that compared the information seeking of novices and experts (Kirschenbaum, 1992; R. Lipshitz
& Shaul, 1997; Serfaty et al., 1997; Waag & Bell, 1997).
One thing that is not certain in this dissertation research is whether or not the expert cyber
defenders successfully defended against the cyber attacks discussed. Although the research
participants have an average of 11 years of experience, cyber attacks are complex and are created
to bypass IDS as well as the skills of cyber defenders. Therefore, even though intuitive cognition
was used to combat the complex attacks, it does not mean that it was the correct way. For
example, in another CCT study, Offredy, Kendall, and Goodman (2008) showed that when nurse
medication prescribers lack expertise in facing a certain task, they switched from using
analytical cognition to using intuitive cognition. Many of the expert cyber defenders felt like
they could not handle all of the cyber attacks as well as the complexity of cyber attacks. More
research is needed to evaluate responses of expert cyber defenders to complex cyber attacks.

182
Additionally, this dissertation research only investigated the work practices of expert
cyber defenders at the task level. However, more research is needed to focus on more dimensions
of the expert cyber defenders’ work domain. Cognitive Work Analysis (CWA) provides a
framework for examining the work domain, the actors in the domain, and the interactions
between these two. Under the CWA perspective, human-information interaction is guided by
goals which can be explicit or implicit, personal or organizational, stable or situational. (Fidel et
al., 2004). Additionally, CWA focuses on the work actors do, their information behaviors, the
context in which they work, and the reasons for their actions as well as the complex interactions
between all of these aspects (Fidel & Pejtersen, 2004). Therefore CWA provides a more robust
framework for examining the work of cyber defenders than the CDM which only focused on the
task level.
Overall, cyber defense is a domain full of high stakes, high uncertainty, and high time
pressure. This dissertation researched showed that for the most complex attacks, intuitive
decision making and high information processing are used by expert cyber defenders to defend
our nations’ critical national security assets against cyber attacks. More training, tools, and
understanding of the actual practices used by expert cyber defenders can better protect our nation
against cyber attacks.

183

List of References

Agada, J. (1999). Inner-city gatekeepers: An exploratory survey of their information use
environment. Journal of the American Society for Information Science, 50(1), 74–85.
Allen, D. (2011). Information behavior and decision making in time-constrained practice: A
dual-processing perspective. Journal of the American Society for Information Science
and Technology, 62(11), 2165–2181.
Baker, L. M. (2004). The information needs of female police officers involved in undercover
prostitution work. Information Research, 10(1).
Barford, P., Dacier, M., Dietterich, T. G., Fredrikson, M., Giffin, J., Jajodia, S., … Ning, P.
(2010). Cyber SA: Situational awareness for cyber defense. In S. Jajodia (Ed.), Cyber
Situational Awareness (pp. 3–13). Springer.
Beach, L. R., & Lipshitz, R. (1993). Why classical decision theory is an inappropriate standard
for evaluating and aiding most human decision making. In G. Klein, J. Orasanu, R.
Calderwood, & C. Zsambok (Eds.), Decision making in action: Models and methods (pp.
21–35). Norwood, NJ: Ablex.
Belkin, N. J., Chang, S., Downs, T., Saracevic, T., & Zhao, S. (1990). Taking account of user
tasks, goals and behavior for the design of online public access catalogs. In Proceedings
of the 53rd ASIS&T Annual Meeting (pp. 69–79).
Benbasat, I., Goldstein, D. K., & Mead, M. (1987). The case research strategy in studies of
information systems. MIS Quarterly, 11(3), 369–386.
Ben-bassat Moshe, & Freedy, E. (1982). Knowledge requirements and management in expert
decision support systems for (military) situation assessment. Systems, Man and
Cybernetics, IEEE Transactions on, 12(4), 479–490.
Benner, P. E. (2001). From novice to expert: Excellence and power in clinical nursing practice.
Menlo-Park, California: Addison-Wesley Publishing.
Berryman, J. M. (2008). Influences on the judgement of enough information: An analysis using
the information use environment as a framework. Information Research, 13(4).
Bertram, S. M., Rook, V. L., Fitzsimmons, J. M., & Fitzsimmons, L. P. (2011). Fine‐and
broad‐scale approaches to understanding the evolution of aggression in crickets.
Ethology, 117(12), 1067–1080.

184
Bjørk, I. T., & Hamilton, G. (2011). Clinical decision making of nurses working in hospital
settings. Nursing Research and Practice, 2011.
Brezovic, C. P., Klein, G., & Thordsen, M. (1990). Decision making in armored platoon
command (ARI Technical Report No. KA-TR-858(B)). Alexandria, VA: U.S. Army
Research Institute for the Behavioral and Social Sciences.
Brunswik, E. (1943). Organismic achievement and environmental probability. Psychological
Review, 50(3), 255–272.
Brunswik, E. (1952). The conceptual framework of psychology. Chicago, IL: University of
Chicago Press.
Byström, K. (1999). Task complexity, information types and information sources: Examination
of relationships. (Unpublished Doctoral Dissertation). University of Tampere, Tampere.
Byström, K. (2002). Information and information sources in tasks of varying complexity.
Journal of the American Society for Information Science and Technology, 53(7), 581–
591.
Byström, K., & Järvelin, K. (1995). Task complexity affects information seeking and use.
Information Processing & Management, 31(2), 191–213.
Campbell, D. J. (1988). Task complexity: A review and analysis. The Academy of Management
Review, 13(1), 40–52.
Cannon-Bowers, J. A., Pruitt, J. S., & Salas, E. (1996). Establishing the boundaries of a
paradigm for decision-making research. Human Factors, 38(2), 193.
Cavaye, A. L. M. (1996). Case study research: A multi-faceted research approach for IS.
Information Systems Journal, 6(3), 227–242.
Cichonski, P., Millar, T., Grance, T., & Scarfone, K. (2012). Computer security incident
handling guide (Special Publication No. 800-61). National Institute of Standards and
Technology.
Clapper, J. R. 2013 World Threat Assessment (2013). HVC-210. U.S. Capitol. Washington DC.
Retrieved from
http://www.dni.gov/files/documents/Intelligence%20Reports/HPSCI%20WWTA%20Re
marks%20as%20delivered%2011%20April%202013.pdf
Cohen, M. S., Adelman, L., Tolcott, M. A., Bresnick, T. A., & Freeman, M. F. (1994). A
cognitive framework for battlefield commanders’ situation assessment (No. TR 93-1).
U.S. Army Research Institute for the Behavioral and Social Sciences.

185
Colquitt, J. A., & Zapata-Phelan, C. P. (2007). Trends in theory building and theory testing: A
five-decade study of the “Academy of Management Journal.” Academy of Management
Journal, 50(6), 1281–1303.
Conover, W. J., & Conover, W. J. (1980). Practical nonparametric statistics. New York, NY:
John Wiley & Sons.
Cooksey, R. W. (1996a). Judgment analysis: Theory, methods, and applications. San Diego, CA:
Academic Press.
Cooksey, R. W. (1996b). The methodology of Social Judgement Theory. Thinking & Reasoning,
2(2/3), 141–174.
Crandall, B., & Calderwood, R. (1989). Clinical assessment skills of experienced neonatal
intensive care nurses: national center for nursing research. National Institutes of Health.
Crandall, B., & Getchell-Reiter, K. (1993). Critical decision method: A technique for eliciting
concrete assessment indicators from the intuition of NICU nurses. Advances in Nursing
Science, 16(1), 42–51.
Crandall, B., Hoffman, R. R., & Shadbolt, N. (1998). Use of the critical decision method to elicit
expert knowledge: A case study in the methodology of cognitive task analysis. Human
Factors, 40.
Creswell, J. W. (2009). Research design: Qualitative, quantitative, and mixed methods
approaches. Thousand Oaks, CA: Sage Publications, Inc.
Culnan, M. J. (1983). Environmental scanning: The effects of task complexity and source
accessibility on information gathering behavior. Decision Sciences, 14(2), 194–206.
D’Amico, A., Buchanan, L., Goodall, J., & Walczak, P. (2009). Mission impact ofcyber events:
Scenarios and ontology to express the relationships between cyber assets, missions, and
users (No. 0704-0188). U.S. Air Force Research Lab.
D’Amico, A., & Whitley, K. (2008). The real work of computer network defense analysts. In J.
Goodall, G. Conti, & K.-L. Ma (Eds.), VizSEC 2007 (pp. 19–37). Springer Berlin
Heidelberg.
D’Amico, A., Whitley, K., Tesone, D., O’Brien, B., & Roth, E. (2005). Achieving cyber defense
situational awareness: A cognitive task analysis of information assurance analysts (Vol.
49, pp. 229–233). Presented at the Human Factors and Ergonomics Society 49th Annual
Meeting.
Daft, R. L., & Macintosh, N. B. (1981). A tentative exploration into the amount and equivocality
of information processing in organizational work units. Administrative Science Quarterly,
26, 207–224.

186
Daniels, M., & Yakel, E. (2010). Seek and you may find: Successful search in online finding aid
systems. American Archivist, 73(2), 535–568.
Darke, P., Shanks, G., & Broadbent, M. (1998). Successfully completing case study research:
Combining rigour, relevance and pragmatism. Information Systems Journal, 8(4), 273–
289.
Demps, E. L., Lincoln, Y. S., & Cifuentes, L. (2011). Conflicts over the utilities of teaching
using educational technologies: An interpretive critical inquiry. Advances in Developing
Human Resources, 13(2), 135–170.
Dervin, B. (1983). Information as a user construct: The relevance of perceived information needs
to synthesis and interpretation. Knowledge Structure and Use: Implications for Synthesis
and Interpretation, 155–183.
Detlor, B. (2000). The corporate portal as information infrastructure: Towards a framework for
portal design. International Journal of Information Management, 20, 91–101.
Doherty, M. E., & Kurz, E. M. (1996). Social Judgement Theory. Thinking & Reasoning, 2(2/3),
109–140.
Dowding, D., Spilsbury, K., Thompson, C., Brownlow, R., & Pattenden, J. (2009). The decision
making of heart failure specialist nurses in clinical practice. Journal of Clinical Nursing,
18(9), 1313–1324.
Dunwoody, P. T., Haarbauer, E., Mahan, R. P., Marino, C., & Tang, C. (2000). Cognitive
adaptation and its consequences: A test of Cognitive Continuum Theory. Journal of
Behavioral Decision Making, 13(1), 35–54.
Durrance, J. C., Souden, M., Walker, D., & Fisher, K. E. (2006). Community problem-solving
framed as a distributed information use environment: Bridging research and practice.
Information Research, 11(4), 11–4.
Eisenhardt, K. M. (1989). Building theories from case study research. The Academy of
Management Review, 14(4), 532–550.
Elliott, T. (2005). Expert decision-making in naturalistic environments: a summary of research.
Australia Defence Science and Technology Organization.
Endsley, M. R. (1995). Toward a theory of situation awareness in dynamic systems. Human
Factors: The Journal of the Human Factors and Ergonomics Society, 37(1), 32–64.
Endsley, M. R. (2000). Theoretical underpinnings of situation awareness: A critical review. In
M. R. Endsley & D. J. Garland (Eds.), Situation awareness analysis and measurement
(pp. 3–32). Mahwah, NJ: Lawrence Erlbaum Associates.

187
Erbacher, R. F., Frincke, D. A., Wong, P. C., Moody, S., & Fink, G. (2010). Cognitive task
analysis of network analysts and managers for network situational awareness. Presented
at the Visualization and Data Analysis.
Fidel, R. (1984). The case study method: A case study. Library and Information Science
Research, 6(3), 273–288.
Fidel, R., & Pejtersen, A. M. (2004). From information behaviour research to the design of
information systems: the Cognitive Work Analysis framework, Information Research
(Vol. 10).
Fidel, R., Pejtersen, A. M., Cleal, B., & Bruce, H. (2004). A multidimensional approach to the
study of human-information interaction: A case study of collaborative information
retrieval. Journal of the American Society for Information Science and Technology,
55(11), 939-953.
Fisher, K. E., Erdelez, S., & McKechnie, L. (2005). Theories of information behavior. Medford,
NJ: Information Today, Inc.
Flanagan, J. C. (1954). The critical incident technique. Psychological Bulletin, 51(4), 327–358.
Flin, R., Slaven, G., & Stewart, K. (1996). Emergency decision making the offshore oil and gas
industry. Human Factors, 38, 262–268.
Forsythe, J. C., Silva, A., Stevens-Adams, S., & Bradshaw, J. (2012). Human dimensions in
cyber operations research and development priorities (No. SAND 2012-9188). Sandia
National Laboratories.
Freeman, G. H., & Halton, J. H. (1951). Note on an exact treatment of contingency, goodness of
fit and other problems of significance. Biometrika, 141–149.
Gall, M. D., Borg, W. R., & Gall, J. P. (2007). Educational Research: An Introduction. Boston,
MA: Pearson Education.
Goldstein, W. M., & Hogarth, R. M. (1997). Judgment and decision research: Some historical
context. In W. M. Goldstein & R. M. Hogarth (Eds.), Research on judgment and decision
making: Currents, connections, and controversies (pp. 3–65).
Goodall, J. R., Lutters, W. G., & Komlodi, A. (2009). Supporting intrusion detection work
practice. Journal of Information System Security, 5(2), 43–74.
Gorodetsky, V., Karsaev, O., & Samoilov, V. (2005). On-line update of situation assessment: A
generic approach. International Journal of Knowledge-Based and Intelligent Engineering
Systems, 9(4), 351–365.

188
Graneheim, U. ., & Lundman, B. (2004). Qualitative content analysis in nursing research:
concepts, procedures and measures to achieve trustworthiness. Nurse Education Today,
24(2), 105–112.
Greyson, D. L., Cunningham, C., & Morgan, S. (2012). Information behaviour of Canadian
pharmaceutical policy makers. Health Information & Libraries Journal, 29(1), 16–27.
Hamm, R. M. (1988a). Codebook for categorization of highway formula protocols. Boulder, CO:
Colorado University at Boulder Institute of Cognitive Science.
Hamm, R. M. (1988b). Moment-by-moment variation in experts’ analytic and intuitive cognitive
activity. IEEE Transactions on Systems, Man and Cybernetics, 18(5), 757–776.
Hammond, K. R. (1980). The integration of research in judgment and decision theory. Boulder,
CO: Center for Research on Judgment and Policy.
Hammond, K. R. (1988). Judgement and decision making in dynamic tasks. Boulder, CO:
University of Colorado.
Hammond, K. R. (1996). Human judgment and social policy: Irreducible uncertainty, inevitable
error, unavoidable injustice. New York: Oxford University Press.
Hammond, K. R., Frederick, E., Robillard, N., & Victor, D. (1989). Application of cognitive
theory to the student–teacher dialogue. In D. A. Evans & V. L. Patel (Eds.), Cognitive
science in medicine: Biomedical modeling (pp. 174–210). Cambridge, MA: MIT Press.
Hammond, K. R., Hamm, R. M., Grassia, J., & Pearson, T. (1997). Direct comparison of the
efficacy of intuitive and analytical cognition in expert judgment. In W. M. Goldstein &
R. M. Hogarth (Eds.), Research on judgment and decision making: Currents,
connections, and controversies (pp. 144–180).
Hammond, K. R., & Stewart, T. R. (1975). Social Judgment Theory. In M. F. Kaplan & S.
Schwartz (Eds.), Human judgment and decision processes (pp. 271–312).
Harvey, N. (2001). Studying judgement: General issues. Thinking and Reasoning, 7(1), 103–118.
Hayes, A. F., & Krippendorff, K. (2007). Answering the call for a standard reliability measure
for coding data. Communication Methods and Measures, 1(1), 77–89.
Hersberger, J. A., Murray, A. L., & Sokoloff, S. M. (2006). The information use environment of
abused and neglected children. Information Research, 12(1).
Heverin, T., & Zach, L. (2010a). Microblogging for crisis communication: Examination of
Twitter use in response to a 2009 violent crisis in the Seattle-Tacoma, Washington area.
In 7th International Information Systems for Crisis Response and Management
(ISCRAM) Conference. Seattle, WA, USA.

189
Heverin, T., & Zach, L. (2010b). Twitter for city police department information sharing. In
Proceedings of the 73rd ASIS&T Annual Meeting.
Heverin, T., & Zach, L. (2011). City police department adoption and use of Twitter as a crisis
communication tool. In Crisis Information Management: Communication and
Technologies (pp. 25–42). Oxford, UK: Woodhead Publishing Limited.
Holsopple, J., Sudit, M., Nusinov, M., Liu, D. F., Haitao Du, & Yang, S. J. (2010). Enhancing
situation awareness via automated situation assessment. Communications Magazine,
IEEE, 48(3), 146–152.
Howell, D. C. (2011). Chi-Square test: Analysis of contingency tables. In International
Encyclopedia of Statistical Science (pp. 250–252). Springer.
Hsieh, H., & Shannon, S. E. (2005). Three approaches to qualitative content analysis. Qualitative
Health Research, 15(9), 1277–1288.
Johannesen, J., Keyghobadi, N., Schuler, H., Stauffer, C., & Vogt, H. (2013). Invasion genetics
of American cherry fruit fly in Europe and signals of hybridization with the European
cherry fruit fly. Entomologia Experimentalis et Applicata, 147(1), 61–72.
Johnston, J. H., Driskell, J. E., & Salas, E. (1997). Vigilant and hypervigilant decision making.
Journal of Applied Psychology, 82(4), 614–622.
Joshua Klayman. (2001). Ambivalence in (not about) naturalistic decision making. Journal of
Behavioral Decision Making, 14(5), 372–373.
Kaempf, G. L., Klein, G., Thorsden, M. L., & Wolf, S. (1996). Decision making in complex
naval command-and-control environments. Human Factors, 38, 206–219.
Kaempf, G. L., Wolf, S., & Miller, T. E. (1993). Decision making in the AEGIS combat
information center. Proceedings of the Human Factors and Ergonomics Society Annual
Meeting, 37(16), 1107–1111.
Kahneman, D., & Klein, G. (2009). Conditions for intuitive expertise: A failure to disagree.
American Psychologist, 64(6), 515–526.
Kang, M. H., & Mayfield, T. (2003). A cyber-event correlation framework and metrics. In
AeroSense 2003 (pp. 72–82). International Society for Optics and Photonics.
Kirillov, V. P. (1994). Constructive stochastic temporal reasoning in situation assessment.
Systems, Man and Cybernetics, IEEE Transactions on, 24(8), 1099–1113.
Kirschenbaum, S. S. (1992). Influence of experience on information-gathering strategies.
Journal of Applied Psychology, 77(3), 343–352.

190
Kirschenbaum, S. S. (2001). Analyzing submarine decision making: A question of levels.
Linking Expertise and Naturalistic Decision Making, 189–207.
Klein, G. (1993). A recognition-primed decision (RPD) model of rapid decision making. In G.
Klein, J. Orasanu, R. Calderwood, & C. Zsambok (Eds.), Decision making in action:
Models and methods (pp. 138–147). Norwood, NJ: Ablex Publishing Corporation.
Klein, G. (2008). Naturalistic Decision Making. Human Factors: The Journal of the Human
Factors and Ergonomics Society, 50(3), 456–460.
Klein, G., & Calderwood, R. (1991). Decision models: some lessons from the field. Systems,
Man and Cybernetics, IEEE Transactions on, 21(5), 1018–1026.
Klein, G., Calderwood, R., & Clinton-Cirocco, A. (1986). Rapid decision making on the fire
ground. In Proceedings of the Human Factors and Ergonomics Society annual meeting
(Vol. 30, pp. 576–580). SAGE Publications.
Klein, G., Calderwood, R., & Clinton-Cirocco, A. (2010). Rapid decision making on the fire
ground: The original study plus a postscript. Journal of Cognitive Engineering and
Decision Making, 4(3), 186 –209.
Klein, G., Calderwood, R., & MacGregor, D. (1989). Critical decision method for eliciting
knowledge. Systems, Man and Cybernetics, IEEE Transactions on, 19(3), 462–472.
Klein, G., & Crandall, B. (1996). Recognition-primed decision strategies (96-36). U.S. Army
Research Institute for the Behavioral and Social Sciences.
Knott, B. A., Mancuso, V. F., Bennett, K., Finomore, V., McNeese, M., McKneely, J. A., &
Beecher, M. (2013). Human factors in cyber warfare alternative perspectives. In
Proceedings of the Human Factors and Ergonomics Society Annual Meeting (Vol. 57,
pp. 399–403). SAGE Publications.
Kobus, D. A., Proctor, S., & Holste, S. (2001). Effects of experience and uncertainty during
dynamic decision making. International Journal of Industrial Ergonomics, 28(5), 275–
290.
Krippendorff, K. (2004). Content analysis: An introduction to its methodology. Thousand Oaks,
CA: Sage Publications, Inc.
Landry, C. F. (2006). Work roles, tasks, and the information behavior of dentists. Journal of the
American Society for Information Science and Technology, 57(14), 1896–1908.
Leckie, G. J., Pettigrew, C., & Sylvain, C. (1996). Modeling the information seeking of
professionals: A general model derived from research on engineers, health care
professionals, and lawyers. Library Quarterly, 66(2), 161–193.

191
Lievrouw, L. A. (2001). New media and the `pluralization of life-worlds’: A role for information
in social differentiation. New Media & Society, 3(1), 7–28.
Lincoln, Y. S., & Guba, E. G. (1985). Naturalistic inquiry. Newbury Park, CA: Sage
Publications, Inc.
Lipshitz, R. (1993). Converging themes in the study of decision making in realistic settings. In
G. Klein, J. Orasanu, R. Calderwood, & C. Zsambok (Eds.), Decision making in action:
Models and methods (pp. 103–137). Westport, CT: Ablex Publishing Corporation.
Lipshitz, R., Klein, G., Orasanu, J., & Salas, E. (2001). Taking stock of naturalistic decision
making. Journal of Behavioral Decision Making, 14(5), 331–352.
Lipshitz, R., & Shaul, O. B. (1997). Schemata and mental models in recognition-primed decision
making. In Naturalistic decision making expertise: Research and applications (pp. 293–
303). Hillsdale, NJ: Erlbaum.
Lipshitz, R., & Strauss, O. (1997). Coping with uncertainty: A naturalistic decision-making
analysis. Organizational Behavior and Human Decision Processes, 69(2), 149–163.
Liu, P., & Li, Z. (2012). Task complexity: A review and conceptualization framework.
International Journal of Industrial Ergonomics, 42(6), 553–568.
Lombard, M., Snyder-Duch, J., & Bracken, C. C. (2004). Practical resources for assessing and
reporting intercoder reliability in content analysis research projects. Retrieved May 1,
2014, from http://www.temple.edu/mmc/reliability
Lowry, R. (2013). VassarStats: Statistical Computation Web Site. Retrieved March 3, 2014, from
http://vassarstats.net/
Luo, M. (2008). Structural equation modeling for high school principals’ data-driven decision
making: An analysis of information use environments. Educational Administration
Quarterly, 44(5), 603–634.
MacMullin, S. E., & Taylor, R. S. (1984). Problem dimensions and information traits. The
Information Society, 3(1).
Mahan, R. P. (1994). Stress-induced strategy shifts toward intuitive cognition: A cognitive
continuum framework approach. Human Performance, 7(2), 85–118.
Maurel, D., & Bergeron, P. (2007). Problem situations encountered by middle managers working
in a municipality in transition. Information Research, 12(4).
Mayring, P. (2000). Qualitative content analysis. Forum Qualitative Sozialforschung/ Forum:
Qualitative Social Research, 1(2).

192
McLennan, J., & Omodei, M. M. (1996). The role of preprimming in recognition-primed
decision making. Perceptual and Motor Skills, 82(3c), 1059–1069.
McNeese, M., Cooke, N. J., D’Amico, A., Endsley, M. R., Gonzalez, C., Roth, E., & Salas, E.
(2012). Perspectives on the role of cognition in cyber security. In Proceedings of the
Human Factors and Ergonomics Society Annual Meeting (Vol. 56, pp. 268–271).
Mishra, J. L., Allene, D. K., & Pearman, A. D. (2011). Information sharing during multi-agency
major incidents. In American Society for Information Science and Technology (ASIST).
New Orleans, LA,.
Nemeth, C., & Klein, G. (2011). The naturalistic decision making perspective. Wiley
Encyclopedia of Operations Research and Management Science.
Neuendorf, K. A. (2002). The content analysis guidebook. Thousand Oaks, CA: Sage
Publications, Incorporated.
Noble, D. (1985). A theory to guide the design of situation assessment aids for decision making.
In 8TH MIT/ONR Workshop on C3 Systems.
Noble, D. (1993). A model to support development of situation assessment aids. In G. Klein, J.
Orasanu, R. Calderwood, & C. E. Zsambok (Eds.), Decision making in action: Models
and methods (pp. 287–305). Norwood, N.J: Ablex.
Noble, D. F. (1989). Schema-based knowledge elicitation for planning and situation assessment
aids. Systems, Man and Cybernetics, IEEE Transactions on, 19(3), 473–482.
Noble, D. F., Boehm-Davis, D., & Grosz, C. (1986). Schema-based model of information
processing for situation assessment (No. AD A175156). Vienna, VA: NTIS Engineering
Research Associates.
Offredy, M., Kendall, S., & Goodman, C. (2008). The use of Cognitive Continuum Theory and
patient scenarios to explore nurse prescribers’ pharmacological knowledge and decisionmaking. International Journal of Nursing Studies, 45(6), 855–868.
Olatokun, W. M., & Ajagbe, E. (2010). Analyzing traditional medical practitioners’ informationseeking behaviour using Taylor’s information-use environment model. Journal of
Librarianship and Information Science, 42(2), 122–135.
Oser, R. L., Gualtieri, J. W., Cannon-Bowers, J. A., & Salas, E. (1999). Training team problem
solving skills: an event-based approach. Computers in Human Behavior, 15(3), 441–462.
Paisley, W. J. (1980). Information and work. In Progress in Communication Sciences (Vol. 2,
pp. 113–165). Norwood, N.J: Ablex Publishing Corporation.

193
Pascual, R., & Henderson, S. (1997). Evidence of naturalistic decision making in military
command and control. In Naturalistic decision making (pp. 217–226). Mahwah, NJ:
Lawrence Erlbaum Associates, Inc., Publishers.
Patel, V. L., Kaufman, D. R., & Arocha, J. F. (2002). Emerging paradigms of cognition in
medical decision-making. Journal of Biomedical Informatics, 35(1), 52–75.
Paul, C. L., & Whitley, K. (2013). A taxonomy of cyber awareness questions for the usercentered design of cyber situation awareness. In Human Aspects of Information Security,
Privacy, and Trust (pp. 145–154). Springer Berlin Heidelberg.
Pinelli, T. E., Glassman, N. A., Affelder, L. O., Hecht, L. M., & Kennedy, J. M. (1993).
Technical uncertainty and project complexity as correlates of information use by US
industry-affiliated aerospace engineers and scientists: results of an exploratory
investigation (No. NASA TM-107693). Washington, D.C.: National Aeronautics and
Space Administration.
Pliske, R., Crandall, B., & Klein, G. (2004). Competence in weather forecasting. Psychological
Investigations of Competent Decision Making. J. Schanteau, P. Johnson, and K. Smith,
Eds. Cambridge University Press.
Potter, W. J., & Levine-Donnerstein, D. (1999). Rethinking validity and reliability in content
analysis. Journal of Applied Communication Research, 27(3), 258.
Randel, J. M., Pugh, H. L., & Reed, S. K. (1996). Differences in expert and novice situation
awareness in naturalistic decision making. International Journal of Human-Computer
Studies, 45(5), 579–597.
Rappoport, L., & Summers, D. A. (1973). Human judgment and social interaction. New York,
NY: Holt McDougal.
Rieh, S. Y. (2004). On the Web at home: Information seeking and Web searching in the home
environment. Journal of the American Society for Information Science and Technology,
55(8), 743–753.
Roberts, N. (1982). A search for information man. Social Science Information Studies, 2, 93–
104.
Rosenbaum, H. (1996). Structure and action: Towards a new concept of the information use
environment. In Proceedings of the 59th ASIS&T Annual Meeting Conference
Proceedings.
Ross, K. G., Shafer, J. L., & Klein, G. (2009). Professional judgments and “naturalistic decision
making.” In Cambridge Handbook of Expertise and Expert Performance. Cambridge,
UK: Cambridge University Press.

194
Runeson, P., & Höst, M. (2009). Guidelines for conducting and reporting case study research in
software engineering. Empirical Software Engineering, 14(2), 131–164.
Ruxton, G. D., & Neuhäuser, M. (2010). Good practice in testing for an association in
contingency tables. Behavioral Ecology and Sociobiology, 64(9), 1505–1513.
Sabata, B., & Ornes, C. (2006). Multisource evidence fusion for cyber-situation assessment. In
Defense and Security Symposium (pp. 624201–624201–9). International Society for
Optics and Photonics.
Salas, E., Prince, C., Baker, D. P., & Shrestha, L. (1995). Situation awareness in team
performance: Implications for measurement and training. Human Factors: The Journal of
the Human Factors and Ergonomics Society, 37(1), 123–136.
Salas, E., Rosen, M. A., & DiazGranados, D. (2010). Expertise-based intuition and decision
making in organizations. Journal of Management, 36(4), 941 –973.
Schraagen, J. M., Browne, G. J., & Hoffman, R. R. (2008). The macrocognition framework of
naturalistic decision making. Naturalistic Decision Making and Macrocognition, 3–25.
Schwandt, T. A., Lincoln, Y. S., & Guba, E. G. (2007). Judging interpretations: But is it
rigorous? trustworthiness and authenticity in naturalistic evaluation. New Directions for
Evaluation, 2007(114), 11–25.
Serfaty, D., MacMillan, J., Entin, E. E., & Entin, E. B. (1997). The decision-making expertise of
battle commanders. Naturalistic Decision Making, 233–246.
Simpson, P. A. (2001). Naturalistic decision making in aviation environments (No. DSTO-GD0279). Melbourne, Australia: Defence Science & Technology Organization.
Standing, M. (2008). Clinical judgement and decision-making in nursing – nine modes of
practice in a revised cognitive continuum. Journal of Advanced Nursing, 62(1), 124–134.
Strauss, A., & Corbin, J. (1998). Basics of qualitative research: Techniques and procedures for
developing grounded theory. Thousand Oaks, CA: Sage Publications, Inc.
Stroeh, K., Mauro Madeira, E. R., & Goldenstein, S. K. (2013). An approach to the correlation of
security events based on machine learning techniques. Journal of Internet Services and
Applications, 4(1), 7.
Symantec Corporation. (2013). Internet Security Threat Report (No. Volume 18).
Taylor, R. S. (1986). Value-added processes in information systems. Norwood, N.J: Ablex Pub.
Corp.

195
Taylor, R. S. (1991). Information use environments. In B. Dervin & M. J. Voigt (Eds.), Progress
in Communication Sciences (Vol. 10, pp. 217–255). Norwood, NJ: Ablex Publishing
Corporation.
Thomas, J., & Biros, D. (2011). A conceptual model of real world, high stakes deception
detection. In 44th Hawaii International Conference on System Sciences (HICSS) (pp. 1–
10). IEEE.
Tiamiyu, M. A. (1992). The relationships between source use and work complexity, decisionmaker discretion and activity duration in Nigerian government ministries. International
Journal of Information Management, 12(2), 130–141.
Tyworth, M., Giacobe, N. A., Mancuso, V., & Dancy, C. (2012). The distributed nature of cyber
situation awareness. In IEEE International Multi-Disciplinary Conference on Cognitive
Methods in Situation Awareness and Decision Support (CogSIMA) (pp. 174–178).
U.S. Computer Emergency Readiness Team. (2012). National strategy to secure cyberspace.
U.S. Government Accountability Office. (2013). Cybersecurity - National strategy, roles, and
responsibilities need to be better defined and more effectively implemented (No. GAO13-187). Retrieved from http://www.gao.gov/assets/660/652170.pdf
Vakkari, P. (1998). Growth of theories on information seeking: An analysis of growth of a
theoretical research program on the relation between task complexity and information
seeking. Information Processing & Management, 34(2–3), 361–382.
Vakkari, P. (1999). Task complexity, problem structure and information actions: Integrating
studies on information seeking and retrieval. Information Processing and Management,
35(1999), 819–837.
Vakkari, P. (2003). Task‐based information searching. Annual Review of Information Science
and Technology, 37(1), 413–464.
Waag, W. L., & Bell, H. H. (1997). In C. Zsambok & G. Klein (Eds.), Naturalistic decision
making (pp. 247–254). Mahwah, N.J: Lawrence Erlbaum Associates, Inc., Publishers.
Walsham, G. (1995). Interpretive case studies in IS research: Nature and method. European
Journal of Information Systems, 4(2), 74–81.
Wersig, G., & Windel, G. (1985). Information science needs a theory of “information actions.”
Social Science Information Studies, 5(1), 11–23.
Wilson, T. D. (1981). On user studies and information needs. Journal of Documentation, 37, 3–
15.
Wood, R. E. (1986). Task complexity: Definition of the construct. Organizational Behavior and
Human Decision Processes, 37(1), 60–82.

196

Yen, J., McNeese, M., Mullen, T., Hall, D., Fan, X., & Liu, P. (2010). RPD-based hypothesis
reasoning for cyber situation awareness. In S. Jajodia (Ed.), Cyber situational awareness
(pp. 39–49). Springer.
Yin, R. K. (2009). Case study research: Design and methods. Beverly Hills, California: Sage
Publications, Inc.
Yin, R. K. (2011). Applications of case study research. Thousand Oaks, CA: Sage.
Zach, L. (2006). Using a multiple-case studies design to investigate the information-seeking
behavior of arts administrators. Library Trends, 55, 4–21.
Zaremba, T., Ketzer, P., Cole, M., Coulthard, S., Plummer, E. R., & Curtin, N. J. (2009). Poly
(ADP-ribose) polymerase-1 polymorphisms, expression and activity in selected human
tumour cell lines. British Journal of Cancer, 101(2), 256–262.
Zeffane, R. M., & Gul, F. A. (1993). The effects of task characteristics and sub-unit structure on
dimensions of information processing. Information Processing & Management, 29(6),
703–719.
Zhang, L., & Hammond, D. L. (2010). Cellular basis for opioid potentiation in the rostral
ventromedial medulla of rats with persistent inflammatory nociception. Pain, 149(1),
107–116.
Zsambok, C. E., Beach, L. R., & Klein, G. (1992). A literature review of analytical and
naturalistic decision making. San Diego, CA: Naval Command, Control and Ocean
Surveillance Center.
Zuccala, A. (2006). Modeling the invisible college. Journal of the American Society for
Information Science and Technology, 57(2), 152–168.

197
Appendix A. Institutional Review Board Approval

198
Appendix B. Interview Protocol

Introductions—provide a brief description of the project and its goals—describe how the
information we are collecting will be used to develop an understanding of how expert cyber
defenders conduct research in response to cyber incidents.
.
Before the interview starts, complete the following tasks: confirm that the interview is being
recorded and tell participant that he/she can stop the interview and/or recording at anytime as
well has have an opportunity to review the transcript of the interview.
The following questions are to be used as guidance—the interviewee should be allowed to share
his/her ideas with minimal interruptions.
General Questions
How long have you worked in cyber security?
What is your educational background?
What is job title?
Critical Decision Questions:
1. Can you think of recent time in which you had to a cyber attack that required your expertise
to conduct research about it?
(If the interviewee cites more than one, try to pick the one that the interviewee felt was the most
challenging to review.)
2. Please describe this specific time in detail, from moment the incident was brought to your
attention until situation was resolved (As the interviewee is telling his or her story, create a
sequence of steps that were taken.)
3. Based on the account that you just told me, I created a sequence of steps that were taken. Here
is how I understand the sequence: (describe the sequence that was created based on the response
given in the previous question.) Are there any changes that I should make on this sequence?
4. For each step, I am going to ask you some questions to learn more about what you were
looking for, why you took this step, and what you found in each step. For each step ask all or
some of the following:

199

2) What were you seeing at this time?
3) What information did you use in making this decision, and how was it obtained?
4) Were you reminded of any previous experience?
5) What were you specific goals at this time or what were you looking for at this time?
6) What other courses of action were considered by or available to you?
7) How was this step elected/other steps not taken? What rule was being followed?
8) What specific training or experience was necessary or helpful in making this decision?
9) If this step was challenging, what training, knowledge, or information could have helped?
10) How much time pressure was involved in making this decision?
11) How would a novice make a mistake in this step?
Now, move onto the subsequent steps and ask these same questions.
After discussing the final step, ask the participant if he or she would mind discussing another
type of cyber attacksuch as a malware attack, a zero-day exploit or a phishing attempt. If so,
follow the above steps again.
Thank the interviewee for his or her time. Encourage follow-up emails if the interviewee
remembers something else that he/she wants to tell or has additional questions about the study.

200

Appendix C. Recruitment Email

Dear ____________,
My name is Thomas Heverin and I am PhD student at the College of Information Science
and Technology at Drexel University based in Philadelphia. I am conducting a research
study* on how cyber security professionals research new cyber attacks. The purpose of
this study is to understand how cyber security professionals going about researching new
attacks.
I would like to request your assistance with the research by participating in a telephone
interview. The interview will take approximately 30 minutes. I will ask some questions
about the research processes you use. Any information you share will be useful for the
research study. Note that your information and company information will not be shared in
any report written about this study.
If you are interested in participating in this study, learning more about this study or if you
have any questions please respond to me at this email address th424@drexel.edu. Thank
you for your time.
Yours sincerely,
Thomas Heverin
College of Information Science & Technology
3141 Chestnut Street
Philadelphia, PA 19104
Th424@drexel.edu
*This research is conducted under the supervision of Dr. Lisl Zach of Drexel University,
lisl@drexel.edu, 215-895-2476

201

Appendix D. Task Complexity Coding

This appendix provides a description of how the coding for task complexity was derived
from previous studies.
The category of “a priori determinability of inputs”
MacMullin and Taylor (1984) stated that that simple tasks consist of the “Initial State
Understood” characteristic in which the interrelationships among contributing factors are
understood to some degree or completely while complex tasks consist of the “Initial State Not
Understood” characteristic in which the interrelationships among contributing factors are not
understood. Byström and Järvelin (1995) consider simple tasks to hold a high degree of a priori
determinability of inputs (the inputs can be a priori determined) while complex tasks do not (the
inputs cannot be a priori determined). Leckie et al. (1996) stated that for simple tasks,
information needs are anticipated while for complex tasks, the information needs are unexpected.
From the Task Continuum Index – Task Decomposition - Hammond et al. (1997) stated
that asimple task holds a priori task decomposition while a complex task consists of a posteriori
task decomposition.
Coding of tasks with low complexity
The expert cyber defender states he or she knows the types of initial inputs that he or she
will see for the cyber attack.
The inputs have a clear value.
The expert cyber defender can immediately make a determination that a cyber attack is
taking place based on the initial inputs.

202

Coding of tasks with high complexity
The expert cyber defender states he or she does not know the exact types of initial inputs
that he or she will see for the cyber attack.
The inputs do not have a clear value and require additional work to decipher the value.
The expert cyber defender cannot immediately make a determination that a cyber attack
is taking place.
The category of “a priori determinability of outcomes”
MacMullin and Taylor (1984) stated that from their list of problem dimensions simple
tasks consist of the “Simple” characteristic, in which the path from initial statement to solution is
easily defined. Complex task consists of the “Complex” characteristic, in which the path from
initial statement to solution is not easily defined. Byström and Järvelin (1995) consider simple
tasks to hold a high degree of a priori determinability of outcomes (the outcomes can be a priori
determined) while complex tasks do not (the outcomes cannot be a priori determined).
From the Task Continuum Index – Outcome Accuracy- Hammond et al. (1997) stated
that for a simple task, the outcomes are known and high accuracy is likely. For a complex task,
the outcomes are unknown and high accuracy is unlikely.
Coding of tasks with low complexity
The expert cyber defender states that specific outcomes are known or that the
possible outcomes are known.
Coding of tasks with high complexity

203
The expert cyber defender states that specific outcomes are unknown or that he or
she does not know the possible outcomes.
The category of “level of task variety”
MacMullin and Taylor (1984) stated that from their list of problem dimensions simple
tasks consist of the “Familiar Pattern” characteristics in which problems are procedural.
Complex task consists of the “New Pattern” characteristic, in which problems are nonprocedural. Leckie et al. (1996) stated that for simple tasks information needs are known and
recurring while for complex tasks, the information needs are new and unpredictable. From the
Task Continuum Index – Task Content - Hammond et al. (1997) stated that for a simple task, the
content consists of familiar task content. For a complex task, the content consists of unfamiliar
content.
Coding of tasks with low complexity
The expert cyber defender states that the pattern of the cyber attack or the pattern
of response is predictable.
The cyber attack does not cause any surprises nor does it offer unpredictable
events.
Coding of tasks with high complexity
The expert cyber defender states that there is no predictable pattern to follow.
The cyber attack offers surprises or unpredictable events.
The expert cyber defender states that actions need to change based on unforeseen
changes in the cyber attack.
The category of “level of risk” was derived from the following:

204
MacMullin and Taylor (1984) stated that from their list of problem dimensions simple
tasks simple tasks consist of the “Risk Not Great” characteristic which means that the
consequences of failure are low. Complex tasks consist of the “Risk Great” characteristic which
means that the consequences of failure are high. Klein (2008) stated that simple tasks consists of
low stakes while complex tasks consist of high stakes.
Coding of tasks with low complexity
The expert cyber defender states that the cyber attack has low consequences due
to the nature of the cyber attack or due to the actions taken by the expert.
Coding of tasks with high complexity
The expert cyber defender states that the cyber attack has high consequences.
The expert cyber defender expresses concern over consequences because of
inability to resolve attack.
The category of “level of time pressure” was derived from the following:
Hammond et al. (1997) and Klein (2008) stated that simple tasks consist of low time
pressure while complex tasks consist of high time pressure.
Coding of tasks with low complexity
The expert cyber defender states that he or she does not face time pressure or that
the time pressure is low.
The expert cyber defender can delay response for over a day.
Coding of tasks with high complexity
The expert cyber defender states that he or she faces high time pressure.
The expert cyber defender feels compelled to respond immediately.

205
Appendix E. Cognitive Modes Coding

This appendix provides details of the coding for each category of analytical and intuitive
cognition.
The category of “insight into the judgment process” was derived from the following:
The use of analytical cognition is evidenced by a “…step by step, logically defensible
process of problem solving” (Hammond, 1980, p. 8). The use of intuitive cognition is evidenced
by a process that is completed “…without the use of a conscious, logically defensible, step by
step process.” (Hammond, 1980, p. 8).
Coding for analytical cognition in use
The expert cyber defender states that he or she follows specific steps in sequential
order.
The expert cyber defender is able to easily recollect the steps that he or she took
to research a cyber attack.
Coding for intuitive cognition in use
The expert cyber defender uses phrases such as “I use my judgment” or “You
develop a sense about how to” or “I just know” or “It is intuitive.”
The expert cyber defender has a difficult time in describing steps taken or bases of
steps.
The category of “level of methods or rules used” was derived from the following:

206
If an individual states that he or she used prescribed methods or rules, this represents the
use of analytical cognition (Hamm, 1988a; Hammond, 1980). When an individual states her or
she did not use any defined methods or rules, this represents the use of intuitive cognition.
Coding for analytical cognition in use
The expert cyber defender mentions a specific checklist he or she uses or
procedures that he or she follows.
Coding for intuitive cognition in use
The expert cyber defender states that he or she does not use a checklist or follows
any named procedures.
The category of “basis of decision” was derived from the following:
For the basis of decision, if the individual stated he or she made decision on his or her
experience, then this represents the use of intuitive cognition; if a user stated he or she used
specific training or education, then this represents the use of analytical cognition (Hamm,
1988a).
Coding for analytical cognition in use
The expert cyber defender mentions specific training or education he or she uses
or principles that he or she uses.
Coding for intuitive cognition in use
The expert cyber defender does not cite specific training or education used.
The expert cyber defender states process was learned over time or just on the job.
The category of “confidence in method” was derived from the following:

207
Confidence in method refers to the individual’s level of confidence in how he or she
completed the task. The use of analytical cognition is associated with high confidence in method
and intuitive cognition is associated with low confidence in method (Hammond, 1980).
Coding for analytical cognition in use
The expert cyber defender states that he or she is confident in methods used to
research the cyber attack.
The expert cyber defender uses phrases such as “I am sure” or “I know how to” or
uses a quantitative measure to express confidence in methods.
Coding for intuitive cognition in use
The expert cyber defender does not express confidence in the methods he or she
used to resolve the cyber attack.
He or she explicitly states that he or she lacks the expertise, tools or knowledge to
resolve the cyber attack.

208

Appendix F. Freeman-Halton Extension Calculation Procedure

From - http://www.danielsoper.com/statcalc3/calc.aspx?id=59

209
Appendix G. Frequencies of Information Sources and Types Used for the
Phishing Attempt SA-Task

Phishing –
Information
Sources/Types
Used
Number of
Sources
Number of
External
Sources
Number of
people used as
sources
Number of
experts used as
sources
Number of
Technical
Pieces of
Information

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Total

Avg.

1

2

2

1

2

1

1

1

1

11

1.2

0

0

1

0

0

0

0

0

0

1

0.1

0

1

1

0

0

0

0

0

0

2

0.2

0

0

0

0

0

0

0

0

0

0

0.0

3

4

2

3

3

2

3

3

3

26

2.9

210
Appendix H. Frequencies of Information Sources and Types Used for the
Zero-Day Exploit SA-Task

Zero-Day
Information
Sources/Types
Used
Number of
Sources
Number of
External
Sources
Number of
people used as
sources
Number of
Expert as
Sources
Number of
Technical
Pieces of
Information

Average
Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Case
10

Case
11

Case
12

Total

3

4

5

3

4

3

3

2

5

4

3

3

42

3.5
3.5
3

4

5

3

4

3

3

2

5

4

3

3

42
0.7

0

1

1

1

0

1

1

1

0

1

0

1

8
0.7

0

1

1

1

0

1

1

1

0

1

0

1

8
6.3

7

6

5

6

8

9

7

7

6

6

5

4

76

211

Appendix I. Frequencies of Information Sources and Types Used for the Malware Attack SA-Task

Malware

Info
Sources/
Types
Used
Number
of
Sources
Number
of
External
Sources
Number
of people
used as
sources
Number
of Expert
as
Sources
Number
of
Technical
Pieces of
Informati
on

Case
1

Case
2

Case
3

Case
4

Case
5

Case
6

Case
7

Case
8

Case
9

Case
10

Case
11

Case
12

Case
13

Case
14

Case
15

Case
16

Case
17

Total

10

7

7

8

8

12

13

9

10

9

7

7

12

9

8

8

9

153

Avg
9.0
5.9

8

4

5

5

6

9

5

6

7

5

6

5

8

6

6

5

4

103
3.5

4

3

4

4

4

4

2

3

4

3

4

3

3

4

3

3

4

59
3.5

4

3

4

4

4

4

2

3

4

3

4

3

3

4

3

3

4

59
12.6

14

12

11

12

13

15

16

14

14

19

8

12

12

11

14

9

9

215

212

Vita
Thomas J. Heverin
thomas.heverin@gmail.com
EDUCATION
2009-2014

2007-2008
1994-1998

COLLEGE OF COMPUTING AND INFORMATICS, DREXEL UNIVERSITY
Philadelphia, PA
Ph.D. in Information Studies
Dissertation: “Information Behaviors and Cognitive Modes Used for Cyber
Situation Assessment”
SYRACUSE UNIVERSITY , M.S. in Library and Information Science
Syracuse, NY
PENNSYLVANIA STATE UNIVERSITY, B.S. in Meteorology
University Park, PA

EXPERIENCE
2009-Present DREXEL UNIVERSITY – APPLIED INFORMATICS GROUP
Philadelphia, PA
Cyber Security Researcher
Contribute to ontology modeling in cyber physical systems domain in support
of a Cyber Security Research Alliance R&D project and the cyber forensics
domain in support of a DARPA Integrated Cyber Analysis System.
2011-Present PROGENY SYSTEMS
Philadelphia, PA
Senior Systems Engineer
Led the research and development of upper and lower ontologies for the Navy
surface and submarine maintenance domains using Protégé Ontology Editor
2008-2012
TEMPLE UNIVERSITY
Philadelphia, PA
Science Librarian and Instruction Coordinator, Science and Engineering
Library
Led 152 research skills training sessions for over 3,800 undergraduate and
graduate students.
1998-2004

U.S. N AVY
U.S. and Japan
Business Management Officer, Training Support Center Great Lakes (20032004)
Supervised two departments of 35 military members and civilian contractors
that provided IT, administrative, business, and maintenance services to 800
instructors and 30,000 students.
Operations Officer, USS Kingfisher (MHC 56) (2001-2003)
Planned and executed ship’s operational, maintenance, and training schedules
resulting in the successful completion of all training exercises, major
maintenance repairs, and mine-hunting missions.
Electrical Engineering Officer, USS Chancellorsville (CG 62) (1999-2001)
Led eight electricians in the maintenance, operation and testing of all
shipboard electrical systems.

